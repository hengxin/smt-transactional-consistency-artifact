2020-05-08 12:15:41 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T12:15:41.261-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T12:15:41.266-0700 I  CONTROL  [main] 
2020-05-08T12:15:41.266-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T12:15:41.266-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T12:15:41.266-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T12:15:41.266-0700 I  CONTROL  [main] 
2020-05-08T12:15:41.266-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] modules: none
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] build environment:
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T12:15:41.266-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-08T12:15:41.267-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.267-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T12:15:41.268-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-08T12:15:41.268-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-08T12:15:41.268-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n3:27017:1588965341:-8033712167525645570 (sleeping for 30000ms)
2020-05-08T12:15:41.269-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:41.465-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588965339, 3), t: 1 }
2020-05-08T12:15:41.768-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.769-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.838-0700 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T12:15:42.272-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T12:15:42.609-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T12:15:42.838-0700 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T12:15:43.842-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T12:15:43.843-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T12:15:43.846-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("177260dc-0c14-4efa-98bc-c9820bcc7841"), lastMod: 0 } took 0 ms
2020-05-08T12:15:43.847-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T12:15:43.847-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T12:15:43.847-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T12:15:43.848-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T12:15:43.848-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T12:15:44.352-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53262 #9 (1 connection now open)
2020-05-08T12:15:44.353-0700 I  NETWORK  [conn9] end connection 192.168.122.1:53262 (0 connections now open)
2020-05-08T12:15:45.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53278 #10 (1 connection now open)
2020-05-08T12:15:45.269-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:53278 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.353-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53286 #11 (2 connections now open)
2020-05-08T12:15:45.353-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53288 #12 (3 connections now open)
2020-05-08T12:15:45.353-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:53286 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.353-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:53288 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.378-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53320 #13 (4 connections now open)
2020-05-08T12:15:45.378-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:53320 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.662-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53454 #14 (5 connections now open)
2020-05-08T12:15:45.662-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:53454 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.663-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53460 #15 (6 connections now open)
2020-05-08T12:15:45.663-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.1:53460 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53496 #16 (7 connections now open)
2020-05-08T12:15:45.745-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.1:53496 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:46.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53544 #17 (8 connections now open)
2020-05-08T12:15:46.900-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.1:53544 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.024-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53596 #18 (9 connections now open)
2020-05-08T12:15:48.025-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.1:53596 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.170-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53614 #19 (10 connections now open)
2020-05-08T12:15:48.171-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:53614 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.872-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53674 #20 (11 connections now open)
2020-05-08T12:15:48.873-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:53674 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:49.837-0700 I  COMMAND  [conn14] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ab9c542-a376-4786-8bbd-c8e0d5a6640f") } } numYields:0 reslen:163 protocol:op_msg 4165ms
2020-05-08T12:15:49.840-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 1 ms
2020-05-08T12:15:49.842-0700 I  NETWORK  [conn14] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:49.843-0700 I  NETWORK  [conn14] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:49.843-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T12:15:49.843-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:15:49.843-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:15:49.843-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-08T12:15:49.843-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-08T12:15:49.843-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-08T12:15:49.871-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:49.872-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:49.872-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:49.873-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:49.873-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T12:15:49.925-0700 I  NETWORK  [conn14] end connection 192.168.122.1:53454 (10 connections now open)
2020-05-08T12:15:49.925-0700 I  NETWORK  [conn15] end connection 192.168.122.1:53460 (9 connections now open)
2020-05-08T12:15:50.448-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53724 #28 (10 connections now open)
2020-05-08T12:15:50.448-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53726 #29 (11 connections now open)
2020-05-08T12:15:50.449-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.1:53724 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.449-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.1:53726 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.462-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53792 #30 (12 connections now open)
2020-05-08T12:15:50.462-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53794 #31 (13 connections now open)
2020-05-08T12:15:50.463-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.1:53792 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.463-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 2 ms
2020-05-08T12:15:50.463-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.1:53794 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.466-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53808 #33 (14 connections now open)
2020-05-08T12:15:50.466-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.1:53808 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.468-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53828 #34 (15 connections now open)
2020-05-08T12:15:50.469-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.1:53828 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.710-0700 I  COMMAND  [conn28] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 232ms
2020-05-08T12:15:50.710-0700 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:351 protocol:op_msg 215ms
2020-05-08T12:15:50.825-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:53980 #39 (16 connections now open)
2020-05-08T12:15:50.826-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.1:53980 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.884-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-08T12:15:50.885-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-08T12:15:50.922-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54030 #43 (17 connections now open)
2020-05-08T12:15:50.922-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.1:54030 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.116-0700 I  TXN      [conn28] transaction parameters:{ lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965350, 222) } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 222) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:230884, timeActiveMicros:241319, timeInactiveMicros:1125, 242ms
2020-05-08T12:15:51.116-0700 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965350, 222) } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 222) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:232030, timeActiveMicros:243225, timeInactiveMicros:754, 243ms
2020-05-08T12:15:51.116-0700 I  COMMAND  [conn28] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 228), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc") }, txnNumber: 5, autocommit: false } numYields:0 reslen:214 protocol:op_msg 231ms
2020-05-08T12:15:51.116-0700 I  COMMAND  [conn30] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 227), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 232ms
2020-05-08T12:15:51.117-0700 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 233), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3") }, txnNumber: 4, autocommit: false } numYields:0 reslen:351 protocol:op_msg 229ms
2020-05-08T12:15:51.373-0700 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 81) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 81) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:103912, timeActiveMicros:166200, timeInactiveMicros:1996, 168ms
2020-05-08T12:15:51.373-0700 I  COMMAND  [conn30] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 109), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661") }, txnNumber: 13, autocommit: false } numYields:0 reslen:214 protocol:op_msg 104ms
2020-05-08T12:15:51.424-0700 I  TXN      [conn33] transaction parameters:{ lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 56) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 56) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:192137, timeActiveMicros:251244, timeInactiveMicros:1874, 253ms
2020-05-08T12:15:51.424-0700 I  COMMAND  [conn33] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3") }, txnNumber: 6, autocommit: false } numYields:0 reslen:214 protocol:op_msg 192ms
2020-05-08T12:15:51.463-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:15:51.463-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:15:51.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:15:51.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:15:52.072-0700 I  COMMAND  [conn30] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 226), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661") }, txnNumber: 16, autocommit: false } numYields:0 reslen:321 protocol:op_msg 563ms
2020-05-08T12:15:52.401-0700 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 264), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3") }, txnNumber: 10, autocommit: false } numYields:0 reslen:352 protocol:op_msg 819ms
2020-05-08T12:15:52.419-0700 I  COMMAND  [conn30] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661") }, txnNumber: 17, autocommit: false } numYields:0 reslen:321 protocol:op_msg 287ms
2020-05-08T12:15:52.490-0700 I  TXN      [conn28] transaction parameters:{ lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 191) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 191) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1005737, timeActiveMicros:1025377, timeInactiveMicros:1534, 1026ms
2020-05-08T12:15:52.490-0700 I  COMMAND  [conn28] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 206), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc") }, txnNumber: 13, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1005ms
2020-05-08T12:15:53.472-0700 I  NETWORK  [conn33] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:53.473-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:53.972-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.973-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.974-0700 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3") }, txnNumber: 12, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1498ms
2020-05-08T12:15:54.585-0700 I  NETWORK  [conn33] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:54.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.174-0700 I  NETWORK  [conn30] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:55.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:55.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:56.087-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.175-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:56.176-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:56.177-0700 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 62) } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 62) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3654912, timeInactiveMicros:780, 3655ms
2020-05-08T12:15:56.178-0700 I  COMMAND  [conn30] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 66), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661") }, txnNumber: 19, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3620ms
2020-05-08T12:15:56.311-0700 I  NETWORK  [conn28] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:56.313-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:56.376-0700 I  NETWORK  [conn31] end connection 192.168.122.1:53794 (16 connections now open)
2020-05-08T12:15:56.377-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54408 #54 (17 connections now open)
2020-05-08T12:15:56.377-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54410 #55 (18 connections now open)
2020-05-08T12:15:56.378-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:54408 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.378-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:54410 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.381-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:56.544-0700 I  NETWORK  [conn34] end connection 192.168.122.1:53828 (17 connections now open)
2020-05-08T12:15:56.544-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54446 #56 (18 connections now open)
2020-05-08T12:15:56.545-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54448 #57 (19 connections now open)
2020-05-08T12:15:56.545-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.1:54446 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.545-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.1:54448 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.546-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:56.828-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54480 #58 (20 connections now open)
2020-05-08T12:15:56.828-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.1:54480 conn58: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.025-0700 I  NETWORK  [Sharding-Fixed-2] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:57.026-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:57.026-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:57.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:57.175-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:57.185-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:57.314-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:15:57.492-0700 I  NETWORK  [conn29] end connection 192.168.122.1:53726 (19 connections now open)
2020-05-08T12:15:57.493-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54576 #60 (20 connections now open)
2020-05-08T12:15:57.493-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54580 #61 (21 connections now open)
2020-05-08T12:15:57.493-0700 I  NETWORK  [conn60] received client metadata from 192.168.122.1:54576 conn60: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.494-0700 I  NETWORK  [conn61] received client metadata from 192.168.122.1:54580 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.496-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:57.497-0700 I  -        [conn28] operation was interrupted because a client disconnected
2020-05-08T12:15:57.498-0700 I  TXN      [conn28] transaction parameters:{ lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 52) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006089, timeInactiveMicros:0, 5006ms
2020-05-08T12:15:57.498-0700 I  COMMAND  [conn28] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 32 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 52), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3b1547c4-3af1-488f-87c4-bc3ed16f24dc") }, txnNumber: 14, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:15:57.498-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:57.498-0700 I  NETWORK  [conn28] end connection 192.168.122.1:53724 (20 connections now open)
2020-05-08T12:15:57.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:57.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:58.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.175-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:58.566-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965350, 10), t: 1 }, now { ts: Timestamp(1588965357, 6), t: 4 }
2020-05-08T12:15:58.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:59.086-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:59.086-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:59.087-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:15:59.095-0700 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965353, 65), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b475af6-d797-4340-872e-f0eaf586e8d3") }, txnNumber: 12, autocommit: false } numYields:0 reslen:514 protocol:op_msg 5119ms
2020-05-08T12:15:59.096-0700 I  NETWORK  [conn33] end connection 192.168.122.1:53808 (19 connections now open)
2020-05-08T12:15:59.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:59.463-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:15:59.498-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965356, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2952571, timeInactiveMicros:0, 2952ms
2020-05-08T12:15:59.498-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965356, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2952ms
2020-05-08T12:15:59.498-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965356, 3) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2003198, timeInactiveMicros:0, 2003ms
2020-05-08T12:15:59.499-0700 I  COMMAND  [conn60] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965356, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2003ms
2020-05-08T12:15:59.675-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:59.675-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:59.677-0700 I  COMMAND  [conn30] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965355, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4db21cd6-39df-4022-be5f-4279d4458661") }, txnNumber: 19, autocommit: false } numYields:0 reslen:515 protocol:op_msg 3497ms
2020-05-08T12:15:59.678-0700 I  NETWORK  [conn30] end connection 192.168.122.1:53792 (18 connections now open)
2020-05-08T12:16:00.180-0700 I  COMMAND  [conn56] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965359, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 680ms
2020-05-08T12:16:00.180-0700 I  COMMAND  [conn60] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965359, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 680ms
2020-05-08T12:16:00.193-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T12:16:00.382-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965356, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 4002ms
2020-05-08T12:16:00.383-0700 I  COMMAND  [conn60] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 41 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965360, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 143ms
2020-05-08T12:16:00.424-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 12) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:207776, timeActiveMicros:213837, timeInactiveMicros:2381, 216ms
2020-05-08T12:16:00.424-0700 I  COMMAND  [conn56] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 3, autocommit: false } numYields:0 reslen:214 protocol:op_msg 208ms
2020-05-08T12:16:00.430-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 22) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:34372, timeActiveMicros:188458, timeInactiveMicros:1308, 189ms
2020-05-08T12:16:00.701-0700 I  COMMAND  [conn60] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 7, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965360, 180), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 130ms
2020-05-08T12:16:00.880-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54846 #67 (19 connections now open)
2020-05-08T12:16:00.880-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.1:54846 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:01.463-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:16:01.879-0700 I  NETWORK  [conn56] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:01.880-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:02.381-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:02.881-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:02.881-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:02.882-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965357, 6), t: 4 }, now { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T12:16:02.882-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:02.882-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 301), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa") }, txnNumber: 10, autocommit: false } numYields:0 reslen:352 protocol:op_msg 2084ms
2020-05-08T12:16:02.883-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:02.883-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:02.885-0700 I  COMMAND  [conn56] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 289), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 12, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2108ms
2020-05-08T12:16:02.902-0700 I  COMMAND  [conn60] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 289), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 9, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2125ms
2020-05-08T12:16:03.046-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 11, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965362, 147) } }, globalReadTimestamp:{ ts: Timestamp(1588965362, 147) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:142487, timeActiveMicros:161504, timeInactiveMicros:1056, 162ms
2020-05-08T12:16:03.046-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965362, 166), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa") }, txnNumber: 11, autocommit: false } numYields:0 reslen:214 protocol:op_msg 142ms
2020-05-08T12:16:03.096-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T12:16:03.270-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965363, 31) } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 32) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:174652, timeActiveMicros:210819, timeInactiveMicros:1522, 212ms
2020-05-08T12:16:03.270-0700 I  COMMAND  [conn60] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 12, autocommit: false } numYields:0 reslen:214 protocol:op_msg 174ms
2020-05-08T12:16:03.981-0700 I  NETWORK  [conn56] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T12:16:03.982-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:04.274-0700 I  NETWORK  [conn60] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:04.275-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:04.481-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:04.481-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:04.494-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 21, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965363, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1202ms
2020-05-08T12:16:04.497-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:04.774-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:05.274-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:05.774-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.274-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.775-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:06.775-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:06.775-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:16:06.955-0700 I  NETWORK  [conn56] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:06.958-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.958-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965363, 111) } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 111) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3677787, timeActiveMicros:3747206, timeInactiveMicros:2027, 3749ms
2020-05-08T12:16:06.960-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 135) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3673499, timeActiveMicros:3687341, timeInactiveMicros:707, 3688ms
2020-05-08T12:16:06.960-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:07.275-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:07.774-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:07.775-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:07.776-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 140), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa") }, txnNumber: 16, autocommit: false } numYields:0 reslen:495 protocol:op_msg 4496ms
2020-05-08T12:16:07.776-0700 I  COMMAND  [conn60] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 141), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 13, autocommit: false } numYields:0 reslen:464 protocol:op_msg 4489ms
2020-05-08T12:16:07.819-0700 I  CONNPOOL [conn60] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T12:16:07.823-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965364, 14) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3326937, timeInactiveMicros:0, 3326ms
2020-05-08T12:16:07.823-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 65 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 22, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 05ff6052-de67-41ab-84cf-5d2411862870:22 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965364, 14) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 3327ms
2020-05-08T12:16:07.942-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 81) } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 81) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:98522, timeActiveMicros:120992, timeInactiveMicros:990, 121ms
2020-05-08T12:16:07.943-0700 I  COMMAND  [conn56] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 22, autocommit: false } numYields:0 reslen:321 protocol:op_msg 119ms
2020-05-08T12:16:07.943-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 84), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa") }, txnNumber: 17, autocommit: false } numYields:0 reslen:321 protocol:op_msg 109ms
2020-05-08T12:16:08.047-0700 I  NETWORK  [conn55] end connection 192.168.122.1:54410 (18 connections now open)
2020-05-08T12:16:08.048-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55158 #74 (19 connections now open)
2020-05-08T12:16:08.048-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55160 #75 (20 connections now open)
2020-05-08T12:16:08.049-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.1:55158 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:08.049-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.1:55160 conn75: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:08.136-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-08T12:16:08.388-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 98) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:438867, timeActiveMicros:442605, timeInactiveMicros:1096, 443ms
2020-05-08T12:16:08.388-0700 I  COMMAND  [conn60] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 15, autocommit: false } numYields:0 reslen:183 protocol:op_msg 439ms
2020-05-08T12:16:08.388-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965367, 98), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("300a9588-ad5b-475f-b415-a678a6896cfa") }, txnNumber: 18, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 98) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 443ms
2020-05-08T12:16:08.388-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 65 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965367, 98), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") }, txnNumber: 23, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 98) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 444ms
2020-05-08T12:16:08.389-0700 I  NETWORK  [conn54] end connection 192.168.122.1:54408 (19 connections now open)
2020-05-08T12:16:08.500-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 98) } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 98) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:86856, timeActiveMicros:553694, timeInactiveMicros:1906, 555ms
2020-05-08T12:16:08.578-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 52) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:51281, timeActiveMicros:103853, timeInactiveMicros:1165, 105ms
2020-05-08T12:16:08.631-0700 I  TXN      [conn74] transaction parameters:{ lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 4) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:495206, timeActiveMicros:518757, timeInactiveMicros:1837, 520ms
2020-05-08T12:16:08.631-0700 I  COMMAND  [conn74] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298") }, txnNumber: 4, autocommit: false } numYields:0 reslen:214 protocol:op_msg 495ms
2020-05-08T12:16:08.815-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 27, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 111) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:97580, timeActiveMicros:151383, timeInactiveMicros:1971, 153ms
2020-05-08T12:16:09.081-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 30, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 192) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:81370, timeActiveMicros:117367, timeInactiveMicros:1929, 119ms
2020-05-08T12:16:10.046-0700 I  NETWORK  [conn56] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:10.047-0700 I  SHARDING [conn74] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965361, 1), t: 5 }, now { ts: Timestamp(1588965369, 16), t: 6 }
2020-05-08T12:16:10.047-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:10.048-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:10.049-0700 I  NETWORK  [conn74] Marking host n4:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:16:10.049-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:10.547-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:11.047-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:11.047-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:11.048-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T12:16:11.051-0700 I  COMMAND  [conn74] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965369, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298") }, txnNumber: 8, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1968ms
2020-05-08T12:16:11.079-0700 I  TXN      [conn60] transaction parameters:{ lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 195) } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 195) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2115495, timeInactiveMicros:0, 2115ms
2020-05-08T12:16:11.080-0700 I  COMMAND  [conn60] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965368, 195), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 22, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 195) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2115ms
2020-05-08T12:16:11.576-0700 I  TXN      [conn74] transaction parameters:{ lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965371, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588965371, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:523877, timeInactiveMicros:0, 523ms
2020-05-08T12:16:11.576-0700 I  COMMAND  [conn74] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 84 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965371, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298") }, txnNumber: 9, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965371, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 6ecf9812-0132-49fb-90a2-3e748409a298:9 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:626 protocol:op_msg 524ms
2020-05-08T12:16:11.880-0700 I  NETWORK  [conn60] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:11.881-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:11.905-0700 I  NETWORK  [Sharding-Fixed-3] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:11.907-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:11.907-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:12.380-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:12.380-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:12.381-0700 I  COMMAND  [conn74] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965371, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298") }, txnNumber: 9, autocommit: false } numYields:0 reslen:438 protocol:op_msg 804ms
2020-05-08T12:16:12.399-0700 I  COMMAND  [conn60] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965371, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 22, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1317ms
2020-05-08T12:16:13.032-0700 I  NETWORK  [conn60] Marking host n5:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:16:13.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.414-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:13.533-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.633-0700 I  NETWORK  [conn61] end connection 192.168.122.1:54580 (18 connections now open)
2020-05-08T12:16:13.633-0700 I  NETWORK  [conn75] end connection 192.168.122.1:55160 (17 connections now open)
2020-05-08T12:16:13.634-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55426 #78 (18 connections now open)
2020-05-08T12:16:13.634-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55428 #79 (19 connections now open)
2020-05-08T12:16:13.634-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:55426 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.634-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55430 #80 (20 connections now open)
2020-05-08T12:16:13.634-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.1:55428 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.635-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55432 #81 (21 connections now open)
2020-05-08T12:16:13.635-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.1:55430 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.635-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.1:55432 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.846-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdb5861abbf7eec2119; invalidating user cache
2020-05-08T12:16:14.033-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:14.083-0700 I  NETWORK  [conn57] end connection 192.168.122.1:54448 (20 connections now open)
2020-05-08T12:16:14.083-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55536 #82 (21 connections now open)
2020-05-08T12:16:14.084-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55538 #83 (22 connections now open)
2020-05-08T12:16:14.084-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.1:55536 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.084-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.1:55538 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.534-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:14.534-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:14.535-0700 I  COMMAND  [conn74] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965372, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ecf9812-0132-49fb-90a2-3e748409a298") }, txnNumber: 9, autocommit: false } numYields:0 reslen:513 protocol:op_msg 2152ms
2020-05-08T12:16:14.535-0700 I  COMMAND  [conn60] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965372, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ee113cc-9076-426d-8d48-600c6245ca88") }, txnNumber: 22, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2135ms
2020-05-08T12:16:14.535-0700 I  NETWORK  [conn74] end connection 192.168.122.1:55158 (21 connections now open)
2020-05-08T12:16:14.536-0700 I  NETWORK  [conn60] end connection 192.168.122.1:54576 (20 connections now open)
2020-05-08T12:16:16.097-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:16.098-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:16.098-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:16.174-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:16.174-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:16.189-0700 I  NETWORK  [conn56] Marking host n5:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:16.189-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 31, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965369, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05ff6052-de67-41ab-84cf-5d2411862870") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:328 protocol:op_msg 7107ms
2020-05-08T12:16:16.189-0700 I  NETWORK  [conn56] end connection 192.168.122.1:54446 (19 connections now open)
2020-05-08T12:16:16.193-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:16.194-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:16.598-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:17.098-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:17.805-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:17.805-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:18.635-0700 I  NETWORK  [conn80] end connection 192.168.122.1:55430 (18 connections now open)
2020-05-08T12:16:18.636-0700 I  NETWORK  [conn81] end connection 192.168.122.1:55432 (17 connections now open)
2020-05-08T12:16:18.636-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55694 #84 (18 connections now open)
2020-05-08T12:16:18.636-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55696 #85 (19 connections now open)
2020-05-08T12:16:18.636-0700 I  NETWORK  [conn84] received client metadata from 192.168.122.1:55694 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.636-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55700 #86 (20 connections now open)
2020-05-08T12:16:18.637-0700 I  NETWORK  [conn85] received client metadata from 192.168.122.1:55696 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.637-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55704 #87 (21 connections now open)
2020-05-08T12:16:18.637-0700 I  NETWORK  [conn86] received client metadata from 192.168.122.1:55700 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.637-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.1:55704 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.639-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T12:16:18.918-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965376, 4) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:279061, timeInactiveMicros:718, 279ms
2020-05-08T12:16:18.918-0700 I  COMMAND  [conn84] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965378, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 273ms
2020-05-08T12:16:18.919-0700 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("25542d91-b7d2-44e6-97c5-0da700794a17"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965373, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:4833241, timeInactiveMicros:0, 4833ms
2020-05-08T12:16:18.919-0700 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25542d91-b7d2-44e6-97c5-0da700794a17") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 4833ms
2020-05-08T12:16:18.919-0700 I  TXN      [conn78] transaction parameters:{ lsid: { id: UUID("e777ee5c-dc6d-4076-90ec-007e1285f93d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965373, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:5283058, timeInactiveMicros:0, 5283ms
2020-05-08T12:16:18.919-0700 I  COMMAND  [conn78] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e777ee5c-dc6d-4076-90ec-007e1285f93d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 5283ms
2020-05-08T12:16:18.919-0700 I  NETWORK  [conn78] end connection 192.168.122.1:55426 (20 connections now open)
2020-05-08T12:16:18.920-0700 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("7f42f050-fe7b-43ec-89bb-6580f9480573"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965373, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:5283455, timeInactiveMicros:0, 5283ms
2020-05-08T12:16:18.920-0700 I  COMMAND  [conn79] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f42f050-fe7b-43ec-89bb-6580f9480573") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 5283ms
2020-05-08T12:16:18.920-0700 I  NETWORK  [conn79] end connection 192.168.122.1:55428 (19 connections now open)
2020-05-08T12:16:18.940-0700 I  COMMAND  [conn86] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965376, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 300ms
2020-05-08T12:16:19.084-0700 I  NETWORK  [conn83] end connection 192.168.122.1:55538 (18 connections now open)
2020-05-08T12:16:19.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55788 #90 (19 connections now open)
2020-05-08T12:16:19.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55790 #91 (20 connections now open)
2020-05-08T12:16:19.085-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.1:55788 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:19.085-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.1:55790 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:19.094-0700 I  NETWORK  [conn82] end connection 192.168.122.1:55536 (19 connections now open)
2020-05-08T12:16:20.214-0700 I  SHARDING [conn90] Received reply from shard n5:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965373, 1), t: 6 }, now { ts: Timestamp(1588965379, 200), t: 9 }
2020-05-08T12:16:20.215-0700 I  NETWORK  [conn90] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:20.216-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:20.220-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:20.716-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:20.716-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:20.717-0700 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965379, 76) } }, globalReadTimestamp:{ ts: Timestamp(1588965379, 77) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1585982, timeActiveMicros:1603326, timeInactiveMicros:1120, 1604ms
2020-05-08T12:16:20.717-0700 I  COMMAND  [conn86] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") }, txnNumber: 6, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1586ms
2020-05-08T12:16:20.731-0700 I  TXN      [conn90] transaction parameters:{ lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965379, 136) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1508609, timeActiveMicros:1528125, timeInactiveMicros:1028, 1529ms
2020-05-08T12:16:20.732-0700 I  COMMAND  [conn90] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 148), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7") }, txnNumber: 4, autocommit: false } numYields:0 reslen:426 protocol:op_msg 1509ms
2020-05-08T12:16:20.819-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965379, 146) } }, globalReadTimestamp:{ ts: Timestamp(1588965379, 146) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1593859, timeActiveMicros:1608266, timeInactiveMicros:1199, 1609ms
2020-05-08T12:16:20.819-0700 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 154), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f") }, txnNumber: 9, autocommit: false } numYields:0 reslen:343 protocol:op_msg 1594ms
2020-05-08T12:16:20.833-0700 I  TXN      [conn90] transaction parameters:{ lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965380, 109) } }, globalReadTimestamp:{ ts: Timestamp(1588965380, 109) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:49277, timeActiveMicros:98799, timeInactiveMicros:1370, 100ms
2020-05-08T12:16:21.135-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 12) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:109143, timeActiveMicros:116488, timeInactiveMicros:1293, 117ms
2020-05-08T12:16:21.135-0700 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f") }, txnNumber: 15, autocommit: false } numYields:0 reslen:214 protocol:op_msg 109ms
2020-05-08T12:16:21.192-0700 I  TXN      [conn90] transaction parameters:{ lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 17) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 17) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:128934, timeActiveMicros:162888, timeInactiveMicros:1973, 164ms
2020-05-08T12:16:21.193-0700 I  COMMAND  [conn90] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 129ms
2020-05-08T12:16:21.366-0700 I  COMMAND  [conn86] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 17, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965381, 143), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 125ms
2020-05-08T12:16:21.583-0700 I  TXN      [conn90] transaction parameters:{ lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 241) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 242) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:72347, timeActiveMicros:102833, timeInactiveMicros:1085, 103ms
2020-05-08T12:16:21.815-0700 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 278) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 279) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:127131, timeActiveMicros:188806, timeInactiveMicros:1895, 190ms
2020-05-08T12:16:21.815-0700 I  COMMAND  [conn86] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 298), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") }, txnNumber: 21, autocommit: false } numYields:0 reslen:214 protocol:op_msg 127ms
2020-05-08T12:16:22.724-0700 I  COMMAND  [conn86] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 22, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965381, 326), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 906ms
2020-05-08T12:16:22.725-0700 I  COMMAND  [conn84] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 332), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f") }, txnNumber: 23, autocommit: false } numYields:0 reslen:352 protocol:op_msg 900ms
2020-05-08T12:16:23.034-0700 I  NETWORK  [conn90] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:16:23.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:23.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.535-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.345-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:25.347-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:25.347-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:25.441-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:25.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.725-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55964 #92 (20 connections now open)
2020-05-08T12:16:25.726-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.1:55964 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:25.809-0700 I  NETWORK  [conn86] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:25.811-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:26.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:26.136-0700 I  NETWORK  [conn85] end connection 192.168.122.1:55696 (19 connections now open)
2020-05-08T12:16:26.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55982 #93 (20 connections now open)
2020-05-08T12:16:26.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55984 #94 (21 connections now open)
2020-05-08T12:16:26.137-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.1:55982 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.138-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.1:55984 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.140-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:26.310-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:26.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:26.585-0700 I  NETWORK  [conn91] end connection 192.168.122.1:55790 (20 connections now open)
2020-05-08T12:16:26.586-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55998 #95 (21 connections now open)
2020-05-08T12:16:26.587-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.1:55998 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.608-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56000 #96 (22 connections now open)
2020-05-08T12:16:26.609-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.1:56000 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.612-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:26.612-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:26.613-0700 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965382, 10) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3888221, timeInactiveMicros:0, 3888ms
2020-05-08T12:16:26.614-0700 I  COMMAND  [conn86] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965382, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") }, txnNumber: 23, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3888ms
2020-05-08T12:16:26.908-0700 I  NETWORK  [conn93] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:26.910-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:27.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:27.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:27.489-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:27.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:27.726-0700 I  NETWORK  [conn87] end connection 192.168.122.1:55704 (21 connections now open)
2020-05-08T12:16:27.727-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56092 #97 (22 connections now open)
2020-05-08T12:16:27.727-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.1:56092 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:27.727-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56098 #98 (23 connections now open)
2020-05-08T12:16:27.728-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.1:56098 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:27.731-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:27.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:28.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:28.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:28.534-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:28.535-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:28.536-0700 I  COMMAND  [conn90] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 354), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f1982b8-8174-4728-a6da-cdac984b59e7") }, txnNumber: 20, autocommit: false } numYields:0 reslen:439 protocol:op_msg 6595ms
2020-05-08T12:16:28.536-0700 I  COMMAND  [conn84] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965382, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a300704e-ea16-41c3-9401-a0a6e8394a4f") }, txnNumber: 24, autocommit: false } numYields:0 reslen:352 protocol:op_msg 5783ms
2020-05-08T12:16:28.536-0700 I  NETWORK  [conn90] end connection 192.168.122.1:55788 (22 connections now open)
2020-05-08T12:16:28.536-0700 I  NETWORK  [conn84] end connection 192.168.122.1:55694 (21 connections now open)
2020-05-08T12:16:28.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:29.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:29.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:30.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:30.696-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56236 #99 (22 connections now open)
2020-05-08T12:16:30.697-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.1:56236 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.909-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:30.910-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:30.910-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:30.917-0700 I  COMMAND  [conn86] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965386, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bfe83851-5662-43c3-b8c3-8202a6d2dce3") }, txnNumber: 23, autocommit: false } numYields:0 reslen:515 protocol:op_msg 4302ms
2020-05-08T12:16:30.918-0700 I  NETWORK  [conn86] end connection 192.168.122.1:55700 (21 connections now open)
2020-05-08T12:16:31.137-0700 I  NETWORK  [conn94] end connection 192.168.122.1:55984 (20 connections now open)
2020-05-08T12:16:31.138-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56256 #101 (21 connections now open)
2020-05-08T12:16:31.139-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56258 #102 (22 connections now open)
2020-05-08T12:16:31.139-0700 I  NETWORK  [conn101] received client metadata from 192.168.122.1:56256 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.139-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.1:56258 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:31.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:31.587-0700 I  NETWORK  [conn96] end connection 192.168.122.1:56000 (21 connections now open)
2020-05-08T12:16:31.588-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56306 #105 (22 connections now open)
2020-05-08T12:16:31.588-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56308 #106 (23 connections now open)
2020-05-08T12:16:31.589-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.1:56306 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.589-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.1:56308 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:32.412-0700 I  TXN      [conn97] transaction parameters:{ lsid: { id: UUID("36af9a78-aefd-47ac-942f-748f8bb3d42b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965386, 4) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4682700, timeInactiveMicros:0, 4682ms
2020-05-08T12:16:32.412-0700 I  COMMAND  [conn97] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 129 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965386, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("36af9a78-aefd-47ac-942f-748f8bb3d42b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 36af9a78-aefd-47ac-942f-748f8bb3d42b:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965386, 4) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 4682ms
2020-05-08T12:16:32.427-0700 I  COMMAND  [conn101] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 131 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965391, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("857d7fda-c26d-43b7-a86c-9b8d89a778d4") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1276ms
2020-05-08T12:16:32.728-0700 I  NETWORK  [conn98] end connection 192.168.122.1:56098 (22 connections now open)
2020-05-08T12:16:32.729-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56418 #108 (23 connections now open)
2020-05-08T12:16:32.730-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56422 #109 (24 connections now open)
2020-05-08T12:16:32.730-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.1:56418 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:32.730-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.1:56422 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:33.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:33.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:34.380-0700 I  NETWORK  [conn108] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:34.383-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:34.385-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:34.882-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:35.363-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:35.381-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:35.381-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:35.381-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:35.383-0700 I  COMMAND  [conn97] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965392, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("36af9a78-aefd-47ac-942f-748f8bb3d42b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2969ms
2020-05-08T12:16:35.384-0700 I  NETWORK  [conn97] end connection 192.168.122.1:56092 (23 connections now open)
2020-05-08T12:16:35.569-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:35.569-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:35.865-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:35.865-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:35.865-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n2:27019 as failed :: caused by :: NotMaster: Node n2:27019 believes it is primary, but its election id 7fffffff000000000000000a is older than the most recent election id 7fffffff000000000000000b
2020-05-08T12:16:35.913-0700 I  NETWORK  [conn95] Marking host n6:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:35.913-0700 I  TXN      [conn101] transaction parameters:{ lsid: { id: UUID("857d7fda-c26d-43b7-a86c-9b8d89a778d4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965390, 2) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3481401, timeActiveMicros:4768152, timeInactiveMicros:4089, 4772ms
2020-05-08T12:16:35.914-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:35.915-0700 I  NETWORK  [conn101] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:35.916-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:35.945-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T12:16:36.139-0700 I  NETWORK  [conn102] end connection 192.168.122.1:56258 (22 connections now open)
2020-05-08T12:16:36.140-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56580 #114 (23 connections now open)
2020-05-08T12:16:36.140-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56582 #115 (24 connections now open)
2020-05-08T12:16:36.140-0700 I  NETWORK  [conn114] received client metadata from 192.168.122.1:56580 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.140-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.1:56582 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.413-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:36.416-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.589-0700 I  NETWORK  [conn106] end connection 192.168.122.1:56308 (23 connections now open)
2020-05-08T12:16:36.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56598 #116 (24 connections now open)
2020-05-08T12:16:36.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56600 #117 (25 connections now open)
2020-05-08T12:16:36.590-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.1:56598 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.591-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.1:56600 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.594-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.914-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:36.916-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.055-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965389, 3), t: 9 }, now { ts: Timestamp(1588965395, 11), t: 11 }
2020-05-08T12:16:37.413-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:37.417-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.443-0700 I  COMMAND  [conn101] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965392, 41), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("857d7fda-c26d-43b7-a86c-9b8d89a778d4") }, txnNumber: 1, autocommit: false } numYields:0 reslen:463 protocol:op_msg 5011ms
2020-05-08T12:16:37.443-0700 I  NETWORK  [conn101] end connection 192.168.122.1:56256 (24 connections now open)
2020-05-08T12:16:37.730-0700 I  NETWORK  [conn109] end connection 192.168.122.1:56422 (23 connections now open)
2020-05-08T12:16:37.731-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56706 #118 (24 connections now open)
2020-05-08T12:16:37.731-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56712 #119 (25 connections now open)
2020-05-08T12:16:37.731-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.1:56706 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.731-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.1:56712 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.734-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.913-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:37.917-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.414-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:38.416-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.840-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56748 #120 (26 connections now open)
2020-05-08T12:16:38.841-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:56748 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:38.913-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:38.914-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:38.917-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.416-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965392, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("752ec9cc-e6ae-4847-b686-66317be2ee19") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 7173ms
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn93] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965385, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ee7a830-4d9c-4e65-aad0-1ad4e6514ff3") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 13765ms
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn105] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965391, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b76d23f-243a-42bf-a1da-fb1af90ed58f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 8314ms
2020-05-08T12:16:39.905-0700 I  NETWORK  [conn108] end connection 192.168.122.1:56418 (25 connections now open)
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn95] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965385, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d56b151f-49c1-4686-be81-cb5ec0ad2f92") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 13294ms
2020-05-08T12:16:39.906-0700 I  NETWORK  [conn93] end connection 192.168.122.1:55982 (24 connections now open)
2020-05-08T12:16:39.906-0700 I  NETWORK  [conn105] end connection 192.168.122.1:56306 (23 connections now open)
2020-05-08T12:16:39.906-0700 I  NETWORK  [conn95] end connection 192.168.122.1:55998 (22 connections now open)
2020-05-08T12:16:39.916-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.417-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.916-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:40.917-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:40.918-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965397, 5), t: 11 }, now { ts: Timestamp(1588965399, 5), t: 12 }
2020-05-08T12:16:40.918-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:40.919-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:40.919-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:41.140-0700 I  NETWORK  [conn115] end connection 192.168.122.1:56582 (21 connections now open)
2020-05-08T12:16:41.141-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56818 #121 (22 connections now open)
2020-05-08T12:16:41.141-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56820 #122 (23 connections now open)
2020-05-08T12:16:41.142-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.1:56818 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.142-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:56820 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.144-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:16:41.147-0700 I  -        [conn114] operation was interrupted because a client disconnected
2020-05-08T12:16:41.147-0700 I  CONNPOOL [conn114] Ending connection to host n9:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T12:16:41.148-0700 I  TXN      [conn114] transaction parameters:{ lsid: { id: UUID("a4db1eb2-6566-4ebc-b2ff-865be2e51a9e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 9) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005794, timeInactiveMicros:0, 5005ms
2020-05-08T12:16:41.148-0700 I  COMMAND  [conn114] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a4db1eb2-6566-4ebc-b2ff-865be2e51a9e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:16:41.148-0700 I  NETWORK  [conn114] end connection 192.168.122.1:56580 (22 connections now open)
2020-05-08T12:16:41.314-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965399, 5), t: 12 }, now { ts: Timestamp(1588965400, 2), t: 13 }
2020-05-08T12:16:41.591-0700 I  NETWORK  [conn117] end connection 192.168.122.1:56600 (21 connections now open)
2020-05-08T12:16:41.592-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56840 #124 (22 connections now open)
2020-05-08T12:16:41.592-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56842 #125 (23 connections now open)
2020-05-08T12:16:41.592-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.1:56840 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.593-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.1:56842 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.596-0700 I  NETWORK  [conn124] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:41.597-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:41.598-0700 I  -        [conn116] operation was interrupted because a client disconnected
2020-05-08T12:16:41.598-0700 I  CONNPOOL [conn116] Ending connection to host n9:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T12:16:41.598-0700 I  TXN      [conn116] transaction parameters:{ lsid: { id: UUID("2eb9ef59-4920-438c-a261-027ad6e78404"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 9) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006042, timeInactiveMicros:0, 5006ms
2020-05-08T12:16:41.599-0700 I  COMMAND  [conn116] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 137 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2eb9ef59-4920-438c-a261-027ad6e78404") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:16:41.599-0700 I  NETWORK  [conn116] end connection 192.168.122.1:56598 (22 connections now open)
2020-05-08T12:16:41.641-0700 I  COMMAND  [conn121] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965400, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 497ms
2020-05-08T12:16:41.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:41.646-0700 I  TXN      [conn118] transaction parameters:{ lsid: { id: UUID("c80fc01a-635d-48e0-91a8-271af04af782"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 11) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3913306, timeInactiveMicros:0, 3913ms
2020-05-08T12:16:41.646-0700 I  COMMAND  [conn118] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c80fc01a-635d-48e0-91a8-271af04af782") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction c80fc01a-635d-48e0-91a8-271af04af782:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588965395, 11) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:554 protocol:op_msg 3913ms
2020-05-08T12:16:42.097-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:42.597-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:42.597-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:42.599-0700 I  TXN      [conn124] transaction parameters:{ lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965401, 3) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1004898, timeInactiveMicros:0, 1004ms
2020-05-08T12:16:42.600-0700 I  COMMAND  [conn124] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1005ms
2020-05-08T12:16:42.600-0700 I  COMMAND  [conn121] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 957ms
2020-05-08T12:16:42.620-0700 I  TXN      [conn121] transaction parameters:{ lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965401, 5) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:17893, timeActiveMicros:976244, timeInactiveMicros:1468, 977ms
2020-05-08T12:16:42.636-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:42.732-0700 I  NETWORK  [conn119] end connection 192.168.122.1:56712 (21 connections now open)
2020-05-08T12:16:42.733-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56984 #127 (22 connections now open)
2020-05-08T12:16:42.734-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56986 #128 (23 connections now open)
2020-05-08T12:16:42.734-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.1:56984 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:42.735-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.1:56986 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:42.742-0700 I  NETWORK  [conn118] end connection 192.168.122.1:56706 (22 connections now open)
2020-05-08T12:16:42.965-0700 I  NETWORK  [conn124] Marking host n9:27018 as failed :: caused by :: PrimarySteppedDown: Received stepdown request while waiting for replication
2020-05-08T12:16:42.965-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:42.983-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:43.465-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:43.466-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:43.468-0700 I  COMMAND  [conn127] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965402, 209), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("610ff1d3-ee24-4357-a149-41e1a5b81c16") }, txnNumber: 6, autocommit: false } numYields:0 reslen:455 protocol:op_msg 533ms
2020-05-08T12:16:43.468-0700 I  COMMAND  [conn121] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965402, 223), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") }, txnNumber: 15, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 486ms
2020-05-08T12:16:43.846-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdb5861abbf7eec2119 to 5eb5afdaa0224cfb413c7171; invalidating user cache
2020-05-08T12:16:43.995-0700 I  TXN      [conn124] transaction parameters:{ lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 11, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965402, 203) } }, globalReadTimestamp:{ ts: Timestamp(1588965402, 203) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1062744, timeActiveMicros:1076228, timeInactiveMicros:803, 1077ms
2020-05-08T12:16:43.995-0700 I  COMMAND  [conn124] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965402, 206), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e") }, txnNumber: 11, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1062ms
2020-05-08T12:16:43.996-0700 I  COMMAND  [conn127] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965403, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("610ff1d3-ee24-4357-a149-41e1a5b81c16") }, txnNumber: 6, autocommit: false } numYields:0 reslen:396 protocol:op_msg 526ms
2020-05-08T12:16:44.047-0700 I  TXN      [conn121] transaction parameters:{ lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965402, 223) } }, globalReadTimestamp:{ ts: Timestamp(1588965402, 223) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:577603, timeActiveMicros:1075877, timeInactiveMicros:2559, 1078ms
2020-05-08T12:16:44.047-0700 I  COMMAND  [conn121] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965403, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") }, txnNumber: 15, autocommit: false } numYields:0 reslen:214 protocol:op_msg 577ms
2020-05-08T12:16:44.074-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-08T12:16:44.433-0700 I  COMMAND  [conn121] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965404, 76), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") }, txnNumber: 22, autocommit: false } numYields:0 reslen:352 protocol:op_msg 237ms
2020-05-08T12:16:46.256-0700 I  NETWORK  [conn121] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:46.257-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:46.758-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:47.258-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:47.258-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:47.260-0700 I  COMMAND  [conn121] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965405, 48), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") }, txnNumber: 100, autocommit: false } numYields:0 reslen:353 protocol:op_msg 1440ms
2020-05-08T12:16:47.273-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:47.274-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:47.274-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:47.291-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965403, 8), t: 13 }, now { ts: Timestamp(1588965407, 1), t: 14 }
2020-05-08T12:16:47.469-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:47.470-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:47.471-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:47.471-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:47.559-0700 I  NETWORK  [conn124] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:47.560-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:47.563-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:47.564-0700 I  NETWORK  [conn127] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 610ff1d3-ee24-4357-a149-41e1a5b81c16:12 stopped due to: Transaction coordinator service stepping down
2020-05-08T12:16:47.564-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:47.760-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965407, 1), t: 14 }, now { ts: Timestamp(1588965407, 4), t: 15 }
2020-05-08T12:16:48.061-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:48.560-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:48.561-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:48.562-0700 I  TXN      [conn124] transaction parameters:{ lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965404, 67) } }, globalReadTimestamp:{ ts: Timestamp(1588965404, 67) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4422715, timeInactiveMicros:0, 4422ms
2020-05-08T12:16:48.563-0700 I  COMMAND  [conn124] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965404, 67), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e") }, txnNumber: 16, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965404, 67) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 4423ms
2020-05-08T12:16:49.092-0700 I  NETWORK  [conn128] end connection 192.168.122.1:56986 (21 connections now open)
2020-05-08T12:16:49.092-0700 I  NETWORK  [conn125] end connection 192.168.122.1:56842 (20 connections now open)
2020-05-08T12:16:49.092-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57330 #130 (21 connections now open)
2020-05-08T12:16:49.093-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.1:57330 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.093-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57332 #131 (22 connections now open)
2020-05-08T12:16:49.093-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57336 #132 (23 connections now open)
2020-05-08T12:16:49.093-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:57332 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.093-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.1:57336 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.094-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57344 #133 (24 connections now open)
2020-05-08T12:16:49.094-0700 I  NETWORK  [conn133] received client metadata from 192.168.122.1:57344 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.096-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:16:49.120-0700 I  NETWORK  [conn122] end connection 192.168.122.1:56820 (23 connections now open)
2020-05-08T12:16:49.120-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57352 #135 (24 connections now open)
2020-05-08T12:16:49.121-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57354 #136 (25 connections now open)
2020-05-08T12:16:49.121-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.1:57352 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.121-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.1:57354 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.126-0700 I  CONNPOOL [conn127] Ending connection to host n9:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T12:16:49.126-0700 I  COMMAND  [conn127] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965404, 55), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("610ff1d3-ee24-4357-a149-41e1a5b81c16") }, txnNumber: 12, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T12:16:49.126-0700 I  NETWORK  [conn127] end connection 192.168.122.1:56984 (24 connections now open)
2020-05-08T12:16:49.463-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:16:49.576-0700 I  COMMAND  [conn135] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965408, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 454ms
2020-05-08T12:16:49.576-0700 I  COMMAND  [conn124] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965408, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b698d13d-d028-4e3b-8a17-0a385d55812e") }, txnNumber: 16, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1011ms
2020-05-08T12:16:49.577-0700 I  NETWORK  [conn124] end connection 192.168.122.1:56840 (23 connections now open)
2020-05-08T12:16:49.577-0700 I  COMMAND  [conn130] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 159 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965408, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("19a94e7b-5dc6-4734-a9af-833ed45d487e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 481ms
2020-05-08T12:16:49.577-0700 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 154 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965408, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 481ms
2020-05-08T12:16:49.578-0700 I  NETWORK  [conn135] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:49.579-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:49.580-0700 I  TXN      [conn130] transaction parameters:{ lsid: { id: UUID("19a94e7b-5dc6-4734-a9af-833ed45d487e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965408, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:484070, timeInactiveMicros:744, 484ms
2020-05-08T12:16:49.597-0700 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965408, 2) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:17571, timeActiveMicros:500441, timeInactiveMicros:1493, 501ms
2020-05-08T12:16:49.600-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:49.603-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:50.045-0700 I  NETWORK  [conn121] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary when performing noop write for NoSuchTransaction error
2020-05-08T12:16:50.046-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:50.079-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:50.546-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:50.546-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:50.579-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:50.579-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:50.581-0700 I  TXN      [conn135] transaction parameters:{ lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965409, 2) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1003505, timeInactiveMicros:0, 1003ms
2020-05-08T12:16:50.581-0700 I  COMMAND  [conn130] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 158 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965409, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("19a94e7b-5dc6-4734-a9af-833ed45d487e") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 978ms
2020-05-08T12:16:50.581-0700 I  COMMAND  [conn135] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965409, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1003ms
2020-05-08T12:16:51.803-0700 I  NETWORK  [conn121] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary when performing noop write for NoSuchTransaction error
2020-05-08T12:16:51.804-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.006-0700 I  TXN      [conn130] transaction parameters:{ lsid: { id: UUID("19a94e7b-5dc6-4734-a9af-833ed45d487e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965409, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588965409, 10) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2405228, timeInactiveMicros:1983, 2407ms
2020-05-08T12:16:52.006-0700 I  COMMAND  [conn130] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965410, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("19a94e7b-5dc6-4734-a9af-833ed45d487e") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Given transaction number 2 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:445 protocol:op_msg 1424ms
2020-05-08T12:16:52.007-0700 I  COMMAND  [conn135] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965410, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1424ms
2020-05-08T12:16:52.007-0700 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965409, 10) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2408287, timeInactiveMicros:0, 2408ms
2020-05-08T12:16:52.008-0700 I  COMMAND  [conn131] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965409, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2408ms
2020-05-08T12:16:52.009-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.062-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.130-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.278-0700 I  COMMAND  [conn121] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965406, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea60c278-9a62-49f7-b301-0853dbc90f0f") }, txnNumber: 101, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T12:16:52.278-0700 I  NETWORK  [conn121] end connection 192.168.122.1:56818 (22 connections now open)
2020-05-08T12:16:52.304-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.805-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:53.305-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:53.305-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:53.306-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:53.313-0700 I  SHARDING [conn135] Received reply from shard n8:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965410, 7), t: 15 }, now { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:16:53.314-0700 I  COMMAND  [conn135] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 159 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965412, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859") }, txnNumber: 4, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:383 protocol:op_msg 1252ms
2020-05-08T12:16:53.513-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:53.513-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:53.929-0700 I  NETWORK  [conn131] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:53.930-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:53.930-0700 I  NETWORK  [conn130] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:53.931-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.093-0700 I  NETWORK  [conn132] end connection 192.168.122.1:57336 (21 connections now open)
2020-05-08T12:16:54.094-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57602 #139 (22 connections now open)
2020-05-08T12:16:54.094-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57604 #140 (23 connections now open)
2020-05-08T12:16:54.094-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:57602 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.094-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.1:57604 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.097-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:54.429-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:54.430-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:54.431-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.578-0700 I  NETWORK  [conn136] end connection 192.168.122.1:57354 (22 connections now open)
2020-05-08T12:16:54.579-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57642 #141 (23 connections now open)
2020-05-08T12:16:54.579-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57644 #142 (24 connections now open)
2020-05-08T12:16:54.579-0700 I  NETWORK  [conn141] received client metadata from 192.168.122.1:57642 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.579-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.1:57644 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.931-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.949-0700 I  TXN      [conn135] transaction parameters:{ lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965412, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588965412, 16) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1634394, timeActiveMicros:2894897, timeInactiveMicros:1591, 2896ms
2020-05-08T12:16:54.950-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.950-0700 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 164 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965412, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf") }, txnNumber: 6, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2820ms
2020-05-08T12:16:54.950-0700 I  COMMAND  [conn141] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965414, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 369ms
2020-05-08T12:16:54.950-0700 I  COMMAND  [conn139] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 165 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965413, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c9a377e0-2fec-44fa-ac98-c4a157359fb0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 854ms
2020-05-08T12:16:54.952-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.980-0700 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965414, 2) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:27247, timeActiveMicros:397707, timeInactiveMicros:1056, 398ms
2020-05-08T12:16:54.982-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:55.431-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:55.931-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:55.931-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:55.933-0700 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 163 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965414, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:277 protocol:op_msg 952ms
2020-05-08T12:16:55.933-0700 I  COMMAND  [conn139] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 163 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965414, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c9a377e0-2fec-44fa-ac98-c4a157359fb0") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 982ms
2020-05-08T12:16:55.934-0700 I  COMMAND  [conn135] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965413, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78112e7f-0ba8-4023-b488-12d43a4fb859") }, txnNumber: 4, autocommit: false } numYields:0 reslen:426 protocol:op_msg 2618ms
2020-05-08T12:16:55.934-0700 I  COMMAND  [conn130] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965412, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("19a94e7b-5dc6-4734-a9af-833ed45d487e") }, txnNumber: 2, autocommit: false } numYields:0 reslen:351 protocol:op_msg 3926ms
2020-05-08T12:16:55.934-0700 I  NETWORK  [conn135] end connection 192.168.122.1:57352 (23 connections now open)
2020-05-08T12:16:55.934-0700 I  NETWORK  [conn130] end connection 192.168.122.1:57330 (22 connections now open)
2020-05-08T12:16:56.226-0700 I  NETWORK  [conn131] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:56.227-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:56.727-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:56.728-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:56.729-0700 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965412, 26) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4598955, timeInactiveMicros:811, 4599ms
2020-05-08T12:16:56.729-0700 I  COMMAND  [conn131] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965414, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf") }, txnNumber: 6, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1778ms
2020-05-08T12:16:56.861-0700 I  NETWORK  [conn139] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:56.862-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:56.862-0700 I  NETWORK  [conn141] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:56.863-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.130-0700 I  NETWORK  [conn133] end connection 192.168.122.1:57344 (21 connections now open)
2020-05-08T12:16:57.131-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57796 #143 (22 connections now open)
2020-05-08T12:16:57.131-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57798 #144 (23 connections now open)
2020-05-08T12:16:57.131-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.1:57796 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:57.132-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.1:57798 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:57.233-0700 I  NETWORK  [conn143] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:57.233-0700 I  TXN      [conn139] transaction parameters:{ lsid: { id: UUID("c9a377e0-2fec-44fa-ac98-c4a157359fb0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965413, 5) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:1298657, timeActiveMicros:3135670, timeInactiveMicros:1487, 3137ms
2020-05-08T12:16:57.234-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.234-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.235-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.362-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.734-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.861-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:58.235-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:58.361-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:58.361-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:58.362-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:16:58.734-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.095-0700 I  NETWORK  [conn140] end connection 192.168.122.1:57604 (22 connections now open)
2020-05-08T12:16:59.095-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57886 #145 (23 connections now open)
2020-05-08T12:16:59.096-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57888 #146 (24 connections now open)
2020-05-08T12:16:59.096-0700 I  NETWORK  [conn145] received client metadata from 192.168.122.1:57886 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:59.096-0700 I  NETWORK  [conn146] received client metadata from 192.168.122.1:57888 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:59.128-0700 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965415, 86) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3187163, timeActiveMicros:3192195, timeInactiveMicros:1243, 3193ms
2020-05-08T12:16:59.130-0700 I  COMMAND  [conn141] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965415, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 3188ms
2020-05-08T12:16:59.160-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.234-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.734-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:59.734-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:59.735-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:16:59.735-0700 I  COMMAND  [conn139] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965415, 86), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c9a377e0-2fec-44fa-ac98-c4a157359fb0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:463 protocol:op_msg 3800ms
2020-05-08T12:16:59.735-0700 I  NETWORK  [conn139] end connection 192.168.122.1:57602 (23 connections now open)
2020-05-08T12:16:59.736-0700 I  COMMAND  [conn131] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965416, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d32794a-5a78-4285-a06f-c0531505ddcf") }, txnNumber: 6, autocommit: false } numYields:0 reslen:513 protocol:op_msg 3004ms
2020-05-08T12:16:59.736-0700 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 175 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965419, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6088989-3fca-48a9-9de8-d35e89cef57d") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 577ms
2020-05-08T12:16:59.736-0700 I  NETWORK  [conn131] end connection 192.168.122.1:57332 (22 connections now open)
2020-05-08T12:17:00.243-0700 I  NETWORK  [conn143] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:00.243-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:00.415-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n8:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:00.744-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.119-0700 I  NETWORK  [conn145] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:01.121-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.243-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.621-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.743-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.879-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n8:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:02.120-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:02.131-0700 I  NETWORK  [conn144] end connection 192.168.122.1:57798 (21 connections now open)
2020-05-08T12:17:02.132-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58012 #147 (22 connections now open)
2020-05-08T12:17:02.132-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58014 #148 (23 connections now open)
2020-05-08T12:17:02.132-0700 I  NETWORK  [conn147] received client metadata from 192.168.122.1:58012 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:02.132-0700 I  NETWORK  [conn148] received client metadata from 192.168.122.1:58014 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:02.134-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:02.135-0700 I  -        [conn143] operation was interrupted because a client disconnected
2020-05-08T12:17:02.136-0700 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("d78d9f9a-8239-42d7-bae8-533a86b38b67"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965416, 15) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002125, timeInactiveMicros:0, 5002ms
2020-05-08T12:17:02.136-0700 I  COMMAND  [conn143] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 168 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965416, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d78d9f9a-8239-42d7-bae8-533a86b38b67") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T12:17:02.136-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:02.136-0700 I  NETWORK  [conn143] end connection 192.168.122.1:57796 (22 connections now open)
2020-05-08T12:17:02.244-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:02.620-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:02.743-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:02.744-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:03.120-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.121-0700 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.123-0700 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 190), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98") }, txnNumber: 52, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2607ms
2020-05-08T12:17:03.123-0700 I  COMMAND  [conn145] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 190), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6088989-3fca-48a9-9de8-d35e89cef57d") }, txnNumber: 33, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2607ms
2020-05-08T12:17:03.586-0700 I  NETWORK  [Sharding-Fixed-7] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:03.589-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:04.086-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:04.087-0700 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:04.087-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T12:17:04.097-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:04.156-0700 I  NETWORK  [conn142] end connection 192.168.122.1:57644 (21 connections now open)
2020-05-08T12:17:04.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58160 #153 (22 connections now open)
2020-05-08T12:17:04.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58162 #154 (23 connections now open)
2020-05-08T12:17:04.157-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:58160 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:04.157-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.1:58162 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:04.367-0700 I  COMMAND  [conn145] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6088989-3fca-48a9-9de8-d35e89cef57d") }, txnNumber: 33, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1242ms
2020-05-08T12:17:04.367-0700 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c22b96ac-9020-4087-b6e9-5aec726c2c98") }, txnNumber: 52, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1242ms
2020-05-08T12:17:04.367-0700 I  NETWORK  [conn141] end connection 192.168.122.1:57642 (22 connections now open)
2020-05-08T12:17:04.368-0700 I  COMMAND  [conn147] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3da9b8ea-2ad7-4d81-8e39-897327044bf6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 2235ms
2020-05-08T12:17:04.369-0700 I  COMMAND  [conn153] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 176 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 209ms
2020-05-08T12:17:04.371-0700 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("3da9b8ea-2ad7-4d81-8e39-897327044bf6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965420, 197) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2237441, timeInactiveMicros:630, 2238ms
2020-05-08T12:17:04.372-0700 I  NETWORK  [conn145] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:04.372-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.374-0700 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 18) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:213284, timeInactiveMicros:1325, 214ms
2020-05-08T12:17:04.457-0700 I  NETWORK  [conn153] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:04.458-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:04.738-0700 I  NETWORK  [conn146] end connection 192.168.122.1:57888 (21 connections now open)
2020-05-08T12:17:04.739-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58202 #155 (22 connections now open)
2020-05-08T12:17:04.739-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58204 #156 (23 connections now open)
2020-05-08T12:17:04.739-0700 I  NETWORK  [conn155] received client metadata from 192.168.122.1:58202 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:04.740-0700 I  NETWORK  [conn156] received client metadata from 192.168.122.1:58204 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:04.743-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:04.765-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965412, 1), t: 16 }, now { ts: Timestamp(1588965424, 57), t: 18 }
2020-05-08T12:17:04.872-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.900-0700 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T12:17:04.957-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:05.373-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:05.458-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:05.873-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:05.957-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:05.958-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:05.959-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:05.959-0700 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965424, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3da9b8ea-2ad7-4d81-8e39-897327044bf6") }, txnNumber: 5, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1508ms
2020-05-08T12:17:05.959-0700 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965424, 53) } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 53) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1510365, timeInactiveMicros:1089, 1511ms
2020-05-08T12:17:05.960-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:05.960-0700 I  COMMAND  [conn153] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c") }, txnNumber: 5, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1508ms
2020-05-08T12:17:05.960-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:06.373-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:06.872-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:06.872-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:06.874-0700 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("e6088989-3fca-48a9-9de8-d35e89cef57d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 34, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965423, 18) } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 1) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2505309, timeInactiveMicros:392, 2505ms
2020-05-08T12:17:06.874-0700 I  COMMAND  [conn145] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6088989-3fca-48a9-9de8-d35e89cef57d") }, txnNumber: 34, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 2502ms
2020-05-08T12:17:06.874-0700 I  NETWORK  [conn145] end connection 192.168.122.1:57886 (22 connections now open)
2020-05-08T12:17:06.967-0700 I  NETWORK  [conn155] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:06.969-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.132-0700 I  NETWORK  [conn148] end connection 192.168.122.1:58014 (21 connections now open)
2020-05-08T12:17:07.133-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58298 #158 (22 connections now open)
2020-05-08T12:17:07.133-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58300 #159 (23 connections now open)
2020-05-08T12:17:07.134-0700 I  NETWORK  [conn158] received client metadata from 192.168.122.1:58298 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:07.134-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.1:58300 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:07.136-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.468-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.969-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.969-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.971-0700 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965425, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3da9b8ea-2ad7-4d81-8e39-897327044bf6") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2009ms
2020-05-08T12:17:07.971-0700 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965425, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2009ms
2020-05-08T12:17:07.971-0700 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("b4a4583a-6b41-48dc-b184-c4e45de00ae7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 56) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3229070, timeInactiveMicros:0, 3229ms
2020-05-08T12:17:07.971-0700 I  COMMAND  [conn155] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 56), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4a4583a-6b41-48dc-b184-c4e45de00ae7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3229ms
2020-05-08T12:17:07.971-0700 I  NETWORK  [conn147] end connection 192.168.122.1:58012 (22 connections now open)
2020-05-08T12:17:07.992-0700 I  COMMAND  [conn158] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 182 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965426, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4c0b1a59-bd32-40c3-a4de-b0b103e909ca") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 856ms
2020-05-08T12:17:07.996-0700 I  TXN      [conn158] transaction parameters:{ lsid: { id: UUID("4c0b1a59-bd32-40c3-a4de-b0b103e909ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965426, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:859610, timeInactiveMicros:884, 860ms
2020-05-08T12:17:08.186-0700 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("b4a4583a-6b41-48dc-b184-c4e45de00ae7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 16) } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 16) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:139617, timeActiveMicros:155845, timeInactiveMicros:1374, 157ms
2020-05-08T12:17:08.186-0700 I  COMMAND  [conn155] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965428, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4a4583a-6b41-48dc-b184-c4e45de00ae7") }, txnNumber: 3, autocommit: false } numYields:0 reslen:214 protocol:op_msg 139ms
2020-05-08T12:17:09.341-0700 I  SHARDING [conn155] Received reply from shard n5:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965424, 57), t: 18 }, now { ts: Timestamp(1588965427, 1), t: 20 }
2020-05-08T12:17:09.342-0700 I  NETWORK  [conn155] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:09.343-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:09.344-0700 I  NETWORK  [conn158] Marking host n5:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:17:09.345-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:09.843-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:10.343-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:10.343-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:10.345-0700 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965428, 192), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c") }, txnNumber: 13, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2001ms
2020-05-08T12:17:11.297-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:11.298-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:11.298-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:11.460-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:11.460-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T12:17:11.839-0700 I  NETWORK  [conn155] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:11.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:12.013-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:12.066-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:12.134-0700 I  NETWORK  [conn159] end connection 192.168.122.1:58300 (21 connections now open)
2020-05-08T12:17:12.134-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58428 #161 (22 connections now open)
2020-05-08T12:17:12.135-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58430 #162 (23 connections now open)
2020-05-08T12:17:12.135-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.1:58428 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:12.135-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.1:58430 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:12.339-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:12.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:12.919-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965427, 1), t: 20 }, now { ts: Timestamp(1588965430, 9), t: 22 }
2020-05-08T12:17:12.930-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:12.934-0700 I  NETWORK  [conn158] Marking host n6:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:17:12.935-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.057-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:13.182-0700 I  NETWORK  [conn154] end connection 192.168.122.1:58162 (22 connections now open)
2020-05-08T12:17:13.183-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58464 #163 (23 connections now open)
2020-05-08T12:17:13.183-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58466 #164 (24 connections now open)
2020-05-08T12:17:13.184-0700 I  NETWORK  [conn163] received client metadata from 192.168.122.1:58464 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.184-0700 I  NETWORK  [conn164] received client metadata from 192.168.122.1:58466 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.186-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.244-0700 I  NETWORK  [conn156] end connection 192.168.122.1:58204 (23 connections now open)
2020-05-08T12:17:13.244-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58472 #165 (24 connections now open)
2020-05-08T12:17:13.245-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58474 #166 (25 connections now open)
2020-05-08T12:17:13.245-0700 I  NETWORK  [conn165] received client metadata from 192.168.122.1:58472 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.245-0700 I  NETWORK  [conn166] received client metadata from 192.168.122.1:58474 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.248-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.251-0700 I  COMMAND  [conn158] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965428, 137), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4c0b1a59-bd32-40c3-a4de-b0b103e909ca") }, txnNumber: 6, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T12:17:13.251-0700 I  NETWORK  [conn158] end connection 192.168.122.1:58298 (24 connections now open)
2020-05-08T12:17:13.339-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.357-0700 I  COMMAND  [conn155] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965428, 201), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4a4583a-6b41-48dc-b184-c4e45de00ae7") }, txnNumber: 7, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5012ms
2020-05-08T12:17:13.357-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.358-0700 I  NETWORK  [conn155] end connection 192.168.122.1:58202 (23 connections now open)
2020-05-08T12:17:13.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.846-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdbf50ef7b0538edfc4; invalidating user cache
2020-05-08T12:17:14.339-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.340-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.341-0700 I  COMMAND  [conn163] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 194 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b40bfd1d-25f8-45ac-b19b-596c2e513dff") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1156ms
2020-05-08T12:17:14.341-0700 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("63b35be8-e236-4e06-9072-b6c22c06a38c") }, txnNumber: 13, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3995ms
2020-05-08T12:17:14.342-0700 I  NETWORK  [conn153] end connection 192.168.122.1:58160 (22 connections now open)
2020-05-08T12:17:14.344-0700 I  NETWORK  [conn163] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:14.345-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.845-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.903-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:14.905-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:14.905-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:15.345-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:15.367-0700 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("4b553b45-646b-4b71-81c3-9b71bd01c401"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2120446, timeInactiveMicros:0, 2120ms
2020-05-08T12:17:15.368-0700 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b553b45-646b-4b71-81c3-9b71bd01c401") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2120ms
2020-05-08T12:17:15.845-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:15.845-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:15.846-0700 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("b40bfd1d-25f8-45ac-b19b-596c2e513dff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965434, 2) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1503294, timeInactiveMicros:0, 1503ms
2020-05-08T12:17:15.847-0700 I  COMMAND  [conn163] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b40bfd1d-25f8-45ac-b19b-596c2e513dff") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1503ms
2020-05-08T12:17:15.856-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965433, 8), t: 22 }, now { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:16.819-0700 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965435, 80), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b40bfd1d-25f8-45ac-b19b-596c2e513dff") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 970ms
2020-05-08T12:17:17.135-0700 I  NETWORK  [conn162] end connection 192.168.122.1:58430 (21 connections now open)
2020-05-08T12:17:17.136-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58638 #168 (22 connections now open)
2020-05-08T12:17:17.136-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58640 #169 (23 connections now open)
2020-05-08T12:17:17.136-0700 I  NETWORK  [conn168] received client metadata from 192.168.122.1:58638 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:17.136-0700 I  NETWORK  [conn169] received client metadata from 192.168.122.1:58640 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:17.141-0700 I  -        [conn161] operation was interrupted because a client disconnected
2020-05-08T12:17:17.141-0700 I  CONNPOOL [conn161] Ending connection to host n7:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:17.141-0700 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("2a3e3e23-452e-4ad9-b1fb-a9d0182a5d1d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965430, 21) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004204, timeInactiveMicros:0, 5004ms
2020-05-08T12:17:17.141-0700 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 193 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965430, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2a3e3e23-452e-4ad9-b1fb-a9d0182a5d1d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:17.141-0700 I  NETWORK  [conn161] end connection 192.168.122.1:58428 (22 connections now open)
2020-05-08T12:17:17.818-0700 I  NETWORK  [conn168] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:17.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.245-0700 I  NETWORK  [conn166] end connection 192.168.122.1:58474 (21 connections now open)
2020-05-08T12:17:18.246-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58676 #170 (22 connections now open)
2020-05-08T12:17:18.246-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58678 #171 (23 connections now open)
2020-05-08T12:17:18.246-0700 I  NETWORK  [conn170] received client metadata from 192.168.122.1:58676 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:18.247-0700 I  NETWORK  [conn171] received client metadata from 192.168.122.1:58678 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:18.247-0700 I  NETWORK  [conn165] end connection 192.168.122.1:58472 (22 connections now open)
2020-05-08T12:17:18.249-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.319-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.819-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:18.819-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:18.821-0700 I  COMMAND  [conn168] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965437, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("400fc9db-f578-4593-81a0-f2f06ed811bf") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1665ms
2020-05-08T12:17:18.821-0700 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 165), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b40bfd1d-25f8-45ac-b19b-596c2e513dff") }, txnNumber: 2, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1981ms
2020-05-08T12:17:18.918-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n7:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:19.344-0700 I  NETWORK  [conn164] end connection 192.168.122.1:58466 (21 connections now open)
2020-05-08T12:17:19.344-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58772 #172 (22 connections now open)
2020-05-08T12:17:19.345-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58774 #173 (23 connections now open)
2020-05-08T12:17:19.345-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.1:58772 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:19.345-0700 I  NETWORK  [conn173] received client metadata from 192.168.122.1:58774 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:20.052-0700 I  COMMAND  [conn168] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 193 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965438, 125), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("400fc9db-f578-4593-81a0-f2f06ed811bf") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965438, 125) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1229ms
2020-05-08T12:17:20.052-0700 I  COMMAND  [conn170] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 199 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965438, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c94d1e10-01ae-4320-af27-c71cdbf67fdd") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1803ms
2020-05-08T12:17:20.053-0700 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965438, 125), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b40bfd1d-25f8-45ac-b19b-596c2e513dff") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1230ms
2020-05-08T12:17:20.053-0700 I  NETWORK  [conn163] end connection 192.168.122.1:58464 (22 connections now open)
2020-05-08T12:17:20.075-0700 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("c94d1e10-01ae-4320-af27-c71cdbf67fdd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965438, 51) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:19121, timeActiveMicros:1824361, timeInactiveMicros:2434, 1826ms
2020-05-08T12:17:20.100-0700 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("400fc9db-f578-4593-81a0-f2f06ed811bf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965438, 125) } }, globalReadTimestamp:{ ts: Timestamp(1588965438, 125) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:39314, timeActiveMicros:1276970, timeInactiveMicros:1060, 1278ms
2020-05-08T12:17:20.150-0700 I  NETWORK  [conn168] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:20.151-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:20.166-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:20.168-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:21.478-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n4:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T12:17:21.527-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n4:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:21.889-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:21.890-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:21.891-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:22.319-0700 I  NETWORK  [conn168] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:22.321-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:22.516-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:22.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:22.951-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n4:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:23.321-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:23.321-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:23.322-0700 I  COMMAND  [conn168] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("400fc9db-f578-4593-81a0-f2f06ed811bf") }, txnNumber: 4, autocommit: false } numYields:0 reslen:544 protocol:op_msg 3151ms
2020-05-08T12:17:24.318-0700 I  NETWORK  [conn172] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:24.319-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:24.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:25.133-0700 I  NETWORK  [conn169] end connection 192.168.122.1:58640 (21 connections now open)
2020-05-08T12:17:25.134-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58982 #174 (22 connections now open)
2020-05-08T12:17:25.134-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58984 #175 (23 connections now open)
2020-05-08T12:17:25.134-0700 I  NETWORK  [conn174] received client metadata from 192.168.122.1:58982 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.134-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.1:58984 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.165-0700 I  NETWORK  [conn173] end connection 192.168.122.1:58774 (22 connections now open)
2020-05-08T12:17:25.166-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59008 #176 (23 connections now open)
2020-05-08T12:17:25.166-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59010 #177 (24 connections now open)
2020-05-08T12:17:25.166-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.1:59008 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.166-0700 I  NETWORK  [conn177] received client metadata from 192.168.122.1:59010 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.169-0700 I  -        [conn172] operation was interrupted because a client disconnected
2020-05-08T12:17:25.169-0700 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("19834f1c-c9be-4d86-ab6d-53290d47853c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 37, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 78) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004080, timeInactiveMicros:0, 5004ms
2020-05-08T12:17:25.169-0700 I  COMMAND  [conn172] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 207 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965440, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("19834f1c-c9be-4d86-ab6d-53290d47853c") }, txnNumber: 37, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:25.170-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:25.170-0700 I  NETWORK  [conn172] end connection 192.168.122.1:58772 (23 connections now open)
2020-05-08T12:17:25.170-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:25.171-0700 I  COMMAND  [conn168] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965443, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("400fc9db-f578-4593-81a0-f2f06ed811bf") }, txnNumber: 4, autocommit: false } numYields:0 reslen:544 protocol:op_msg 1847ms
2020-05-08T12:17:25.171-0700 I  NETWORK  [conn168] end connection 192.168.122.1:58638 (22 connections now open)
2020-05-08T12:17:25.231-0700 I  NETWORK  [conn171] end connection 192.168.122.1:58678 (21 connections now open)
2020-05-08T12:17:25.232-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59034 #178 (22 connections now open)
2020-05-08T12:17:25.232-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59036 #179 (23 connections now open)
2020-05-08T12:17:25.232-0700 I  NETWORK  [conn178] received client metadata from 192.168.122.1:59034 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.232-0700 I  NETWORK  [conn179] received client metadata from 192.168.122.1:59036 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:17:25.863-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.932-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 2917 timed out, deadline was 2020-05-08T12:17:25.932-0700, op was RemoteCommand 2917 -- target:[n2:27019] db:config expDate:2020-05-08T12:17:25.932-0700 cmd:{ update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000 }
2020-05-08T12:17:25.932-0700 I  CONNPOOL [ShardRegistry] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 4 connections to that host remain open
2020-05-08T12:17:25.932-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Operation timed out with status NetworkInterfaceExceededTimeLimit: Request 2917 timed out, deadline was 2020-05-08T12:17:25.932-0700, op was RemoteCommand 2917 -- target:[n2:27019] db:config expDate:2020-05-08T12:17:25.932-0700 cmd:{ update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000 }
2020-05-08T12:17:25.932-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: NetworkInterfaceExceededTimeLimit: Request 2917 timed out, deadline was 2020-05-08T12:17:25.932-0700, op was RemoteCommand 2917 -- target:[n2:27019] db:config expDate:2020-05-08T12:17:25.932-0700 cmd:{ update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000 }
2020-05-08T12:17:26.017-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:26.517-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:27.517-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:27.517-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:27.561-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.561-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:28.709-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:28.709-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:28.709-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T12:17:29.007-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965434, 11), t: 23 }, now { ts: Timestamp(1588965448, 18), t: 28 }
2020-05-08T12:17:29.567-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965448, 18), t: 28 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T12:17:30.134-0700 I  NETWORK  [conn175] end connection 192.168.122.1:58984 (22 connections now open)
2020-05-08T12:17:30.135-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59290 #183 (23 connections now open)
2020-05-08T12:17:30.136-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59294 #184 (24 connections now open)
2020-05-08T12:17:30.136-0700 I  NETWORK  [conn183] received client metadata from 192.168.122.1:59290 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.136-0700 I  NETWORK  [conn184] received client metadata from 192.168.122.1:59294 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.141-0700 I  -        [conn174] operation was interrupted because a client disconnected
2020-05-08T12:17:30.141-0700 I  CONNPOOL [conn174] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:30.142-0700 I  TXN      [conn174] transaction parameters:{ lsid: { id: UUID("9cc23e79-9c8c-4618-97a8-5f642a8d5ea3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965443, 6) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005879, timeInactiveMicros:0, 5005ms
2020-05-08T12:17:30.142-0700 I  COMMAND  [conn174] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 212 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9cc23e79-9c8c-4618-97a8-5f642a8d5ea3") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:17:30.142-0700 I  NETWORK  [conn174] end connection 192.168.122.1:58982 (23 connections now open)
2020-05-08T12:17:30.166-0700 I  NETWORK  [conn177] end connection 192.168.122.1:59010 (22 connections now open)
2020-05-08T12:17:30.167-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59304 #185 (23 connections now open)
2020-05-08T12:17:30.167-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59306 #186 (24 connections now open)
2020-05-08T12:17:30.168-0700 I  NETWORK  [conn185] received client metadata from 192.168.122.1:59304 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.168-0700 I  NETWORK  [conn186] received client metadata from 192.168.122.1:59306 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.169-0700 I  -        [conn176] operation was interrupted because a client disconnected
2020-05-08T12:17:30.169-0700 I  CONNPOOL [conn176] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T12:17:30.169-0700 I  COMMAND  [conn176] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b0ef8629-014a-4e92-8a1b-8a122b3c5ff2") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T12:17:30.170-0700 I  NETWORK  [conn176] end connection 192.168.122.1:59008 (23 connections now open)
2020-05-08T12:17:30.170-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:30.232-0700 I  NETWORK  [conn179] end connection 192.168.122.1:59036 (22 connections now open)
2020-05-08T12:17:30.233-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59332 #188 (23 connections now open)
2020-05-08T12:17:30.233-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59334 #189 (24 connections now open)
2020-05-08T12:17:30.233-0700 I  NETWORK  [conn188] received client metadata from 192.168.122.1:59332 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.233-0700 I  NETWORK  [conn189] received client metadata from 192.168.122.1:59334 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:17:35.136-0700 I  NETWORK  [conn184] end connection 192.168.122.1:59294 (23 connections now open)
2020-05-08T12:17:35.136-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59554 #192 (24 connections now open)
2020-05-08T12:17:35.136-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59556 #193 (25 connections now open)
2020-05-08T12:17:35.137-0700 I  NETWORK  [conn192] received client metadata from 192.168.122.1:59554 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.137-0700 I  NETWORK  [conn193] received client metadata from 192.168.122.1:59556 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.139-0700 I  NETWORK  [conn192] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:35.140-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:35.140-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:35.141-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:35.168-0700 I  NETWORK  [conn186] end connection 192.168.122.1:59306 (24 connections now open)
2020-05-08T12:17:35.168-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59568 #194 (25 connections now open)
2020-05-08T12:17:35.169-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59570 #195 (26 connections now open)
2020-05-08T12:17:35.169-0700 I  NETWORK  [conn194] received client metadata from 192.168.122.1:59568 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.169-0700 I  NETWORK  [conn195] received client metadata from 192.168.122.1:59570 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.173-0700 I  -        [conn185] operation was interrupted because a client disconnected
2020-05-08T12:17:35.173-0700 I  CONNPOOL [conn185] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:35.173-0700 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("eeb75a73-7bf2-45fd-8e30-696a965c158a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965449, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003886, timeInactiveMicros:0, 5003ms
2020-05-08T12:17:35.173-0700 I  COMMAND  [conn185] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 216 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965449, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eeb75a73-7bf2-45fd-8e30-696a965c158a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:35.174-0700 I  NETWORK  [conn185] end connection 192.168.122.1:59304 (25 connections now open)
2020-05-08T12:17:35.234-0700 I  NETWORK  [conn189] end connection 192.168.122.1:59334 (24 connections now open)
2020-05-08T12:17:35.234-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59594 #196 (25 connections now open)
2020-05-08T12:17:35.235-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59596 #197 (26 connections now open)
2020-05-08T12:17:35.235-0700 I  NETWORK  [conn196] received client metadata from 192.168.122.1:59594 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.235-0700 I  NETWORK  [conn197] received client metadata from 192.168.122.1:59596 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.237-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:35.524-0700 I  SHARDING [conn194] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965448, 18), t: 28 }, now { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T12:17:35.525-0700 I  COMMAND  [conn194] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75a46884-3c11-4579-bdf2-cc023361ea53") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 353ms
2020-05-08T12:17:35.525-0700 I  COMMAND  [conn192] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 222 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965450, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a24f41ac-8a45-406e-bd0b-643abcc29930") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 387ms
2020-05-08T12:17:35.612-0700 I  NETWORK  [conn194] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:35.613-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:35.639-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:36.139-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:36.139-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:36.140-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T12:17:36.642-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:36.642-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:36.647-0700 I  NETWORK  [conn194] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:36.647-0700 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("a24f41ac-8a45-406e-bd0b-643abcc29930"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965450, 5) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:1120195, timeActiveMicros:1508269, timeInactiveMicros:1031, 1509ms
2020-05-08T12:17:36.649-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:36.706-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:37.147-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:37.647-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:37.648-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:37.649-0700 I  COMMAND  [conn192] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965455, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a24f41ac-8a45-406e-bd0b-643abcc29930") }, txnNumber: 1, autocommit: false } numYields:0 reslen:463 protocol:op_msg 2122ms
2020-05-08T12:17:38.662-0700 I  TXN      [conn194] transaction parameters:{ lsid: { id: UUID("75a46884-3c11-4579-bdf2-cc023361ea53"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965453, 12) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3135568, timeActiveMicros:3490070, timeInactiveMicros:673, 3490ms
2020-05-08T12:17:38.662-0700 I  COMMAND  [conn194] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75a46884-3c11-4579-bdf2-cc023361ea53") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3135ms
2020-05-08T12:17:38.663-0700 I  COMMAND  [conn192] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965457, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a24f41ac-8a45-406e-bd0b-643abcc29930") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1011ms
2020-05-08T12:17:38.663-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:39.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:17:39.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:17:40.142-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n2:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5366 timed out, deadline was 2020-05-08T12:17:40.142-0700, op was RemoteCommand 5366 -- target:[n2:27019] db:admin expDate:2020-05-08T12:17:40.142-0700 cmd:{ isMaster: 1 }
2020-05-08T12:17:40.142-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T12:17:40.142-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:40.235-0700 I  NETWORK  [conn197] end connection 192.168.122.1:59596 (25 connections now open)
2020-05-08T12:17:40.236-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59910 #207 (26 connections now open)
2020-05-08T12:17:40.236-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59912 #208 (27 connections now open)
2020-05-08T12:17:40.237-0700 I  NETWORK  [conn207] received client metadata from 192.168.122.1:59910 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.237-0700 I  NETWORK  [conn208] received client metadata from 192.168.122.1:59912 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.239-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:40.241-0700 I  -        [conn196] operation was interrupted because a client disconnected
2020-05-08T12:17:40.241-0700 I  CONNPOOL [conn196] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T12:17:40.242-0700 I  COMMAND  [conn196] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 223 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5903bc0-5a58-480e-9087-df2fa20ea564") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:17:40.242-0700 I  NETWORK  [conn196] end connection 192.168.122.1:59594 (26 connections now open)
2020-05-08T12:17:41.140-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n1:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5389 timed out, deadline was 2020-05-08T12:17:41.140-0700, op was RemoteCommand 5389 -- target:[n1:27019] db:admin expDate:2020-05-08T12:17:41.140-0700 cmd:{ isMaster: 1 }
2020-05-08T12:17:41.140-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:41.140-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-08T12:17:42.063-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:42.063-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:42.065-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:42.565-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:43.065-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:43.066-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:43.628-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:43.629-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:43.664-0700 I  NETWORK  [conn195] end connection 192.168.122.1:59570 (25 connections now open)
2020-05-08T12:17:43.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60090 #211 (26 connections now open)
2020-05-08T12:17:43.666-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60092 #212 (27 connections now open)
2020-05-08T12:17:43.666-0700 I  NETWORK  [conn211] received client metadata from 192.168.122.1:60090 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:43.666-0700 I  NETWORK  [conn212] received client metadata from 192.168.122.1:60092 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:43.668-0700 I  -        [conn194] operation was interrupted because a client disconnected
2020-05-08T12:17:43.669-0700 I  CONNPOOL [conn194] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T12:17:43.669-0700 I  COMMAND  [conn194] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 223 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965458, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75a46884-3c11-4579-bdf2-cc023361ea53") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:17:43.669-0700 I  NETWORK  [conn194] end connection 192.168.122.1:59568 (26 connections now open)
2020-05-08T12:17:43.681-0700 I  NETWORK  [conn193] end connection 192.168.122.1:59556 (25 connections now open)
2020-05-08T12:17:43.682-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60096 #213 (26 connections now open)
2020-05-08T12:17:43.682-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60098 #214 (27 connections now open)
2020-05-08T12:17:43.683-0700 I  NETWORK  [conn213] received client metadata from 192.168.122.1:60096 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:43.683-0700 I  NETWORK  [conn214] received client metadata from 192.168.122.1:60098 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:43.685-0700 I  -        [conn192] operation was interrupted because a client disconnected
2020-05-08T12:17:43.685-0700 I  CONNPOOL [conn192] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T12:17:43.685-0700 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("a24f41ac-8a45-406e-bd0b-643abcc29930"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965458, 7) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004383, timeInactiveMicros:0, 5004ms
2020-05-08T12:17:43.686-0700 I  COMMAND  [conn192] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 223 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965458, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a24f41ac-8a45-406e-bd0b-643abcc29930") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:43.686-0700 I  NETWORK  [conn192] end connection 192.168.122.1:59554 (26 connections now open)
2020-05-08T12:17:43.889-0700 I  NETWORK  [conn211] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:43.890-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:43.891-0700 I  NETWORK  [conn213] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:43.892-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:44.090-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n7:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:44.390-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:44.391-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:44.392-0700 I  COMMAND  [conn213] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965463, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2d7c55d2-298a-440b-8bea-9b9aa2a087d3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 697ms
2020-05-08T12:17:44.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.237-0700 I  NETWORK  [conn208] end connection 192.168.122.1:59912 (25 connections now open)
2020-05-08T12:17:45.237-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60188 #215 (26 connections now open)
2020-05-08T12:17:45.237-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60190 #216 (27 connections now open)
2020-05-08T12:17:45.238-0700 I  NETWORK  [conn215] received client metadata from 192.168.122.1:60188 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.238-0700 I  NETWORK  [conn216] received client metadata from 192.168.122.1:60190 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.241-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.656-0700 I  NETWORK  [conn211] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:45.657-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:45.740-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.157-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.405-0700 I  NETWORK  [Uptime-reporter] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:46.409-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:46.657-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.740-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.909-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:46.909-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:47.157-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:47.157-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:47.158-0700 I  COMMAND  [conn213] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965464, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2d7c55d2-298a-440b-8bea-9b9aa2a087d3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2764ms
2020-05-08T12:17:47.159-0700 I  COMMAND  [conn211] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965463, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b616dbab-3a25-4327-a199-f8ae394baf36") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3491ms
2020-05-08T12:17:47.171-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.208-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.406-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:47.407-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:47.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:48.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:48.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.241-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.238-0700 I  NETWORK  [conn216] end connection 192.168.122.1:60190 (26 connections now open)
2020-05-08T12:17:50.238-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60372 #217 (27 connections now open)
2020-05-08T12:17:50.238-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60374 #218 (28 connections now open)
2020-05-08T12:17:50.239-0700 I  NETWORK  [conn217] received client metadata from 192.168.122.1:60372 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.239-0700 I  NETWORK  [conn218] received client metadata from 192.168.122.1:60374 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.241-0700 I  NETWORK  [conn217] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:50.242-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:50.242-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:50.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:51.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:51.740-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:51.909-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n1:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5526 timed out, deadline was 2020-05-08T12:17:51.909-0700, op was RemoteCommand 5526 -- target:[n1:27019] db:admin expDate:2020-05-08T12:17:51.909-0700 cmd:{ isMaster: 1 }
2020-05-08T12:17:51.909-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n2:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5524 timed out, deadline was 2020-05-08T12:17:51.909-0700, op was RemoteCommand 5524 -- target:[n2:27019] db:admin expDate:2020-05-08T12:17:51.909-0700 cmd:{ isMaster: 1 }
2020-05-08T12:17:51.909-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T12:17:51.909-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-08T12:17:51.909-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:51.910-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:51.912-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:52.173-0700 I  -        [conn211] operation was interrupted because a client disconnected
2020-05-08T12:17:52.173-0700 I  TXN      [conn211] transaction parameters:{ lsid: { id: UUID("b616dbab-3a25-4327-a199-f8ae394baf36"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965466, 3) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5013044, timeInactiveMicros:527, 5013ms
2020-05-08T12:17:52.174-0700 I  COMMAND  [conn211] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 233 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965467, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b616dbab-3a25-4327-a199-f8ae394baf36") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T12:17:52.174-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60418 #221 (29 connections now open)
2020-05-08T12:17:52.174-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:52.174-0700 I  NETWORK  [conn211] end connection 192.168.122.1:60090 (28 connections now open)
2020-05-08T12:17:52.174-0700 I  NETWORK  [conn221] received client metadata from 192.168.122.1:60418 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:52.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:52.210-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60424 #222 (29 connections now open)
2020-05-08T12:17:52.210-0700 I  NETWORK  [conn222] received client metadata from 192.168.122.1:60424 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:52.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:52.409-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:52.409-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:52.740-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:53.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:53.313-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n8:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:53.339-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965453, 11), t: 29 }, now { ts: Timestamp(1588965471, 2), t: 35 }
2020-05-08T12:17:53.740-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:54.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:54.740-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:54.950-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n9:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:55.239-0700 I  NETWORK  [conn217] end connection 192.168.122.1:60372 (28 connections now open)
2020-05-08T12:17:55.240-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60464 #223 (29 connections now open)
2020-05-08T12:17:55.240-0700 I  NETWORK  [conn223] received client metadata from 192.168.122.1:60464 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:55.243-0700 I  NETWORK  [conn212] end connection 192.168.122.1:60092 (28 connections now open)
2020-05-08T12:17:55.243-0700 I  NETWORK  [conn223] end connection 192.168.122.1:60464 (27 connections now open)
2020-05-08T12:17:55.244-0700 I  NETWORK  [conn214] end connection 192.168.122.1:60098 (26 connections now open)
2020-05-08T12:17:55.247-0700 I  NETWORK  [conn218] end connection 192.168.122.1:60374 (25 connections now open)
2020-05-08T12:17:55.251-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60474 #224 (26 connections now open)
2020-05-08T12:17:55.252-0700 I  NETWORK  [conn224] received client metadata from 192.168.122.1:60474 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.252-0700 I  NETWORK  [conn224] end connection 192.168.122.1:60474 (25 connections now open)
2020-05-08T12:17:55.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:56.240-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:56.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
