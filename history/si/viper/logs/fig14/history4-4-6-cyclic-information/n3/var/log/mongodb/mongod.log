2020-05-08T12:15:36.244-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T12:15:36.261-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=650730 port=27019 dbpath=/var/lib/mongodb 64-bit host=n3
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] modules: none
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] build environment:
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-08T12:15:36.261-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-08T12:15:36.262-0700 I  STORAGE  [initandlisten] 
2020-05-08T12:15:36.262-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-08T12:15:36.262-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-08T12:15:36.262-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-08T12:15:37.001-0700 I  STORAGE  [initandlisten] WiredTiger message [1588965337:1153][650730:0x7ffaf71fd140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-08T12:15:37.062-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-08T12:15:37.116-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.143-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-08T12:15:37.144-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-08T12:15:37.144-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-08T12:15:37.144-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-08T12:15:37.144-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 25fe7c5f-f058-4bb0-841f-24ae6dd2e986 and options: { capped: true, size: 10485760 }
2020-05-08T12:15:37.195-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-08T12:15:37.196-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-08T12:15:37.196-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-08T12:15:37.202-0700 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-05-08T12:15:37.202-0700 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-05-08T12:15:37.202-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: ccdc42d3-3d68-4fe5-96f3-d555eec25b41 and options: {}
2020-05-08T12:15:37.252-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-08T12:15:37.252-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 5341c7b0-8f92-4695-a3e0-891a9c3b85c0 and options: {}
2020-05-08T12:15:37.306-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-08T12:15:37.306-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-08T12:15:37.306-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 554175a3-86b6-4c6d-b39c-96b2acc83ef9 and options: {}
2020-05-08T12:15:37.363-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-08T12:15:37.363-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-08T12:15:37.363-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-08T12:15:37.363-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-08T12:15:37.363-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 382a3739-2489-479e-b71d-329e9d1d3326 and options: {}
2020-05-08T12:15:37.417-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-08T12:15:37.417-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-08T12:15:37.417-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-08T12:15:37.417-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-08T12:15:37.419-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("5de0b739-f527-41dd-a4b2-053f44abbff9"), lastMod: 0 } took 0 ms
2020-05-08T12:15:37.419-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-05-08T12:15:37.420-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T12:15:37.420-0700 I  NETWORK  [listener] waiting for connections on port 27019
2020-05-08T12:15:37.420-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-05-08T12:15:37.421-0700 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-05-08T12:15:37.421-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-05-08T12:15:38.000-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-08T12:15:38.296-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57142 #1 (1 connection now open)
2020-05-08T12:15:38.297-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:57142 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:38.297-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57154 #2 (2 connections now open)
2020-05-08T12:15:38.298-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:57154 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:38.300-0700 I  NETWORK  [conn1] end connection 192.168.122.1:57142 (1 connection now open)
2020-05-08T12:15:38.300-0700 I  NETWORK  [conn2] end connection 192.168.122.1:57154 (0 connections now open)
2020-05-08T12:15:38.335-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35534 #3 (1 connection now open)
2020-05-08T12:15:38.335-0700 I  NETWORK  [conn3] end connection 192.168.122.11:35534 (0 connections now open)
2020-05-08T12:15:38.337-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35538 #4 (1 connection now open)
2020-05-08T12:15:38.337-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.11:35538 conn4: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:38.338-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:15:38.876-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:55532 #6 (2 connections now open)
2020-05-08T12:15:38.877-0700 I  NETWORK  [conn6] end connection 192.168.122.12:55532 (1 connection now open)
2020-05-08T12:15:38.878-0700 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: 4299b416-1d08-407f-bcc2-543a4d9fcce1 and options: {}
2020-05-08T12:15:38.935-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2020-05-08T12:15:38.936-0700 I  REPL     [replexec-0] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n1:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n2:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n3:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb5afdaa0224cfb413c716c') } }
2020-05-08T12:15:38.936-0700 I  REPL     [replexec-0] This node is n3:27019 in the config
2020-05-08T12:15:38.936-0700 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2020-05-08T12:15:38.937-0700 I  REPL     [replexec-0] Starting replication storage threads
2020-05-08T12:15:38.937-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:15:38.937-0700 I  REPL     [replexec-3] Member n1:27019 is now in state SECONDARY
2020-05-08T12:15:38.938-0700 I  REPL     [replexec-2] Member n2:27019 is now in state STARTUP
2020-05-08T12:15:38.939-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:55546 #10 (2 connections now open)
2020-05-08T12:15:38.939-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.12:55546 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:38.941-0700 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: 6b4aac1b-681b-4bc3-b526-74667e438d6e and options: { temp: true }
2020-05-08T12:15:39.000-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-08T12:15:39.000-0700 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2020-05-08T12:15:39.001-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (6b4aac1b-681b-4bc3-b526-74667e438d6e).
2020-05-08T12:15:39.010-0700 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: ab9cd3ff-293f-4ce2-8816-1412e70eb09f and options: { temp: true }
2020-05-08T12:15:39.067-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-08T12:15:39.067-0700 I  REPL     [replication-0] sync source candidate: n1:27019
2020-05-08T12:15:39.067-0700 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2020-05-08T12:15:39.067-0700 I  REPL     [replication-0] ******
2020-05-08T12:15:39.067-0700 I  REPL     [replication-0] creating replication oplog of size: 36643MB...
2020-05-08T12:15:39.067-0700 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: e4b6d940-9ade-4e27-bb87-2b4c1b1a6d23 and options: { capped: true, size: 38423989657.0, autoIndexId: false }
2020-05-08T12:15:39.124-0700 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2020-05-08T12:15:39.124-0700 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-08T12:15:39.124-0700 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:15:39.125-0700 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2020-05-08T12:15:39.438-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP2
2020-05-08T12:15:39.479-0700 I  REPL     [replication-0] ******
2020-05-08T12:15:39.479-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2020-05-08T12:15:39.479-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2020-05-08T12:15:39.479-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-08T12:15:39.483-0700 I  SHARDING [replication-1] Marking collection local.temp_oplog_buffer as collection version: <unsharded>
2020-05-08T12:15:39.484-0700 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:admin.system.version
2020-05-08T12:15:39.485-0700 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: 9776b654-fbe0-4ade-a717-5da68907cd8a and options: { uuid: UUID("9776b654-fbe0-4ade-a717-5da68907cd8a") }
2020-05-08T12:15:39.614-0700 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2020-05-08T12:15:39.614-0700 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:39.616-0700 I  COMMAND  [repl-writer-worker-15] setting featureCompatibilityVersion to 4.2
2020-05-08T12:15:39.616-0700 I  NETWORK  [repl-writer-worker-15] Skip closing connection for connection # 10
2020-05-08T12:15:39.616-0700 I  NETWORK  [repl-writer-worker-15] Skip closing connection for connection # 4
2020-05-08T12:15:39.616-0700 I  INITSYNC [replication-1] CollectionCloner ns:admin.system.version finished cloning with status: OK
2020-05-08T12:15:39.618-0700 I  INDEX    [replication-1] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-05-08T12:15:39.635-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns admin.system.version
2020-05-08T12:15:39.637-0700 I  INITSYNC [replication-1] Finished cloning data: OK. Beginning oplog replay.
2020-05-08T12:15:39.638-0700 I  INITSYNC [replication-0] No need to apply operations. (currently at { : Timestamp(1588965338, 1) })
2020-05-08T12:15:39.639-0700 I  SHARDING [replication-1] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-08T12:15:39.640-0700 I  INITSYNC [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(0, 0), t: -1 }
2020-05-08T12:15:39.640-0700 I  INITSYNC [replication-1] Initial sync attempt finishing up.
2020-05-08T12:15:39.640-0700 I  INITSYNC [replication-1] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1588965339000), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1588965338, 1), initialSyncOplogEnd: Timestamp(1588965338, 1), databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1588965339483), end: new Date(1588965339638), elapsedMillis: 155, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1588965339484), end: new Date(1588965339638), elapsedMillis: 154, receivedBatches: 1 } } } }
2020-05-08T12:15:39.640-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:15:39.640-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (ab9cd3ff-293f-4ce2-8816-1412e70eb09f).
2020-05-08T12:15:39.663-0700 I  SHARDING [replication-0] Marking collection config.transactions as collection version: <unsharded>
2020-05-08T12:15:39.676-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965338, 1), t: -1 } }
2020-05-08T12:15:39.678-0700 I  ELECTION [conn4] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2020-05-08T12:15:39.678-0700 I  INITSYNC [replication-0] initial sync done; took 0s.
2020-05-08T12:15:39.678-0700 I  REPL     [replication-0] transition to RECOVERING from STARTUP2
2020-05-08T12:15:39.678-0700 I  REPL     [replication-0] Starting replication fetcher thread
2020-05-08T12:15:39.678-0700 I  REPL     [replication-0] Starting replication applier thread
2020-05-08T12:15:39.678-0700 I  REPL     [replication-0] Starting replication reporter thread
2020-05-08T12:15:39.678-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-08T12:15:39.679-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:15:39.680-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-08T12:15:39.680-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-08T12:15:39.681-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-08T12:15:39.695-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965338, 1), t: -1 } }
2020-05-08T12:15:39.695-0700 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-08T12:15:40.180-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-08T12:15:40.604-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57340 #14 (3 connections now open)
2020-05-08T12:15:40.604-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:57340 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:40.605-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57352 #15 (4 connections now open)
2020-05-08T12:15:40.605-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.1:57352 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:40.612-0700 I  NETWORK  [conn14] end connection 192.168.122.1:57340 (3 connections now open)
2020-05-08T12:15:40.612-0700 I  NETWORK  [conn15] end connection 192.168.122.1:57352 (2 connections now open)
2020-05-08T12:15:40.680-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-08T12:15:41.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35736 #16 (3 connections now open)
2020-05-08T12:15:41.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:53272 #17 (4 connections now open)
2020-05-08T12:15:41.269-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.11:35736 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.269-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.13:53272 conn17: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:53342 #18 (5 connections now open)
2020-05-08T12:15:41.269-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.16:53342 conn18: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.289-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38756 #19 (6 connections now open)
2020-05-08T12:15:41.289-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.15:38756 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.290-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53556 #20 (7 connections now open)
2020-05-08T12:15:41.290-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.14:53556 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.291-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38770 #21 (8 connections now open)
2020-05-08T12:15:41.291-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.15:38770 conn21: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.297-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:33110 #22 (9 connections now open)
2020-05-08T12:15:41.297-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.19:33110 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.297-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:50284 #23 (10 connections now open)
2020-05-08T12:15:41.298-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.18:50284 conn23: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.300-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:46272 #24 (11 connections now open)
2020-05-08T12:15:41.301-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.17:46272 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.313-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:55742 #25 (12 connections now open)
2020-05-08T12:15:41.313-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.12:55742 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.372-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:50336 #26 (13 connections now open)
2020-05-08T12:15:41.373-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:33170 #27 (14 connections now open)
2020-05-08T12:15:41.373-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.18:50336 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.373-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53630 #28 (15 connections now open)
2020-05-08T12:15:41.373-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.19:33170 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.373-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:46324 #29 (16 connections now open)
2020-05-08T12:15:41.373-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.14:53630 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.374-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:46326 #30 (17 connections now open)
2020-05-08T12:15:41.374-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.17:46324 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.374-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:50346 #31 (18 connections now open)
2020-05-08T12:15:41.374-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.17:46326 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.375-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:33178 #32 (19 connections now open)
2020-05-08T12:15:41.375-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.18:50346 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.375-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53642 #33 (20 connections now open)
2020-05-08T12:15:41.375-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.19:33178 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.375-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:55800 #34 (21 connections now open)
2020-05-08T12:15:41.375-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.14:53642 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.375-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:50364 #35 (22 connections now open)
2020-05-08T12:15:41.376-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.12:55800 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.376-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.18:50364 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.409-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-08T12:15:41.413-0700 I  STORAGE  [repl-writer-worker-2] createCollection: config.transactions with provided UUID: 102592d2-904e-4bad-918e-733bcd99a988 and options: { uuid: UUID("102592d2-904e-4bad-918e-733bcd99a988") }
2020-05-08T12:15:41.462-0700 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns config.transactions
2020-05-08T12:15:41.462-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-08T12:15:41.465-0700 I  STORAGE  [repl-writer-worker-6] createCollection: config.chunks with provided UUID: 2d652394-987f-4aa4-a6e9-0606d5d5533d and options: { uuid: UUID("2d652394-987f-4aa4-a6e9-0606d5d5533d") }
2020-05-08T12:15:41.519-0700 I  INDEX    [repl-writer-worker-6] index build: done building index _id_ on ns config.chunks
2020-05-08T12:15:41.597-0700 I  INDEX    [repl-writer-worker-10] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-08T12:15:41.597-0700 I  INDEX    [repl-writer-worker-10] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:41.597-0700 I  STORAGE  [repl-writer-worker-10] Index build initialized: 6a4c75bb-c752-4e3a-979b-58405ef1ee36: config.chunks (2d652394-987f-4aa4-a6e9-0606d5d5533d ): indexes: 1
2020-05-08T12:15:41.598-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:41.599-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:41.609-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-05-08T12:15:41.618-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 6a4c75bb-c752-4e3a-979b-58405ef1ee36: config.chunks ( 2d652394-987f-4aa4-a6e9-0606d5d5533d ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-08T12:15:41.682-0700 I  INDEX    [repl-writer-worker-14] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-08T12:15:41.682-0700 I  INDEX    [repl-writer-worker-14] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:41.682-0700 I  STORAGE  [repl-writer-worker-14] Index build initialized: c92425e8-58b0-4867-9990-ec739ad7ca01: config.chunks (2d652394-987f-4aa4-a6e9-0606d5d5533d ): indexes: 1
2020-05-08T12:15:41.683-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:41.685-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:41.690-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-05-08T12:15:41.699-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: c92425e8-58b0-4867-9990-ec739ad7ca01: config.chunks ( 2d652394-987f-4aa4-a6e9-0606d5d5533d ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-05-08T12:15:41.773-0700 I  INDEX    [repl-writer-worker-2] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-05-08T12:15:41.773-0700 I  INDEX    [repl-writer-worker-2] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:41.773-0700 I  STORAGE  [repl-writer-worker-2] Index build initialized: 4676b2c1-a402-4f6d-a6ed-973f36565344: config.chunks (2d652394-987f-4aa4-a6e9-0606d5d5533d ): indexes: 1
2020-05-08T12:15:41.773-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:41.775-0700 I  STORAGE  [repl-writer-worker-4] createCollection: config.migrations with provided UUID: 2a55a29f-6ce9-4f79-b893-278af01d545c and options: { uuid: UUID("2a55a29f-6ce9-4f79-b893-278af01d545c") }
2020-05-08T12:15:41.775-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:41.776-0700 I  STORAGE  [replication-1] Triggering the first stable checkpoint. Initial Data: Timestamp(1588965338, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1588965340, 4)
2020-05-08T12:15:41.776-0700 I  SHARDING [conn28] Marking collection admin.system.keys as collection version: <unsharded>
2020-05-08T12:15:41.776-0700 I  SHARDING [conn29] Marking collection config.version as collection version: <unsharded>
2020-05-08T12:15:41.776-0700 I  SHARDING [conn30] Marking collection config.shards as collection version: <unsharded>
2020-05-08T12:15:41.814-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-05-08T12:15:41.838-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 4676b2c1-a402-4f6d-a6ed-973f36565344: config.chunks ( 2d652394-987f-4aa4-a6e9-0606d5d5533d ). Index specs built: 1. Indexes in catalog before build: 3. Indexes in catalog after build: 4
2020-05-08T12:15:41.839-0700 I  INDEX    [repl-writer-worker-4] index build: done building index _id_ on ns config.migrations
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn32] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 401ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn33] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:550 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 401ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn21] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 485ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn28] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 402ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn31] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 401ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn27] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 402ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn35] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 400ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn34] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 400ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn26] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:550 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 403ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn30] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 401ms
2020-05-08T12:15:41.840-0700 I  COMMAND  [conn29] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:550 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 401ms
2020-05-08T12:15:41.927-0700 I  INDEX    [repl-writer-worker-8] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-05-08T12:15:41.927-0700 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:41.927-0700 I  STORAGE  [repl-writer-worker-8] Index build initialized: 66528755-2d75-4fdb-b807-043d6678546c: config.migrations (2a55a29f-6ce9-4f79-b893-278af01d545c ): indexes: 1
2020-05-08T12:15:41.927-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:41.929-0700 I  STORAGE  [repl-writer-worker-10] createCollection: config.shards with provided UUID: f0fccbd1-5de7-40cd-aa99-5999ae922b22 and options: { uuid: UUID("f0fccbd1-5de7-40cd-aa99-5999ae922b22") }
2020-05-08T12:15:41.930-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:41.961-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.migrations
2020-05-08T12:15:41.989-0700 I  INDEX    [repl-writer-worker-10] index build: done building index _id_ on ns config.shards
2020-05-08T12:15:41.995-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 66528755-2d75-4fdb-b807-043d6678546c: config.migrations ( 2a55a29f-6ce9-4f79-b893-278af01d545c ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-08T12:15:42.064-0700 I  INDEX    [repl-writer-worker-14] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-05-08T12:15:42.064-0700 I  INDEX    [repl-writer-worker-14] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:42.064-0700 I  STORAGE  [repl-writer-worker-14] Index build initialized: fd1f7427-955e-43dc-b98c-a4d0bc9c78b1: config.shards (f0fccbd1-5de7-40cd-aa99-5999ae922b22 ): indexes: 1
2020-05-08T12:15:42.064-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:42.065-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:42.065-0700 I  STORAGE  [repl-writer-worker-15] createCollection: config.locks with provided UUID: f67e3cf8-f609-40d5-b10f-51cc8df9bd92 and options: { uuid: UUID("f67e3cf8-f609-40d5-b10f-51cc8df9bd92") }
2020-05-08T12:15:42.071-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index host_1 on ns config.shards
2020-05-08T12:15:42.116-0700 I  INDEX    [repl-writer-worker-15] index build: done building index _id_ on ns config.locks
2020-05-08T12:15:42.120-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: fd1f7427-955e-43dc-b98c-a4d0bc9c78b1: config.shards ( f0fccbd1-5de7-40cd-aa99-5999ae922b22 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-08T12:15:42.169-0700 I  INDEX    [repl-writer-worker-4] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-05-08T12:15:42.169-0700 I  INDEX    [repl-writer-worker-4] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:42.169-0700 I  STORAGE  [repl-writer-worker-4] Index build initialized: 2e525d53-7507-46cc-9ebf-3f860c4945a5: config.locks (f67e3cf8-f609-40d5-b10f-51cc8df9bd92 ): indexes: 1
2020-05-08T12:15:42.169-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:42.171-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:42.181-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ts_1 on ns config.locks
2020-05-08T12:15:42.184-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 2e525d53-7507-46cc-9ebf-3f860c4945a5: config.locks ( f67e3cf8-f609-40d5-b10f-51cc8df9bd92 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-08T12:15:42.236-0700 I  INDEX    [repl-writer-worker-8] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-05-08T12:15:42.236-0700 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:42.236-0700 I  STORAGE  [repl-writer-worker-8] Index build initialized: a0a1436d-8161-49aa-8757-b230eeb8c80a: config.locks (f67e3cf8-f609-40d5-b10f-51cc8df9bd92 ): indexes: 1
2020-05-08T12:15:42.236-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:42.238-0700 I  STORAGE  [repl-writer-worker-10] createCollection: config.lockpings with provided UUID: 81acf486-601b-4e2b-8ee1-bbf74a1edd96 and options: { uuid: UUID("81acf486-601b-4e2b-8ee1-bbf74a1edd96") }
2020-05-08T12:15:42.238-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:42.272-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index state_1_process_1 on ns config.locks
2020-05-08T12:15:42.273-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:53452 #37 (23 connections now open)
2020-05-08T12:15:42.273-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.13:53452 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.296-0700 I  INDEX    [repl-writer-worker-10] index build: done building index _id_ on ns config.lockpings
2020-05-08T12:15:42.297-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: a0a1436d-8161-49aa-8757-b230eeb8c80a: config.locks ( f67e3cf8-f609-40d5-b10f-51cc8df9bd92 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-05-08T12:15:42.343-0700 I  INDEX    [repl-writer-worker-14] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-05-08T12:15:42.343-0700 I  INDEX    [repl-writer-worker-14] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:42.344-0700 I  STORAGE  [repl-writer-worker-14] Index build initialized: 49d10d3c-780f-4e0b-aaca-6cfe45b653e4: config.lockpings (81acf486-601b-4e2b-8ee1-bbf74a1edd96 ): indexes: 1
2020-05-08T12:15:42.344-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:42.345-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:42.346-0700 I  STORAGE  [repl-writer-worker-15] createCollection: config.tags with provided UUID: bc4858df-e110-456c-83bd-e519d850f168 and options: { uuid: UUID("bc4858df-e110-456c-83bd-e519d850f168") }
2020-05-08T12:15:42.351-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ping_1 on ns config.lockpings
2020-05-08T12:15:42.373-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 49d10d3c-780f-4e0b-aaca-6cfe45b653e4: config.lockpings ( 81acf486-601b-4e2b-8ee1-bbf74a1edd96 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-08T12:15:42.395-0700 I  INDEX    [repl-writer-worker-15] index build: done building index _id_ on ns config.tags
2020-05-08T12:15:42.464-0700 I  INDEX    [repl-writer-worker-4] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-05-08T12:15:42.465-0700 I  INDEX    [repl-writer-worker-4] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:42.465-0700 I  STORAGE  [repl-writer-worker-4] Index build initialized: 95b53b74-5fa4-4ede-880a-bef2dee4ba3f: config.tags (bc4858df-e110-456c-83bd-e519d850f168 ): indexes: 1
2020-05-08T12:15:42.465-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:42.467-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:42.477-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.tags
2020-05-08T12:15:42.491-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 95b53b74-5fa4-4ede-880a-bef2dee4ba3f: config.tags ( bc4858df-e110-456c-83bd-e519d850f168 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-08T12:15:42.544-0700 I  INDEX    [repl-writer-worker-8] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-05-08T12:15:42.544-0700 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:42.545-0700 I  STORAGE  [repl-writer-worker-8] Index build initialized: ed035477-da73-4200-8489-9885363885f4: config.tags (bc4858df-e110-456c-83bd-e519d850f168 ): indexes: 1
2020-05-08T12:15:42.545-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:42.546-0700 I  STORAGE  [repl-writer-worker-10] createCollection: config.version with provided UUID: bed99a80-dcc6-4152-9366-8222f3d1172a and options: { uuid: UUID("bed99a80-dcc6-4152-9366-8222f3d1172a") }
2020-05-08T12:15:42.547-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:42.553-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-05-08T12:15:42.577-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: ed035477-da73-4200-8489-9885363885f4: config.tags ( bc4858df-e110-456c-83bd-e519d850f168 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-05-08T12:15:42.595-0700 I  INDEX    [repl-writer-worker-10] index build: done building index _id_ on ns config.version
2020-05-08T12:15:42.597-0700 I  SHARDING [repl-writer-worker-0] Marking collection config.lockpings as collection version: <unsharded>
2020-05-08T12:15:42.649-0700 I  STORAGE  [repl-writer-worker-4] createCollection: admin.system.keys with provided UUID: d89be7fe-6053-4310-be2b-4bff25fadfb8 and options: { uuid: UUID("d89be7fe-6053-4310-be2b-4bff25fadfb8") }
2020-05-08T12:15:42.700-0700 I  INDEX    [repl-writer-worker-4] index build: done building index _id_ on ns admin.system.keys
2020-05-08T12:15:42.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35946 #38 (24 connections now open)
2020-05-08T12:15:42.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:53544 #39 (25 connections now open)
2020-05-08T12:15:42.899-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.11:35946 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.900-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.16:53544 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:43.599-0700 I  SHARDING [conn27] Marking collection config.settings as collection version: <unsharded>
2020-05-08T12:15:43.607-0700 I  SHARDING [conn27] Marking collection config.collections as collection version: <unsharded>
2020-05-08T12:15:43.653-0700 I  STORAGE  [repl-writer-worker-10] createCollection: config.mongos with provided UUID: ed1a62fa-1d96-460b-b917-f8098f56b82b and options: { uuid: UUID("ed1a62fa-1d96-460b-b917-f8098f56b82b") }
2020-05-08T12:15:43.698-0700 I  INDEX    [repl-writer-worker-10] index build: done building index _id_ on ns config.mongos
2020-05-08T12:15:43.700-0700 I  SHARDING [repl-writer-worker-14] Marking collection config.mongos as collection version: <unsharded>
2020-05-08T12:15:45.376-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53856 #40 (26 connections now open)
2020-05-08T12:15:45.376-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.14:53856 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.382-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:53696 #41 (27 connections now open)
2020-05-08T12:15:45.383-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:39092 #42 (28 connections now open)
2020-05-08T12:15:45.383-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.16:53696 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.383-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.15:39092 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.386-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:53716 #43 (29 connections now open)
2020-05-08T12:15:45.387-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.16:53716 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.414-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53906 #44 (30 connections now open)
2020-05-08T12:15:45.414-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53908 #45 (31 connections now open)
2020-05-08T12:15:45.414-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.14:53906 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.415-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.14:53908 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.495-0700 I  STORAGE  [repl-writer-worker-1] createCollection: config.changelog with provided UUID: b5b04cc3-7329-463d-9284-d3319d7ed8dd and options: { uuid: UUID("b5b04cc3-7329-463d-9284-d3319d7ed8dd"), capped: true, size: 209715200 }
2020-05-08T12:15:45.537-0700 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns config.changelog
2020-05-08T12:15:45.546-0700 I  SHARDING [repl-writer-worker-2] Marking collection config.changelog as collection version: <unsharded>
2020-05-08T12:15:45.566-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:46614 #46 (32 connections now open)
2020-05-08T12:15:45.567-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.17:46614 conn46: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.571-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:50646 #47 (33 connections now open)
2020-05-08T12:15:45.572-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.18:50646 conn47: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.572-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:33482 #48 (34 connections now open)
2020-05-08T12:15:45.573-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.19:33482 conn48: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.598-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:46668 #49 (35 connections now open)
2020-05-08T12:15:45.598-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.17:46668 conn49: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.677-0700 I  SHARDING [repl-writer-worker-13] Marking collection config.locks as collection version: <unsharded>
2020-05-08T12:15:45.726-0700 I  STORAGE  [repl-writer-worker-12] createCollection: config.databases with provided UUID: ca3f968d-1e40-42a7-82a2-1fb918dba4dd and options: { uuid: UUID("ca3f968d-1e40-42a7-82a2-1fb918dba4dd") }
2020-05-08T12:15:45.769-0700 I  INDEX    [repl-writer-worker-12] index build: done building index _id_ on ns config.databases
2020-05-08T12:15:45.770-0700 I  SHARDING [repl-writer-worker-15] Marking collection config.databases as collection version: <unsharded>
2020-05-08T12:15:45.921-0700 I  SHARDING [conn45] Marking collection config.chunks as collection version: <unsharded>
2020-05-08T12:15:46.247-0700 I  STORAGE  [repl-writer-worker-11] createCollection: config.collections with provided UUID: a3749b3b-8edc-4244-a80b-c03e81de0177 and options: { uuid: UUID("a3749b3b-8edc-4244-a80b-c03e81de0177") }
2020-05-08T12:15:46.300-0700 I  INDEX    [repl-writer-worker-11] index build: done building index _id_ on ns config.collections
2020-05-08T12:15:50.781-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58380 #50 (36 connections now open)
2020-05-08T12:15:50.781-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.1:58380 conn50: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.782-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58386 #51 (37 connections now open)
2020-05-08T12:15:50.782-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.1:58386 conn51: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.785-0700 I  NETWORK  [conn50] end connection 192.168.122.1:58380 (36 connections now open)
2020-05-08T12:15:50.785-0700 I  NETWORK  [conn51] end connection 192.168.122.1:58386 (35 connections now open)
2020-05-08T12:15:51.403-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58490 #52 (36 connections now open)
2020-05-08T12:15:51.404-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58498 #53 (37 connections now open)
2020-05-08T12:15:51.404-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:58490 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.404-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:58498 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.408-0700 I  NETWORK  [conn52] end connection 192.168.122.1:58490 (36 connections now open)
2020-05-08T12:15:51.408-0700 I  NETWORK  [conn53] end connection 192.168.122.1:58498 (35 connections now open)
2020-05-08T12:15:52.461-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:15:52.461-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 1
2020-05-08T12:15:52.461-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 593 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:52.461-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 594 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:52.462-0700 I  ELECTION [replexec-1] VoteRequester(term 1 dry run) received a yes vote from n2:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1588965350, 10), $clusterTime: { clusterTime: Timestamp(1588965350, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965350, 10) }
2020-05-08T12:15:52.462-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 2
2020-05-08T12:15:52.462-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:15:52.462-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:15:52.473-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 595 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:52.473-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 596 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:52.489-0700 I  ELECTION [replexec-0] VoteRequester(term 2) received a yes vote from n2:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1588965350, 10), $clusterTime: { clusterTime: Timestamp(1588965350, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965350, 10) }
2020-05-08T12:15:52.489-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 2
2020-05-08T12:15:52.489-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-08T12:15:52.489-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was n1:27019
2020-05-08T12:15:52.490-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-08T12:15:53.490-0700 I  REPL     [replexec-2] Member n1:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:15:53.490-0700 I  REPL     [replexec-1] Catchup timed out after becoming primary.
2020-05-08T12:15:53.490-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-08T12:15:53.490-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-08T12:15:53.490-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:15:53.490-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 2
2020-05-08T12:15:53.490-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:15:53.491-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:15:53.491-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:15:53.491-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:15:53.494-0700 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-05-08T12:15:53.494-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:15:53.494-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-05-08T12:15:53.495-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:15:53.496-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:15:53.496-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:15:53.497-0700 I  NETWORK  [PeriodicShardedIndexConsistencyChecker] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:53.497-0700 I  NETWORK  [PeriodicShardedIndexConsistencyChecker] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.497-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:15:53.497-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:53.498-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T12:15:53.498-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:15:53.498-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-08T12:15:53.498-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-08T12:15:53.498-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-08T12:15:53.498-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 0 ms
2020-05-08T12:15:53.501-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:53.501-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:53.503-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:53.505-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-05-08T12:15:53.631-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:51562 #65 (36 connections now open)
2020-05-08T12:15:53.632-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.18:51562 conn65: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:53.664-0700 I  REPL     [replexec-4] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:15:53.664-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-08T12:15:53.664-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-08T12:15:53.664-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:15:53.664-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:15:53.665-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:15:53.665-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:15:53.665-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:15:53.665-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:15:53.665-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:53.665-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:15:53.770-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:53.770-0700 I  ELECTION [conn10] Sending vote response: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965350, 10), t: 1 }, my last applied OpTime: { ts: Timestam..." }
2020-05-08T12:15:53.999-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:54.492-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-08T12:15:54.501-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:15:54.501-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:15:54.718-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:15:54.718-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 2
2020-05-08T12:15:54.718-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 625 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965353, 1), t: 2 } }
2020-05-08T12:15:54.718-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 626 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965353, 1), t: 2 } }
2020-05-08T12:15:54.719-0700 I  ELECTION [replexec-0] VoteRequester(term 2 dry run) received a yes vote from n2:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1588965350, 10), $clusterTime: { clusterTime: Timestamp(1588965353, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965350, 10) }
2020-05-08T12:15:54.719-0700 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 3
2020-05-08T12:15:54.727-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 627 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965353, 1), t: 2 } }
2020-05-08T12:15:54.727-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 628 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965353, 1), t: 2 } }
2020-05-08T12:15:54.733-0700 I  ELECTION [replexec-4] VoteRequester(term 3) received a yes vote from n2:27019; response message: { term: 3, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1588965350, 10), $clusterTime: { clusterTime: Timestamp(1588965353, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965350, 10) }
2020-05-08T12:15:54.733-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 3
2020-05-08T12:15:54.733-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:15:54.733-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-05-08T12:15:54.733-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:15:55.733-0700 I  REPL     [replexec-1] Catchup timed out after becoming primary.
2020-05-08T12:15:55.733-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-08T12:15:55.733-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-08T12:15:55.733-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 3
2020-05-08T12:15:55.733-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:15:55.733-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:15:55.734-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:15:55.734-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:15:55.734-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-08T12:15:55.734-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-08T12:15:55.734-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:15:55.734-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:15:55.734-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:15:55.734-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-08T12:15:55.827-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:55.827-0700 I  ELECTION [conn10] Sending vote response: { term: 3, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965350, 10), t: 1 }, my last applied OpTime: { ts: Timestam..." }
2020-05-08T12:15:56.708-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:56.709-0700 I  ELECTION [conn10] Sending vote response: { term: 4, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965350, 10), t: 1 }, my last applied OpTime: { ts: Timestam..." }
2020-05-08T12:15:56.734-0700 I  REPL     [replexec-3] Member n2:27019 is now in state PRIMARY
2020-05-08T12:15:56.734-0700 I  ELECTION [replexec-3] Scheduling catchup takeover at 2020-05-08T12:15:59.734-0700
2020-05-08T12:15:56.856-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:57176 #68 (37 connections now open)
2020-05-08T12:15:56.857-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.12:57176 conn68: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:57.235-0700 I  REPL     [replexec-1] Canceling catchup takeover callback
2020-05-08T12:15:57.667-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:15:57.668-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-08T12:15:57.672-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:15:58.561-0700 I  NETWORK  [conn4] end connection 192.168.122.11:35538 (36 connections now open)
2020-05-08T12:15:58.562-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source changed from n1:27019 to n2:27019
2020-05-08T12:15:59.836-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59138 #73 (37 connections now open)
2020-05-08T12:15:59.836-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59144 #74 (38 connections now open)
2020-05-08T12:15:59.836-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.1:59138 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:59.837-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.1:59144 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:59.840-0700 I  NETWORK  [conn73] end connection 192.168.122.1:59138 (37 connections now open)
2020-05-08T12:15:59.841-0700 I  NETWORK  [conn74] end connection 192.168.122.1:59144 (36 connections now open)
2020-05-08T12:15:59.841-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:37038 #75 (37 connections now open)
2020-05-08T12:15:59.841-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.11:37038 conn75: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:00.363-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:37506 #76 (38 connections now open)
2020-05-08T12:16:00.363-0700 I  NETWORK  [conn76] received client metadata from 192.168.122.11:37506 conn76: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:00.367-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:37508 #77 (39 connections now open)
2020-05-08T12:16:00.367-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.11:37508 conn77: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:00.664-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59222 #78 (40 connections now open)
2020-05-08T12:16:00.664-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59226 #79 (41 connections now open)
2020-05-08T12:16:00.664-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:59222 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:00.664-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.1:59226 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:00.667-0700 I  NETWORK  [conn78] end connection 192.168.122.1:59222 (40 connections now open)
2020-05-08T12:16:00.668-0700 I  NETWORK  [conn79] end connection 192.168.122.1:59226 (39 connections now open)
2020-05-08T12:16:00.733-0700 I  REPL     [replexec-3] Member n1:27019 is now in state SECONDARY
2020-05-08T12:16:00.886-0700 I  ELECTION [conn75] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965357, 6), t: 4 } }
2020-05-08T12:16:00.887-0700 I  ELECTION [conn75] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-08T12:16:00.891-0700 I  ELECTION [conn75] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965357, 6), t: 4 } }
2020-05-08T12:16:00.891-0700 I  ELECTION [conn75] Sending vote response: { term: 5, voteGranted: true, reason: "" }
2020-05-08T12:16:01.555-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:57566 #80 (40 connections now open)
2020-05-08T12:16:01.555-0700 I  NETWORK  [conn10] end connection 192.168.122.12:55546 (39 connections now open)
2020-05-08T12:16:01.556-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.12:57566 conn80: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:01.737-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:02.327-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1588965357, 6), t: 4 }, latest oplog optime of sync source: { ts: Timestamp(1588965357, 6), t: 4 } (n1:27019 is)
2020-05-08T12:16:02.327-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1588965357, 6), t: 4 }, its sync source index:-1
2020-05-08T12:16:02.327-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965357, 6), t: 4 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-08T12:16:02.327-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:16:02.327-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:16:02.328-0700 I  REPL     [replexec-4] Member n1:27019 is now in state PRIMARY
2020-05-08T12:16:02.478-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34958 #81 (40 connections now open)
2020-05-08T12:16:02.478-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.19:34958 conn81: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:02.730-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:03.328-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:03.330-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:06.425-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:40766 #82 (41 connections now open)
2020-05-08T12:16:06.426-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.15:40766 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:06.715-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59464 #83 (42 connections now open)
2020-05-08T12:16:06.715-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59468 #84 (43 connections now open)
2020-05-08T12:16:06.716-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.1:59464 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:06.716-0700 I  NETWORK  [conn84] received client metadata from 192.168.122.1:59468 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:06.719-0700 I  NETWORK  [conn83] end connection 192.168.122.1:59464 (42 connections now open)
2020-05-08T12:16:06.719-0700 I  NETWORK  [conn84] end connection 192.168.122.1:59468 (41 connections now open)
2020-05-08T12:16:07.619-0700 I  ELECTION [conn80] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965361, 1), t: 5 } }
2020-05-08T12:16:07.619-0700 I  ELECTION [conn80] Sending vote response: { term: 5, voteGranted: true, reason: "" }
2020-05-08T12:16:07.633-0700 I  ELECTION [conn80] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965361, 1), t: 5 } }
2020-05-08T12:16:07.633-0700 I  ELECTION [conn80] Sending vote response: { term: 6, voteGranted: true, reason: "" }
2020-05-08T12:16:08.331-0700 I  REPL     [replexec-4] Member n1:27019 is now in state RS_DOWN - Request 687 timed out, deadline was 2020-05-08T12:16:08.331-0700, op was RemoteCommand 687 -- target:[n1:27019] db:admin expDate:2020-05-08T12:16:08.331-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 5 }
2020-05-08T12:16:08.331-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:08.662-0700 I  REPL     [replication-0] Restarting oplog query due to error: CappedPositionLost: error in fetcher batch callback :: caused by :: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824554290036604929). Last fetched optime: { ts: Timestamp(1588965368, 1), t: 6 }. Restarts remaining: 1
2020-05-08T12:16:08.663-0700 I  REPL     [replication-0] Scheduled new oplog query Fetcher source: n2:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1588965368, 1) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 6, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 696 -- target:n2:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1588965368, 1) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 6, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-08T12:16:08.670-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: Sync source must be ahead of me. My last fetched oplog optime: { ts: Timestamp(1588965368, 1), t: 6 }, latest oplog optime of sync source: { ts: Timestamp(1588965368, 1), t: 6 }
2020-05-08T12:16:08.671-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:16:08.671-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:16:08.672-0700 I  REPL     [replexec-3] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:08.674-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:09.671-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:09.671-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:16:09.671-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:09.673-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:11.619-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59720 #85 (42 connections now open)
2020-05-08T12:16:11.619-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59724 #86 (43 connections now open)
2020-05-08T12:16:11.619-0700 I  NETWORK  [conn85] received client metadata from 192.168.122.1:59720 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:11.620-0700 I  NETWORK  [conn86] received client metadata from 192.168.122.1:59724 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:11.623-0700 I  NETWORK  [conn85] end connection 192.168.122.1:59720 (42 connections now open)
2020-05-08T12:16:11.623-0700 I  NETWORK  [conn86] end connection 192.168.122.1:59724 (41 connections now open)
2020-05-08T12:16:12.555-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59782 #87 (42 connections now open)
2020-05-08T12:16:12.555-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59788 #88 (43 connections now open)
2020-05-08T12:16:12.555-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.1:59782 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:12.555-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.1:59788 conn88: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:12.559-0700 I  NETWORK  [conn87] end connection 192.168.122.1:59782 (42 connections now open)
2020-05-08T12:16:12.559-0700 I  NETWORK  [conn88] end connection 192.168.122.1:59788 (41 connections now open)
2020-05-08T12:16:12.776-0700 I  NETWORK  [conn16] end connection 192.168.122.11:35736 (40 connections now open)
2020-05-08T12:16:12.776-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:38132 #90 (41 connections now open)
2020-05-08T12:16:12.777-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.11:38132 conn90: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:13.172-0700 I  REPL     [replexec-4] Member n1:27019 is now in state SECONDARY
2020-05-08T12:16:13.181-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59816 #91 (42 connections now open)
2020-05-08T12:16:13.182-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59820 #92 (43 connections now open)
2020-05-08T12:16:13.182-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.1:59816 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.182-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.1:59820 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.186-0700 I  NETWORK  [conn91] end connection 192.168.122.1:59816 (42 connections now open)
2020-05-08T12:16:13.186-0700 I  NETWORK  [conn92] end connection 192.168.122.1:59820 (41 connections now open)
2020-05-08T12:16:13.665-0700 I  NETWORK  [conn75] end connection 192.168.122.11:37038 (40 connections now open)
2020-05-08T12:16:13.699-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59860 #93 (41 connections now open)
2020-05-08T12:16:13.699-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59866 #94 (42 connections now open)
2020-05-08T12:16:13.699-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.1:59860 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.699-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.1:59866 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.703-0700 I  NETWORK  [conn93] end connection 192.168.122.1:59860 (41 connections now open)
2020-05-08T12:16:13.703-0700 I  NETWORK  [conn94] end connection 192.168.122.1:59866 (40 connections now open)
2020-05-08T12:16:14.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59968 #95 (41 connections now open)
2020-05-08T12:16:14.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59972 #96 (42 connections now open)
2020-05-08T12:16:14.327-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.1:59968 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.327-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.1:59972 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.330-0700 I  NETWORK  [conn95] end connection 192.168.122.1:59968 (41 connections now open)
2020-05-08T12:16:14.330-0700 I  NETWORK  [conn96] end connection 192.168.122.1:59972 (40 connections now open)
2020-05-08T12:16:15.014-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:38320 #97 (41 connections now open)
2020-05-08T12:16:15.015-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.11:38320 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:15.016-0700 I  ELECTION [conn97] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:15.016-0700 I  ELECTION [conn97] Sending vote response: { term: 6, voteGranted: true, reason: "" }
2020-05-08T12:16:15.025-0700 I  ELECTION [conn97] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:15.025-0700 I  ELECTION [conn97] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-05-08T12:16:15.173-0700 I  REPL     [replexec-2] Member n1:27019 is now in state PRIMARY
2020-05-08T12:16:15.201-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:37896 #98 (42 connections now open)
2020-05-08T12:16:15.201-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.11:37896 conn98: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:15.883-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:16.725-0700 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1588965373, 1), t: 6 }, latest oplog optime of sync source: { ts: Timestamp(1588965373, 1), t: 6 } (sync source does not know the primary)
2020-05-08T12:16:16.725-0700 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1588965373, 1), t: 6 }, its sync source index:-1
2020-05-08T12:16:16.726-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965373, 1), t: 6 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:16:16.726-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:16:16.726-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:16:16.727-0700 I  REPL     [replexec-1] Member n1:27019 is now in state SECONDARY
2020-05-08T12:16:16.757-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:17.011-0700 I  ELECTION [conn80] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:17.011-0700 I  ELECTION [conn80] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-05-08T12:16:17.018-0700 I  ELECTION [conn80] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:17.018-0700 I  ELECTION [conn80] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-05-08T12:16:17.228-0700 I  REPL     [replexec-3] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:17.533-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60042 #99 (43 connections now open)
2020-05-08T12:16:17.534-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60046 #100 (44 connections now open)
2020-05-08T12:16:17.534-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.1:60042 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:17.534-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.1:60046 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:17.537-0700 I  NETWORK  [conn99] end connection 192.168.122.1:60042 (43 connections now open)
2020-05-08T12:16:17.538-0700 I  NETWORK  [conn100] end connection 192.168.122.1:60046 (42 connections now open)
2020-05-08T12:16:17.726-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-08T12:16:17.728-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-08T12:16:17.729-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-08T12:16:18.116-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60086 #102 (43 connections now open)
2020-05-08T12:16:18.117-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60090 #103 (44 connections now open)
2020-05-08T12:16:18.117-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.1:60086 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.117-0700 I  NETWORK  [conn103] received client metadata from 192.168.122.1:60090 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.120-0700 I  NETWORK  [conn102] end connection 192.168.122.1:60086 (43 connections now open)
2020-05-08T12:16:18.120-0700 I  NETWORK  [conn103] end connection 192.168.122.1:60090 (42 connections now open)
2020-05-08T12:16:19.033-0700 I  ELECTION [conn98] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965376, 4), t: 7 } }
2020-05-08T12:16:19.033-0700 I  ELECTION [conn98] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-05-08T12:16:19.041-0700 I  ELECTION [conn98] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965376, 4), t: 7 } }
2020-05-08T12:16:19.041-0700 I  ELECTION [conn98] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-08T12:16:19.727-0700 I  REPL     [replexec-4] Member n1:27019 is now in state PRIMARY
2020-05-08T12:16:20.728-0700 I  REPL     [replexec-0] Member n2:27019 is now in state RS_DOWN - Request 780 timed out, deadline was 2020-05-08T12:16:20.728-0700, op was RemoteCommand 780 -- target:[n2:27019] db:admin expDate:2020-05-08T12:16:20.728-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 9 }
2020-05-08T12:16:20.728-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:20.728-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:24.471-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60328 #104 (43 connections now open)
2020-05-08T12:16:24.471-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60332 #105 (44 connections now open)
2020-05-08T12:16:24.472-0700 I  NETWORK  [conn104] received client metadata from 192.168.122.1:60328 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.472-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.1:60332 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.475-0700 I  NETWORK  [conn104] end connection 192.168.122.1:60328 (43 connections now open)
2020-05-08T12:16:24.475-0700 I  NETWORK  [conn105] end connection 192.168.122.1:60332 (42 connections now open)
2020-05-08T12:16:24.499-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:58586 #106 (43 connections now open)
2020-05-08T12:16:24.737-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.12:58586 conn106: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:24.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60354 #107 (44 connections now open)
2020-05-08T12:16:24.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60358 #108 (45 connections now open)
2020-05-08T12:16:24.899-0700 I  NETWORK  [conn107] received client metadata from 192.168.122.1:60354 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.900-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.1:60358 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.903-0700 I  NETWORK  [conn107] end connection 192.168.122.1:60354 (44 connections now open)
2020-05-08T12:16:24.903-0700 I  NETWORK  [conn108] end connection 192.168.122.1:60358 (43 connections now open)
2020-05-08T12:16:25.189-0700 I  NETWORK  [conn25] end connection 192.168.122.12:55742 (42 connections now open)
2020-05-08T12:16:25.697-0700 I  NETWORK  [conn80] end connection 192.168.122.12:57566 (41 connections now open)
2020-05-08T12:16:27.233-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:58524 #109 (42 connections now open)
2020-05-08T12:16:27.233-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.12:58524 conn109: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:28.729-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:29.861-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60594 #111 (43 connections now open)
2020-05-08T12:16:29.862-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60598 #112 (44 connections now open)
2020-05-08T12:16:29.862-0700 I  NETWORK  [conn111] received client metadata from 192.168.122.1:60594 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:29.862-0700 I  NETWORK  [conn112] received client metadata from 192.168.122.1:60598 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:29.863-0700 I  NETWORK  [conn111] end connection 192.168.122.1:60594 (43 connections now open)
2020-05-08T12:16:29.863-0700 I  NETWORK  [conn112] end connection 192.168.122.1:60598 (42 connections now open)
2020-05-08T12:16:30.173-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60608 #113 (43 connections now open)
2020-05-08T12:16:30.173-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60612 #114 (44 connections now open)
2020-05-08T12:16:30.173-0700 I  NETWORK  [conn113] received client metadata from 192.168.122.1:60608 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.173-0700 I  NETWORK  [conn114] received client metadata from 192.168.122.1:60612 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.175-0700 I  NETWORK  [conn113] end connection 192.168.122.1:60608 (43 connections now open)
2020-05-08T12:16:30.175-0700 I  NETWORK  [conn114] end connection 192.168.122.1:60612 (42 connections now open)
2020-05-08T12:16:30.594-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60636 #115 (43 connections now open)
2020-05-08T12:16:30.594-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60642 #116 (44 connections now open)
2020-05-08T12:16:30.595-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.1:60636 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.595-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.1:60642 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.598-0700 I  NETWORK  [conn115] end connection 192.168.122.1:60636 (43 connections now open)
2020-05-08T12:16:30.599-0700 I  NETWORK  [conn116] end connection 192.168.122.1:60642 (42 connections now open)
2020-05-08T12:16:33.000-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60856 #117 (43 connections now open)
2020-05-08T12:16:33.000-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60860 #118 (44 connections now open)
2020-05-08T12:16:33.000-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.1:60856 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:33.000-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.1:60860 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:33.004-0700 I  NETWORK  [conn117] end connection 192.168.122.1:60856 (43 connections now open)
2020-05-08T12:16:33.004-0700 I  NETWORK  [conn118] end connection 192.168.122.1:60860 (42 connections now open)
2020-05-08T12:16:34.004-0700 I  ELECTION [conn109] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:34.004-0700 I  ELECTION [conn109] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-08T12:16:34.010-0700 I  ELECTION [conn109] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 10, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:34.010-0700 I  ELECTION [conn109] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-08T12:16:34.561-0700 I  REPL     [replexec-1] Member n1:27019 is now in state SECONDARY
2020-05-08T12:16:34.696-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60932 #119 (43 connections now open)
2020-05-08T12:16:34.697-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60936 #120 (44 connections now open)
2020-05-08T12:16:34.697-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.1:60932 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:34.697-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:60936 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:34.699-0700 I  NETWORK  [conn119] end connection 192.168.122.1:60932 (43 connections now open)
2020-05-08T12:16:34.699-0700 I  NETWORK  [conn120] end connection 192.168.122.1:60936 (42 connections now open)
2020-05-08T12:16:34.721-0700 I  NETWORK  [conn98] end connection 192.168.122.11:37896 (41 connections now open)
2020-05-08T12:16:35.061-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:16:35.061-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 10
2020-05-08T12:16:35.061-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 881 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:35.061-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 882 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:35.061-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:35.061-0700 I  ELECTION [replexec-3] VoteRequester(term 10 dry run) received a yes vote from n1:27019; response message: { term: 10, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1588965389, 3), $clusterTime: { clusterTime: Timestamp(1588965395, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965389, 3) }
2020-05-08T12:16:35.062-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 11
2020-05-08T12:16:35.064-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 883 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:35.064-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 884 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:35.066-0700 I  ELECTION [replexec-1] VoteRequester(term 11) received a yes vote from n1:27019; response message: { term: 11, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1588965389, 3), $clusterTime: { clusterTime: Timestamp(1588965395, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965389, 3) }
2020-05-08T12:16:35.067-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 11
2020-05-08T12:16:35.067-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-08T12:16:35.067-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was n1:27019
2020-05-08T12:16:35.067-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-05-08T12:16:35.067-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-08T12:16:35.105-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965389, 3), t: 9 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-08T12:16:35.605-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-08T12:16:35.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60962 #121 (42 connections now open)
2020-05-08T12:16:35.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60966 #122 (43 connections now open)
2020-05-08T12:16:35.665-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.1:60962 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:35.665-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:60966 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:35.667-0700 I  NETWORK  [conn121] end connection 192.168.122.1:60962 (42 connections now open)
2020-05-08T12:16:35.668-0700 I  NETWORK  [conn122] end connection 192.168.122.1:60966 (41 connections now open)
2020-05-08T12:16:35.730-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-08T12:16:35.730-0700 I  REPL     [replexec-1] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965389, 3), t: 9 }. My Last Applied: { ts: Timestamp(1588965389, 3), t: 9 }
2020-05-08T12:16:35.730-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-08T12:16:35.730-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-08T12:16:35.730-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 11
2020-05-08T12:16:35.730-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:35.731-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:35.731-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:35.733-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:35.733-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:35.733-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:35.734-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:35.734-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:35.737-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:35.946-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:56848 #123 (42 connections now open)
2020-05-08T12:16:35.946-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39316 #124 (43 connections now open)
2020-05-08T12:16:35.947-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.13:56848 conn123: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:35.947-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.11:39316 conn124: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:36.237-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.737-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.951-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:59350 #127 (44 connections now open)
2020-05-08T12:16:36.951-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.12:59350 conn127: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:36.953-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:59352 #128 (45 connections now open)
2020-05-08T12:16:36.954-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.12:59352 conn128: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:36.996-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39420 #129 (46 connections now open)
2020-05-08T12:16:36.997-0700 I  NETWORK  [conn129] received client metadata from 192.168.122.11:39420 conn129: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:37.047-0700 I  NETWORK  [conn129] end connection 192.168.122.11:39420 (45 connections now open)
2020-05-08T12:16:37.054-0700 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-05-08T12:16:37.054-0700 I  COMMAND  [conn123] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, D1A6364B23E002829B6AB8203C84275E888AA2E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965389, 3), t: 9 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1107ms
2020-05-08T12:16:37.055-0700 I  COMMAND  [conn26] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, D1A6364B23E002829B6AB8203C84275E888AA2E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965389, 3), t: 9 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1108ms
2020-05-08T12:16:37.055-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:16:37.055-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1588965395470), up: 51, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, D1A6364B23E002829B6AB8203C84275E888AA2E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965389, 3), t: 9 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1109ms
2020-05-08T12:16:37.055-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:16:37.055-0700 I  COMMAND  [conn124] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, D1A6364B23E002829B6AB8203C84275E888AA2E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965389, 3), t: 9 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 1107ms
2020-05-08T12:16:37.055-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1588965395360), up: 51, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, D1A6364B23E002829B6AB8203C84275E888AA2E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965389, 3), t: 9 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1109ms
2020-05-08T12:16:37.074-0700 I  NETWORK  [conn128] end connection 192.168.122.12:59352 (44 connections now open)
2020-05-08T12:16:37.212-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T12:16:37.236-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.468-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32870 #130 (45 connections now open)
2020-05-08T12:16:37.468-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32874 #131 (46 connections now open)
2020-05-08T12:16:37.468-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.1:32870 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.469-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:32874 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.472-0700 I  NETWORK  [conn130] end connection 192.168.122.1:32870 (45 connections now open)
2020-05-08T12:16:37.472-0700 I  NETWORK  [conn131] end connection 192.168.122.1:32874 (44 connections now open)
2020-05-08T12:16:37.730-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:37.736-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.236-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.736-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.023-0700 I  ELECTION [conn109] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965397, 5), t: 11 } }
2020-05-08T12:16:39.023-0700 I  ELECTION [conn109] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-08T12:16:39.024-0700 I  NETWORK  [conn109] end connection 192.168.122.12:58524 (43 connections now open)
2020-05-08T12:16:39.025-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:59442 #132 (44 connections now open)
2020-05-08T12:16:39.025-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.12:59442 conn132: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:39.030-0700 I  REPL     [conn132] stepping down from primary, because a new term has begun: 12
2020-05-08T12:16:39.031-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:39.031-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:39.031-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-05-08T12:16:39.031-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-08T12:16:39.032-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:16:39.032-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:39.032-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:39.032-0700 I  ELECTION [conn132] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965397, 5), t: 11 } }
2020-05-08T12:16:39.032-0700 I  ELECTION [conn132] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-05-08T12:16:39.034-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:59444 #133 (45 connections now open)
2020-05-08T12:16:39.035-0700 I  NETWORK  [conn133] received client metadata from 192.168.122.12:59444 conn133: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:39.035-0700 I  NETWORK  [conn132] end connection 192.168.122.12:59442 (44 connections now open)
2020-05-08T12:16:39.237-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.265-0700 I  NETWORK  [conn68] end connection 192.168.122.12:57176 (43 connections now open)
2020-05-08T12:16:39.731-0700 I  REPL     [replexec-1] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:39.736-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.032-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:40.034-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:40.236-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.296-0700 I  ELECTION [conn97] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965399, 5), t: 12 } }
2020-05-08T12:16:40.296-0700 I  ELECTION [conn97] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-05-08T12:16:40.300-0700 I  ELECTION [conn97] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965399, 5), t: 12 } }
2020-05-08T12:16:40.300-0700 I  ELECTION [conn97] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-05-08T12:16:40.528-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32972 #134 (44 connections now open)
2020-05-08T12:16:40.529-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32976 #135 (45 connections now open)
2020-05-08T12:16:40.529-0700 I  NETWORK  [conn134] received client metadata from 192.168.122.1:32972 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:40.529-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.1:32976 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:40.531-0700 I  NETWORK  [conn134] end connection 192.168.122.1:32972 (44 connections now open)
2020-05-08T12:16:40.531-0700 I  NETWORK  [conn135] end connection 192.168.122.1:32976 (43 connections now open)
2020-05-08T12:16:40.541-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1588965399, 5), t: 12 }, latest oplog optime of sync source: { ts: Timestamp(1588965399, 5), t: 12 } (sync source does not know the primary)
2020-05-08T12:16:40.541-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1588965399, 5), t: 12 }, its sync source index:-1
2020-05-08T12:16:40.541-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965399, 5), t: 12 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:16:40.541-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:16:40.542-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:16:40.543-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:40.737-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.749-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-08T12:16:41.041-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:41.236-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:41.542-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-08T12:16:41.544-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-08T12:16:41.549-0700 I  COMMAND  [conn43] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(1604517341, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965400, 2), t: 13 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965401, 4), signature: { hash: BinData(0, 9F359F1F1561E034D8F7B53829925BB4BF56B12A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965400, 2), t: 13 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 hasSortStage:1 cursorExhausted:1 numYields:0 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 117ms
2020-05-08T12:16:41.840-0700 I  NETWORK  [conn32] end connection 192.168.122.19:33178 (41 connections now open)
2020-05-08T12:16:41.840-0700 I  NETWORK  [conn31] end connection 192.168.122.18:50346 (39 connections now open)
2020-05-08T12:16:41.840-0700 I  NETWORK  [conn35] end connection 192.168.122.18:50364 (42 connections now open)
2020-05-08T12:16:41.840-0700 I  NETWORK  [conn33] end connection 192.168.122.14:53642 (40 connections now open)
2020-05-08T12:16:41.841-0700 I  NETWORK  [conn30] end connection 192.168.122.17:46326 (38 connections now open)
2020-05-08T12:16:44.278-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33254 #136 (39 connections now open)
2020-05-08T12:16:44.278-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33260 #137 (40 connections now open)
2020-05-08T12:16:44.278-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.1:33254 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:44.278-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.1:33260 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:44.283-0700 I  NETWORK  [conn136] end connection 192.168.122.1:33254 (39 connections now open)
2020-05-08T12:16:44.283-0700 I  NETWORK  [conn137] end connection 192.168.122.1:33260 (38 connections now open)
2020-05-08T12:16:45.155-0700 I  ELECTION [conn133] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.155-0700 I  ELECTION [conn133] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-05-08T12:16:45.155-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:16:45.155-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 13
2020-05-08T12:16:45.155-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 982 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.155-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 983 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.156-0700 I  ELECTION [replexec-4] VoteRequester(term 13 dry run) received a yes vote from n2:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1588965403, 8), $clusterTime: { clusterTime: Timestamp(1588965403, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965403, 8) }
2020-05-08T12:16:45.157-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 14
2020-05-08T12:16:45.157-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:45.157-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:16:45.158-0700 I  ELECTION [conn133] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.159-0700 I  ELECTION [conn133] Sending vote response: { term: 14, voteGranted: false, reason: "already voted for another candidate (n3:27019) this term (14)" }
2020-05-08T12:16:45.160-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 984 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.160-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 985 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.161-0700 I  ELECTION [replexec-2] VoteRequester(term 14) received a no vote from n2:27019 with reason "already voted for another candidate (n2:27019) this term (14)"; response message: { term: 14, voteGranted: false, reason: "already voted for another candidate (n2:27019) this term (14)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1588965403, 8), $clusterTime: { clusterTime: Timestamp(1588965403, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965403, 8) }
2020-05-08T12:16:45.415-0700 I  NETWORK  [conn44] end connection 192.168.122.14:53906 (37 connections now open)
2020-05-08T12:16:45.757-0700 I  ELECTION [replexec-5] VoteRequester(term 14) received a yes vote from n1:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000d') }, lastCommittedOpTime: Timestamp(1588965403, 8), $clusterTime: { clusterTime: Timestamp(1588965405, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965403, 8) }
2020-05-08T12:16:45.757-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 14
2020-05-08T12:16:45.757-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-08T12:16:45.757-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n1:27019
2020-05-08T12:16:45.757-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-08T12:16:45.757-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:45.902-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33306 #139 (38 connections now open)
2020-05-08T12:16:45.903-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33308 #140 (39 connections now open)
2020-05-08T12:16:45.903-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:33306 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:45.903-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.1:33308 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:45.907-0700 I  NETWORK  [conn139] end connection 192.168.122.1:33306 (38 connections now open)
2020-05-08T12:16:45.907-0700 I  NETWORK  [conn140] end connection 192.168.122.1:33308 (37 connections now open)
2020-05-08T12:16:46.178-0700 I  REPL     [replexec-3] Member n1:27019 is now in state SECONDARY
2020-05-08T12:16:46.179-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965403, 8), t: 13 }. My Last Applied: { ts: Timestamp(1588965403, 8), t: 13 }
2020-05-08T12:16:46.179-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-08T12:16:46.179-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-08T12:16:46.179-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:16:46.179-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 14
2020-05-08T12:16:46.179-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:46.179-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:46.179-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:46.180-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:46.182-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:46.182-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:46.182-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:46.183-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:46.183-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:46.184-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T12:16:46.337-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39842 #143 (38 connections now open)
2020-05-08T12:16:46.337-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.11:39842 conn143: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:46.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33386 #144 (39 connections now open)
2020-05-08T12:16:46.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33388 #145 (40 connections now open)
2020-05-08T12:16:46.733-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.1:33386 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.733-0700 I  NETWORK  [conn145] received client metadata from 192.168.122.1:33388 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.736-0700 I  NETWORK  [conn144] end connection 192.168.122.1:33386 (39 connections now open)
2020-05-08T12:16:46.736-0700 I  NETWORK  [conn145] end connection 192.168.122.1:33388 (38 connections now open)
2020-05-08T12:16:46.741-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-08T12:16:47.291-0700 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965406, 2), signature: { hash: BinData(0, C6CC92E0CA1A8170CBCEB9AA3005A9DA97A9BCAB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965403, 8), t: 13 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 369ms
2020-05-08T12:16:47.291-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:16:47.291-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:16:47.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39994 #146 (39 connections now open)
2020-05-08T12:16:47.458-0700 I  NETWORK  [conn146] received client metadata from 192.168.122.11:39994 conn146: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:47.460-0700 I  REPL     [conn146] stepping down from primary, because a new term has begun: 15
2020-05-08T12:16:47.461-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:47.461-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:47.461-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-08T12:16:47.461-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-08T12:16:47.462-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard1 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:47.462-0700 I  ELECTION [conn146] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965407, 1), t: 14 } }
2020-05-08T12:16:47.462-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard2 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:47.462-0700 I  ELECTION [conn146] Sending vote response: { term: 15, voteGranted: true, reason: "" }
2020-05-08T12:16:47.462-0700 I  CONNPOOL [ShardRegistry] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:47.462-0700 W  SHARDING [Balancer] Multi version cluster detected. Local version: 4.2.6, shard versions: rs_shard1 is at ; rs_shard2 is at ; 
2020-05-08T12:16:47.462-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-08T12:16:47.463-0700 W  SHARDING [Balancer] Failed to enforce tag ranges :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:47.463-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33428 #148 (40 connections now open)
2020-05-08T12:16:47.463-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:16:47.463-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:47.463-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:47.464-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33434 #149 (41 connections now open)
2020-05-08T12:16:47.464-0700 I  NETWORK  [conn148] received client metadata from 192.168.122.1:33428 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:47.464-0700 I  NETWORK  [conn149] received client metadata from 192.168.122.1:33434 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:47.465-0700 I  NETWORK  [conn143] end connection 192.168.122.11:39842 (40 connections now open)
2020-05-08T12:16:47.466-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40010 #150 (41 connections now open)
2020-05-08T12:16:47.466-0700 I  NETWORK  [conn146] end connection 192.168.122.11:39994 (40 connections now open)
2020-05-08T12:16:47.466-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.11:40010 conn150: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:47.467-0700 I  NETWORK  [conn148] end connection 192.168.122.1:33428 (39 connections now open)
2020-05-08T12:16:47.468-0700 I  NETWORK  [conn149] end connection 192.168.122.1:33434 (38 connections now open)
2020-05-08T12:16:47.649-0700 I  NETWORK  [conn97] end connection 192.168.122.11:38320 (37 connections now open)
2020-05-08T12:16:47.746-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:59980 #151 (38 connections now open)
2020-05-08T12:16:47.746-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.12:59980 conn151: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:47.791-0700 I  NETWORK  [conn77] end connection 192.168.122.11:37508 (37 connections now open)
2020-05-08T12:16:48.179-0700 I  REPL     [replexec-4] Member n1:27019 is now in state PRIMARY
2020-05-08T12:16:48.462-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:48.465-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:48.470-0700 I  COMMAND  [conn27] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965407, 8), t: 15 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965407, 8), signature: { hash: BinData(0, 44F2904FF45A0449A2D359F3DA486CF736BDABB6), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965407, 8), t: 15 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 689ms
2020-05-08T12:16:48.470-0700 I  COMMAND  [conn26] command config.settings command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965407, 5), t: 15 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965407, 8), signature: { hash: BinData(0, 44F2904FF45A0449A2D359F3DA486CF736BDABB6), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965407, 5), t: 15 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 691ms
2020-05-08T12:16:48.470-0700 I  COMMAND  [conn39] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965407, 8), t: 15 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965407, 8), signature: { hash: BinData(0, 44F2904FF45A0449A2D359F3DA486CF736BDABB6), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965407, 8), t: 15 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 689ms
2020-05-08T12:16:51.110-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33632 #152 (38 connections now open)
2020-05-08T12:16:51.111-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33638 #153 (39 connections now open)
2020-05-08T12:16:51.111-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:33632 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.111-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:33638 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.114-0700 I  NETWORK  [conn152] end connection 192.168.122.1:33632 (38 connections now open)
2020-05-08T12:16:51.114-0700 I  NETWORK  [conn153] end connection 192.168.122.1:33638 (37 connections now open)
2020-05-08T12:16:51.885-0700 I  ELECTION [conn133] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965410, 7), t: 15 } }
2020-05-08T12:16:51.885-0700 I  ELECTION [conn133] Sending vote response: { term: 15, voteGranted: true, reason: "" }
2020-05-08T12:16:51.890-0700 I  ELECTION [conn133] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965410, 7), t: 15 } }
2020-05-08T12:16:51.890-0700 I  ELECTION [conn133] Sending vote response: { term: 16, voteGranted: true, reason: "" }
2020-05-08T12:16:52.761-0700 I  REPL     [replexec-2] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:52.889-0700 I  REPL     [replexec-3] Member n1:27019 is now in state SECONDARY
2020-05-08T12:16:53.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33738 #154 (38 connections now open)
2020-05-08T12:16:53.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33742 #155 (39 connections now open)
2020-05-08T12:16:53.021-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.1:33738 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.021-0700 I  NETWORK  [conn155] received client metadata from 192.168.122.1:33742 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.024-0700 I  NETWORK  [conn154] end connection 192.168.122.1:33738 (38 connections now open)
2020-05-08T12:16:53.024-0700 I  NETWORK  [conn155] end connection 192.168.122.1:33742 (37 connections now open)
2020-05-08T12:16:53.153-0700 I  NETWORK  [conn150] end connection 192.168.122.11:40010 (36 connections now open)
2020-05-08T12:16:53.473-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40260 #156 (37 connections now open)
2020-05-08T12:16:53.474-0700 I  NETWORK  [conn156] received client metadata from 192.168.122.11:40260 conn156: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:53.649-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33764 #157 (38 connections now open)
2020-05-08T12:16:53.650-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33770 #158 (39 connections now open)
2020-05-08T12:16:53.650-0700 I  NETWORK  [conn157] received client metadata from 192.168.122.1:33764 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.650-0700 I  NETWORK  [conn158] received client metadata from 192.168.122.1:33770 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.653-0700 I  NETWORK  [conn157] end connection 192.168.122.1:33764 (38 connections now open)
2020-05-08T12:16:53.653-0700 I  NETWORK  [conn158] end connection 192.168.122.1:33770 (37 connections now open)
2020-05-08T12:16:53.798-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40346 #159 (38 connections now open)
2020-05-08T12:16:53.798-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.11:40346 conn159: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:53.997-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.484-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33808 #160 (39 connections now open)
2020-05-08T12:16:54.485-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33814 #161 (40 connections now open)
2020-05-08T12:16:54.485-0700 I  NETWORK  [conn160] received client metadata from 192.168.122.1:33808 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.485-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.1:33814 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.488-0700 I  NETWORK  [conn160] end connection 192.168.122.1:33808 (39 connections now open)
2020-05-08T12:16:54.489-0700 I  NETWORK  [conn161] end connection 192.168.122.1:33814 (38 connections now open)
2020-05-08T12:16:54.525-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:54.526-0700 I  ELECTION [conn156] Sending vote response: { term: 16, voteGranted: true, reason: "" }
2020-05-08T12:16:54.530-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 17, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:54.530-0700 I  ELECTION [conn156] Sending vote response: { term: 17, voteGranted: true, reason: "" }
2020-05-08T12:16:54.761-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:54.890-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-08T12:16:54.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33856 #162 (39 connections now open)
2020-05-08T12:16:54.910-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33860 #163 (40 connections now open)
2020-05-08T12:16:54.910-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.1:33856 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.910-0700 I  NETWORK  [conn163] received client metadata from 192.168.122.1:33860 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.913-0700 I  NETWORK  [conn162] end connection 192.168.122.1:33856 (39 connections now open)
2020-05-08T12:16:54.913-0700 I  NETWORK  [conn163] end connection 192.168.122.1:33860 (38 connections now open)
2020-05-08T12:16:55.940-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:16:55.940-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 17
2020-05-08T12:16:55.940-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1075 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:55.940-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1076 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:56.890-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:16:56.940-0700 I  ELECTION [replexec-1] VoteRequester(term 17 dry run) failed to receive response from n1:27019: NetworkInterfaceExceededTimeLimit: Request 1075 timed out, deadline was 2020-05-08T12:16:56.940-0700, op was RemoteCommand 1075 -- target:[n1:27019] db:admin expDate:2020-05-08T12:16:56.940-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:56.940-0700 I  ELECTION [replexec-2] VoteRequester(term 17 dry run) failed to receive response from n2:27019: NetworkInterfaceExceededTimeLimit: Request 1076 timed out, deadline was 2020-05-08T12:16:56.940-0700, op was RemoteCommand 1076 -- target:[n2:27019] db:admin expDate:2020-05-08T12:16:56.940-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:56.940-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:56.940-0700 I  ELECTION [replexec-2] not running for primary, we received insufficient votes
2020-05-08T12:16:56.940-0700 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-05-08T12:16:56.940-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:56.990-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:16:56.990-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 17
2020-05-08T12:16:56.990-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1079 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:56.990-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1080 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:56.990-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:57.761-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - Request 1077 timed out, deadline was 2020-05-08T12:16:57.761-0700, op was RemoteCommand 1077 -- target:[n2:27019] db:admin expDate:2020-05-08T12:16:57.761-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 17 }
2020-05-08T12:16:57.761-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:57.890-0700 I  REPL     [replexec-1] Member n1:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-08T12:16:57.990-0700 I  ELECTION [replexec-4] VoteRequester(term 17 dry run) failed to receive response from n2:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:16:57.990-0700 I  ELECTION [replexec-2] VoteRequester(term 17 dry run) failed to receive response from n1:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:16:57.990-0700 I  ELECTION [replexec-2] not running for primary, we received insufficient votes
2020-05-08T12:16:57.990-0700 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-05-08T12:16:58.038-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:59.086-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:59.963-0700 I  REPL     [replication-0] Restarting oplog query due to error: NetworkInterfaceExceededTimeLimit: error in fetcher batch callback :: caused by :: Request 1068 timed out, deadline was 2020-05-08T12:16:59.963-0700, op was RemoteCommand 1068 -- target:[n2:27019] db:local expDate:2020-05-08T12:16:59.962-0700 cmd:{ getMore: 6539241622233694723, collection: "oplog.rs", batchSize: 13981010, maxTimeMS: 500, term: 16, lastKnownCommittedOpTime: { ts: Timestamp(1588965412, 1), t: 16 } }. Last fetched optime: { ts: Timestamp(1588965412, 1), t: 16 }. Restarts remaining: 1
2020-05-08T12:16:59.963-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:59.963-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-08T12:16:59.963-0700 I  REPL     [replication-0] Scheduled new oplog query Fetcher source: n2:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1588965412, 1) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 17, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 1083 -- target:n2:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1588965412, 1) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 17, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-08T12:17:00.172-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:01.195-0700 I  ELECTION [replexec-4] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:02.286-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:03.010-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: Sync source must be ahead of me. My last fetched oplog optime: { ts: Timestamp(1588965412, 1), t: 16 }, latest oplog optime of sync source: { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:17:03.011-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:17:03.011-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:17:03.011-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:03.014-0700 I  REPL     [replexec-5] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:03.073-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60412 #166 (39 connections now open)
2020-05-08T12:17:03.073-0700 I  NETWORK  [conn166] received client metadata from 192.168.122.12:60412 conn166: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:03.303-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:03.303-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 17
2020-05-08T12:17:03.303-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1090 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:17:03.303-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1091 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:17:03.304-0700 I  ELECTION [replexec-3] VoteRequester(term 17 dry run) received a yes vote from n2:27019; response message: { term: 17, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000010') }, lastCommittedOpTime: Timestamp(1588965412, 1), $clusterTime: { clusterTime: Timestamp(1588965421, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965412, 1) }
2020-05-08T12:17:03.304-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 18
2020-05-08T12:17:03.308-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1092 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 18, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:17:03.308-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1093 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 18, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:17:03.312-0700 I  ELECTION [replexec-1] VoteRequester(term 18) received a yes vote from n2:27019; response message: { term: 18, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000010') }, lastCommittedOpTime: Timestamp(1588965412, 1), $clusterTime: { clusterTime: Timestamp(1588965421, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965412, 1) }
2020-05-08T12:17:03.312-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 18
2020-05-08T12:17:03.312-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-08T12:17:03.312-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-08T12:17:03.312-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-08T12:17:03.329-0700 I  NETWORK  [conn156] end connection 192.168.122.11:40260 (38 connections now open)
2020-05-08T12:17:03.890-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965412, 1), t: 16 }. My Last Applied: { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:17:03.890-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-08T12:17:03.890-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-08T12:17:03.890-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 18
2020-05-08T12:17:03.891-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:03.891-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:03.891-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:03.893-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:03.893-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:03.894-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:03.894-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:03.894-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:03.896-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.896-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:17:03.909-0700 I  SHARDING [Balancer] Marking collection config.tags as collection version: <unsharded>
2020-05-08T12:17:03.989-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:38148 #168 (39 connections now open)
2020-05-08T12:17:03.990-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:38150 #169 (40 connections now open)
2020-05-08T12:17:03.990-0700 I  NETWORK  [conn168] received client metadata from 192.168.122.19:38148 conn168: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:03.990-0700 I  NETWORK  [conn169] received client metadata from 192.168.122.19:38150 conn169: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:03.991-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:38152 #170 (41 connections now open)
2020-05-08T12:17:03.991-0700 I  NETWORK  [conn170] received client metadata from 192.168.122.19:38152 conn170: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:03.991-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:38154 #171 (42 connections now open)
2020-05-08T12:17:03.992-0700 I  NETWORK  [conn171] received client metadata from 192.168.122.19:38154 conn171: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:03.993-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:38156 #172 (43 connections now open)
2020-05-08T12:17:03.993-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.19:38156 conn172: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:03.993-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:38158 #173 (44 connections now open)
2020-05-08T12:17:03.993-0700 I  NETWORK  [conn173] received client metadata from 192.168.122.19:38158 conn173: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.000-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58436 #174 (45 connections now open)
2020-05-08T12:17:04.001-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58438 #175 (46 connections now open)
2020-05-08T12:17:04.001-0700 I  NETWORK  [conn174] received client metadata from 192.168.122.16:58436 conn174: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.001-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.16:58438 conn175: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.002-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58440 #176 (47 connections now open)
2020-05-08T12:17:04.002-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58442 #177 (48 connections now open)
2020-05-08T12:17:04.002-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.16:58440 conn176: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.003-0700 I  NETWORK  [conn177] received client metadata from 192.168.122.16:58442 conn177: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.003-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58444 #178 (49 connections now open)
2020-05-08T12:17:04.004-0700 I  NETWORK  [conn178] received client metadata from 192.168.122.16:58444 conn178: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:55340 #179 (50 connections now open)
2020-05-08T12:17:04.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:55342 #180 (51 connections now open)
2020-05-08T12:17:04.021-0700 I  NETWORK  [conn179] received client metadata from 192.168.122.18:55340 conn179: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.021-0700 I  NETWORK  [conn180] received client metadata from 192.168.122.18:55342 conn180: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.022-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:55344 #181 (52 connections now open)
2020-05-08T12:17:04.022-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:55346 #182 (53 connections now open)
2020-05-08T12:17:04.023-0700 I  NETWORK  [conn181] received client metadata from 192.168.122.18:55344 conn181: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.023-0700 I  NETWORK  [conn182] received client metadata from 192.168.122.18:55346 conn182: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.065-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60650 #183 (54 connections now open)
2020-05-08T12:17:04.065-0700 I  NETWORK  [conn183] received client metadata from 192.168.122.12:60650 conn183: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.068-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60792 #184 (55 connections now open)
2020-05-08T12:17:04.068-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60794 #185 (56 connections now open)
2020-05-08T12:17:04.068-0700 I  NETWORK  [conn184] received client metadata from 192.168.122.12:60792 conn184: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.068-0700 I  NETWORK  [conn185] received client metadata from 192.168.122.12:60794 conn185: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.069-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60796 #186 (57 connections now open)
2020-05-08T12:17:04.070-0700 I  NETWORK  [conn186] received client metadata from 192.168.122.12:60796 conn186: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.070-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60798 #187 (58 connections now open)
2020-05-08T12:17:04.070-0700 I  NETWORK  [conn187] received client metadata from 192.168.122.12:60798 conn187: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.071-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60800 #188 (59 connections now open)
2020-05-08T12:17:04.072-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60802 #189 (60 connections now open)
2020-05-08T12:17:04.072-0700 I  NETWORK  [conn188] received client metadata from 192.168.122.12:60800 conn188: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.072-0700 I  NETWORK  [conn189] received client metadata from 192.168.122.12:60802 conn189: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.075-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51342 #190 (61 connections now open)
2020-05-08T12:17:04.076-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51344 #191 (62 connections now open)
2020-05-08T12:17:04.076-0700 I  NETWORK  [conn190] received client metadata from 192.168.122.17:51342 conn190: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40874 #192 (63 connections now open)
2020-05-08T12:17:04.077-0700 I  NETWORK  [conn191] received client metadata from 192.168.122.17:51344 conn191: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:43862 #193 (64 connections now open)
2020-05-08T12:17:04.077-0700 I  NETWORK  [conn192] received client metadata from 192.168.122.11:40874 conn192: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:43864 #194 (65 connections now open)
2020-05-08T12:17:04.077-0700 I  NETWORK  [conn193] received client metadata from 192.168.122.15:43862 conn193: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40880 #195 (66 connections now open)
2020-05-08T12:17:04.077-0700 I  NETWORK  [conn194] received client metadata from 192.168.122.15:43864 conn194: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.078-0700 I  NETWORK  [conn195] received client metadata from 192.168.122.11:40880 conn195: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.078-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51354 #196 (67 connections now open)
2020-05-08T12:17:04.078-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40884 #197 (68 connections now open)
2020-05-08T12:17:04.079-0700 I  NETWORK  [conn196] received client metadata from 192.168.122.17:51354 conn196: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.079-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51358 #198 (69 connections now open)
2020-05-08T12:17:04.079-0700 I  NETWORK  [conn197] received client metadata from 192.168.122.11:40884 conn197: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.079-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:43874 #199 (70 connections now open)
2020-05-08T12:17:04.080-0700 I  NETWORK  [conn198] received client metadata from 192.168.122.17:51358 conn198: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.080-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:43876 #200 (71 connections now open)
2020-05-08T12:17:04.080-0700 I  NETWORK  [conn199] received client metadata from 192.168.122.15:43874 conn199: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.080-0700 I  NETWORK  [conn200] received client metadata from 192.168.122.15:43876 conn200: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.080-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51364 #201 (72 connections now open)
2020-05-08T12:17:04.081-0700 I  NETWORK  [conn201] received client metadata from 192.168.122.17:51364 conn201: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.081-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:43880 #202 (73 connections now open)
2020-05-08T12:17:04.082-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51368 #203 (74 connections now open)
2020-05-08T12:17:04.082-0700 I  NETWORK  [conn202] received client metadata from 192.168.122.15:43880 conn202: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.082-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:43884 #204 (75 connections now open)
2020-05-08T12:17:04.082-0700 I  NETWORK  [conn203] received client metadata from 192.168.122.17:51368 conn203: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.082-0700 I  NETWORK  [conn204] received client metadata from 192.168.122.15:43884 conn204: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58430 #205 (76 connections now open)
2020-05-08T12:17:04.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58432 #206 (77 connections now open)
2020-05-08T12:17:04.088-0700 I  NETWORK  [conn205] received client metadata from 192.168.122.13:58430 conn205: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.089-0700 I  NETWORK  [conn206] received client metadata from 192.168.122.13:58432 conn206: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58434 #207 (78 connections now open)
2020-05-08T12:17:04.090-0700 I  NETWORK  [conn207] received client metadata from 192.168.122.13:58434 conn207: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.098-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58436 #211 (79 connections now open)
2020-05-08T12:17:04.098-0700 I  CONNPOOL [Replication] Ending idle connection to host n1:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:04.098-0700 I  NETWORK  [conn211] received client metadata from 192.168.122.13:58436 conn211: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.101-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:60446 #212 (80 connections now open)
2020-05-08T12:17:04.101-0700 I  NETWORK  [conn212] received client metadata from 192.168.122.12:60446 conn212: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.234-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:58722 #213 (81 connections now open)
2020-05-08T12:17:04.235-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:58724 #214 (82 connections now open)
2020-05-08T12:17:04.235-0700 I  NETWORK  [conn213] received client metadata from 192.168.122.14:58722 conn213: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.235-0700 I  NETWORK  [conn214] received client metadata from 192.168.122.14:58724 conn214: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.237-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:58726 #215 (83 connections now open)
2020-05-08T12:17:04.237-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:58728 #216 (84 connections now open)
2020-05-08T12:17:04.237-0700 I  NETWORK  [conn215] received client metadata from 192.168.122.14:58726 conn215: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.237-0700 I  NETWORK  [conn216] received client metadata from 192.168.122.14:58728 conn216: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.238-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:58730 #217 (85 connections now open)
2020-05-08T12:17:04.239-0700 I  NETWORK  [conn217] received client metadata from 192.168.122.14:58730 conn217: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.609-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40582 #218 (86 connections now open)
2020-05-08T12:17:04.609-0700 I  NETWORK  [conn218] received client metadata from 192.168.122.11:40582 conn218: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.611-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40956 #219 (87 connections now open)
2020-05-08T12:17:04.611-0700 I  NETWORK  [conn219] received client metadata from 192.168.122.11:40956 conn219: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.763-0700 I  COMMAND  [conn168] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 772ms
2020-05-08T12:17:04.763-0700 I  COMMAND  [conn171] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 770ms
2020-05-08T12:17:04.763-0700 I  COMMAND  [conn169] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 772ms
2020-05-08T12:17:04.763-0700 I  COMMAND  [conn27] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 774ms
2020-05-08T12:17:04.763-0700 I  COMMAND  [conn172] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 769ms
2020-05-08T12:17:04.763-0700 I  COMMAND  [conn39] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 763ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn175] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 761ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn192] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 686ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn199] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 683ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn204] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 681ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn185] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 694ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn182] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965419, 11), signature: { hash: BinData(0, 45DCC546E0C6C86869591F381AF62EC83F3501FA), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 740ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn186] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 693ms
2020-05-08T12:17:04.764-0700 I  COMMAND  [conn206] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 675ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn170] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1588965418472), up: 74, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 772ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn173] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 770ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn180] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965419, 11), signature: { hash: BinData(0, 45DCC546E0C6C86869591F381AF62EC83F3501FA), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 742ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn189] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 691ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn179] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1588965418471), up: 74, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965419, 11), signature: { hash: BinData(0, 45DCC546E0C6C86869591F381AF62EC83F3501FA), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 743ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965419, 11), signature: { hash: BinData(0, 45DCC546E0C6C86869591F381AF62EC83F3501FA), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 741ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn188] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 692ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn197] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 685ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn194] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 686ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn200] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1588965420081), up: 76, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 684ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 531ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn201] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1588965420289), up: 76, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 684ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn178] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 761ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn26] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965419, 11), signature: { hash: BinData(0, 45DCC546E0C6C86869591F381AF62EC83F3501FA), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 745ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn214] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 529ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn29] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 690ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn217] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 525ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn215] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 527ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn193] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 687ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn219] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1588965417764), up: 73, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965424, 56), signature: { hash: BinData(0, 4ECFD216B39CDB4863389B7F011C915AB4422825), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 153ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn202] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 682ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn205] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 676ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 678ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn195] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 687ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn213] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1588965420090), up: 76, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 529ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 690ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn124] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 690ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn176] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 762ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn21] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 690ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn196] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 686ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn198] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 684ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn123] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 677ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn216] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 528ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn184] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 696ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn203] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 682ms
2020-05-08T12:17:04.765-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn207] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 5), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 675ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1588965417782), up: 74, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 698ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn187] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 1), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 695ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn190] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 688ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn177] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 762ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn191] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 687ms
2020-05-08T12:17:04.765-0700 I  COMMAND  [conn211] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1588965417294), up: 73, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 18), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 666ms
2020-05-08T12:17:04.766-0700 I  COMMAND  [conn174] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1588965418472), up: 74, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 9C5A2BDDA4624E943AAD6F7240E7E799A9F89C11), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965412, 1), t: 16 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 764ms
2020-05-08T12:17:04.766-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:17:04.901-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40962 #220 (88 connections now open)
2020-05-08T12:17:04.902-0700 I  NETWORK  [conn220] received client metadata from 192.168.122.11:40962 conn220: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.987-0700 I  NETWORK  [conn220] end connection 192.168.122.11:40962 (87 connections now open)
2020-05-08T12:17:05.411-0700 I  ELECTION [conn212] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 18, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:05.411-0700 I  ELECTION [conn212] Sending vote response: { term: 18, voteGranted: true, reason: "" }
2020-05-08T12:17:05.414-0700 I  REPL     [conn212] stepping down from primary, because a new term has begun: 19
2020-05-08T12:17:05.414-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:05.415-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:05.415-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-05-08T12:17:05.415-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:17:05.415-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:05.415-0700 I  ELECTION [conn212] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:05.415-0700 I  ELECTION [conn212] Sending vote response: { term: 19, voteGranted: true, reason: "" }
2020-05-08T12:17:05.419-0700 I  NETWORK  [conn212] end connection 192.168.122.12:60446 (86 connections now open)
2020-05-08T12:17:05.766-0700 I  NETWORK  [conn151] end connection 192.168.122.12:59980 (85 connections now open)
2020-05-08T12:17:05.891-0700 I  REPL     [replexec-1] Member n1:27019 is now in state SECONDARY
2020-05-08T12:17:06.014-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34412 #221 (86 connections now open)
2020-05-08T12:17:06.014-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34418 #222 (87 connections now open)
2020-05-08T12:17:06.014-0700 I  NETWORK  [conn221] received client metadata from 192.168.122.1:34412 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.014-0700 I  NETWORK  [conn222] received client metadata from 192.168.122.1:34418 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.016-0700 I  NETWORK  [conn221] end connection 192.168.122.1:34412 (86 connections now open)
2020-05-08T12:17:06.016-0700 I  NETWORK  [conn222] end connection 192.168.122.1:34418 (85 connections now open)
2020-05-08T12:17:06.323-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34426 #223 (86 connections now open)
2020-05-08T12:17:06.324-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34430 #224 (87 connections now open)
2020-05-08T12:17:06.324-0700 I  NETWORK  [conn223] received client metadata from 192.168.122.1:34426 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.324-0700 I  NETWORK  [conn224] received client metadata from 192.168.122.1:34430 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.328-0700 I  NETWORK  [conn223] end connection 192.168.122.1:34426 (86 connections now open)
2020-05-08T12:17:06.328-0700 I  NETWORK  [conn224] end connection 192.168.122.1:34430 (85 connections now open)
2020-05-08T12:17:06.450-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:06.450-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 19
2020-05-08T12:17:06.450-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1112 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:06.450-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1113 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:06.451-0700 I  ELECTION [replexec-5] VoteRequester(term 19 dry run) received a yes vote from n1:27019; response message: { term: 19, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000011') }, lastCommittedOpTime: Timestamp(1588965424, 57), $clusterTime: { clusterTime: Timestamp(1588965425, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965424, 57) }
2020-05-08T12:17:06.451-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 20
2020-05-08T12:17:06.451-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:06.454-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1114 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 20, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:06.454-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1115 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 20, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:06.458-0700 I  ELECTION [replexec-4] VoteRequester(term 20) received a yes vote from n1:27019; response message: { term: 20, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000011') }, lastCommittedOpTime: Timestamp(1588965424, 57), $clusterTime: { clusterTime: Timestamp(1588965425, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965424, 57) }
2020-05-08T12:17:06.458-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 20
2020-05-08T12:17:06.458-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:17:06.458-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:06.458-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-05-08T12:17:06.458-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:06.459-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:17:07.459-0700 I  REPL     [replexec-6] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:07.459-0700 I  REPL     [replexec-1] Catchup timed out after becoming primary.
2020-05-08T12:17:07.459-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-08T12:17:07.459-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-08T12:17:07.459-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 20
2020-05-08T12:17:07.460-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:07.460-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:07.460-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:07.462-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:07.462-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:07.462-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:07.463-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:07.463-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:08.505-0700 I  COMMAND  [conn202] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 8), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 824ms
2020-05-08T12:17:08.505-0700 I  COMMAND  [conn124] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 2), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 629ms
2020-05-08T12:17:08.505-0700 I  COMMAND  [conn216] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 2), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 536ms
2020-05-08T12:17:08.505-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 2), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 535ms
2020-05-08T12:17:08.505-0700 I  COMMAND  [conn26] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965426, 8), signature: { hash: BinData(0, 8C626FFEF0932C7C2F73BB1EAF3335ECBC406DC9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 536ms
2020-05-08T12:17:08.505-0700 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965426, 8), signature: { hash: BinData(0, 8C626FFEF0932C7C2F73BB1EAF3335ECBC406DC9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 999ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn21] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 8), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 824ms
2020-05-08T12:17:08.506-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn190] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 5), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 781ms
2020-05-08T12:17:08.506-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn174] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 48), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 545ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn170] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 16), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 760ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn172] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 16), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 760ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn213] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 2), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 632ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn191] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 5), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 781ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn177] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 48), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 545ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn173] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 16), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 760ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn203] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 5), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 781ms
2020-05-08T12:17:08.506-0700 I  COMMAND  [conn176] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965427, 48), signature: { hash: BinData(0, CF6257F82DDBEA4165780513338A1611B34C1483), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 537ms
2020-05-08T12:17:09.029-0700 I  ELECTION [conn218] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 20, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:09.029-0700 I  ELECTION [conn218] Sending vote response: { term: 20, voteGranted: true, reason: "" }
2020-05-08T12:17:09.032-0700 I  REPL     [conn218] stepping down from primary, because a new term has begun: 21
2020-05-08T12:17:09.032-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:09.032-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:09.032-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-08T12:17:09.032-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:17:09.033-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:09.033-0700 I  ELECTION [conn218] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 21, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:09.033-0700 I  ELECTION [conn218] Sending vote response: { term: 21, voteGranted: true, reason: "" }
2020-05-08T12:17:10.173-0700 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:10.173-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 21
2020-05-08T12:17:10.173-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1126 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:10.173-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1127 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:10.173-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:10.174-0700 I  ELECTION [replexec-6] VoteRequester(term 21 dry run) received a yes vote from n1:27019; response message: { term: 21, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1588965427, 1), $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965427, 1) }
2020-05-08T12:17:10.174-0700 I  ELECTION [replexec-6] dry election run succeeded, running for election in term 22
2020-05-08T12:17:10.177-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1128 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:10.178-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1129 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:10.183-0700 I  ELECTION [replexec-5] VoteRequester(term 22) received a yes vote from n1:27019; response message: { term: 22, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000015') }, lastCommittedOpTime: Timestamp(1588965427, 1), $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965427, 1) }
2020-05-08T12:17:10.183-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 22
2020-05-08T12:17:10.183-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-08T12:17:10.183-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-05-08T12:17:10.184-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-08T12:17:10.459-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965427, 1), t: 20 }. My Last Applied: { ts: Timestamp(1588965427, 1), t: 20 }
2020-05-08T12:17:10.459-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-08T12:17:10.459-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-08T12:17:10.459-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 22
2020-05-08T12:17:10.460-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:10.460-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:10.460-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:10.462-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:10.462-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:10.463-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:10.463-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:10.463-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:10.753-0700 I  NETWORK  [conn166] end connection 192.168.122.12:60412 (84 connections now open)
2020-05-08T12:17:11.421-0700 I  NETWORK  [conn183] end connection 192.168.122.12:60650 (83 connections now open)
2020-05-08T12:17:11.421-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:32874 #226 (84 connections now open)
2020-05-08T12:17:11.422-0700 I  NETWORK  [conn226] received client metadata from 192.168.122.12:32874 conn226: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:11.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:32814 #227 (85 connections now open)
2020-05-08T12:17:11.457-0700 I  NETWORK  [conn227] received client metadata from 192.168.122.12:32814 conn227: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:11.736-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:12.460-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:12.902-0700 I  COMMAND  [conn127] command local.oplog.rs command: find { find: "oplog.rs", limit: 1, sort: { $natural: 1 }, projection: { ts: 1, t: 1 }, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1588965430, 21), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:1 nreturned:1 queryHash:B04BA76E planCacheKey:B04BA76E reslen:337 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 478ms
2020-05-08T12:17:12.902-0700 I  COMMAND  [conn76] command local.oplog.rs command: find { find: "oplog.rs", limit: 1, sort: { $natural: 1 }, projection: { ts: 1, t: 1 }, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1588965430, 17), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:1 nreturned:1 queryHash:B04BA76E planCacheKey:B04BA76E reslen:337 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 1393ms
2020-05-08T12:17:12.905-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:32894 #228 (86 connections now open)
2020-05-08T12:17:12.906-0700 I  NETWORK  [conn228] received client metadata from 192.168.122.12:32894 conn228: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:12.908-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:32898 #229 (87 connections now open)
2020-05-08T12:17:12.909-0700 I  NETWORK  [conn229] received client metadata from 192.168.122.12:32898 conn229: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:12.918-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:17:12.918-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 10), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 2072ms
2020-05-08T12:17:12.918-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:17:12.918-0700 I  COMMAND  [conn21] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 8), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 2073ms
2020-05-08T12:17:12.918-0700 I  COMMAND  [conn213] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 8), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 2399ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn173] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 12), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 2070ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn203] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 10), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 2071ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 17), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 2002ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, A42BD00F195D4050B9E36FCBDC0D5133D1B4B1CB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1456ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn184] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, A42BD00F195D4050B9E36FCBDC0D5133D1B4B1CB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 1456ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn211] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 9), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1619ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn207] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965430, 9), signature: { hash: BinData(0, 74B93DA2E0DD724CFDFAC84A9923280BE16F1B8B), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1620ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn188] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, A42BD00F195D4050B9E36FCBDC0D5133D1B4B1CB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1457ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn187] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, A42BD00F195D4050B9E36FCBDC0D5133D1B4B1CB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1457ms
2020-05-08T12:17:12.919-0700 I  COMMAND  [conn176] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, A42BD00F195D4050B9E36FCBDC0D5133D1B4B1CB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965427, 1), t: 20 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 2399ms
2020-05-08T12:17:13.084-0700 I  NETWORK  [conn229] end connection 192.168.122.12:32898 (86 connections now open)
2020-05-08T12:17:14.607-0700 I  ELECTION [conn218] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:14.607-0700 I  ELECTION [conn218] Sending vote response: { term: 22, voteGranted: true, reason: "" }
2020-05-08T12:17:14.616-0700 I  REPL     [conn218] stepping down from primary, because a new term has begun: 23
2020-05-08T12:17:14.616-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:14.616-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:14.616-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-08T12:17:14.617-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:17:14.617-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:14.617-0700 I  ELECTION [conn218] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 23, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:14.617-0700 I  ELECTION [conn218] Sending vote response: { term: 23, voteGranted: true, reason: "" }
2020-05-08T12:17:14.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41318 #231 (87 connections now open)
2020-05-08T12:17:14.623-0700 I  NETWORK  [conn231] received client metadata from 192.168.122.11:41318 conn231: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:14.630-0700 I  NETWORK  [conn218] end connection 192.168.122.11:40582 (86 connections now open)
2020-05-08T12:17:15.098-0700 I  NETWORK  [conn159] end connection 192.168.122.11:40346 (85 connections now open)
2020-05-08T12:17:15.395-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34756 #232 (86 connections now open)
2020-05-08T12:17:15.395-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34760 #233 (87 connections now open)
2020-05-08T12:17:15.395-0700 I  NETWORK  [conn232] received client metadata from 192.168.122.1:34756 conn232: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.396-0700 I  NETWORK  [conn233] received client metadata from 192.168.122.1:34760 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.398-0700 I  NETWORK  [conn232] end connection 192.168.122.1:34756 (86 connections now open)
2020-05-08T12:17:15.398-0700 I  NETWORK  [conn233] end connection 192.168.122.1:34760 (85 connections now open)
2020-05-08T12:17:15.641-0700 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:15.641-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 23
2020-05-08T12:17:15.641-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1145 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:15.641-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1146 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:15.642-0700 I  ELECTION [replexec-1] VoteRequester(term 23 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965433, 8), t: 22 }, my last applied OpTime: { ts: Timestamp(1588965434, 2), t: 23 }"; response message: { term: 23, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965433, 8), t: 22 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000013') }, lastCommittedOpTime: Timestamp(1588965433, 8), $clusterTime: { clusterTime: Timestamp(1588965435, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965434, 2) }
2020-05-08T12:17:15.849-0700 I  ELECTION [replexec-2] VoteRequester(term 23 dry run) received a no vote from n1:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965433, 8), t: 22 }, my last applied OpTime: { ts: Timestamp(1588965434, 11), t: 23 }"; response message: { term: 23, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965433, 8), t: 22 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000017') }, lastCommittedOpTime: Timestamp(1588965434, 2), $clusterTime: { clusterTime: Timestamp(1588965435, 75), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965434, 11) }
2020-05-08T12:17:15.849-0700 I  ELECTION [replexec-2] not running for primary, we received insufficient votes
2020-05-08T12:17:15.849-0700 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-05-08T12:17:16.187-0700 I  REPL     [replexec-5] Member n1:27019 is now in state PRIMARY
2020-05-08T12:17:16.618-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:16.620-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:17.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34830 #234 (86 connections now open)
2020-05-08T12:17:17.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34834 #235 (87 connections now open)
2020-05-08T12:17:17.915-0700 I  NETWORK  [conn234] received client metadata from 192.168.122.1:34830 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:17.916-0700 I  NETWORK  [conn235] received client metadata from 192.168.122.1:34834 conn235: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:17.918-0700 I  NETWORK  [conn234] end connection 192.168.122.1:34830 (86 connections now open)
2020-05-08T12:17:17.918-0700 I  NETWORK  [conn235] end connection 192.168.122.1:34834 (85 connections now open)
2020-05-08T12:17:18.996-0700 I  ELECTION [conn227] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:18.996-0700 I  ELECTION [conn227] Sending vote response: { term: 23, voteGranted: true, reason: "" }
2020-05-08T12:17:19.002-0700 I  ELECTION [conn227] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 24, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:19.002-0700 I  ELECTION [conn227] Sending vote response: { term: 24, voteGranted: true, reason: "" }
2020-05-08T12:17:19.688-0700 I  REPL     [replexec-5] Member n1:27019 is now in state RS_DOWN - Request 1160 timed out, deadline was 2020-05-08T12:17:19.688-0700, op was RemoteCommand 1160 -- target:[n1:27019] db:admin expDate:2020-05-08T12:17:19.688-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 23 }
2020-05-08T12:17:19.688-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:19.688-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:17:20.131-0700 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1588965434, 11), t: 23 }, latest oplog optime of sync source: { ts: Timestamp(1588965434, 11), t: 23 } (sync source does not know the primary)
2020-05-08T12:17:20.131-0700 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1588965434, 11), t: 23 }, its sync source index:-1
2020-05-08T12:17:20.132-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965434, 11), t: 23 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:17:20.132-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:17:20.132-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:17:20.689-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:20.689-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 24
2020-05-08T12:17:20.689-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1168 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 24, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:20.689-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1169 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 24, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:20.689-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:17:20.690-0700 I  ELECTION [replexec-4] VoteRequester(term 24 dry run) received a yes vote from n2:27019; response message: { term: 24, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965440, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965434, 11) }
2020-05-08T12:17:20.690-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 25
2020-05-08T12:17:20.707-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1170 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 25, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:20.707-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1171 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 25, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:20.716-0700 I  ELECTION [replexec-3] VoteRequester(term 25) received a yes vote from n2:27019; response message: { term: 25, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965440, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965434, 11) }
2020-05-08T12:17:20.716-0700 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 25
2020-05-08T12:17:20.716-0700 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-05-08T12:17:20.716-0700 I  REPL     [replexec-3] Resetting sync source to empty, which was :27017
2020-05-08T12:17:20.716-0700 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-05-08T12:17:21.132-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965434, 11), t: 23 }. My Last Applied: { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:21.132-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-08T12:17:21.132-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-08T12:17:21.132-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 25
2020-05-08T12:17:21.133-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:21.133-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:21.133-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:21.134-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:21.135-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:21.135-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:21.135-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:21.135-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:21.138-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:21.138-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-08T12:17:21.953-0700 I  NETWORK  [conn231] end connection 192.168.122.11:41318 (84 connections now open)
2020-05-08T12:17:21.972-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35016 #237 (85 connections now open)
2020-05-08T12:17:21.973-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35020 #238 (86 connections now open)
2020-05-08T12:17:21.973-0700 I  NETWORK  [conn237] received client metadata from 192.168.122.1:35016 conn237: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:21.973-0700 I  NETWORK  [conn238] received client metadata from 192.168.122.1:35020 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:21.977-0700 I  NETWORK  [conn237] end connection 192.168.122.1:35016 (85 connections now open)
2020-05-08T12:17:21.977-0700 I  NETWORK  [conn238] end connection 192.168.122.1:35020 (84 connections now open)
2020-05-08T12:17:22.510-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:22.510-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:22.510-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-08T12:17:22.510-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:22.511-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:22.511-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 19, userOpsRunning: 0 }
2020-05-08T12:17:22.511-0700 W  COMMAND  [conn82] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.511-0700 I  COMMAND  [conn82] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27018:1588965345:-3184880103931982133" }, update: { $set: { ping: new Date(1588965439786) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 20), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1222ms
2020-05-08T12:17:22.511-0700 W  COMMAND  [conn202] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.511-0700 I  COMMAND  [conn202] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 94), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 1148ms
2020-05-08T12:17:22.512-0700 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.512-0700 I  COMMAND  [conn43] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27018:1588965345:-465166209935970491" }, update: { $set: { ping: new Date(1588965439773) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 20), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1235ms
2020-05-08T12:17:22.512-0700 W  COMMAND  [conn26] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.512-0700 I  COMMAND  [conn26] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 78), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1147ms
2020-05-08T12:17:22.512-0700 W  COMMAND  [conn176] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.512-0700 I  COMMAND  [conn176] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 129), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1148ms
2020-05-08T12:17:22.512-0700 W  COMMAND  [conn216] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.512-0700 I  COMMAND  [conn216] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 84), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1149ms
2020-05-08T12:17:22.513-0700 W  COMMAND  [conn203] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.513-0700 I  COMMAND  [conn203] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 96), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1074ms
2020-05-08T12:17:22.513-0700 W  COMMAND  [conn45] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.514-0700 I  COMMAND  [conn45] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27018:1588965345:-5626666314136012223" }, update: { $set: { ping: new Date(1588965439786) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 130), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1224ms
2020-05-08T12:17:22.514-0700 W  COMMAND  [conn177] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.514-0700 W  COMMAND  [conn181] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.514-0700 I  COMMAND  [conn177] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 129), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1150ms
2020-05-08T12:17:22.514-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-08T12:17:22.514-0700 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 78), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1150ms
2020-05-08T12:17:22.515-0700 W  COMMAND  [conn49] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.515-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:22.515-0700 I  COMMAND  [conn49] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27018:1588965345:4642009900937274884" }, update: { $set: { ping: new Date(1588965438745) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 11), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 1150ms
2020-05-08T12:17:22.515-0700 W  COMMAND  [conn213] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.515-0700 I  COMMAND  [conn213] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 84), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1151ms
2020-05-08T12:17:22.515-0700 W  COMMAND  [conn65] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.515-0700 W  COMMAND  [conn211] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.515-0700 I  COMMAND  [conn65] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27018:1588965345:-3830833260225672011" }, update: { $set: { ping: new Date(1588965438747) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 11), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1151ms
2020-05-08T12:17:22.516-0700 I  COMMAND  [conn211] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 37), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 624ms
2020-05-08T12:17:22.516-0700 W  COMMAND  [conn191] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.515-0700 W  COMMAND  [conn173] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.516-0700 W  COMMAND  [conn21] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.516-0700 I  COMMAND  [conn173] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 129), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 988ms
2020-05-08T12:17:22.516-0700 I  COMMAND  [conn191] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 96), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1077ms
2020-05-08T12:17:22.516-0700 W  COMMAND  [conn172] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.516-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-08T12:17:22.516-0700 I  COMMAND  [conn21] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 94), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1152ms
2020-05-08T12:17:22.516-0700 I  COMMAND  [conn172] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965440, 129), signature: { hash: BinData(0, FB47FD94BBA5DE550068CCD5441105644336E0E2), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 988ms
2020-05-08T12:17:22.516-0700 W  COMMAND  [conn81] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:22.516-0700 I  COMMAND  [conn81] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27018:1588965345:-3626659247996741111" }, update: { $set: { ping: new Date(1588965438746) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 11), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1152ms
2020-05-08T12:17:23.526-0700 I  ELECTION [replexec-6] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:23.717-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:24.626-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:24.865-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41666 #239 (85 connections now open)
2020-05-08T12:17:24.865-0700 I  NETWORK  [conn239] received client metadata from 192.168.122.11:41666 conn239: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:25.061-0700 I  REPL     [replexec-6] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:25.118-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:33430 #240 (86 connections now open)
2020-05-08T12:17:25.119-0700 I  NETWORK  [conn240] received client metadata from 192.168.122.12:33430 conn240: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:25.120-0700 I  ELECTION [conn240] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:25.120-0700 I  ELECTION [conn240] Sending vote response: { term: 26, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965434, 11), t: 23 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:25.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35184 #241 (87 connections now open)
2020-05-08T12:17:25.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35188 #242 (88 connections now open)
2020-05-08T12:17:25.157-0700 I  NETWORK  [conn241] received client metadata from 192.168.122.1:35184 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.157-0700 I  NETWORK  [conn242] received client metadata from 192.168.122.1:35188 conn242: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.159-0700 I  NETWORK  [conn241] end connection 192.168.122.1:35184 (87 connections now open)
2020-05-08T12:17:25.159-0700 I  NETWORK  [conn242] end connection 192.168.122.1:35188 (86 connections now open)
2020-05-08T12:17:25.310-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:25.310-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: NetworkInterfaceExceededTimeLimit: Request 1074 timed out, deadline was 2020-05-08T12:17:25.310-0700, op was RemoteCommand 1074 -- target:[n2:27019] db:admin expDate:2020-05-08T12:17:25.310-0700 cmd:{ replSetUpdatePosition: 1, optimes: [ { durableOpTime: { ts: Timestamp(1588965412, 1), t: 16 }, durableWallTime: new Date(1588965412747), appliedOpTime: { ts: Timestamp(1588965412, 1), t: 16 }, appliedWallTime: new Date(1588965412747), memberId: 0, cfgver: 1 }, { durableOpTime: { ts: Timestamp(1588965412, 1), t: 16 }, durableWallTime: new Date(1588965412747), appliedOpTime: { ts: Timestamp(1588965412, 1), t: 16 }, appliedWallTime: new Date(1588965412747), memberId: 1, cfgver: 1 }, { durableOpTime: { ts: Timestamp(1588965412, 1), t: 16 }, durableWallTime: new Date(1588965412747), appliedOpTime: { ts: Timestamp(1588965412, 1), t: 16 }, appliedWallTime: new Date(1588965412747), memberId: 2, cfgver: 1 } ], $replData: { term: 17, lastOpCommitted: { ts: Timestamp(1588965412, 1), t: 16 }, lastCommittedWall: new Date(1588965412747), lastOpVisible: { ts: Timestamp(1588965412, 1), t: 16 }, configVersion: 1, replicaSetId: ObjectId('5eb5afdaa0224cfb413c716c'), primaryIndex: 0, syncSourceIndex: 1 } }
2020-05-08T12:17:25.345-0700 I  NETWORK  [conn227] end connection 192.168.122.12:32814 (85 connections now open)
2020-05-08T12:17:25.569-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:33316 #243 (86 connections now open)
2020-05-08T12:17:25.569-0700 I  NETWORK  [conn243] received client metadata from 192.168.122.12:33316 conn243: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:25.578-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35246 #244 (87 connections now open)
2020-05-08T12:17:25.578-0700 I  NETWORK  [conn244] received client metadata from 192.168.122.1:35246 conn244: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.578-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35252 #245 (88 connections now open)
2020-05-08T12:17:25.579-0700 I  NETWORK  [conn245] received client metadata from 192.168.122.1:35252 conn245: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.582-0700 I  NETWORK  [conn244] end connection 192.168.122.1:35246 (87 connections now open)
2020-05-08T12:17:25.582-0700 I  NETWORK  [conn245] end connection 192.168.122.1:35252 (86 connections now open)
2020-05-08T12:17:26.097-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:26.097-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 26
2020-05-08T12:17:26.097-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1192 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965441, 26), t: 25 } }
2020-05-08T12:17:26.097-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1193 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965441, 26), t: 25 } }
2020-05-08T12:17:26.098-0700 I  ELECTION [replexec-6] VoteRequester(term 26 dry run) received a yes vote from n2:27019; response message: { term: 26, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965441, 26) }
2020-05-08T12:17:26.098-0700 I  ELECTION [replexec-6] dry election run succeeded, running for election in term 27
2020-05-08T12:17:26.101-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1194 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 27, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965441, 26), t: 25 } }
2020-05-08T12:17:26.101-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1195 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 27, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965441, 26), t: 25 } }
2020-05-08T12:17:26.113-0700 I  ELECTION [replexec-4] VoteRequester(term 27) received a yes vote from n2:27019; response message: { term: 27, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965441, 26) }
2020-05-08T12:17:26.113-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 27
2020-05-08T12:17:26.113-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:17:26.113-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-05-08T12:17:26.113-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:17:26.299-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35264 #246 (87 connections now open)
2020-05-08T12:17:26.300-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35268 #247 (88 connections now open)
2020-05-08T12:17:26.300-0700 I  NETWORK  [conn246] received client metadata from 192.168.122.1:35264 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.300-0700 I  NETWORK  [conn247] received client metadata from 192.168.122.1:35268 conn247: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.304-0700 I  NETWORK  [conn246] end connection 192.168.122.1:35264 (87 connections now open)
2020-05-08T12:17:26.304-0700 I  NETWORK  [conn247] end connection 192.168.122.1:35268 (86 connections now open)
2020-05-08T12:17:26.657-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41662 #248 (87 connections now open)
2020-05-08T12:17:26.657-0700 I  NETWORK  [conn248] received client metadata from 192.168.122.11:41662 conn248: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:26.722-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35288 #249 (88 connections now open)
2020-05-08T12:17:26.722-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35292 #250 (89 connections now open)
2020-05-08T12:17:26.723-0700 I  NETWORK  [conn249] received client metadata from 192.168.122.1:35288 conn249: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.723-0700 I  NETWORK  [conn250] received client metadata from 192.168.122.1:35292 conn250: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.726-0700 I  NETWORK  [conn249] end connection 192.168.122.1:35288 (88 connections now open)
2020-05-08T12:17:26.726-0700 I  NETWORK  [conn250] end connection 192.168.122.1:35292 (87 connections now open)
2020-05-08T12:17:27.113-0700 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-05-08T12:17:27.113-0700 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-05-08T12:17:27.113-0700 I  REPL     [replexec-4] Stopping replication producer
2020-05-08T12:17:27.113-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 27
2020-05-08T12:17:27.113-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:27.114-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:27.114-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:27.116-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:27.116-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:27.116-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:27.117-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:27.117-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:27.557-0700 I  REPL     [replexec-6] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:27.557-0700 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:27.557-0700 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-05-08T12:17:27.557-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:27.557-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:27.557-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 25, userOpsRunning: 0 }
2020-05-08T12:17:27.560-0700 W  COMMAND  [conn203] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:27.560-0700 I  COMMAND  [conn203] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 8551F0F32DBD23A8C9F77A0833D44B1590B11CA4), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 238ms
2020-05-08T12:17:27.560-0700 W  COMMAND  [conn190] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:27.560-0700 W  COMMAND  [conn191] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:27.560-0700 I  COMMAND  [conn190] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1588965445859), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 8551F0F32DBD23A8C9F77A0833D44B1590B11CA4), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 238ms
2020-05-08T12:17:27.560-0700 I  COMMAND  [conn191] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 8551F0F32DBD23A8C9F77A0833D44B1590B11CA4), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 238ms
2020-05-08T12:17:27.561-0700 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-05-08T12:17:27.561-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard1 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.561-0700 I  CONNPOOL [ShardRegistry] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:27.561-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-08T12:17:27.561-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:17:27.561-0700 W  SHARDING [Balancer] Failed to enforce tag ranges :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.562-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:17:27.562-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.562-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:28.481-0700 I  NETWORK  [conn243] end connection 192.168.122.12:33316 (86 connections now open)
2020-05-08T12:17:28.529-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:28.769-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41910 #252 (87 connections now open)
2020-05-08T12:17:28.769-0700 I  NETWORK  [conn252] received client metadata from 192.168.122.11:41910 conn252: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.833-0700 I  NETWORK  [conn248] end connection 192.168.122.11:41662 (86 connections now open)
2020-05-08T12:17:29.562-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:29.564-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:29.564-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-08T12:17:29.566-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965447, 8), t: 27 }. source's GTE: { ts: Timestamp(1588965448, 1), t: 28 }
2020-05-08T12:17:29.566-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:29.566-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:17:29.566-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-08T12:17:29.566-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:17:29.566-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 3, userOpsRunning: 84 }
2020-05-08T12:17:29.566-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 252
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 240
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 239
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 228
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 226
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 219
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 217
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 216
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 215
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 214
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 213
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 211
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 207
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 206
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 205
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 204
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 203
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 202
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 201
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 200
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 199
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 198
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 197
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 196
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 195
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 194
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 193
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 192
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 191
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 190
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 189
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 188
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 187
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 186
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 185
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 184
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 182
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 181
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 180
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 179
2020-05-08T12:17:29.566-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 178
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 177
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 176
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 175
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 174
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 173
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 172
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 171
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 170
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 169
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 168
2020-05-08T12:17:29.567-0700 I  COMMAND  [conn211] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965448, 18), t: 28 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965448, 18), t: 28 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965448, 18), t: 28 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:757 locks:{} protocol:op_msg 557ms
2020-05-08T12:17:29.567-0700 I  COMMAND  [conn213] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965448, 18), t: 28 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965448, 18), t: 28 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965448, 18), t: 28 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:757 locks:{} protocol:op_msg 557ms
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 133
2020-05-08T12:17:29.567-0700 I  COMMAND  [conn176] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965448, 18), t: 28 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965448, 18), t: 28 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965448, 18), t: 28 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:757 locks:{} protocol:op_msg 558ms
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 127
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 124
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 123
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 18
2020-05-08T12:17:29.567-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 17
2020-05-08T12:17:29.567-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-08T12:17:29.567-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-08T12:17:29.568-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-08T12:17:29.573-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:29.578-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-08T12:17:29.578-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-08T12:17:29.578-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid ed1a62fa-1d96-460b-b917-f8098f56b82b to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-08T19-17-29.0.bson
2020-05-08T12:17:29.579-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 81acf486-601b-4e2b-8ee1-bbf74a1edd96 to /var/lib/mongodb/rollback/config.lockpings/removed.2020-05-08T19-17-29.1.bson
2020-05-08T12:17:29.580-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-08T12:17:29.580-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-08T12:17:29.580-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-08T12:17:29.580-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-08T12:17:29.623-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1588965434, 11) Initial Data Timestamp: Timestamp(1588965338, 1)
2020-05-08T12:17:29.624-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-08T12:17:29.633-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-08T12:17:29.633-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 302 records totaling to 64028 bytes
2020-05-08T12:17:29.633-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:17:29.633-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-08T12:17:29.636-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-08T12:17:29.637-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-08T12:17:29.653-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-08T12:17:29.653-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-08T12:17:29.653-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1588965434, 11)
2020-05-08T12:17:29.653-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 13 update operations and 0 delete operations.
2020-05-08T12:17:29.653-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1588965441, 1), t: 25 }
2020-05-08T12:17:29.654-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1588965441, 1) }
2020-05-08T12:17:29.654-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-08T12:17:29.666-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1588965434, 11) (top of oplog: { ts: Timestamp(1588965434, 11), t: 23 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-08T12:17:29.666-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1588965434, 11)
2020-05-08T12:17:29.666-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-08T12:17:29.566-0700
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-08T12:17:29.667-0700
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1588965447, 8), t: 27 }
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-08T12:17:27.524-0700
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-08T12:17:14.907-0700
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 12 second(s)
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1588965441, 1)
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1588965434, 11)
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 		update: 13
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 15
2020-05-08T12:17:29.667-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:17:29.667-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:29.669-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:30.501-0700 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to n6:27018 due to ShutdownInProgress: Pool for n6:27018 has expired.
2020-05-08T12:17:30.501-0700 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to n5:27018 due to ShutdownInProgress: Pool for n5:27018 has expired.
2020-05-08T12:17:32.257-0700 I  NETWORK  [conn90] end connection 192.168.122.11:38132 (85 connections now open)
2020-05-08T12:17:32.482-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35598 #255 (86 connections now open)
2020-05-08T12:17:32.482-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35602 #256 (87 connections now open)
2020-05-08T12:17:32.482-0700 I  NETWORK  [conn255] received client metadata from 192.168.122.1:35598 conn255: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:32.483-0700 I  NETWORK  [conn256] received client metadata from 192.168.122.1:35602 conn256: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:32.485-0700 I  NETWORK  [conn255] end connection 192.168.122.1:35598 (86 connections now open)
2020-05-08T12:17:32.486-0700 I  NETWORK  [conn256] end connection 192.168.122.1:35602 (85 connections now open)
2020-05-08T12:17:33.121-0700 I  ELECTION [conn240] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 28, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965448, 18), t: 28 } }
2020-05-08T12:17:33.122-0700 I  ELECTION [conn240] Sending vote response: { term: 28, voteGranted: true, reason: "" }
2020-05-08T12:17:33.125-0700 I  ELECTION [conn240] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 29, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965448, 18), t: 28 } }
2020-05-08T12:17:33.125-0700 I  ELECTION [conn240] Sending vote response: { term: 29, voteGranted: true, reason: "" }
2020-05-08T12:17:34.033-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-08T12:17:34.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35692 #257 (86 connections now open)
2020-05-08T12:17:34.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35696 #258 (87 connections now open)
2020-05-08T12:17:34.733-0700 I  NETWORK  [conn257] received client metadata from 192.168.122.1:35692 conn257: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:34.733-0700 I  NETWORK  [conn258] received client metadata from 192.168.122.1:35696 conn258: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:34.734-0700 I  NETWORK  [conn257] end connection 192.168.122.1:35692 (86 connections now open)
2020-05-08T12:17:34.734-0700 I  NETWORK  [conn258] end connection 192.168.122.1:35696 (85 connections now open)
2020-05-08T12:17:35.073-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41540 #260 (86 connections now open)
2020-05-08T12:17:35.073-0700 I  NETWORK  [conn260] received client metadata from 192.168.122.11:41540 conn260: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:35.113-0700 I  REPL     [replexec-6] Member n1:27019 is now in state SECONDARY
2020-05-08T12:17:35.196-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:42340 #261 (87 connections now open)
2020-05-08T12:17:35.197-0700 I  NETWORK  [conn261] received client metadata from 192.168.122.11:42340 conn261: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:35.628-0700 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:35.628-0700 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 29
2020-05-08T12:17:35.628-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1248 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 29, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:35.628-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1249 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 29, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:35.629-0700 I  ELECTION [replexec-2] VoteRequester(term 29 dry run) received a yes vote from n1:27019; response message: { term: 29, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001c') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965453, 11) }
2020-05-08T12:17:35.629-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 30
2020-05-08T12:17:35.629-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:35.629-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:35.633-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1250 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:35.633-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1251 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:35.637-0700 I  ELECTION [replexec-6] VoteRequester(term 30) received a yes vote from n1:27019; response message: { term: 30, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001c') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965453, 11) }
2020-05-08T12:17:35.637-0700 I  ELECTION [replexec-6] election succeeded, assuming primary role in term 30
2020-05-08T12:17:35.637-0700 I  REPL     [replexec-6] transition to PRIMARY from SECONDARY
2020-05-08T12:17:35.637-0700 I  REPL     [replexec-6] Resetting sync source to empty, which was n2:27019
2020-05-08T12:17:35.637-0700 I  REPL     [replexec-6] Entering primary catch-up mode.
2020-05-08T12:17:35.841-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965453, 11), t: 29 }; sync source index: -1; primary index: 1) is no longer valid
2020-05-08T12:17:35.841-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:17:35.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35830 #262 (88 connections now open)
2020-05-08T12:17:35.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35834 #263 (89 connections now open)
2020-05-08T12:17:35.910-0700 I  NETWORK  [conn262] received client metadata from 192.168.122.1:35830 conn262: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.910-0700 I  NETWORK  [conn263] received client metadata from 192.168.122.1:35834 conn263: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.913-0700 I  NETWORK  [conn262] end connection 192.168.122.1:35830 (88 connections now open)
2020-05-08T12:17:35.914-0700 I  NETWORK  [conn263] end connection 192.168.122.1:35834 (87 connections now open)
2020-05-08T12:17:36.637-0700 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-05-08T12:17:36.637-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-08T12:17:36.637-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-08T12:17:36.637-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:36.637-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 30
2020-05-08T12:17:36.638-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:36.638-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:36.638-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:36.640-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:36.640-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:36.641-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:36.642-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:36.642-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:36.642-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:36.642-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:36.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:36.643-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:36.704-0700 I  REPL     [replexec-1] Member n1:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:36.704-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:36.704-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-08T12:17:36.704-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:36.705-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:36.705-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 2, userOpsRunning: 0 }
2020-05-08T12:17:36.705-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-08T12:17:36.705-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:17:36.706-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:17:36.706-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:36.706-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:37.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:37.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:37.705-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:38.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:38.638-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:38.644-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:38.793-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:39.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:39.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:39.807-0700 I  NETWORK  [conn226] end connection 192.168.122.12:32874 (86 connections now open)
2020-05-08T12:17:39.808-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34292 #264 (87 connections now open)
2020-05-08T12:17:39.809-0700 I  NETWORK  [conn264] received client metadata from 192.168.122.12:34292 conn264: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:39.852-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:39.946-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36024 #265 (88 connections now open)
2020-05-08T12:17:39.946-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36028 #266 (89 connections now open)
2020-05-08T12:17:39.946-0700 I  NETWORK  [conn265] received client metadata from 192.168.122.1:36024 conn265: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:39.946-0700 I  NETWORK  [conn266] received client metadata from 192.168.122.1:36028 conn266: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:39.950-0700 I  NETWORK  [conn265] end connection 192.168.122.1:36024 (88 connections now open)
2020-05-08T12:17:39.950-0700 I  NETWORK  [conn266] end connection 192.168.122.1:36028 (87 connections now open)
2020-05-08T12:17:40.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:40.161-0700 I  ELECTION [conn260] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:40.161-0700 I  ELECTION [conn260] Sending vote response: { term: 30, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965453, 11), t: 29 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:40.161-0700 I  NETWORK  [conn260] end connection 192.168.122.11:41540 (86 connections now open)
2020-05-08T12:17:40.644-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:40.689-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:17:40.691-0700 I  REPL     [replexec-3] Member n1:27019 is now in state SECONDARY
2020-05-08T12:17:40.705-0700 I  NETWORK  [conn252] end connection 192.168.122.11:41910 (85 connections now open)
2020-05-08T12:17:40.869-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:42448 #268 (86 connections now open)
2020-05-08T12:17:40.869-0700 I  NETWORK  [conn268] received client metadata from 192.168.122.11:42448 conn268: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:40.962-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:40.962-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 30
2020-05-08T12:17:40.962-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1290 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:40.962-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1291 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:40.963-0700 I  ELECTION [replexec-5] VoteRequester(term 30 dry run) received a yes vote from n1:27019; response message: { term: 30, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001c') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965458, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965456, 1) }
2020-05-08T12:17:40.963-0700 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 31
2020-05-08T12:17:40.966-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1292 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 31, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:40.967-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1293 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 31, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:40.970-0700 I  ELECTION [replexec-2] VoteRequester(term 31) received a yes vote from n1:27019; response message: { term: 31, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001c') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965458, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965456, 1) }
2020-05-08T12:17:40.970-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 31
2020-05-08T12:17:40.970-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-08T12:17:40.970-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-08T12:17:40.971-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-08T12:17:41.138-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965456, 1), t: 30 }. My Last Applied: { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:41.138-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-08T12:17:41.138-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-08T12:17:41.138-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 31
2020-05-08T12:17:41.139-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:41.139-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:41.139-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:41.141-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:41.141-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:41.141-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:41.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:41.644-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:41.985-0700 I  NETWORK  [conn240] end connection 192.168.122.12:33430 (85 connections now open)
2020-05-08T12:17:42.057-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34440 #269 (86 connections now open)
2020-05-08T12:17:42.057-0700 I  NETWORK  [conn269] received client metadata from 192.168.122.12:34440 conn269: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:42.058-0700 I  REPL     [conn269] stepping down from primary, because a new term has begun: 32
2020-05-08T12:17:42.059-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:42.061-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:42.061-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 20, userOpsRunning: 1 }
2020-05-08T12:17:42.061-0700 W  COMMAND  [conn181] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.061-0700 I  COMMAND  [conn181] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 45), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 512ms
2020-05-08T12:17:42.061-0700 W  COMMAND  [conn174] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.061-0700 I  COMMAND  [conn174] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1588965459570), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965460, 103), signature: { hash: BinData(0, 82BA34F2C513CE5E55385E992972F4D9F4764E0D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 598ms
2020-05-08T12:17:42.062-0700 W  COMMAND  [conn200] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.062-0700 I  COMMAND  [conn200] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 58), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 446ms
2020-05-08T12:17:42.062-0700 W  COMMAND  [conn213] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.062-0700 I  COMMAND  [conn213] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1588965459570), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965460, 26), signature: { hash: BinData(0, 82BA34F2C513CE5E55385E992972F4D9F4764E0D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 488ms
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn178] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn187] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn178] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965460, 103), signature: { hash: BinData(0, 82BA34F2C513CE5E55385E992972F4D9F4764E0D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 600ms
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn187] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1588965459011), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965460, 92), signature: { hash: BinData(0, 82BA34F2C513CE5E55385E992972F4D9F4764E0D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 548ms
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn211] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn176] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn211] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965458, 7), signature: { hash: BinData(0, 5E6F74CFFE14EACECA3E812589850CDA0C5E90AC), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 920ms
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn176] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965460, 103), signature: { hash: BinData(0, 82BA34F2C513CE5E55385E992972F4D9F4764E0D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 600ms
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn38] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn173] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1588965459012), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 7), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 719ms
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn173] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1588965459011), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965458, 45), signature: { hash: BinData(0, 5E6F74CFFE14EACECA3E812589850CDA0C5E90AC), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 549ms
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn21] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn26] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn21] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 58), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 447ms
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn123] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn190] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn207] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn190] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1588965459010), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965458, 1), signature: { hash: BinData(0, 5E6F74CFFE14EACECA3E812589850CDA0C5E90AC), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 550ms
2020-05-08T12:17:42.063-0700 W  COMMAND  [conn180] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.064-0700 I  COMMAND  [conn207] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965458, 7), signature: { hash: BinData(0, 5E6F74CFFE14EACECA3E812589850CDA0C5E90AC), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 920ms
2020-05-08T12:17:42.064-0700 W  COMMAND  [conn124] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.064-0700 I  COMMAND  [conn180] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1588965459009), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 45), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 515ms
2020-05-08T12:17:42.064-0700 I  COMMAND  [conn124] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 7), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 720ms
2020-05-08T12:17:42.064-0700 W  COMMAND  [conn179] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn123] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1588965459570), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965458, 7), signature: { hash: BinData(0, 5E6F74CFFE14EACECA3E812589850CDA0C5E90AC), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 920ms
2020-05-08T12:17:42.064-0700 I  REPL     [replexec-3] transition to SECONDARY from PRIMARY
2020-05-08T12:17:42.063-0700 I  COMMAND  [conn26] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 45), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 515ms
2020-05-08T12:17:42.064-0700 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.064-0700 I  COMMAND  [conn179] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 45), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 515ms
2020-05-08T12:17:42.064-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965458, 7), signature: { hash: BinData(0, 5E6F74CFFE14EACECA3E812589850CDA0C5E90AC), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 920ms
2020-05-08T12:17:42.064-0700 W  COMMAND  [conn193] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:42.064-0700 I  COMMAND  [conn193] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1588965459010), up: 115, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965461, 58), signature: { hash: BinData(0, 80D28330E549DF51511CF82BC0240A7A660EF724), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 448ms
2020-05-08T12:17:42.064-0700 W  SHARDING [Balancer] Balancer settings could not be loaded and will be retried in 10 seconds :: caused by :: InterruptedDueToReplStateChange: Failed to refresh the balancer settings :: caused by :: Error waiting for snapshot not less than { ts: Timestamp(1588965456, 1), t: 30 }, current relevant optime is { ts: Timestamp(1588965453, 11), t: 29 }. :: caused by :: operation was interrupted
2020-05-08T12:17:42.064-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:42.064-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:42.064-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:42.065-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-08T12:17:42.065-0700 I  ELECTION [conn269] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:42.065-0700 I  ELECTION [conn269] Sending vote response: { term: 32, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965456, 1), t: 30 }, my last applied OpTime: { ts: Timestam..." }
2020-05-08T12:17:42.065-0700 I  NETWORK  [conn269] end connection 192.168.122.12:34440 (85 connections now open)
2020-05-08T12:17:42.144-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:42.551-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36188 #270 (86 connections now open)
2020-05-08T12:17:42.551-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36192 #271 (87 connections now open)
2020-05-08T12:17:42.551-0700 I  NETWORK  [conn270] received client metadata from 192.168.122.1:36188 conn270: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:42.552-0700 I  NETWORK  [conn271] received client metadata from 192.168.122.1:36192 conn271: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:42.555-0700 I  NETWORK  [conn270] end connection 192.168.122.1:36188 (86 connections now open)
2020-05-08T12:17:42.555-0700 I  NETWORK  [conn271] end connection 192.168.122.1:36192 (85 connections now open)
2020-05-08T12:17:42.644-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:43.097-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:43.097-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 32
2020-05-08T12:17:43.097-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1309 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:43.097-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1310 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:43.097-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:17:43.098-0700 I  ELECTION [replexec-1] VoteRequester(term 32 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timestamp(1588965463, 8), t: 32 }"; response message: { term: 32, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000020') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965463, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965463, 8) }
2020-05-08T12:17:43.138-0700 I  REPL     [replexec-5] Member n2:27019 is now in state PRIMARY
2020-05-08T12:17:43.144-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:43.265-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34118 #274 (86 connections now open)
2020-05-08T12:17:43.265-0700 I  NETWORK  [conn274] received client metadata from 192.168.122.12:34118 conn274: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:43.639-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:43.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:43.972-0700 I  REPL     [replexec-4] Member n1:27019 is now in state RS_DOWN - Request 1308 timed out, deadline was 2020-05-08T12:17:43.972-0700, op was RemoteCommand 1308 -- target:[n1:27019] db:admin expDate:2020-05-08T12:17:43.972-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 32 }
2020-05-08T12:17:43.972-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:44.066-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:44.067-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:44.069-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965461, 59), t: 31 }. source's GTE: { ts: Timestamp(1588965463, 1), t: 32 }
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-08T12:17:44.070-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 87 }
2020-05-08T12:17:44.070-0700 I  ROLLBACK [rsBackgroundSync] ElectionInProgress: Cannot transition from SECONDARY to ROLLBACK :: caused by :: Cannot set follower mode to ROLLBACK because we are in the middle of running an election
2020-05-08T12:17:44.070-0700 W  REPL     [rsBackgroundSync] Rollback failed with retryable error: ElectionInProgress: Cannot transition from SECONDARY to ROLLBACK :: caused by :: Cannot set follower mode to ROLLBACK because we are in the middle of running an election
2020-05-08T12:17:44.070-0700 I  ELECTION [replexec-3] not running for primary, we received insufficient votes
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:17:44.070-0700 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:17:44.070-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:44.072-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:44.073-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965461, 59), t: 31 }. source's GTE: { ts: Timestamp(1588965463, 1), t: 32 }
2020-05-08T12:17:44.073-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T12:17:44.073-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:17:44.073-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-08T12:17:44.074-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:17:44.074-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 87 }
2020-05-08T12:17:44.074-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 274
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 268
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 264
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 261
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 239
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 228
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 219
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 217
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 216
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 215
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 214
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 213
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 211
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 207
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 206
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 205
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 204
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 203
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 202
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 201
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 200
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 199
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 198
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 197
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 196
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 195
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 194
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 193
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 192
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 191
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 190
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 189
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 188
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 187
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 186
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 185
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 184
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 182
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 181
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 180
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 179
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 178
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 177
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 176
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 175
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 174
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 173
2020-05-08T12:17:44.074-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 172
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 171
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 170
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 169
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 168
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 133
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 127
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 124
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 123
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 18
2020-05-08T12:17:44.075-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 17
2020-05-08T12:17:44.075-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-08T12:17:44.075-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-08T12:17:44.075-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-08T12:17:44.079-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:44.082-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 3
2020-05-08T12:17:44.082-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-08T12:17:44.082-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid ed1a62fa-1d96-460b-b917-f8098f56b82b to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-08T19-17-44.2.bson
2020-05-08T12:17:44.082-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-08T12:17:44.082-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-08T12:17:44.082-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-08T12:17:44.082-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-08T12:17:44.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:44.150-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1588965453, 11) Initial Data Timestamp: Timestamp(1588965338, 1)
2020-05-08T12:17:44.151-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-08T12:17:44.163-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-08T12:17:44.163-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 317 records totaling to 66738 bytes
2020-05-08T12:17:44.163-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:17:44.164-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-08T12:17:44.167-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-08T12:17:44.168-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-08T12:17:44.184-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-08T12:17:44.184-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-08T12:17:44.184-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1588965453, 11)
2020-05-08T12:17:44.184-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 9 update operations and 0 delete operations.
2020-05-08T12:17:44.184-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1588965461, 1), t: 31 }
2020-05-08T12:17:44.185-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1588965461, 1) }
2020-05-08T12:17:44.185-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-08T12:17:44.188-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1588965453, 11) (top of oplog: { ts: Timestamp(1588965456, 1), t: 30 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-08T12:17:44.188-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1588965453, 11)
2020-05-08T12:17:44.188-0700 I  REPL     [rsBackgroundSync] Replaying stored operations from Timestamp(1588965453, 11) (inclusive) to Timestamp(1588965456, 1) (inclusive).
2020-05-08T12:17:44.190-0700 I  REPL     [rsBackgroundSync] Applied 1 operations in 1 batches. Last operation applied with optime: { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:44.190-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-08T12:17:44.190-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-08T12:17:44.073-0700
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-08T12:17:44.191-0700
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.mongos
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 3
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1588965461, 59), t: 31 }
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-08T12:17:41.616-0700
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-08T12:17:41.140-0700
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1588965461, 1)
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1588965453, 11)
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 		update: 9
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 10
2020-05-08T12:17:44.191-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-08T12:17:44.191-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-08T12:17:44.191-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-08T12:17:44.191-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-08T12:17:44.191-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:17:44.191-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:17:44.191-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:44.192-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:44.195-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1588965463, 18), t: 32 }, latest oplog optime of sync source: { ts: Timestamp(1588965463, 18), t: 32 } (sync source does not know the primary)
2020-05-08T12:17:44.195-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1588965463, 18), t: 32 }, its sync source index:-1
2020-05-08T12:17:44.195-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965463, 18), t: 32 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:17:44.195-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:17:44.195-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:17:44.200-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:17:44.685-0700 I  ELECTION [conn274] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:44.685-0700 I  ELECTION [conn274] Sending vote response: { term: 32, voteGranted: true, reason: "" }
2020-05-08T12:17:44.689-0700 I  ELECTION [conn274] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 33, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:44.689-0700 I  ELECTION [conn274] Sending vote response: { term: 33, voteGranted: true, reason: "" }
2020-05-08T12:17:44.693-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34588 #276 (87 connections now open)
2020-05-08T12:17:44.693-0700 I  NETWORK  [conn276] received client metadata from 192.168.122.12:34588 conn276: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:44.693-0700 I  NETWORK  [conn274] end connection 192.168.122.12:34118 (86 connections now open)
2020-05-08T12:17:44.697-0700 I  REPL     [replexec-6] Member n2:27019 is now in state PRIMARY
2020-05-08T12:17:44.833-0700 I  ELECTION [conn268] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:44.833-0700 I  ELECTION [conn268] Sending vote response: { term: 33, voteGranted: false, reason: "candidate's term (32) is lower than mine (33)" }
2020-05-08T12:17:44.833-0700 I  NETWORK  [conn268] end connection 192.168.122.11:42448 (85 connections now open)
2020-05-08T12:17:45.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:42866 #277 (86 connections now open)
2020-05-08T12:17:45.157-0700 I  NETWORK  [conn277] received client metadata from 192.168.122.11:42866 conn277: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:45.158-0700 I  ELECTION [conn277] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:45.158-0700 I  ELECTION [conn277] Sending vote response: { term: 33, voteGranted: false, reason: "candidate's term (32) is lower than mine (33)" }
2020-05-08T12:17:45.276-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36384 #278 (87 connections now open)
2020-05-08T12:17:45.276-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36388 #279 (88 connections now open)
2020-05-08T12:17:45.277-0700 I  NETWORK  [conn278] received client metadata from 192.168.122.1:36384 conn278: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.277-0700 I  NETWORK  [conn279] received client metadata from 192.168.122.1:36388 conn279: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.280-0700 I  NETWORK  [conn278] end connection 192.168.122.1:36384 (87 connections now open)
2020-05-08T12:17:45.280-0700 I  NETWORK  [conn279] end connection 192.168.122.1:36388 (86 connections now open)
2020-05-08T12:17:45.569-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:42884 #280 (87 connections now open)
2020-05-08T12:17:45.570-0700 I  NETWORK  [conn280] received client metadata from 192.168.122.11:42884 conn280: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:45.798-0700 I  ELECTION [conn280] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:45.798-0700 I  ELECTION [conn280] Sending vote response: { term: 33, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:46.146-0700 I  REPL     [replexec-1] Member n1:27019 is now in state SECONDARY
2020-05-08T12:17:46.196-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:17:46.222-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:57488 #282 (88 connections now open)
2020-05-08T12:17:46.222-0700 I  NETWORK  [conn282] received client metadata from 192.168.122.18:57488 conn282: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:46.249-0700 I  ELECTION [replexec-6] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:46.249-0700 I  ELECTION [replexec-6] conducting a dry run election to see if we could be elected. current term: 33
2020-05-08T12:17:46.249-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1348 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:46.249-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 1349 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:46.250-0700 I  ELECTION [replexec-4] VoteRequester(term 33 dry run) received a yes vote from n1:27019; response message: { term: 33, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001c') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965461, 59) }
2020-05-08T12:17:46.250-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 34
2020-05-08T12:17:46.250-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:46.252-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1350 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 34, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:46.253-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1351 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 34, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:46.253-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:46.256-0700 I  ELECTION [replexec-6] VoteRequester(term 34) received a yes vote from n1:27019; response message: { term: 34, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001c') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965461, 59) }
2020-05-08T12:17:46.256-0700 I  ELECTION [replexec-6] election succeeded, assuming primary role in term 34
2020-05-08T12:17:46.256-0700 I  REPL     [replexec-6] transition to PRIMARY from SECONDARY
2020-05-08T12:17:46.256-0700 I  REPL     [replexec-6] Resetting sync source to empty, which was :27017
2020-05-08T12:17:46.256-0700 I  REPL     [replexec-6] Entering primary catch-up mode.
2020-05-08T12:17:46.256-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:46.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36434 #283 (89 connections now open)
2020-05-08T12:17:46.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36438 #284 (90 connections now open)
2020-05-08T12:17:46.590-0700 I  NETWORK  [conn283] received client metadata from 192.168.122.1:36434 conn283: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:46.591-0700 I  NETWORK  [conn284] received client metadata from 192.168.122.1:36438 conn284: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:46.594-0700 I  NETWORK  [conn283] end connection 192.168.122.1:36434 (89 connections now open)
2020-05-08T12:17:46.594-0700 I  NETWORK  [conn284] end connection 192.168.122.1:36438 (88 connections now open)
2020-05-08T12:17:46.609-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:17:46.697-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-08T12:17:46.697-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965461, 59), t: 31 }. My Last Applied: { ts: Timestamp(1588965463, 18), t: 32 }
2020-05-08T12:17:46.697-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-08T12:17:46.697-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-08T12:17:46.697-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:17:46.697-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 34
2020-05-08T12:17:46.697-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:46.698-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:46.698-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:46.698-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 8 }
2020-05-08T12:17:46.700-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:46.700-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:46.701-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:47.401-0700 I  REPL     [replexec-4] Member n1:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:47.401-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:47.401-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-08T12:17:47.401-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:47.402-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:47.402-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 18, userOpsRunning: 8 }
2020-05-08T12:17:47.402-0700 W  COMMAND  [conn177] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.402-0700 I  COMMAND  [conn177] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27017:1588965341:-562014436095676681" }, update: { $set: { ping: new Date(1588965463075) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 3), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 243ms
2020-05-08T12:17:47.402-0700 W  COMMAND  [conn174] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.402-0700 I  COMMAND  [conn174] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 3), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 243ms
2020-05-08T12:17:47.402-0700 W  COMMAND  [conn26] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.403-0700 I  COMMAND  [conn26] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 2), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 699ms
2020-05-08T12:17:47.403-0700 W  COMMAND  [conn216] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.403-0700 I  COMMAND  [conn216] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27017:1588965341:3187934225528271170" }, update: { $set: { ping: new Date(1588965463075) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 699ms
2020-05-08T12:17:47.404-0700 W  COMMAND  [conn217] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.404-0700 I  COMMAND  [conn217] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 244ms
2020-05-08T12:17:47.404-0700 W  COMMAND  [conn173] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.404-0700 I  COMMAND  [conn173] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 531ms
2020-05-08T12:17:47.405-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:17:47.405-0700 W  SHARDING [Balancer] Balancer settings could not be loaded and will be retried in 10 seconds :: caused by :: InterruptedDueToReplStateChange: Failed to refresh the balancer settings :: caused by :: Error waiting for snapshot not less than { ts: Timestamp(1588965456, 1), t: 30 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T12:17:47.405-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:47.405-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:47.405-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:47.405-0700 W  COMMAND  [conn190] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.405-0700 I  COMMAND  [conn190] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27017:1588965341:6871791939861018853" }, update: { $set: { ping: new Date(1588965463075) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 701ms
2020-05-08T12:17:47.405-0700 W  COMMAND  [conn213] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.405-0700 W  COMMAND  [conn180] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.405-0700 I  COMMAND  [conn213] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 702ms
2020-05-08T12:17:47.405-0700 W  COMMAND  [conn178] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.405-0700 I  COMMAND  [conn180] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 2), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 701ms
2020-05-08T12:17:47.405-0700 I  COMMAND  [conn178] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 3), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 246ms
2020-05-08T12:17:47.405-0700 W  COMMAND  [conn172] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.405-0700 W  COMMAND  [conn200] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn172] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27017:1588965341:2106346409928220643" }, update: { $set: { ping: new Date(1588965463097) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 532ms
2020-05-08T12:17:47.406-0700 W  COMMAND  [conn202] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 W  COMMAND  [conn211] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn200] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 247ms
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn202] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27017:1588965341:-4005854753316312821" }, update: { $set: { ping: new Date(1588965463098) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 247ms
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn211] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 247ms
2020-05-08T12:17:47.406-0700 W  COMMAND  [conn181] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 W  COMMAND  [conn123] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn181] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27017:1588965341:-4138072281809841771" }, update: { $set: { ping: new Date(1588965463097) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 2), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 702ms
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn123] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 496ms
2020-05-08T12:17:47.406-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-08T12:17:47.406-0700 W  COMMAND  [conn21] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 W  COMMAND  [conn207] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn21] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 248ms
2020-05-08T12:17:47.406-0700 I  COMMAND  [conn207] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n3:27017:1588965341:-8033712167525645570" }, update: { $set: { ping: new Date(1588965463097) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 496ms
2020-05-08T12:17:47.941-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:40366 #285 (89 connections now open)
2020-05-08T12:17:47.941-0700 I  NETWORK  [conn285] received client metadata from 192.168.122.19:40366 conn285: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:48.521-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:49.257-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:49.257-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-08T12:17:49.647-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:50.497-0700 I  NETWORK  [conn280] end connection 192.168.122.11:42884 (88 connections now open)
2020-05-08T12:17:50.625-0700 I  ELECTION [conn277] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:50.625-0700 I  ELECTION [conn277] Sending vote response: { term: 34, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:50.625-0700 I  NETWORK  [conn277] end connection 192.168.122.11:42866 (87 connections now open)
2020-05-08T12:17:50.659-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43138 #286 (88 connections now open)
2020-05-08T12:17:50.660-0700 I  NETWORK  [conn286] received client metadata from 192.168.122.11:43138 conn286: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:50.661-0700 I  ELECTION [conn286] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:50.661-0700 I  ELECTION [conn286] Sending vote response: { term: 34, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:50.721-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34734 #287 (89 connections now open)
2020-05-08T12:17:50.721-0700 I  NETWORK  [conn287] received client metadata from 192.168.122.12:34734 conn287: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:50.756-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43142 #288 (90 connections now open)
2020-05-08T12:17:50.757-0700 I  NETWORK  [conn288] received client metadata from 192.168.122.11:43142 conn288: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:50.786-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:50.850-0700 I  NETWORK  [conn288] end connection 192.168.122.11:43142 (89 connections now open)
2020-05-08T12:17:51.210-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34852 #289 (90 connections now open)
2020-05-08T12:17:51.210-0700 I  NETWORK  [conn289] received client metadata from 192.168.122.12:34852 conn289: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.321-0700 I  NETWORK  [conn289] end connection 192.168.122.12:34852 (89 connections now open)
2020-05-08T12:17:51.329-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43054 #290 (90 connections now open)
2020-05-08T12:17:51.329-0700 I  NETWORK  [conn290] received client metadata from 192.168.122.11:43054 conn290: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.701-0700 I  NETWORK  [conn264] end connection 192.168.122.12:34292 (89 connections now open)
2020-05-08T12:17:51.701-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:34856 #291 (90 connections now open)
2020-05-08T12:17:51.701-0700 I  NETWORK  [conn291] received client metadata from 192.168.122.12:34856 conn291: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.882-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:51.910-0700 I  NETWORK  [conn239] end connection 192.168.122.11:41666 (89 connections now open)
2020-05-08T12:17:51.910-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43160 #292 (90 connections now open)
2020-05-08T12:17:51.910-0700 I  NETWORK  [conn292] received client metadata from 192.168.122.11:43160 conn292: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.961-0700 I  ELECTION [conn290] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965466, 2), t: 34 } }
2020-05-08T12:17:51.961-0700 I  ELECTION [conn290] Sending vote response: { term: 34, voteGranted: true, reason: "" }
2020-05-08T12:17:51.966-0700 I  ELECTION [conn290] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 35, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965466, 2), t: 34 } }
2020-05-08T12:17:51.966-0700 I  ELECTION [conn290] Sending vote response: { term: 35, voteGranted: true, reason: "" }
2020-05-08T12:17:52.758-0700 I  REPL     [replexec-5] Member n1:27019 is now in state PRIMARY
2020-05-08T12:17:53.408-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-08T12:17:53.410-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-08T12:17:53.411-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-08T12:17:53.413-0700 I  COMMAND  [conn45] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965466, 2), signature: { hash: BinData(0, 8D72A8D081E4047A2A6A013C9B4AFC5FDC319D3C), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 2900ms
2020-05-08T12:17:53.413-0700 I  COMMAND  [conn193] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 7210ms
2020-05-08T12:17:53.413-0700 I  COMMAND  [conn37] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 7008ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn282] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(1604517341, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 hasSortStage:1 cursorExhausted:1 numYields:0 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 7190ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn81] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 cursorExhausted:1 numYields:0 nreturned:2 reslen:739 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 7834ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn285] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(1604517341, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965467, 106), signature: { hash: BinData(0, B2C0B39B13884B26BEDF41C2EF5B6E84028E06DF), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 hasSortStage:1 cursorExhausted:1 numYields:0 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 5471ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn65] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965464, 8), signature: { hash: BinData(0, F136610D19C9AD9DF7E1C0B15B5C7B6C095149CA), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 cursorExhausted:1 numYields:0 nreturned:2 reslen:739 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 7832ms
2020-05-08T12:17:53.413-0700 I  COMMAND  [conn179] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 7212ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn176] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 9C3A7852656A9AEC17E98EBC96FA92E6CCD3972D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 7214ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn49] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965453, 11), t: 29 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 13), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 3249ms
2020-05-08T12:17:53.414-0700 I  COMMAND  [conn82] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965434, 11), t: 23 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965462, 2), signature: { hash: BinData(0, 5375CCD6A36689B998E36578EDE19985EEFADCE5), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 cursorExhausted:1 numYields:0 nreturned:2 reslen:739 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 8024ms
2020-05-08T12:17:53.506-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:53.509-0700 I  NETWORK  [conn276] end connection 192.168.122.12:34588 (89 connections now open)
