2020-05-08 12:15:41 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T12:15:41.286-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T12:15:41.288-0700 I  CONTROL  [main] 
2020-05-08T12:15:41.288-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T12:15:41.288-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T12:15:41.288-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T12:15:41.288-0700 I  CONTROL  [main] 
2020-05-08T12:15:41.288-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] modules: none
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] build environment:
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T12:15:41.288-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-08T12:15:41.289-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.289-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-08T12:15:41.289-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-08T12:15:41.289-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n4:27017:1588965341:3187934225528271170 (sleeping for 30000ms)
2020-05-08T12:15:41.289-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T12:15:41.338-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:41.789-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.789-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.840-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588965340, 4), t: 1 }
2020-05-08T12:15:42.608-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T12:15:43.844-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T12:15:43.844-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T12:15:43.848-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("f35c2de0-0d52-4306-af56-d3f610a9f184"), lastMod: 0 } took 0 ms
2020-05-08T12:15:43.848-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T12:15:43.848-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T12:15:43.848-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T12:15:43.849-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T12:15:43.849-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T12:15:44.350-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60330 #8 (1 connection now open)
2020-05-08T12:15:44.352-0700 I  NETWORK  [conn8] received client metadata from 192.168.122.1:60330 conn8: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:44.353-0700 I  NETWORK  [conn8] end connection 192.168.122.1:60330 (0 connections now open)
2020-05-08T12:15:45.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60344 #9 (1 connection now open)
2020-05-08T12:15:45.268-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.1:60344 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.354-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60364 #10 (2 connections now open)
2020-05-08T12:15:45.355-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60370 #11 (3 connections now open)
2020-05-08T12:15:45.355-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:60364 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.355-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:60370 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.378-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60396 #12 (4 connections now open)
2020-05-08T12:15:45.378-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:60396 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.663-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60532 #13 (5 connections now open)
2020-05-08T12:15:45.664-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60536 #14 (6 connections now open)
2020-05-08T12:15:45.664-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:60532 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.664-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:60536 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:46.246-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60588 #15 (7 connections now open)
2020-05-08T12:15:46.246-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.1:60588 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:46.902-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60628 #16 (8 connections now open)
2020-05-08T12:15:46.903-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.1:60628 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:47.368-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60648 #17 (9 connections now open)
2020-05-08T12:15:47.368-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.1:60648 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.025-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60678 #18 (10 connections now open)
2020-05-08T12:15:48.025-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.1:60678 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.170-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60690 #19 (11 connections now open)
2020-05-08T12:15:48.171-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:60690 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.356-0700 I  COMMAND  [conn13] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c41e3398-3d05-41a3-9df4-b19b6b8bb41a") } } numYields:0 reslen:163 protocol:op_msg 4685ms
2020-05-08T12:15:50.359-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 1 ms
2020-05-08T12:15:50.361-0700 I  NETWORK  [conn13] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:50.361-0700 I  NETWORK  [conn13] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:50.361-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:15:50.361-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:15:50.362-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T12:15:50.362-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-08T12:15:50.362-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-08T12:15:50.362-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-08T12:15:50.364-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:50.364-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:50.392-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:50.392-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:50.392-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T12:15:50.439-0700 I  NETWORK  [conn13] end connection 192.168.122.1:60532 (10 connections now open)
2020-05-08T12:15:50.440-0700 I  NETWORK  [conn14] end connection 192.168.122.1:60536 (9 connections now open)
2020-05-08T12:15:50.453-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60826 #27 (10 connections now open)
2020-05-08T12:15:50.453-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60830 #28 (11 connections now open)
2020-05-08T12:15:50.453-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.1:60826 conn27: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.453-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.1:60830 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.458-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60854 #29 (12 connections now open)
2020-05-08T12:15:50.459-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60856 #30 (13 connections now open)
2020-05-08T12:15:50.459-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.1:60854 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.459-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.1:60856 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.462-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60858 #31 (14 connections now open)
2020-05-08T12:15:50.462-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60860 #32 (15 connections now open)
2020-05-08T12:15:50.462-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.1:60858 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.462-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.1:60860 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.468-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 2 ms
2020-05-08T12:15:50.730-0700 I  TXN      [conn31] transaction parameters:{ lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 11) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:235782, timeActiveMicros:254895, timeInactiveMicros:1278, 256ms
2020-05-08T12:15:50.731-0700 I  COMMAND  [conn31] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 235ms
2020-05-08T12:15:50.825-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32812 #40 (16 connections now open)
2020-05-08T12:15:50.826-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.1:32812 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.869-0700 I  COMMAND  [conn31] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 2, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965350, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 136ms
2020-05-08T12:15:50.870-0700 I  TXN      [conn27] transaction parameters:{ lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965350, 182) } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 182) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:51602, timeActiveMicros:98863, timeInactiveMicros:1713, 100ms
2020-05-08T12:15:50.892-0700 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 172) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:125277, timeActiveMicros:131830, timeInactiveMicros:2032, 133ms
2020-05-08T12:15:50.892-0700 I  COMMAND  [conn29] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 178), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc") }, txnNumber: 8, autocommit: false } numYields:0 reslen:214 protocol:op_msg 125ms
2020-05-08T12:15:50.923-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32874 #44 (17 connections now open)
2020-05-08T12:15:50.923-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.1:32874 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.124-0700 I  TXN      [conn31] transaction parameters:{ lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 240) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:209550, timeActiveMicros:231520, timeInactiveMicros:554, 232ms
2020-05-08T12:15:51.124-0700 I  COMMAND  [conn31] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 246), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3") }, txnNumber: 4, autocommit: false } numYields:0 reslen:183 protocol:op_msg 209ms
2020-05-08T12:15:51.124-0700 I  COMMAND  [conn27] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 255), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47") }, txnNumber: 11, autocommit: false } numYields:0 reslen:352 protocol:op_msg 179ms
2020-05-08T12:15:51.330-0700 I  COMMAND  [conn29] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc") }, txnNumber: 24, autocommit: false } numYields:0 reslen:321 protocol:op_msg 124ms
2020-05-08T12:15:51.342-0700 I  COMMAND  [conn27] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47") }, txnNumber: 13, autocommit: false } numYields:0 reslen:321 protocol:op_msg 107ms
2020-05-08T12:15:51.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:15:51.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:15:51.476-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:15:51.477-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:15:52.072-0700 I  COMMAND  [conn31] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 231), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3") }, txnNumber: 16, autocommit: false } numYields:0 reslen:321 protocol:op_msg 556ms
2020-05-08T12:15:52.072-0700 I  COMMAND  [conn27] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 230), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47") }, txnNumber: 16, autocommit: false } numYields:0 reslen:352 protocol:op_msg 557ms
2020-05-08T12:15:52.420-0700 I  COMMAND  [conn27] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47") }, txnNumber: 17, autocommit: false } numYields:0 reslen:321 protocol:op_msg 292ms
2020-05-08T12:15:52.490-0700 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 27, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 182) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 182) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1004175, timeActiveMicros:1053993, timeInactiveMicros:1389, 1055ms
2020-05-08T12:15:52.490-0700 I  COMMAND  [conn29] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 207), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc") }, txnNumber: 27, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1004ms
2020-05-08T12:15:52.545-0700 I  TXN      [conn27] transaction parameters:{ lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 43) } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 43) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:123647, timeInactiveMicros:710, 124ms
2020-05-08T12:15:53.471-0700 I  NETWORK  [conn29] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:53.473-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:53.864-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:53.865-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:53.972-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.972-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.973-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T12:15:53.974-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:53.974-0700 I  COMMAND  [conn27] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47") }, txnNumber: 18, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1428ms
2020-05-08T12:15:54.365-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:54.584-0700 I  NETWORK  [conn27] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:54.585-0700 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 52) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2083309, timeActiveMicros:2091886, timeInactiveMicros:1335, 2093ms
2020-05-08T12:15:54.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:54.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:54.865-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:55.085-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.180-0700 I  NETWORK  [conn31] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 9d901bed-1fe4-41cd-8604-ebd93907d9a3:17 stopped due to: operation was interrupted
2020-05-08T12:15:55.365-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:55.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.865-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:55.933-0700 I  NETWORK  [conn28] end connection 192.168.122.1:60830 (16 connections now open)
2020-05-08T12:15:55.934-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33210 #54 (17 connections now open)
2020-05-08T12:15:55.934-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33212 #55 (18 connections now open)
2020-05-08T12:15:55.935-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:33210 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:55.935-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:33212 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.085-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.229-0700 I  NETWORK  [conn32] end connection 192.168.122.1:60860 (17 connections now open)
2020-05-08T12:15:56.229-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33230 #56 (18 connections now open)
2020-05-08T12:15:56.230-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33232 #57 (19 connections now open)
2020-05-08T12:15:56.230-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.1:33230 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.230-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.1:33232 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.365-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:56.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.828-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33320 #58 (20 connections now open)
2020-05-08T12:15:56.828-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.1:33320 conn58: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.865-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:56.865-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:56.865-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:15:57.085-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:57.163-0700 I  COMMAND  [conn31] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9d901bed-1fe4-41cd-8604-ebd93907d9a3") }, txnNumber: 17, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5012ms
2020-05-08T12:15:57.164-0700 I  NETWORK  [conn31] end connection 192.168.122.1:60858 (19 connections now open)
2020-05-08T12:15:57.492-0700 I  NETWORK  [conn30] end connection 192.168.122.1:60856 (18 connections now open)
2020-05-08T12:15:57.493-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33412 #61 (19 connections now open)
2020-05-08T12:15:57.493-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33416 #62 (20 connections now open)
2020-05-08T12:15:57.493-0700 I  NETWORK  [conn61] received client metadata from 192.168.122.1:33412 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.494-0700 I  NETWORK  [conn62] received client metadata from 192.168.122.1:33416 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.513-0700 I  COMMAND  [conn29] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 52), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8cf1bb42-04c8-4e62-ad68-07623ba6bddc") }, txnNumber: 28, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5010ms
2020-05-08T12:15:57.513-0700 I  NETWORK  [conn29] end connection 192.168.122.1:60854 (19 connections now open)
2020-05-08T12:15:57.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.085-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.529-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:58.566-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965350, 10), t: 1 }, now { ts: Timestamp(1588965357, 6), t: 4 }
2020-05-08T12:15:58.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.681-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:58.977-0700 I  -        [conn27] operation was interrupted because a client disconnected
2020-05-08T12:15:58.978-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:58.978-0700 I  TXN      [conn27] transaction parameters:{ lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965353, 37) } }, globalReadTimestamp:{ ts: Timestamp(1588965353, 65) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002890, timeInactiveMicros:0, 5002ms
2020-05-08T12:15:58.978-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:58.978-0700 I  COMMAND  [conn27] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 5 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965353, 65), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29431bef-4731-44f3-a876-b602c41f6a47") }, txnNumber: 19, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965353, 37) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T12:15:58.978-0700 I  NETWORK  [conn27] end connection 192.168.122.1:60826 (18 connections now open)
2020-05-08T12:15:59.389-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:59.681-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:59.681-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:00.382-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 4151ms
2020-05-08T12:16:00.385-0700 I  TXN      [conn61] transaction parameters:{ lsid: { id: UUID("9b9e99be-7866-4dbb-ae4d-dd088e0a9614"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965354, 12) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2890125, timeInactiveMicros:0, 2890ms
2020-05-08T12:16:00.385-0700 I  COMMAND  [conn61] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 34 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9b9e99be-7866-4dbb-ae4d-dd088e0a9614") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 9b9e99be-7866-4dbb-ae4d-dd088e0a9614:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965354, 12) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 2890ms
2020-05-08T12:16:00.386-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965354, 12) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4449773, timeInactiveMicros:0, 4449ms
2020-05-08T12:16:00.386-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction fcde799b-7cc7-4193-8742-2669bb2bec23:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from n4:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588965354, 12) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:554 protocol:op_msg 4450ms
2020-05-08T12:16:00.453-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T12:16:00.701-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 178) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:125757, timeActiveMicros:137059, timeInactiveMicros:1513, 138ms
2020-05-08T12:16:00.701-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 183), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 6, autocommit: false } numYields:0 reslen:214 protocol:op_msg 125ms
2020-05-08T12:16:00.880-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33692 #65 (19 connections now open)
2020-05-08T12:16:00.881-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.1:33692 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:01.879-0700 I  NETWORK  [conn54] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:01.880-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:02.380-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:02.881-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:02.881-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:02.881-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T12:16:02.882-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965357, 6), t: 4 }, now { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T12:16:02.882-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:02.883-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:02.884-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:02.884-0700 I  COMMAND  [conn61] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 287), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9b9e99be-7866-4dbb-ae4d-dd088e0a9614") }, txnNumber: 11, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2108ms
2020-05-08T12:16:02.909-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 298) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 298) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2111639, timeActiveMicros:2127296, timeInactiveMicros:651, 2127ms
2020-05-08T12:16:02.909-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 286) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 286) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:2110645, timeActiveMicros:2136397, timeInactiveMicros:1586, 2137ms
2020-05-08T12:16:02.909-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 301), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 9, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2111ms
2020-05-08T12:16:02.909-0700 I  COMMAND  [conn56] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 301), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44") }, txnNumber: 9, autocommit: false } numYields:0 reslen:426 protocol:op_msg 2110ms
2020-05-08T12:16:03.173-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965362, 207) } }, globalReadTimestamp:{ ts: Timestamp(1588965362, 208) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:162423, timeActiveMicros:194395, timeInactiveMicros:1622, 196ms
2020-05-08T12:16:03.173-0700 I  COMMAND  [conn56] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44") }, txnNumber: 12, autocommit: false } numYields:0 reslen:214 protocol:op_msg 162ms
2020-05-08T12:16:03.982-0700 I  NETWORK  [conn54] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:16:03.982-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:04.274-0700 I  NETWORK  [conn56] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:04.482-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:04.483-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:04.484-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 319), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 50, autocommit: false } numYields:0 reslen:439 protocol:op_msg 518ms
2020-05-08T12:16:05.754-0700 I  NETWORK  [conn62] end connection 192.168.122.1:33416 (18 connections now open)
2020-05-08T12:16:05.755-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33856 #68 (19 connections now open)
2020-05-08T12:16:05.755-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33858 #69 (20 connections now open)
2020-05-08T12:16:05.755-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:33856 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:05.756-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:33858 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:05.953-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.275-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.775-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:06.776-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:06.776-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:16:06.789-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 65 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:277 protocol:op_msg 2220ms
2020-05-08T12:16:06.958-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 123) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3669886, timeActiveMicros:3713414, timeInactiveMicros:1714, 3715ms
2020-05-08T12:16:06.959-0700 I  NETWORK  [conn54] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:06.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:07.275-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:07.601-0700 I  TXN      [conn61] transaction parameters:{ lsid: { id: UUID("9b9e99be-7866-4dbb-ae4d-dd088e0a9614"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965363, 77) } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 78) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:4403971, timeActiveMicros:4450619, timeInactiveMicros:1801, 4452ms
2020-05-08T12:16:07.602-0700 I  COMMAND  [conn61] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 107), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9b9e99be-7866-4dbb-ae4d-dd088e0a9614") }, txnNumber: 16, autocommit: false } numYields:0 reslen:214 protocol:op_msg 4404ms
2020-05-08T12:16:07.602-0700 I  NETWORK  [conn61] end connection 192.168.122.1:33412 (19 connections now open)
2020-05-08T12:16:07.775-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:07.775-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:07.776-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:07.776-0700 I  COMMAND  [conn56] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 143), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44") }, txnNumber: 14, autocommit: false } numYields:0 reslen:495 protocol:op_msg 4488ms
2020-05-08T12:16:07.776-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 54, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965366, 13) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:985140, timeInactiveMicros:0, 985ms
2020-05-08T12:16:07.777-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965366, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 54, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 985ms
2020-05-08T12:16:07.777-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:07.863-0700 I  COMMAND  [conn68] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 2105ms
2020-05-08T12:16:07.944-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 64), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 54, autocommit: false } numYields:0 reslen:397 protocol:op_msg 165ms
2020-05-08T12:16:08.243-0700 I  NETWORK  [conn57] end connection 192.168.122.1:33232 (18 connections now open)
2020-05-08T12:16:08.244-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34008 #72 (19 connections now open)
2020-05-08T12:16:08.244-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34010 #73 (20 connections now open)
2020-05-08T12:16:08.245-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.1:34008 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:08.245-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.1:34010 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:08.277-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:08.347-0700 I  TXN      [conn68] transaction parameters:{ lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 89) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:453781, timeActiveMicros:480881, timeInactiveMicros:1278, 482ms
2020-05-08T12:16:08.347-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 81) } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 81) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:501541, timeActiveMicros:524167, timeInactiveMicros:2161, 526ms
2020-05-08T12:16:08.347-0700 I  COMMAND  [conn68] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 93), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 454ms
2020-05-08T12:16:08.347-0700 I  COMMAND  [conn56] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 86), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25e42fa5-d80b-4ebb-80b4-13428d484a44") }, txnNumber: 15, autocommit: false } numYields:0 reslen:214 protocol:op_msg 501ms
2020-05-08T12:16:08.347-0700 I  NETWORK  [conn56] end connection 192.168.122.1:33230 (19 connections now open)
2020-05-08T12:16:08.403-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 55, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 98) } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 98) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:458010, timeInactiveMicros:0, 458ms
2020-05-08T12:16:08.403-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965367, 98), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 55, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 98) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 458ms
2020-05-08T12:16:08.570-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:08.602-0700 I  TXN      [conn68] transaction parameters:{ lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 53) } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 53) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:73750, timeActiveMicros:127228, timeInactiveMicros:1569, 128ms
2020-05-08T12:16:08.626-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-08T12:16:08.734-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 57, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 81) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:108115, timeActiveMicros:161311, timeInactiveMicros:1537, 162ms
2020-05-08T12:16:08.734-0700 I  TXN      [conn68] transaction parameters:{ lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 87) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:107856, timeActiveMicros:129478, timeInactiveMicros:1183, 130ms
2020-05-08T12:16:08.734-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 57, autocommit: false } numYields:0 reslen:214 protocol:op_msg 108ms
2020-05-08T12:16:08.734-0700 I  COMMAND  [conn68] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517") }, txnNumber: 5, autocommit: false } numYields:0 reslen:214 protocol:op_msg 108ms
2020-05-08T12:16:08.777-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:08.777-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:08.853-0700 I  TXN      [conn68] transaction parameters:{ lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 130) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:58191, timeActiveMicros:114470, timeInactiveMicros:2548, 117ms
2020-05-08T12:16:08.962-0700 I  COMMAND  [conn68] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 7, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965368, 159), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 106ms
2020-05-08T12:16:09.692-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965361, 1), t: 5 }, now { ts: Timestamp(1588965369, 16), t: 6 }
2020-05-08T12:16:10.047-0700 I  NETWORK  [conn68] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:10.881-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:10.881-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:10.881-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:10.883-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965369, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 61, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1864ms
2020-05-08T12:16:12.705-0700 I  TXN      [conn68] transaction parameters:{ lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 193) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3709792, timeActiveMicros:3739929, timeInactiveMicros:2086, 3742ms
2020-05-08T12:16:12.705-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:12.706-0700 I  NETWORK  [conn54] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:12.706-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:12.707-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:12.708-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965370, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 61, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1823ms
2020-05-08T12:16:12.708-0700 I  COMMAND  [conn68] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 198), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517") }, txnNumber: 8, autocommit: false } numYields:0 reslen:462 protocol:op_msg 3713ms
2020-05-08T12:16:12.737-0700 I  NETWORK  [conn72] Marking host n6:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:12.737-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:16:13.031-0700 I  NETWORK  [conn54] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:13.032-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.033-0700 I  NETWORK  [conn72] Marking host n5:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:13.033-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.206-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.646-0700 I  NETWORK  [conn73] end connection 192.168.122.1:34010 (18 connections now open)
2020-05-08T12:16:13.647-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34274 #78 (19 connections now open)
2020-05-08T12:16:13.647-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34276 #79 (20 connections now open)
2020-05-08T12:16:13.647-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:34274 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.648-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.1:34276 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.707-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.736-0700 I  NETWORK  [conn55] end connection 192.168.122.1:33212 (19 connections now open)
2020-05-08T12:16:13.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34296 #80 (20 connections now open)
2020-05-08T12:16:13.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34300 #81 (21 connections now open)
2020-05-08T12:16:13.737-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.1:34296 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.738-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.1:34300 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.847-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdb5861abbf7eec2119; invalidating user cache
2020-05-08T12:16:13.869-0700 I  COMMAND  [conn72] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 163), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a227ec89-37cd-482f-99cc-b17511b0be72") }, txnNumber: 9, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T12:16:13.869-0700 I  NETWORK  [conn72] end connection 192.168.122.1:34008 (20 connections now open)
2020-05-08T12:16:13.964-0700 I  NETWORK  [conn69] end connection 192.168.122.1:33858 (19 connections now open)
2020-05-08T12:16:13.964-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34316 #82 (20 connections now open)
2020-05-08T12:16:13.965-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34320 #83 (21 connections now open)
2020-05-08T12:16:13.965-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.1:34316 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.965-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.1:34320 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.207-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:14.207-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:14.209-0700 I  COMMAND  [conn68] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965372, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b77a3b2-4084-45b0-9eeb-299f72d1e517") }, txnNumber: 8, autocommit: false } numYields:0 reslen:462 protocol:op_msg 1497ms
2020-05-08T12:16:14.209-0700 I  NETWORK  [conn68] end connection 192.168.122.1:33856 (20 connections now open)
2020-05-08T12:16:14.476-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:16:17.025-0700 I  NETWORK  [conn54] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:17.026-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:17.715-0700 I  -        [conn54] operation was interrupted because a client disconnected
2020-05-08T12:16:17.716-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 62, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965372, 20) } }, globalReadTimestamp:{ ts: Timestamp(1588965372, 20) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006023, timeInactiveMicros:0, 5006ms
2020-05-08T12:16:17.716-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 85 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965372, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fcde799b-7cc7-4193-8742-2669bb2bec23") }, txnNumber: 62, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965372, 20) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:16:17.716-0700 I  NETWORK  [conn54] end connection 192.168.122.1:33210 (19 connections now open)
2020-05-08T12:16:17.945-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:18.025-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:18.526-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:18.526-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:18.648-0700 I  NETWORK  [conn79] end connection 192.168.122.1:34276 (18 connections now open)
2020-05-08T12:16:18.649-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34550 #85 (19 connections now open)
2020-05-08T12:16:18.649-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34552 #86 (20 connections now open)
2020-05-08T12:16:18.649-0700 I  NETWORK  [conn85] received client metadata from 192.168.122.1:34550 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.649-0700 I  NETWORK  [conn86] received client metadata from 192.168.122.1:34552 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.651-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T12:16:18.732-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:18.733-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:18.738-0700 I  NETWORK  [conn81] end connection 192.168.122.1:34300 (19 connections now open)
2020-05-08T12:16:18.739-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34564 #88 (20 connections now open)
2020-05-08T12:16:18.739-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34568 #89 (21 connections now open)
2020-05-08T12:16:18.739-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.1:34564 conn88: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.740-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.1:34568 conn89: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.913-0700 I  COMMAND  [conn88] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 97 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965378, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de0168b9-ede7-4345-952e-f7daec7eb14d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 167ms
2020-05-08T12:16:18.913-0700 I  COMMAND  [conn82] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 91 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bb1f999c-b6a5-472c-a546-5f67239bd3fe") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4946ms
2020-05-08T12:16:18.916-0700 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("349f30ca-e33e-473b-b12b-f2028cc4849f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 5176ms
2020-05-08T12:16:18.916-0700 I  NETWORK  [conn80] end connection 192.168.122.1:34296 (20 connections now open)
2020-05-08T12:16:18.919-0700 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("bb1f999c-b6a5-472c-a546-5f67239bd3fe"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965373, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:4952504, timeInactiveMicros:543, 4953ms
2020-05-08T12:16:18.945-0700 I  COMMAND  [conn78] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5660c4cd-1922-4edb-88c5-9e21dcdec6d9") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 5296ms
2020-05-08T12:16:18.946-0700 I  NETWORK  [conn78] end connection 192.168.122.1:34274 (19 connections now open)
2020-05-08T12:16:18.952-0700 I  TXN      [conn88] transaction parameters:{ lsid: { id: UUID("de0168b9-ede7-4345-952e-f7daec7eb14d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965378, 10) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:36402, timeActiveMicros:205378, timeInactiveMicros:1038, 206ms
2020-05-08T12:16:18.952-0700 I  COMMAND  [conn85] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965376, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 301ms
2020-05-08T12:16:18.965-0700 I  NETWORK  [conn83] end connection 192.168.122.1:34320 (18 connections now open)
2020-05-08T12:16:18.965-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34598 #91 (19 connections now open)
2020-05-08T12:16:18.966-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34602 #92 (20 connections now open)
2020-05-08T12:16:18.966-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.1:34598 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.966-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.1:34602 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:19.000-0700 I  NETWORK  [conn82] end connection 192.168.122.1:34316 (19 connections now open)
2020-05-08T12:16:19.061-0700 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965378, 64) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:45628, timeActiveMicros:105749, timeInactiveMicros:1193, 106ms
2020-05-08T12:16:19.117-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:16:19.233-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:19.699-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:19.699-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:19.714-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965373, 1), t: 6 }, now { ts: Timestamp(1588965379, 197), t: 9 }
2020-05-08T12:16:20.929-0700 I  NETWORK  [conn88] Marking host n5:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T12:16:20.930-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:20.930-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:20.931-0700 I  COMMAND  [conn88] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 108 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965379, 148), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de0168b9-ede7-4345-952e-f7daec7eb14d") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:288 protocol:op_msg 1717ms
2020-05-08T12:16:21.061-0700 I  NETWORK  [conn91] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:21.062-0700 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f") }, txnNumber: 6, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1864ms
2020-05-08T12:16:21.081-0700 I  TXN      [conn91] transaction parameters:{ lsid: { id: UUID("037a8218-4134-4916-a385-4b17dbfdcbbd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965379, 127) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1887638, timeActiveMicros:1908944, timeInactiveMicros:906, 1909ms
2020-05-08T12:16:21.082-0700 I  COMMAND  [conn91] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 132), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("037a8218-4134-4916-a385-4b17dbfdcbbd") }, txnNumber: 5, autocommit: false } numYields:0 reslen:426 protocol:op_msg 1888ms
2020-05-08T12:16:21.384-0700 I  TXN      [conn91] transaction parameters:{ lsid: { id: UUID("037a8218-4134-4916-a385-4b17dbfdcbbd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 134) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:151578, timeActiveMicros:164981, timeInactiveMicros:1020, 166ms
2020-05-08T12:16:21.384-0700 I  COMMAND  [conn91] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 139), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("037a8218-4134-4916-a385-4b17dbfdcbbd") }, txnNumber: 8, autocommit: false } numYields:0 reslen:214 protocol:op_msg 151ms
2020-05-08T12:16:21.508-0700 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 201) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 201) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:136707, timeActiveMicros:157069, timeInactiveMicros:2549, 159ms
2020-05-08T12:16:21.508-0700 I  COMMAND  [conn85] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 213), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 136ms
2020-05-08T12:16:21.512-0700 I  TXN      [conn88] transaction parameters:{ lsid: { id: UUID("de0168b9-ede7-4345-952e-f7daec7eb14d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 214) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 214) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:138196, timeInactiveMicros:1336, 139ms
2020-05-08T12:16:21.604-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-08T12:16:21.654-0700 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 245) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:73379, timeActiveMicros:142537, timeInactiveMicros:1697, 144ms
2020-05-08T12:16:21.814-0700 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 288) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:123340, timeActiveMicros:156184, timeInactiveMicros:2218, 158ms
2020-05-08T12:16:21.814-0700 I  TXN      [conn91] transaction parameters:{ lsid: { id: UUID("037a8218-4134-4916-a385-4b17dbfdcbbd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 303) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:84540, timeActiveMicros:118823, timeInactiveMicros:1034, 119ms
2020-05-08T12:16:21.815-0700 I  COMMAND  [conn85] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 302), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f") }, txnNumber: 16, autocommit: false } numYields:0 reslen:214 protocol:op_msg 123ms
2020-05-08T12:16:22.725-0700 I  COMMAND  [conn88] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 343), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de0168b9-ede7-4345-952e-f7daec7eb14d") }, txnNumber: 22, autocommit: false } numYields:0 reslen:321 protocol:op_msg 867ms
2020-05-08T12:16:23.034-0700 I  NETWORK  [conn88] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:16:23.035-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:23.535-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.535-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.725-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34802 #95 (20 connections now open)
2020-05-08T12:16:25.726-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.1:34802 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:26.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:26.668-0700 I  NETWORK  [conn89] end connection 192.168.122.1:34568 (19 connections now open)
2020-05-08T12:16:26.669-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34850 #96 (20 connections now open)
2020-05-08T12:16:26.669-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34852 #97 (21 connections now open)
2020-05-08T12:16:26.669-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.1:34850 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.670-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.1:34852 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.904-0700 I  NETWORK  [conn92] end connection 192.168.122.1:34602 (20 connections now open)
2020-05-08T12:16:26.904-0700 I  NETWORK  [conn86] end connection 192.168.122.1:34552 (19 connections now open)
2020-05-08T12:16:26.905-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34884 #98 (20 connections now open)
2020-05-08T12:16:26.905-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34886 #99 (21 connections now open)
2020-05-08T12:16:26.905-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.1:34884 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.905-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34888 #100 (22 connections now open)
2020-05-08T12:16:26.906-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.1:34886 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.906-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:34890 #101 (23 connections now open)
2020-05-08T12:16:26.906-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.1:34888 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.906-0700 I  NETWORK  [conn101] received client metadata from 192.168.122.1:34890 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.908-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:27.034-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:27.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:27.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:27.534-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:28.035-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:28.535-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:28.535-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:28.536-0700 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 352), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1201a253-be5a-4516-86a3-d034f6a8b20f") }, txnNumber: 18, autocommit: false } numYields:0 reslen:439 protocol:op_msg 6602ms
2020-05-08T12:16:28.536-0700 I  COMMAND  [conn88] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965382, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de0168b9-ede7-4345-952e-f7daec7eb14d") }, txnNumber: 23, autocommit: false } numYields:0 reslen:352 protocol:op_msg 5781ms
2020-05-08T12:16:28.536-0700 I  NETWORK  [conn85] end connection 192.168.122.1:34550 (22 connections now open)
2020-05-08T12:16:28.537-0700 I  NETWORK  [conn88] end connection 192.168.122.1:34564 (21 connections now open)
2020-05-08T12:16:30.696-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35078 #103 (22 connections now open)
2020-05-08T12:16:30.697-0700 I  NETWORK  [conn103] received client metadata from 192.168.122.1:35078 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.670-0700 I  NETWORK  [conn97] end connection 192.168.122.1:34852 (21 connections now open)
2020-05-08T12:16:31.670-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35162 #104 (22 connections now open)
2020-05-08T12:16:31.671-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35164 #105 (23 connections now open)
2020-05-08T12:16:31.671-0700 I  NETWORK  [conn104] received client metadata from 192.168.122.1:35162 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.671-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.1:35164 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.673-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:31.906-0700 I  NETWORK  [conn100] end connection 192.168.122.1:34888 (22 connections now open)
2020-05-08T12:16:31.906-0700 I  NETWORK  [conn101] end connection 192.168.122.1:34890 (21 connections now open)
2020-05-08T12:16:31.906-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35208 #107 (22 connections now open)
2020-05-08T12:16:31.907-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35210 #108 (23 connections now open)
2020-05-08T12:16:31.907-0700 I  NETWORK  [conn107] received client metadata from 192.168.122.1:35208 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.907-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35212 #109 (24 connections now open)
2020-05-08T12:16:31.907-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.1:35210 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.907-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35214 #110 (25 connections now open)
2020-05-08T12:16:31.908-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.1:35212 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.908-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.1:35214 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.913-0700 I  -        [conn99] operation was interrupted because a client disconnected
2020-05-08T12:16:31.913-0700 I  CONNPOOL [conn99] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T12:16:31.913-0700 I  TXN      [conn99] transaction parameters:{ lsid: { id: UUID("39a020cf-136f-4644-9ba2-ba426af27450"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965383, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005395, timeInactiveMicros:0, 5005ms
2020-05-08T12:16:31.914-0700 I  COMMAND  [conn99] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 129 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965383, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39a020cf-136f-4644-9ba2-ba426af27450") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:16:31.914-0700 I  NETWORK  [conn99] end connection 192.168.122.1:34886 (24 connections now open)
2020-05-08T12:16:32.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:34.658-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:36.671-0700 I  NETWORK  [conn105] end connection 192.168.122.1:35164 (23 connections now open)
2020-05-08T12:16:36.671-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35448 #120 (24 connections now open)
2020-05-08T12:16:36.672-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35450 #121 (25 connections now open)
2020-05-08T12:16:36.672-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:35448 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.672-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.1:35450 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.674-0700 I  NETWORK  [conn120] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:36.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.677-0700 I  -        [conn104] operation was interrupted because a client disconnected
2020-05-08T12:16:36.677-0700 I  CONNPOOL [conn104] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T12:16:36.678-0700 I  TXN      [conn104] transaction parameters:{ lsid: { id: UUID("912b66a9-f05a-451d-9647-cbbbf3a89e30"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965389, 3) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004919, timeInactiveMicros:0, 5004ms
2020-05-08T12:16:36.678-0700 I  COMMAND  [conn104] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 135 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965389, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("912b66a9-f05a-451d-9647-cbbbf3a89e30") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:16:36.678-0700 I  NETWORK  [conn104] end connection 192.168.122.1:35162 (24 connections now open)
2020-05-08T12:16:36.831-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35472 #122 (25 connections now open)
2020-05-08T12:16:36.831-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:35472 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.907-0700 I  NETWORK  [conn109] end connection 192.168.122.1:35212 (24 connections now open)
2020-05-08T12:16:36.908-0700 I  NETWORK  [conn110] end connection 192.168.122.1:35214 (23 connections now open)
2020-05-08T12:16:36.908-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35486 #123 (24 connections now open)
2020-05-08T12:16:36.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35488 #124 (25 connections now open)
2020-05-08T12:16:36.909-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.1:35486 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35490 #125 (26 connections now open)
2020-05-08T12:16:36.909-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.1:35488 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35492 #126 (27 connections now open)
2020-05-08T12:16:36.909-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.1:35490 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.910-0700 I  NETWORK  [conn126] received client metadata from 192.168.122.1:35492 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.912-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.913-0700 I  -        [conn108] operation was interrupted because a client disconnected
2020-05-08T12:16:36.913-0700 I  CONNPOOL [conn108] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:16:36.913-0700 I  COMMAND  [conn108] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 134 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965389, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f6ab7ea-ed0e-4ef5-a3fb-01278d1bb5c9") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T12:16:36.914-0700 I  NETWORK  [conn108] end connection 192.168.122.1:35210 (26 connections now open)
2020-05-08T12:16:37.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.676-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.730-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965389, 3), t: 9 }, now { ts: Timestamp(1588965397, 5), t: 11 }
2020-05-08T12:16:39.731-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:39.732-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:39.732-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:40.042-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965397, 5), t: 11 }, now { ts: Timestamp(1588965399, 5), t: 12 }
2020-05-08T12:16:40.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.676-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:41.175-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:41.176-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:41.177-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:41.178-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:41.178-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:41.314-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965399, 5), t: 12 }, now { ts: Timestamp(1588965400, 2), t: 13 }
2020-05-08T12:16:41.645-0700 I  TXN      [conn123] transaction parameters:{ lsid: { id: UUID("f6acb32b-74ad-407b-b2d7-19af697653ef"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 9) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4734896, timeInactiveMicros:0, 4734ms
2020-05-08T12:16:41.646-0700 I  COMMAND  [conn123] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f6acb32b-74ad-407b-b2d7-19af697653ef") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction f6acb32b-74ad-407b-b2d7-19af697653ef:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965395, 9) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 4735ms
2020-05-08T12:16:41.646-0700 I  TXN      [conn120] transaction parameters:{ lsid: { id: UUID("cbb61783-71ec-4951-bfbe-31cdf19facdf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965389, 3) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4972628, timeInactiveMicros:0, 4972ms
2020-05-08T12:16:41.646-0700 I  COMMAND  [conn120] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965389, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cbb61783-71ec-4951-bfbe-31cdf19facdf") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction cbb61783-71ec-4951-bfbe-31cdf19facdf:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965389, 3) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 4972ms
2020-05-08T12:16:41.647-0700 I  TXN      [conn124] transaction parameters:{ lsid: { id: UUID("92600b5a-5f08-4fdc-b2ff-02a591d5be99"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 9) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4735831, timeInactiveMicros:0, 4735ms
2020-05-08T12:16:41.647-0700 I  COMMAND  [conn124] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92600b5a-5f08-4fdc-b2ff-02a591d5be99") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 92600b5a-5f08-4fdc-b2ff-02a591d5be99:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588965395, 9) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:553 protocol:op_msg 4736ms
2020-05-08T12:16:41.672-0700 I  NETWORK  [conn121] end connection 192.168.122.1:35450 (25 connections now open)
2020-05-08T12:16:41.672-0700 I  NETWORK  [conn120] end connection 192.168.122.1:35448 (24 connections now open)
2020-05-08T12:16:41.673-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35704 #127 (25 connections now open)
2020-05-08T12:16:41.673-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35706 #128 (26 connections now open)
2020-05-08T12:16:41.673-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.1:35704 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.674-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.1:35706 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.675-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:41.840-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n3:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:16:41.909-0700 I  NETWORK  [conn126] end connection 192.168.122.1:35492 (25 connections now open)
2020-05-08T12:16:41.909-0700 I  NETWORK  [conn125] end connection 192.168.122.1:35490 (24 connections now open)
2020-05-08T12:16:41.910-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35740 #130 (25 connections now open)
2020-05-08T12:16:41.911-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35742 #131 (26 connections now open)
2020-05-08T12:16:41.911-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.1:35740 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.911-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35744 #132 (27 connections now open)
2020-05-08T12:16:41.911-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:35742 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.911-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35746 #133 (28 connections now open)
2020-05-08T12:16:41.911-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.1:35744 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.912-0700 I  NETWORK  [conn133] received client metadata from 192.168.122.1:35746 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.912-0700 I  NETWORK  [conn123] end connection 192.168.122.1:35486 (27 connections now open)
2020-05-08T12:16:41.920-0700 I  NETWORK  [conn124] end connection 192.168.122.1:35488 (26 connections now open)
2020-05-08T12:16:42.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:42.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:43.847-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdb5861abbf7eec2119 to 5eb5afdaa0224cfb413c7171; invalidating user cache
2020-05-08T12:16:46.673-0700 I  NETWORK  [conn128] end connection 192.168.122.1:35706 (25 connections now open)
2020-05-08T12:16:46.674-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36014 #138 (26 connections now open)
2020-05-08T12:16:46.675-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36016 #139 (27 connections now open)
2020-05-08T12:16:46.675-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.1:36014 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.675-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:36016 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.677-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:46.911-0700 I  NETWORK  [conn132] end connection 192.168.122.1:35744 (26 connections now open)
2020-05-08T12:16:46.911-0700 I  NETWORK  [conn133] end connection 192.168.122.1:35746 (25 connections now open)
2020-05-08T12:16:46.912-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36050 #141 (26 connections now open)
2020-05-08T12:16:46.913-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36052 #142 (27 connections now open)
2020-05-08T12:16:46.913-0700 I  NETWORK  [conn141] received client metadata from 192.168.122.1:36050 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.913-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36054 #143 (28 connections now open)
2020-05-08T12:16:46.913-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.1:36052 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.913-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36056 #144 (29 connections now open)
2020-05-08T12:16:46.913-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.1:36054 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.914-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.1:36056 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.916-0700 I  NETWORK  [conn141] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:46.917-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:46.918-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:46.919-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:46.920-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:46.920-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:47.291-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965403, 8), t: 13 }, now { ts: Timestamp(1588965407, 1), t: 14 }
2020-05-08T12:16:47.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:47.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:47.563-0700 I  NETWORK  [conn141] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:16:47.564-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:48.064-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:48.564-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:48.565-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:48.566-0700 I  SHARDING [conn141] Received reply from shard n9:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965407, 1), t: 14 }, now { ts: Timestamp(1588965407, 8), t: 15 }
2020-05-08T12:16:48.566-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:48.566-0700 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965406, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467d05de-48bb-427c-9747-777d4c7ed9e7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1643ms
2020-05-08T12:16:48.567-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:48.567-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:49.577-0700 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965408, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467d05de-48bb-427c-9747-777d4c7ed9e7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1009ms
2020-05-08T12:16:50.043-0700 I  NETWORK  [conn141] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:50.044-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:50.397-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:16:50.543-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:50.543-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:51.429-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:51.430-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:51.675-0700 I  NETWORK  [conn139] end connection 192.168.122.1:36016 (28 connections now open)
2020-05-08T12:16:51.676-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36304 #150 (29 connections now open)
2020-05-08T12:16:51.677-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36306 #151 (30 connections now open)
2020-05-08T12:16:51.677-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.1:36304 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.677-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.1:36306 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.682-0700 I  -        [conn138] operation was interrupted because a client disconnected
2020-05-08T12:16:51.682-0700 I  CONNPOOL [conn138] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T12:16:51.683-0700 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("e9b4b87f-5d46-4019-a588-c8a595dc9c24"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965403, 10) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006029, timeInactiveMicros:0, 5006ms
2020-05-08T12:16:51.683-0700 I  COMMAND  [conn138] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 157 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965403, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e9b4b87f-5d46-4019-a588-c8a595dc9c24") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:16:51.683-0700 I  NETWORK  [conn138] end connection 192.168.122.1:36014 (29 connections now open)
2020-05-08T12:16:51.801-0700 I  NETWORK  [conn150] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:51.802-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:51.913-0700 I  NETWORK  [conn143] end connection 192.168.122.1:36054 (28 connections now open)
2020-05-08T12:16:51.914-0700 I  NETWORK  [conn144] end connection 192.168.122.1:36056 (27 connections now open)
2020-05-08T12:16:51.914-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36330 #152 (28 connections now open)
2020-05-08T12:16:51.914-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36332 #153 (29 connections now open)
2020-05-08T12:16:51.915-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:36330 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.915-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:36332 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36334 #154 (30 connections now open)
2020-05-08T12:16:51.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36336 #155 (31 connections now open)
2020-05-08T12:16:51.915-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.1:36334 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.916-0700 I  NETWORK  [conn155] received client metadata from 192.168.122.1:36336 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.918-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.301-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.802-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:53.301-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:53.302-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:53.303-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:53.304-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:53.304-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:53.306-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965410, 7), t: 15 }, now { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:16:53.927-0700 I  NETWORK  [conn154] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:53.927-0700 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965410, 12) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2239207, timeActiveMicros:2245650, timeInactiveMicros:2599, 2248ms
2020-05-08T12:16:53.928-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:53.929-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:54.428-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:54.429-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:54.429-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:16:54.430-0700 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("b4197e17-68e5-4eda-8e07-6f106c018e44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965411, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2513732, timeInactiveMicros:0, 2513ms
2020-05-08T12:16:54.431-0700 I  COMMAND  [conn150] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965410, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396") }, txnNumber: 1, autocommit: false } numYields:0 reslen:494 protocol:op_msg 2742ms
2020-05-08T12:16:54.431-0700 I  COMMAND  [conn152] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965411, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4197e17-68e5-4eda-8e07-6f106c018e44") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2514ms
2020-05-08T12:16:54.431-0700 I  TXN      [conn154] transaction parameters:{ lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965411, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2514007, timeInactiveMicros:0, 2514ms
2020-05-08T12:16:54.432-0700 I  COMMAND  [conn154] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965411, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2514ms
2020-05-08T12:16:54.579-0700 I  -        [conn141] operation was interrupted because a client disconnected
2020-05-08T12:16:54.580-0700 I  CONNPOOL [conn141] Ending connection to host n9:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T12:16:54.580-0700 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("467d05de-48bb-427c-9747-777d4c7ed9e7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965409, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588965409, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002732, timeInactiveMicros:0, 5002ms
2020-05-08T12:16:54.581-0700 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965409, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467d05de-48bb-427c-9747-777d4c7ed9e7") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965409, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T12:16:54.581-0700 I  NETWORK  [conn141] end connection 192.168.122.1:36050 (30 connections now open)
2020-05-08T12:16:54.951-0700 I  COMMAND  [conn150] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965414, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 518ms
2020-05-08T12:16:54.951-0700 I  COMMAND  [conn154] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965414, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 517ms
2020-05-08T12:16:54.951-0700 I  COMMAND  [conn152] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965414, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4197e17-68e5-4eda-8e07-6f106c018e44") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 518ms
2020-05-08T12:16:55.309-0700 I  NETWORK  [conn154] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:55.311-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:55.341-0700 I  NETWORK  [conn150] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:55.342-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:55.811-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:56.228-0700 I  NETWORK  [conn152] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:56.230-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:56.729-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:56.730-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:56.731-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:56.731-0700 I  COMMAND  [conn152] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965415, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4197e17-68e5-4eda-8e07-6f106c018e44") }, txnNumber: 14, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1276ms
2020-05-08T12:16:56.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:56.915-0700 I  NETWORK  [conn153] end connection 192.168.122.1:36332 (29 connections now open)
2020-05-08T12:16:56.916-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36600 #157 (30 connections now open)
2020-05-08T12:16:56.917-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36602 #158 (31 connections now open)
2020-05-08T12:16:56.917-0700 I  NETWORK  [conn157] received client metadata from 192.168.122.1:36600 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:56.917-0700 I  NETWORK  [conn158] received client metadata from 192.168.122.1:36602 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:57.153-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.229-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.232-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:57.235-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.310-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.733-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:57.736-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.810-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:58.233-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:58.235-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:58.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:58.735-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.233-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.235-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.735-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:59.735-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:59.736-0700 I  COMMAND  [conn152] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965416, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4197e17-68e5-4eda-8e07-6f106c018e44") }, txnNumber: 14, autocommit: false } numYields:0 reslen:515 protocol:op_msg 3003ms
2020-05-08T12:16:59.736-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.737-0700 I  NETWORK  [conn152] end connection 192.168.122.1:36330 (30 connections now open)
2020-05-08T12:16:59.973-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:59.973-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:59.975-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.975-0700 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965415, 30) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:4839812, timeInactiveMicros:0, 4839ms
2020-05-08T12:16:59.975-0700 I  COMMAND  [conn150] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396") }, txnNumber: 6, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 4840ms
2020-05-08T12:16:59.976-0700 I  COMMAND  [conn157] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 163 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965416, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28dc59b2-c31c-4836-8e1e-1008454c1364") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 3057ms
2020-05-08T12:17:00.000-0700 I  COMMAND  [conn154] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 5, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 4896ms
2020-05-08T12:17:00.093-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.136-0700 I  NETWORK  [conn151] end connection 192.168.122.1:36306 (29 connections now open)
2020-05-08T12:17:00.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36760 #159 (30 connections now open)
2020-05-08T12:17:00.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36762 #160 (31 connections now open)
2020-05-08T12:17:00.138-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.1:36760 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:00.138-0700 I  NETWORK  [conn160] received client metadata from 192.168.122.1:36762 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:00.232-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.241-0700 I  NETWORK  [conn159] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:00.242-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:00.243-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:00.733-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.115-0700 I  NETWORK  [conn150] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:01.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.120-0700 I  NETWORK  [conn154] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:01.121-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.232-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:01.241-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:01.741-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.879-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n8:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:01.918-0700 I  NETWORK  [conn158] end connection 192.168.122.1:36602 (30 connections now open)
2020-05-08T12:17:01.919-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36826 #161 (31 connections now open)
2020-05-08T12:17:01.919-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36828 #162 (32 connections now open)
2020-05-08T12:17:01.919-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.1:36826 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:01.920-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.1:36828 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:01.923-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:02.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:02.232-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:02.242-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:02.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:02.741-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:02.741-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:02.742-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:02.821-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:03.116-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.117-0700 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.118-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:03.119-0700 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965419, 160) } }, globalReadTimestamp:{ ts: Timestamp(1588965419, 160) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3117309, timeInactiveMicros:0, 3117ms
2020-05-08T12:17:03.119-0700 I  COMMAND  [conn150] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965419, 160), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f5a05f4-9b0b-442c-bc1e-0ea762409396") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965419, 160) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3117ms
2020-05-08T12:17:03.119-0700 I  NETWORK  [conn150] end connection 192.168.122.1:36304 (31 connections now open)
2020-05-08T12:17:03.120-0700 I  COMMAND  [conn154] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 190), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337") }, txnNumber: 27, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2604ms
2020-05-08T12:17:03.232-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:03.256-0700 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("28dc59b2-c31c-4836-8e1e-1008454c1364"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965416, 13) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3276562, timeActiveMicros:6336545, timeInactiveMicros:1374, 6337ms
2020-05-08T12:17:03.258-0700 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 175 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1336ms
2020-05-08T12:17:03.258-0700 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 175 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3102593f-a5e4-4172-b7fc-95c5a571b0bf") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3119ms
2020-05-08T12:17:03.258-0700 I  COMMAND  [conn157] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965419, 152), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28dc59b2-c31c-4836-8e1e-1008454c1364") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 3278ms
2020-05-08T12:17:03.259-0700 I  NETWORK  [conn157] end connection 192.168.122.1:36600 (30 connections now open)
2020-05-08T12:17:03.276-0700 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965420, 197) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:13334, timeActiveMicros:1351810, timeInactiveMicros:2179, 1353ms
2020-05-08T12:17:03.307-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n9:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:03.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:04.233-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:04.233-0700 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:04.233-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T12:17:04.367-0700 I  COMMAND  [conn154] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337") }, txnNumber: 27, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1245ms
2020-05-08T12:17:04.368-0700 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("3102593f-a5e4-4172-b7fc-95c5a571b0bf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965420, 23) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:4227227, timeInactiveMicros:1310, 4228ms
2020-05-08T12:17:04.368-0700 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 176 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1090ms
2020-05-08T12:17:04.368-0700 I  COMMAND  [conn159] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3102593f-a5e4-4172-b7fc-95c5a571b0bf") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1107ms
2020-05-08T12:17:04.370-0700 I  NETWORK  [conn159] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:04.371-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.373-0700 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 16) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1093787, timeInactiveMicros:1470, 1095ms
2020-05-08T12:17:04.392-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.458-0700 I  NETWORK  [conn161] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:04.765-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965412, 1), t: 16 }, now { ts: Timestamp(1588965424, 57), t: 18 }
2020-05-08T12:17:04.870-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:05.002-0700 I  NETWORK  [conn155] end connection 192.168.122.1:36336 (29 connections now open)
2020-05-08T12:17:05.002-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37050 #168 (30 connections now open)
2020-05-08T12:17:05.002-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37052 #169 (31 connections now open)
2020-05-08T12:17:05.002-0700 I  NETWORK  [conn168] received client metadata from 192.168.122.1:37050 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:05.002-0700 I  NETWORK  [conn169] received client metadata from 192.168.122.1:37052 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:05.138-0700 I  NETWORK  [conn160] end connection 192.168.122.1:36762 (30 connections now open)
2020-05-08T12:17:05.139-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37058 #170 (31 connections now open)
2020-05-08T12:17:05.139-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37060 #171 (32 connections now open)
2020-05-08T12:17:05.139-0700 I  NETWORK  [conn170] received client metadata from 192.168.122.1:37058 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:05.140-0700 I  NETWORK  [conn171] received client metadata from 192.168.122.1:37060 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:05.370-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:05.870-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:05.961-0700 I  COMMAND  [conn168] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 179 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 957ms
2020-05-08T12:17:05.961-0700 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965424, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 6, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1510ms
2020-05-08T12:17:06.370-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:06.870-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:06.870-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:06.872-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:06.872-0700 I  COMMAND  [conn154] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67f8d067-fa39-46c7-b6b1-9ed7d4783337") }, txnNumber: 29, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 2480ms
2020-05-08T12:17:06.873-0700 I  NETWORK  [conn154] end connection 192.168.122.1:36334 (31 connections now open)
2020-05-08T12:17:06.873-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:06.966-0700 I  NETWORK  [conn168] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:06.968-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.372-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:07.383-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.467-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.873-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:07.873-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:07.967-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.968-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.970-0700 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965424, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3102593f-a5e4-4172-b7fc-95c5a571b0bf") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 3600ms
2020-05-08T12:17:07.970-0700 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("c7cf6999-1acc-4eac-bc1d-838eaf1a24a9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 57) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2829016, timeInactiveMicros:0, 2829ms
2020-05-08T12:17:07.970-0700 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965425, 6) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2007266, timeInactiveMicros:0, 2007ms
2020-05-08T12:17:07.970-0700 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965425, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 6, autocommit: false } numYields:0 reslen:513 protocol:op_msg 2007ms
2020-05-08T12:17:07.970-0700 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c7cf6999-1acc-4eac-bc1d-838eaf1a24a9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2829ms
2020-05-08T12:17:07.970-0700 I  NETWORK  [conn159] end connection 192.168.122.1:36760 (30 connections now open)
2020-05-08T12:17:07.970-0700 I  COMMAND  [conn168] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965425, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2007ms
2020-05-08T12:17:08.506-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965424, 57), t: 18 }, now { ts: Timestamp(1588965427, 1), t: 20 }
2020-05-08T12:17:08.645-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n7:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:10.017-0700 I  COMMAND  [conn161] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 183), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 14, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 183) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1695ms
2020-05-08T12:17:10.017-0700 I  NETWORK  [conn170] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:10.081-0700 I  COMMAND  [conn168] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 183), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa") }, txnNumber: 10, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 182) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1759ms
2020-05-08T12:17:10.140-0700 I  NETWORK  [conn171] end connection 192.168.122.1:37060 (29 connections now open)
2020-05-08T12:17:10.141-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37226 #172 (30 connections now open)
2020-05-08T12:17:10.141-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37228 #173 (31 connections now open)
2020-05-08T12:17:10.141-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.1:37226 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:10.141-0700 I  NETWORK  [conn173] received client metadata from 192.168.122.1:37228 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:10.145-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:10.518-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:10.519-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:10.521-0700 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("c7cf6999-1acc-4eac-bc1d-838eaf1a24a9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 187) } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 187) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2194380, timeInactiveMicros:0, 2194ms
2020-05-08T12:17:10.521-0700 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c7cf6999-1acc-4eac-bc1d-838eaf1a24a9") }, txnNumber: 10, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 187) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2194ms
2020-05-08T12:17:10.522-0700 I  NETWORK  [conn170] end connection 192.168.122.1:37058 (30 connections now open)
2020-05-08T12:17:10.522-0700 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 183) } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 183) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2198813, timeInactiveMicros:1774, 2200ms
2020-05-08T12:17:10.522-0700 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 182) } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 183) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2199704, timeInactiveMicros:907, 2200ms
2020-05-08T12:17:10.522-0700 I  COMMAND  [conn161] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 192), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 14, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: Given transaction number 14 does not match any in-progress transactions. The active transaction number is 12" errName:NoSuchTransaction errCode:251 reslen:446 protocol:op_msg 503ms
2020-05-08T12:17:10.522-0700 I  COMMAND  [conn168] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa") }, txnNumber: 10, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: Given transaction number 10 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:446 protocol:op_msg 440ms
2020-05-08T12:17:10.964-0700 I  NETWORK  [conn169] end connection 192.168.122.1:37052 (29 connections now open)
2020-05-08T12:17:10.965-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37236 #174 (30 connections now open)
2020-05-08T12:17:10.965-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37238 #175 (31 connections now open)
2020-05-08T12:17:10.965-0700 I  NETWORK  [conn174] received client metadata from 192.168.122.1:37236 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:10.966-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.1:37238 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:12.705-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n6:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:12.706-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n6:27018 because the pool meets constraints; 8 connections to that host remain open
2020-05-08T12:17:12.706-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n6:27018 because the pool meets constraints; 7 connections to that host remain open
2020-05-08T12:17:12.908-0700 I  NETWORK  [conn172] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:12.910-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:12.919-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965427, 1), t: 20 }, now { ts: Timestamp(1588965430, 9), t: 22 }
2020-05-08T12:17:12.931-0700 I  NETWORK  [conn168] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:12.934-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.042-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n2:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:13.246-0700 I  NETWORK  [conn162] end connection 192.168.122.1:36828 (30 connections now open)
2020-05-08T12:17:13.247-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37314 #176 (31 connections now open)
2020-05-08T12:17:13.247-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37316 #177 (32 connections now open)
2020-05-08T12:17:13.248-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.1:37314 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.248-0700 I  NETWORK  [conn177] received client metadata from 192.168.122.1:37316 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.250-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:13.435-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.847-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdbf50ef7b0538edfc4; invalidating user cache
2020-05-08T12:17:13.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:13.934-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:14.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.434-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.434-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.435-0700 I  COMMAND  [conn176] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 182 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c2e87c5-2c22-4938-80b3-dbcc3ae2007d") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:299 protocol:op_msg 1186ms
2020-05-08T12:17:14.435-0700 I  COMMAND  [conn168] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04e1b6fc-79b4-4370-bb91-5ea2e3daafaa") }, txnNumber: 10, autocommit: false } numYields:0 reslen:546 protocol:op_msg 3912ms
2020-05-08T12:17:14.436-0700 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2cea7e8-8b21-48f4-9e22-8f7175653230") }, txnNumber: 14, autocommit: false } numYields:0 reslen:546 protocol:op_msg 3912ms
2020-05-08T12:17:14.436-0700 I  NETWORK  [conn168] end connection 192.168.122.1:37050 (31 connections now open)
2020-05-08T12:17:14.436-0700 I  NETWORK  [conn161] end connection 192.168.122.1:36826 (30 connections now open)
2020-05-08T12:17:14.438-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.771-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:14.772-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:14.772-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:14.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:15.141-0700 I  NETWORK  [conn173] end connection 192.168.122.1:37228 (29 connections now open)
2020-05-08T12:17:15.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37402 #178 (30 connections now open)
2020-05-08T12:17:15.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37404 #179 (31 connections now open)
2020-05-08T12:17:15.142-0700 I  NETWORK  [conn178] received client metadata from 192.168.122.1:37402 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.142-0700 I  NETWORK  [conn179] received client metadata from 192.168.122.1:37404 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.145-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:15.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:15.857-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965433, 8), t: 22 }, now { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:15.909-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:15.910-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:15.910-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:17:15.911-0700 I  TXN      [conn174] transaction parameters:{ lsid: { id: UUID("177d8f9c-00c5-429a-95c7-518417572552"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965430, 18) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:4943729, timeInactiveMicros:0, 4943ms
2020-05-08T12:17:15.911-0700 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("506d1872-aa3e-4269-a0c1-d4e2d7856254") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 5761ms
2020-05-08T12:17:15.912-0700 I  COMMAND  [conn174] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965430, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("177d8f9c-00c5-429a-95c7-518417572552") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 4944ms
2020-05-08T12:17:15.912-0700 I  NETWORK  [conn172] end connection 192.168.122.1:37226 (30 connections now open)
2020-05-08T12:17:15.966-0700 I  NETWORK  [conn175] end connection 192.168.122.1:37238 (29 connections now open)
2020-05-08T12:17:15.967-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37458 #181 (30 connections now open)
2020-05-08T12:17:15.967-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37460 #182 (31 connections now open)
2020-05-08T12:17:15.967-0700 I  NETWORK  [conn181] received client metadata from 192.168.122.1:37458 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.968-0700 I  NETWORK  [conn182] received client metadata from 192.168.122.1:37460 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:16.476-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:17:16.818-0700 I  COMMAND  [conn178] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 197 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40a86612-b120-4d32-a391-dc342ea8421e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1674ms
2020-05-08T12:17:16.818-0700 I  COMMAND  [conn176] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 197 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c2e87c5-2c22-4938-80b3-dbcc3ae2007d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2381ms
2020-05-08T12:17:16.819-0700 I  COMMAND  [conn181] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965435, 107), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("06da21ff-26ea-434e-8ecc-1e3e5e4b6926") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 837ms
2020-05-08T12:17:16.819-0700 I  COMMAND  [conn174] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965435, 91), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("177d8f9c-00c5-429a-95c7-518417572552") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 905ms
2020-05-08T12:17:16.819-0700 I  NETWORK  [conn174] end connection 192.168.122.1:37236 (30 connections now open)
2020-05-08T12:17:16.823-0700 I  TXN      [conn176] transaction parameters:{ lsid: { id: UUID("1c2e87c5-2c22-4938-80b3-dbcc3ae2007d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965434, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2384508, timeInactiveMicros:1440, 2385ms
2020-05-08T12:17:17.818-0700 I  NETWORK  [conn178] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:17.818-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:17.818-0700 I  NETWORK  [conn181] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:17.819-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.318-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.818-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:18.818-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:18.819-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T12:17:18.820-0700 I  COMMAND  [conn176] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 158), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c2e87c5-2c22-4938-80b3-dbcc3ae2007d") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1996ms
2020-05-08T12:17:18.862-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:18.863-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:18.914-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n7:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T12:17:18.916-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n7:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:19.014-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n7:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:19.121-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n5:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:19.184-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 8 connections to that host remain open
2020-05-08T12:17:19.213-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n5:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:19.363-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:19.437-0700 I  NETWORK  [conn177] end connection 192.168.122.1:37316 (29 connections now open)
2020-05-08T12:17:19.438-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37616 #186 (30 connections now open)
2020-05-08T12:17:19.438-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37614 #187 (31 connections now open)
2020-05-08T12:17:19.438-0700 I  NETWORK  [conn186] received client metadata from 192.168.122.1:37616 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:19.439-0700 I  NETWORK  [conn187] received client metadata from 192.168.122.1:37614 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:19.714-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:19.862-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.051-0700 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("40a86612-b120-4d32-a391-dc342ea8421e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965434, 2) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3222788, timeActiveMicros:4904571, timeInactiveMicros:2582, 4907ms
2020-05-08T12:17:20.051-0700 I  TXN      [conn181] transaction parameters:{ lsid: { id: UUID("06da21ff-26ea-434e-8ecc-1e3e5e4b6926"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965436, 155) } }, globalReadTimestamp:{ ts: Timestamp(1588965436, 155) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:3212249, timeActiveMicros:3230422, timeInactiveMicros:762, 3231ms
2020-05-08T12:17:20.051-0700 I  COMMAND  [conn181] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 165), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("06da21ff-26ea-434e-8ecc-1e3e5e4b6926") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3212ms
2020-05-08T12:17:20.051-0700 I  COMMAND  [conn187] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 193 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965439, 96), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("702aeb73-3acd-48d3-aad7-3479fdd897a7") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 562ms
2020-05-08T12:17:20.052-0700 I  COMMAND  [conn176] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965438, 125), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c2e87c5-2c22-4938-80b3-dbcc3ae2007d") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1229ms
2020-05-08T12:17:20.052-0700 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 163), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40a86612-b120-4d32-a391-dc342ea8421e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3223ms
2020-05-08T12:17:20.052-0700 I  NETWORK  [conn176] end connection 192.168.122.1:37314 (30 connections now open)
2020-05-08T12:17:20.061-0700 I  TXN      [conn187] transaction parameters:{ lsid: { id: UUID("702aeb73-3acd-48d3-aad7-3479fdd897a7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965439, 96) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:571975, timeInactiveMicros:587, 572ms
2020-05-08T12:17:20.143-0700 I  NETWORK  [conn179] end connection 192.168.122.1:37404 (29 connections now open)
2020-05-08T12:17:20.144-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37636 #188 (30 connections now open)
2020-05-08T12:17:20.144-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37638 #189 (31 connections now open)
2020-05-08T12:17:20.144-0700 I  NETWORK  [conn188] received client metadata from 192.168.122.1:37636 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:20.144-0700 I  NETWORK  [conn189] received client metadata from 192.168.122.1:37638 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:20.147-0700 I  NETWORK  [conn178] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:20.148-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:20.162-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:20.168-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:20.168-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:20.169-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.362-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.862-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.929-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 7 connections to that host remain open
2020-05-08T12:17:21.061-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 6 connections to that host remain open
2020-05-08T12:17:21.362-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:21.363-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:21.612-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n4:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:21.666-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n4:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:21.901-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n7:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:22.318-0700 I  NETWORK  [conn188] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:22.319-0700 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("40a86612-b120-4d32-a391-dc342ea8421e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965440, 41) } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 41) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2183391, timeActiveMicros:2215813, timeInactiveMicros:1795, 2217ms
2020-05-08T12:17:22.320-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:22.321-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:22.513-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:22.515-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:22.517-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:22.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:23.014-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:23.320-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:23.320-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:23.321-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:23.322-0700 I  TXN      [conn188] transaction parameters:{ lsid: { id: UUID("1db50bd4-6ed3-4646-8e36-631e61ef53d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 80) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3154523, timeInactiveMicros:0, 3154ms
2020-05-08T12:17:23.322-0700 I  COMMAND  [conn188] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965440, 80), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1db50bd4-6ed3-4646-8e36-631e61ef53d7") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3154ms
2020-05-08T12:17:23.514-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:24.014-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:24.319-0700 I  NETWORK  [conn188] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:24.320-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:24.490-0700 I  NETWORK  [conn186] end connection 192.168.122.1:37616 (30 connections now open)
2020-05-08T12:17:24.491-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37752 #190 (31 connections now open)
2020-05-08T12:17:24.491-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37754 #191 (32 connections now open)
2020-05-08T12:17:24.491-0700 I  NETWORK  [conn190] received client metadata from 192.168.122.1:37752 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:24.491-0700 I  NETWORK  [conn191] received client metadata from 192.168.122.1:37754 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:24.514-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:24.515-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:24.515-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T12:17:24.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:25.020-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.022-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.023-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.023-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.023-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.053-0700 I  NETWORK  [conn182] end connection 192.168.122.1:37460 (31 connections now open)
2020-05-08T12:17:25.054-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37794 #194 (32 connections now open)
2020-05-08T12:17:25.054-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37796 #195 (33 connections now open)
2020-05-08T12:17:25.055-0700 I  NETWORK  [conn194] received client metadata from 192.168.122.1:37794 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.055-0700 I  NETWORK  [conn195] received client metadata from 192.168.122.1:37796 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.081-0700 I  CONNPOOL [conn181] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T12:17:25.081-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:17:25.081-0700 I  COMMAND  [conn181] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("06da21ff-26ea-434e-8ecc-1e3e5e4b6926") }, txnNumber: 3, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5012ms
2020-05-08T12:17:25.081-0700 I  NETWORK  [conn181] end connection 192.168.122.1:37458 (32 connections now open)
2020-05-08T12:17:25.148-0700 I  CONNPOOL [conn178] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T12:17:25.148-0700 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 67), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40a86612-b120-4d32-a391-dc342ea8421e") }, txnNumber: 3, autocommit: false } numYields:0 reslen:494 protocol:op_msg 5012ms
2020-05-08T12:17:25.148-0700 I  NETWORK  [conn178] end connection 192.168.122.1:37402 (31 connections now open)
2020-05-08T12:17:25.167-0700 I  NETWORK  [conn189] end connection 192.168.122.1:37638 (30 connections now open)
2020-05-08T12:17:25.168-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37854 #197 (31 connections now open)
2020-05-08T12:17:25.168-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37856 #198 (32 connections now open)
2020-05-08T12:17:25.168-0700 I  NETWORK  [conn197] received client metadata from 192.168.122.1:37854 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.169-0700 I  NETWORK  [conn198] received client metadata from 192.168.122.1:37856 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.320-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:25.321-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:25.322-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.322-0700 I  COMMAND  [conn188] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965443, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1db50bd4-6ed3-4646-8e36-631e61ef53d7") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1998ms
2020-05-08T12:17:25.322-0700 I  NETWORK  [conn188] end connection 192.168.122.1:37636 (31 connections now open)
2020-05-08T12:17:25.520-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.863-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:26.020-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:26.520-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:27.020-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:27.520-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:27.520-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:27.559-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.559-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.560-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:27.561-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:28.021-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:28.520-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:28.521-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:29.008-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965434, 11), t: 23 }, now { ts: Timestamp(1588965448, 18), t: 28 }
2020-05-08T12:17:29.492-0700 I  NETWORK  [conn191] end connection 192.168.122.1:37754 (30 connections now open)
2020-05-08T12:17:29.493-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38074 #199 (31 connections now open)
2020-05-08T12:17:29.493-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38076 #200 (32 connections now open)
2020-05-08T12:17:29.494-0700 I  NETWORK  [conn199] received client metadata from 192.168.122.1:38074 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:29.494-0700 I  NETWORK  [conn200] received client metadata from 192.168.122.1:38076 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:29.497-0700 I  -        [conn190] operation was interrupted because a client disconnected
2020-05-08T12:17:29.497-0700 I  NETWORK  [conn199] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:29.497-0700 I  CONNPOOL [conn190] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T12:17:29.498-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:29.498-0700 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("4c2a7ec4-835a-4fff-9eb4-f77bd3a92bfc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965443, 6) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005548, timeInactiveMicros:0, 5005ms
2020-05-08T12:17:29.498-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:29.498-0700 I  COMMAND  [conn190] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 202 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4c2a7ec4-835a-4fff-9eb4-f77bd3a92bfc") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:17:29.498-0700 I  NETWORK  [conn190] end connection 192.168.122.1:37752 (31 connections now open)
2020-05-08T12:17:29.567-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965448, 18), t: 28 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T12:17:30.055-0700 I  NETWORK  [conn194] end connection 192.168.122.1:37794 (30 connections now open)
2020-05-08T12:17:30.056-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38106 #201 (31 connections now open)
2020-05-08T12:17:30.056-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38108 #202 (32 connections now open)
2020-05-08T12:17:30.056-0700 I  NETWORK  [conn201] received client metadata from 192.168.122.1:38106 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.056-0700 I  NETWORK  [conn202] received client metadata from 192.168.122.1:38108 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.169-0700 I  NETWORK  [conn198] end connection 192.168.122.1:37856 (31 connections now open)
2020-05-08T12:17:30.170-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38150 #203 (32 connections now open)
2020-05-08T12:17:30.170-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38152 #204 (33 connections now open)
2020-05-08T12:17:30.171-0700 I  NETWORK  [conn203] received client metadata from 192.168.122.1:38150 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.171-0700 I  NETWORK  [conn204] received client metadata from 192.168.122.1:38152 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.452-0700 I  COMMAND  [conn199] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 215 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8d19fa7c-4052-422f-8e3d-17b6e7edd0b9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 956ms
2020-05-08T12:17:30.459-0700 I  TXN      [conn199] transaction parameters:{ lsid: { id: UUID("8d19fa7c-4052-422f-8e3d-17b6e7edd0b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965448, 18) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:961767, timeInactiveMicros:1914, 963ms
2020-05-08T12:17:31.453-0700 I  NETWORK  [conn199] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:31.454-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:31.953-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:32.453-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:32.470-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T12:17:32.953-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:33.453-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:33.453-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:33.455-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:33.455-0700 I  COMMAND  [conn199] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965449, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8d19fa7c-4052-422f-8e3d-17b6e7edd0b9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 2994ms
2020-05-08T12:17:33.456-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:33.501-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:33.953-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:33.954-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:33.955-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:34.455-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:34.456-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:34.456-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:17:34.457-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965448, 18), t: 28 }, now { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T12:17:34.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:17:35.056-0700 I  NETWORK  [conn202] end connection 192.168.122.1:38108 (32 connections now open)
2020-05-08T12:17:35.057-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38368 #206 (33 connections now open)
2020-05-08T12:17:35.057-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38370 #207 (34 connections now open)
2020-05-08T12:17:35.057-0700 I  NETWORK  [conn206] received client metadata from 192.168.122.1:38368 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.058-0700 I  NETWORK  [conn207] received client metadata from 192.168.122.1:38370 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.059-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:35.171-0700 I  NETWORK  [conn204] end connection 192.168.122.1:38152 (33 connections now open)
2020-05-08T12:17:35.172-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38414 #209 (34 connections now open)
2020-05-08T12:17:35.172-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38416 #210 (35 connections now open)
2020-05-08T12:17:35.172-0700 I  NETWORK  [conn209] received client metadata from 192.168.122.1:38414 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.172-0700 I  NETWORK  [conn210] received client metadata from 192.168.122.1:38416 conn210: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.177-0700 I  -        [conn203] operation was interrupted because a client disconnected
2020-05-08T12:17:35.177-0700 I  CONNPOOL [conn203] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T12:17:35.178-0700 I  TXN      [conn203] transaction parameters:{ lsid: { id: UUID("b56811ff-f2b1-4d20-a58a-315f8790b0e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965449, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005090, timeInactiveMicros:0, 5005ms
2020-05-08T12:17:35.178-0700 I  COMMAND  [conn203] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 217 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965449, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b56811ff-f2b1-4d20-a58a-315f8790b0e0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:17:35.178-0700 I  NETWORK  [conn203] end connection 192.168.122.1:38150 (34 connections now open)
2020-05-08T12:17:38.502-0700 I  NETWORK  [conn200] end connection 192.168.122.1:38076 (33 connections now open)
2020-05-08T12:17:38.503-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38592 #215 (34 connections now open)
2020-05-08T12:17:38.503-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38594 #216 (35 connections now open)
2020-05-08T12:17:38.503-0700 I  NETWORK  [conn215] received client metadata from 192.168.122.1:38592 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:38.503-0700 I  NETWORK  [conn216] received client metadata from 192.168.122.1:38594 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:38.505-0700 I  -        [conn199] operation was interrupted because a client disconnected
2020-05-08T12:17:38.505-0700 I  CONNPOOL [conn199] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T12:17:38.505-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:38.506-0700 I  COMMAND  [conn199] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 218 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8d19fa7c-4052-422f-8e3d-17b6e7edd0b9") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:38.506-0700 I  NETWORK  [conn199] end connection 192.168.122.1:38074 (34 connections now open)
2020-05-08T12:17:39.572-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:39.573-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:40.057-0700 I  NETWORK  [conn207] end connection 192.168.122.1:38370 (33 connections now open)
2020-05-08T12:17:40.058-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38690 #218 (34 connections now open)
2020-05-08T12:17:40.059-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38692 #219 (35 connections now open)
2020-05-08T12:17:40.059-0700 I  NETWORK  [conn218] received client metadata from 192.168.122.1:38690 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.059-0700 I  NETWORK  [conn219] received client metadata from 192.168.122.1:38692 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.073-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:40.115-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:40.172-0700 I  NETWORK  [conn210] end connection 192.168.122.1:38416 (34 connections now open)
2020-05-08T12:17:40.173-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38732 #221 (35 connections now open)
2020-05-08T12:17:40.174-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38734 #222 (36 connections now open)
2020-05-08T12:17:40.174-0700 I  NETWORK  [conn221] received client metadata from 192.168.122.1:38732 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.174-0700 I  NETWORK  [conn222] received client metadata from 192.168.122.1:38734 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.177-0700 I  -        [conn209] operation was interrupted because a client disconnected
2020-05-08T12:17:40.177-0700 I  CONNPOOL [conn209] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T12:17:40.177-0700 I  TXN      [conn209] transaction parameters:{ lsid: { id: UUID("46d7e32f-6c82-4649-b17a-2553ef8c0e7e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965453, 11) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003946, timeInactiveMicros:0, 5003ms
2020-05-08T12:17:40.177-0700 I  COMMAND  [conn209] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 218 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46d7e32f-6c82-4649-b17a-2553ef8c0e7e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:40.178-0700 I  NETWORK  [conn209] end connection 192.168.122.1:38414 (35 connections now open)
2020-05-08T12:17:40.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:17:40.573-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:41.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:41.573-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:41.573-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:42.063-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:42.064-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:42.073-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:42.573-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:43.073-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:43.074-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:43.503-0700 I  NETWORK  [conn216] end connection 192.168.122.1:38594 (34 connections now open)
2020-05-08T12:17:43.504-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38916 #225 (35 connections now open)
2020-05-08T12:17:43.504-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38918 #226 (36 connections now open)
2020-05-08T12:17:43.505-0700 I  NETWORK  [conn225] received client metadata from 192.168.122.1:38916 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:43.505-0700 I  NETWORK  [conn226] received client metadata from 192.168.122.1:38918 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:43.509-0700 I  -        [conn215] operation was interrupted because a client disconnected
2020-05-08T12:17:43.509-0700 I  CONNPOOL [conn215] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T12:17:43.510-0700 I  COMMAND  [conn215] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 223 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("003c33b2-ef10-4db6-9d91-d717d4496478") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:43.510-0700 I  NETWORK  [conn215] end connection 192.168.122.1:38592 (35 connections now open)
2020-05-08T12:17:43.631-0700 I  NETWORK  [Uptime-reporter] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:43.633-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:43.847-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdbf50ef7b0538edfc4 to 5eb5afdaa0224cfb413c7171; invalidating user cache
2020-05-08T12:17:43.892-0700 I  NETWORK  [conn225] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:43.893-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:44.132-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:44.392-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:44.392-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:44.394-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:44.394-0700 I  COMMAND  [conn225] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965463, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d23a55d8-3023-4025-9741-83ed8eb6a848") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 879ms
2020-05-08T12:17:44.632-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:44.935-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.110-0700 I  NETWORK  [conn219] end connection 192.168.122.1:38692 (34 connections now open)
2020-05-08T12:17:45.111-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38978 #227 (35 connections now open)
2020-05-08T12:17:45.111-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38980 #228 (36 connections now open)
2020-05-08T12:17:45.111-0700 I  NETWORK  [conn227] received client metadata from 192.168.122.1:38978 conn227: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.112-0700 I  NETWORK  [conn228] received client metadata from 192.168.122.1:38980 conn228: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.114-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.117-0700 I  -        [conn218] operation was interrupted because a client disconnected
2020-05-08T12:17:45.117-0700 I  CONNPOOL [conn218] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T12:17:45.117-0700 I  TXN      [conn218] transaction parameters:{ lsid: { id: UUID("c20d32f8-5ddc-46c7-9f4b-a9c2cc3315a8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965460, 24) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006872, timeInactiveMicros:904, 5007ms
2020-05-08T12:17:45.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.117-0700 I  COMMAND  [conn218] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 227 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965460, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c20d32f8-5ddc-46c7-9f4b-a9c2cc3315a8") }, txnNumber: 4, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T12:17:45.117-0700 I  NETWORK  [conn218] end connection 192.168.122.1:38690 (35 connections now open)
2020-05-08T12:17:45.132-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:45.132-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:45.174-0700 I  NETWORK  [conn222] end connection 192.168.122.1:38734 (34 connections now open)
2020-05-08T12:17:45.175-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39014 #229 (35 connections now open)
2020-05-08T12:17:45.175-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39016 #230 (36 connections now open)
2020-05-08T12:17:45.175-0700 I  NETWORK  [conn229] received client metadata from 192.168.122.1:39014 conn229: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.176-0700 I  NETWORK  [conn230] received client metadata from 192.168.122.1:39016 conn230: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.178-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.657-0700 I  NETWORK  [conn225] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:45.658-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.158-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.201-0700 I  NETWORK  [replSetDistLockPinger] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:46.202-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:46.465-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.613-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.659-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.702-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:46.703-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:47.113-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.158-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:47.158-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:47.160-0700 I  COMMAND  [conn225] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d23a55d8-3023-4025-9741-83ed8eb6a848") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2764ms
2020-05-08T12:17:47.404-0700 I  NETWORK  [replSetDistLockPinger] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:47.404-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:47.407-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:47.613-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.905-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:47.939-0700 I  NETWORK  [conn225] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T12:17:47.940-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:48.405-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:48.439-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:48.439-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:48.440-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:48.537-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:48.613-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:48.905-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:48.953-0700 I  COMMAND  [conn225] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 4, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965467, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d23a55d8-3023-4025-9741-83ed8eb6a848") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1735ms
2020-05-08T12:17:48.956-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.113-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.406-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:49.613-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.906-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:50.111-0700 I  NETWORK  [conn228] end connection 192.168.122.1:38980 (35 connections now open)
2020-05-08T12:17:50.112-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39170 #231 (36 connections now open)
2020-05-08T12:17:50.112-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39172 #232 (37 connections now open)
2020-05-08T12:17:50.112-0700 I  NETWORK  [conn231] received client metadata from 192.168.122.1:39170 conn231: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.113-0700 I  NETWORK  [conn232] received client metadata from 192.168.122.1:39172 conn232: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.113-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.166-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.177-0700 I  NETWORK  [conn230] end connection 192.168.122.1:39016 (36 connections now open)
2020-05-08T12:17:50.178-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39186 #233 (37 connections now open)
2020-05-08T12:17:50.178-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39188 #234 (38 connections now open)
2020-05-08T12:17:50.178-0700 I  NETWORK  [conn233] received client metadata from 192.168.122.1:39186 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.179-0700 I  NETWORK  [conn234] received client metadata from 192.168.122.1:39188 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.181-0700 I  -        [conn229] operation was interrupted because a client disconnected
2020-05-08T12:17:50.182-0700 I  TXN      [conn229] transaction parameters:{ lsid: { id: UUID("beec49c7-b7ef-4db5-807d-63792034f28d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965464, 4) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004621, timeInactiveMicros:0, 5004ms
2020-05-08T12:17:50.182-0700 I  COMMAND  [conn229] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 202 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("beec49c7-b7ef-4db5-807d-63792034f28d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:50.182-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.182-0700 I  NETWORK  [conn229] end connection 192.168.122.1:39014 (37 connections now open)
2020-05-08T12:17:50.406-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:50.905-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:51.405-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:51.905-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:52.405-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:52.405-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:53.339-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965453, 11), t: 29 }, now { ts: Timestamp(1588965471, 2), t: 35 }
2020-05-08T12:17:53.958-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39282 #235 (38 connections now open)
2020-05-08T12:17:53.958-0700 I  NETWORK  [conn235] received client metadata from 192.168.122.1:39282 conn235: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.170-0700 I  -        [conn231] operation was interrupted because a client disconnected
2020-05-08T12:17:55.171-0700 I  TXN      [conn231] transaction parameters:{ lsid: { id: UUID("55a126da-aadf-491b-b595-866fa83868a6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965470, 13) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005817, timeInactiveMicros:0, 5005ms
2020-05-08T12:17:55.171-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39296 #236 (39 connections now open)
2020-05-08T12:17:55.171-0700 I  COMMAND  [conn231] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 232 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965470, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("55a126da-aadf-491b-b595-866fa83868a6") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:17:55.171-0700 I  NETWORK  [conn231] end connection 192.168.122.1:39170 (38 connections now open)
2020-05-08T12:17:55.172-0700 I  NETWORK  [conn236] received client metadata from 192.168.122.1:39296 conn236: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.243-0700 I  NETWORK  [conn226] end connection 192.168.122.1:38918 (37 connections now open)
2020-05-08T12:17:55.244-0700 I  NETWORK  [conn232] end connection 192.168.122.1:39172 (36 connections now open)
2020-05-08T12:17:55.245-0700 I  NETWORK  [conn234] end connection 192.168.122.1:39188 (35 connections now open)
2020-05-08T12:17:55.247-0700 I  NETWORK  [conn233] end connection 192.168.122.1:39186 (34 connections now open)
2020-05-08T12:17:55.251-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39316 #237 (35 connections now open)
2020-05-08T12:17:55.252-0700 I  NETWORK  [conn237] received client metadata from 192.168.122.1:39316 conn237: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.252-0700 I  NETWORK  [conn237] end connection 192.168.122.1:39316 (34 connections now open)
2020-05-08T12:17:55.613-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n5:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 3161 timed out, deadline was 2020-05-08T12:17:55.613-0700, op was RemoteCommand 3161 -- target:[n5:27018] db:admin expDate:2020-05-08T12:17:55.613-0700 cmd:{ isMaster: 1 }
2020-05-08T12:17:55.613-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:55.613-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T12:17:55.613-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:17:55.613-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:55.613-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n5:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
