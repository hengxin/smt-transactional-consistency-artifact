2020-05-08 12:15:41 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T12:15:41.284-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T12:15:41.286-0700 I  CONTROL  [main] 
2020-05-08T12:15:41.286-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T12:15:41.286-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T12:15:41.286-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T12:15:41.286-0700 I  CONTROL  [main] 
2020-05-08T12:15:41.286-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] modules: none
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] build environment:
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T12:15:41.286-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-08T12:15:41.287-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.288-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-08T12:15:41.288-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-08T12:15:41.288-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n5:27017:1588965341:-4005854753316312821 (sleeping for 30000ms)
2020-05-08T12:15:41.288-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T12:15:41.290-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:41.788-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.789-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:41.840-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588965340, 4), t: 1 }
2020-05-08T12:15:42.442-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:15:42.598-0700 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T12:15:42.609-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T12:15:43.602-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T12:15:43.603-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T12:15:43.607-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("ffa25d41-dddf-47a1-9176-9a5eb74537ca"), lastMod: 0 } took 0 ms
2020-05-08T12:15:43.607-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T12:15:43.611-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T12:15:43.611-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T12:15:43.611-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T12:15:43.611-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T12:15:43.847-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54658 #9 (1 connection now open)
2020-05-08T12:15:43.847-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.1:54658 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:43.849-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54672 #10 (2 connections now open)
2020-05-08T12:15:43.850-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:54672 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.265-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54692 #11 (3 connections now open)
2020-05-08T12:15:45.266-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:54692 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.380-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54764 #12 (4 connections now open)
2020-05-08T12:15:45.381-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:54764 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.663-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54888 #13 (5 connections now open)
2020-05-08T12:15:45.664-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:54888 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54894 #14 (6 connections now open)
2020-05-08T12:15:45.665-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:54894 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:45.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54914 #15 (7 connections now open)
2020-05-08T12:15:45.744-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.1:54914 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:46.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54968 #16 (8 connections now open)
2020-05-08T12:15:46.900-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.1:54968 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:47.222-0700 I  COMMAND  [conn13] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fff7247f-b881-4a37-882a-fafa8a45a14e") } } numYields:0 reslen:163 protocol:op_msg 1551ms
2020-05-08T12:15:47.224-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 1 ms
2020-05-08T12:15:47.227-0700 I  NETWORK  [conn13] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:47.227-0700 I  NETWORK  [conn13] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:47.227-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:15:47.227-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:15:47.227-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T12:15:47.227-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-08T12:15:47.227-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-08T12:15:47.228-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-08T12:15:47.231-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:47.231-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:47.231-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:47.232-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:47.319-0700 I  NETWORK  [conn13] end connection 192.168.122.1:54888 (7 connections now open)
2020-05-08T12:15:47.319-0700 I  NETWORK  [conn14] end connection 192.168.122.1:54894 (6 connections now open)
2020-05-08T12:15:48.025-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55026 #23 (7 connections now open)
2020-05-08T12:15:48.025-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:55026 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.176-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55052 #24 (8 connections now open)
2020-05-08T12:15:48.177-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:55052 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:48.868-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55096 #25 (9 connections now open)
2020-05-08T12:15:48.869-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.1:55096 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.450-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55160 #26 (10 connections now open)
2020-05-08T12:15:50.450-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55162 #27 (11 connections now open)
2020-05-08T12:15:50.450-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.1:55160 conn26: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.451-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.1:55162 conn27: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.455-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55188 #28 (12 connections now open)
2020-05-08T12:15:50.455-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.1:55188 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.455-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55192 #29 (13 connections now open)
2020-05-08T12:15:50.456-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.1:55192 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.456-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55196 #30 (14 connections now open)
2020-05-08T12:15:50.456-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.1:55196 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55206 #31 (15 connections now open)
2020-05-08T12:15:50.457-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.1:55206 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.467-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 2 ms
2020-05-08T12:15:50.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T12:15:50.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:15:50.672-0700 I  TXN      [conn26] transaction parameters:{ lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 75) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:87851, timeActiveMicros:104135, timeInactiveMicros:1340, 105ms
2020-05-08T12:15:50.775-0700 I  TXN      [conn28] transaction parameters:{ lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965350, 62) } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 62) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:205572, timeActiveMicros:218850, timeInactiveMicros:970, 219ms
2020-05-08T12:15:50.775-0700 I  COMMAND  [conn28] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 75), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93") }, txnNumber: 4, autocommit: false } numYields:0 reslen:214 protocol:op_msg 205ms
2020-05-08T12:15:50.825-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55398 #40 (16 connections now open)
2020-05-08T12:15:50.826-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.1:55398 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.922-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55456 #42 (17 connections now open)
2020-05-08T12:15:50.923-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.1:55456 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.117-0700 I  COMMAND  [conn29] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 229), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542") }, txnNumber: 9, autocommit: false } numYields:0 reslen:351 protocol:op_msg 230ms
2020-05-08T12:15:51.126-0700 I  TXN      [conn26] transaction parameters:{ lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 240) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:234132, timeInactiveMicros:701, 234ms
2020-05-08T12:15:51.127-0700 I  COMMAND  [conn26] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965350, 246), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034") }, txnNumber: 10, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 212ms
2020-05-08T12:15:51.163-0700 I  TXN      [conn28] transaction parameters:{ lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 253) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:223058, timeInactiveMicros:0, 223ms
2020-05-08T12:15:51.163-0700 I  COMMAND  [conn28] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965350, 253), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93") }, txnNumber: 9, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 223ms
2020-05-08T12:15:51.330-0700 I  COMMAND  [conn26] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 84), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034") }, txnNumber: 11, autocommit: false } numYields:0 reslen:321 protocol:op_msg 123ms
2020-05-08T12:15:51.373-0700 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 22) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 22) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:233332, timeActiveMicros:253878, timeInactiveMicros:1472, 255ms
2020-05-08T12:15:51.373-0700 I  COMMAND  [conn29] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 233ms
2020-05-08T12:15:51.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:15:51.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:15:51.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:15:51.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:15:51.855-0700 I  COMMAND  [conn29] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 278), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542") }, txnNumber: 19, autocommit: false } numYields:0 reslen:321 protocol:op_msg 212ms
2020-05-08T12:15:51.965-0700 I  COMMAND  [conn28] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 219), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93") }, txnNumber: 14, autocommit: false } numYields:0 reslen:352 protocol:op_msg 462ms
2020-05-08T12:15:52.151-0700 I  COMMAND  [conn26] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 18 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965351, 243), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034") }, txnNumber: 16, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 243) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:363 protocol:op_msg 623ms
2020-05-08T12:15:52.151-0700 I  COMMAND  [conn28] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965351, 301), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93") }, txnNumber: 15, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 178ms
2020-05-08T12:15:52.419-0700 I  COMMAND  [conn26] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 16 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034") }, txnNumber: 16, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 268ms
2020-05-08T12:15:52.510-0700 I  COMMAND  [conn29] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542") }, txnNumber: 33, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 14) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 411ms
2020-05-08T12:15:52.544-0700 I  TXN      [conn26] transaction parameters:{ lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 243) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 243) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:121816, timeActiveMicros:1015163, timeInactiveMicros:1556, 1016ms
2020-05-08T12:15:52.544-0700 I  COMMAND  [conn26] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034") }, txnNumber: 16, autocommit: false } numYields:0 reslen:214 protocol:op_msg 122ms
2020-05-08T12:15:52.546-0700 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 33, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 14) } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 15) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:445841, timeInactiveMicros:683, 446ms
2020-05-08T12:15:53.472-0700 I  NETWORK  [conn29] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:53.473-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:53.712-0700 I  NETWORK  [Sharding-Fixed-2] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:53.712-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:53.972-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.973-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:53.974-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:53.974-0700 I  COMMAND  [conn29] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542") }, txnNumber: 33, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1427ms
2020-05-08T12:15:54.213-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:54.585-0700 I  NETWORK  [conn29] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:54.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:54.712-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:55.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.212-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:55.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:55.712-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:55.940-0700 I  NETWORK  [conn30] end connection 192.168.122.1:55196 (16 connections now open)
2020-05-08T12:15:55.941-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55800 #52 (17 connections now open)
2020-05-08T12:15:55.941-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55802 #53 (18 connections now open)
2020-05-08T12:15:55.941-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:55800 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:55.941-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:55802 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.157-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:15:56.158-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:56.159-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:56.160-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:56.212-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:56.311-0700 I  NETWORK  [conn52] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:56.312-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:56.375-0700 I  NETWORK  [conn31] end connection 192.168.122.1:55206 (17 connections now open)
2020-05-08T12:15:56.376-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55826 #54 (18 connections now open)
2020-05-08T12:15:56.377-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55828 #55 (19 connections now open)
2020-05-08T12:15:56.377-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:55826 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.377-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:55828 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.380-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:56.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:56.712-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:15:56.827-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55894 #56 (20 connections now open)
2020-05-08T12:15:56.828-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.1:55894 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:56.833-0700 I  NETWORK  [conn26] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:15:57.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:57.164-0700 I  COMMAND  [conn28] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771ccb64-b8ba-4d53-a78f-099ddef84f93") }, txnNumber: 15, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T12:15:57.164-0700 I  NETWORK  [conn28] end connection 192.168.122.1:55188 (19 connections now open)
2020-05-08T12:15:57.212-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:57.212-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:15:57.213-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:15:57.546-0700 I  NETWORK  [conn27] end connection 192.168.122.1:55162 (18 connections now open)
2020-05-08T12:15:57.547-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56006 #59 (19 connections now open)
2020-05-08T12:15:57.547-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56008 #60 (20 connections now open)
2020-05-08T12:15:57.547-0700 I  NETWORK  [conn59] received client metadata from 192.168.122.1:56006 conn59: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.547-0700 I  NETWORK  [conn60] received client metadata from 192.168.122.1:56008 conn60: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:57.550-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:57.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.086-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.341-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:58.567-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965350, 10), t: 1 }, now { ts: Timestamp(1588965357, 6), t: 4 }
2020-05-08T12:15:58.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:15:58.658-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:15:59.086-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:59.086-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:59.088-0700 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 34, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965353, 37) } }, globalReadTimestamp:{ ts: Timestamp(1588965353, 65) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:5112800, timeInactiveMicros:0, 5112ms
2020-05-08T12:15:59.088-0700 I  COMMAND  [conn29] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965353, 65), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d777d818-1da4-44eb-a04f-f6b65f2a3542") }, txnNumber: 34, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965353, 37) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 5113ms
2020-05-08T12:15:59.088-0700 I  NETWORK  [conn29] end connection 192.168.122.1:55192 (19 connections now open)
2020-05-08T12:15:59.365-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:59.365-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:59.367-0700 I  TXN      [conn26] transaction parameters:{ lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 63) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6821535, timeInactiveMicros:0, 6821ms
2020-05-08T12:15:59.367-0700 I  COMMAND  [conn26] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1c54a9e0-344f-496d-8621-7ca9d962a034") }, txnNumber: 17, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 6821ms
2020-05-08T12:15:59.367-0700 I  NETWORK  [conn26] end connection 192.168.122.1:55160 (18 connections now open)
2020-05-08T12:15:59.498-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965356, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1949037, timeInactiveMicros:0, 1949ms
2020-05-08T12:15:59.498-0700 I  COMMAND  [conn59] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965356, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1949ms
2020-05-08T12:16:00.179-0700 I  COMMAND  [conn59] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965359, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 679ms
2020-05-08T12:16:00.385-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965353, 82) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4443028, timeInactiveMicros:0, 4443ms
2020-05-08T12:16:00.386-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 36 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965353, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction f22ffbee-41ee-4724-b7a3-23671b84b64e:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965353, 82) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 4443ms
2020-05-08T12:16:00.386-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965356, 2) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4007476, timeInactiveMicros:0, 4007ms
2020-05-08T12:16:00.386-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965356, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction ce89b3a9-af94-452e-ad5d-7f8e2daee9ab:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from n4:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588965356, 2) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:553 protocol:op_msg 4007ms
2020-05-08T12:16:00.463-0700 I  COMMAND  [conn59] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 40 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965360, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 4, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 219ms
2020-05-08T12:16:00.489-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T12:16:00.517-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 23) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 23) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:50858, timeActiveMicros:274367, timeInactiveMicros:2166, 276ms
2020-05-08T12:16:00.710-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 159) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 159) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:137548, timeActiveMicros:168281, timeInactiveMicros:1388, 169ms
2020-05-08T12:16:00.710-0700 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 180), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e") }, txnNumber: 4, autocommit: false } numYields:0 reslen:214 protocol:op_msg 137ms
2020-05-08T12:16:00.879-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56268 #64 (19 connections now open)
2020-05-08T12:16:00.879-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.1:56268 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:01.874-0700 I  NETWORK  [conn54] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:01.877-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:01.877-0700 I  NETWORK  [conn59] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:01.878-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:01.879-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:02.375-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:02.874-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:02.875-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:02.875-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T12:16:02.876-0700 I  SHARDING [conn52] Received reply from shard n9:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965357, 6), t: 4 }, now { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T12:16:02.876-0700 I  COMMAND  [conn52] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 304), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e") }, txnNumber: 7, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2076ms
2020-05-08T12:16:02.876-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:02.878-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:02.878-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:02.885-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 299) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 299) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2087929, timeActiveMicros:2100990, timeInactiveMicros:620, 2101ms
2020-05-08T12:16:02.885-0700 I  COMMAND  [conn59] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 301), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2088ms
2020-05-08T12:16:02.895-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 251) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 251) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:2157551, timeActiveMicros:2181235, timeInactiveMicros:1629, 2182ms
2020-05-08T12:16:02.895-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 269), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab") }, txnNumber: 9, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2157ms
2020-05-08T12:16:03.975-0700 I  NETWORK  [conn59] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:03.976-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:03.976-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:04.477-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:04.477-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:04.478-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965363, 146) } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 146) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1180954, timeInactiveMicros:378, 1181ms
2020-05-08T12:16:04.479-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965363, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab") }, txnNumber: 18, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1180ms
2020-05-08T12:16:05.697-0700 I  NETWORK  [conn59] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:05.698-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.199-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:06.625-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:06.626-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:06.626-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:06.626-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:16:06.627-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965363, 123) } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 123) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3383216, timeInactiveMicros:645, 3383ms
2020-05-08T12:16:06.627-0700 I  COMMAND  [conn59] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965363, 132), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 18, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3366ms
2020-05-08T12:16:06.959-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965363, 110) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3681986, timeActiveMicros:3754545, timeInactiveMicros:898, 3755ms
2020-05-08T12:16:06.960-0700 I  NETWORK  [conn52] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:06.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:07.461-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:07.461-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:07.463-0700 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 136), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e") }, txnNumber: 14, autocommit: false } numYields:0 reslen:463 protocol:op_msg 4185ms
2020-05-08T12:16:07.476-0700 I  CONNPOOL [conn52] Ending connection to host n7:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T12:16:07.477-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-08T12:16:07.497-0700 I  COMMAND  [conn59] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965366, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 18, autocommit: false } numYields:0 reslen:515 protocol:op_msg 868ms
2020-05-08T12:16:07.560-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:07.561-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:07.607-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab") }, txnNumber: 19, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 3108ms
2020-05-08T12:16:07.654-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965364, 14) } }, globalReadTimestamp:{ ts: Timestamp(1588965364, 14) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3155725, timeInactiveMicros:2002, 3157ms
2020-05-08T12:16:07.734-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 15) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:124385, timeActiveMicros:223224, timeInactiveMicros:2016, 225ms
2020-05-08T12:16:07.734-0700 I  COMMAND  [conn59] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 19, autocommit: false } numYields:0 reslen:214 protocol:op_msg 124ms
2020-05-08T12:16:08.027-0700 I  NETWORK  [conn55] end connection 192.168.122.1:55828 (18 connections now open)
2020-05-08T12:16:08.028-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56572 #70 (19 connections now open)
2020-05-08T12:16:08.028-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56574 #71 (20 connections now open)
2020-05-08T12:16:08.029-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.1:56572 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:08.029-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.1:56574 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:08.031-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:16:08.060-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:08.362-0700 I  COMMAND  [conn59] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 91), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 21, autocommit: false } numYields:0 reslen:352 protocol:op_msg 478ms
2020-05-08T12:16:08.362-0700 I  COMMAND  [conn70] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 78 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965367, 91), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 331ms
2020-05-08T12:16:08.362-0700 I  COMMAND  [conn52] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e") }, txnNumber: 21, autocommit: false } numYields:0 reslen:321 protocol:op_msg 543ms
2020-05-08T12:16:08.366-0700 I  COMMAND  [conn54] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce89b3a9-af94-452e-ad5d-7f8e2daee9ab") }, txnNumber: 21, autocommit: false } numYields:0 reslen:352 protocol:op_msg 551ms
2020-05-08T12:16:08.366-0700 I  NETWORK  [conn54] end connection 192.168.122.1:55826 (19 connections now open)
2020-05-08T12:16:08.390-0700 I  TXN      [conn70] transaction parameters:{ lsid: { id: UUID("7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 91) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:354821, timeInactiveMicros:4310, 359ms
2020-05-08T12:16:08.471-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 19) } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 21) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:78690, timeActiveMicros:103043, timeInactiveMicros:1739, 104ms
2020-05-08T12:16:08.560-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:08.570-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:09.060-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:09.061-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:09.692-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965361, 1), t: 5 }, now { ts: Timestamp(1588965369, 16), t: 6 }
2020-05-08T12:16:10.882-0700 I  NETWORK  [conn59] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:10.883-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:10.883-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:10.886-0700 I  COMMAND  [conn59] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965369, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 29, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1864ms
2020-05-08T12:16:10.913-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:10.913-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:12.385-0700 I  COMMAND  [conn70] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 78 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965368, 196), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf") }, txnNumber: 6, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 196) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 3393ms
2020-05-08T12:16:12.531-0700 I  NETWORK  [conn53] end connection 192.168.122.1:55802 (18 connections now open)
2020-05-08T12:16:12.532-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56780 #74 (19 connections now open)
2020-05-08T12:16:12.533-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56782 #75 (20 connections now open)
2020-05-08T12:16:12.533-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.1:56780 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:12.533-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.1:56782 conn75: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:12.536-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:12.705-0700 I  NETWORK  [conn52] Marking host n6:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:12.706-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:12.706-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:12.708-0700 I  COMMAND  [conn59] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965370, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 29, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1820ms
2020-05-08T12:16:12.805-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:12.808-0700 I  TXN      [conn70] transaction parameters:{ lsid: { id: UUID("7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 196) } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 196) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3815547, timeInactiveMicros:690, 3816ms
2020-05-08T12:16:12.808-0700 I  COMMAND  [conn70] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965371, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf") }, txnNumber: 6, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf:6 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered error from n7:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588965368, 196) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:555 protocol:op_msg 422ms
2020-05-08T12:16:13.029-0700 I  NETWORK  [conn71] end connection 192.168.122.1:56574 (19 connections now open)
2020-05-08T12:16:13.030-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56818 #77 (20 connections now open)
2020-05-08T12:16:13.030-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56820 #78 (21 connections now open)
2020-05-08T12:16:13.030-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.1:56818 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.030-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:56820 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.031-0700 I  NETWORK  [conn59] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:13.033-0700 I  NETWORK  [conn52] Marking host n5:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:13.205-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.606-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdb5861abbf7eec2119; invalidating user cache
2020-05-08T12:16:13.705-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:13.736-0700 I  NETWORK  [conn60] end connection 192.168.122.1:56008 (20 connections now open)
2020-05-08T12:16:13.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56880 #80 (21 connections now open)
2020-05-08T12:16:13.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56884 #81 (22 connections now open)
2020-05-08T12:16:13.737-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.1:56880 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.738-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.1:56884 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.764-0700 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 135), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f22ffbee-41ee-4724-b7a3-23671b84b64e") }, txnNumber: 25, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T12:16:13.765-0700 I  NETWORK  [conn52] end connection 192.168.122.1:55800 (21 connections now open)
2020-05-08T12:16:14.205-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:14.205-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:14.207-0700 I  COMMAND  [conn70] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965372, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7c4ca0ca-0a1d-4859-b677-6e73d4efc5bf") }, txnNumber: 6, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1397ms
2020-05-08T12:16:14.208-0700 I  NETWORK  [conn70] end connection 192.168.122.1:56572 (20 connections now open)
2020-05-08T12:16:16.188-0700 I  NETWORK  [conn59] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:17.025-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:17.189-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:17.534-0700 I  NETWORK  [conn75] end connection 192.168.122.1:56782 (19 connections now open)
2020-05-08T12:16:17.534-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57062 #82 (20 connections now open)
2020-05-08T12:16:17.535-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57064 #83 (21 connections now open)
2020-05-08T12:16:17.535-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.1:57062 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:17.535-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.1:57064 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:17.713-0700 I  -        [conn59] operation was interrupted because a client disconnected
2020-05-08T12:16:17.714-0700 I  TXN      [conn59] transaction parameters:{ lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 30, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965372, 19) } }, globalReadTimestamp:{ ts: Timestamp(1588965372, 20) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004425, timeInactiveMicros:0, 5004ms
2020-05-08T12:16:17.714-0700 I  COMMAND  [conn59] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 85 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965372, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e284e15d-1bed-455f-b998-4665fa6041c2") }, txnNumber: 30, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965372, 19) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:16:17.714-0700 I  NETWORK  [conn59] end connection 192.168.122.1:56006 (20 connections now open)
2020-05-08T12:16:18.030-0700 I  NETWORK  [conn78] end connection 192.168.122.1:56820 (19 connections now open)
2020-05-08T12:16:18.031-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57078 #84 (20 connections now open)
2020-05-08T12:16:18.031-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57080 #85 (21 connections now open)
2020-05-08T12:16:18.031-0700 I  NETWORK  [conn84] received client metadata from 192.168.122.1:57078 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.032-0700 I  NETWORK  [conn85] received client metadata from 192.168.122.1:57080 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.033-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T12:16:18.037-0700 I  -        [conn77] operation was interrupted because a client disconnected
2020-05-08T12:16:18.037-0700 I  CONNPOOL [conn77] Ending connection to host n7:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T12:16:18.037-0700 I  TXN      [conn77] transaction parameters:{ lsid: { id: UUID("f901414f-65ea-427f-8023-56f33f7eaf76"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965372, 22) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005553, timeInactiveMicros:0, 5005ms
2020-05-08T12:16:18.038-0700 I  COMMAND  [conn77] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 91 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965372, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f901414f-65ea-427f-8023-56f33f7eaf76") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:16:18.038-0700 I  NETWORK  [conn77] end connection 192.168.122.1:56818 (20 connections now open)
2020-05-08T12:16:18.105-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:18.190-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:18.190-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:18.732-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:18.734-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:18.738-0700 I  NETWORK  [conn81] end connection 192.168.122.1:56884 (19 connections now open)
2020-05-08T12:16:18.739-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57148 #87 (20 connections now open)
2020-05-08T12:16:18.739-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57152 #88 (21 connections now open)
2020-05-08T12:16:18.739-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.1:57148 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.739-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.1:57152 conn88: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.897-0700 I  COMMAND  [conn74] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965372, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("150c7510-e568-4ce6-a7c0-2dffe2194dfe") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 6362ms
2020-05-08T12:16:18.898-0700 I  NETWORK  [conn74] end connection 192.168.122.1:56780 (20 connections now open)
2020-05-08T12:16:18.913-0700 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 97 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965377, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 876ms
2020-05-08T12:16:18.916-0700 I  COMMAND  [conn87] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965378, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 175ms
2020-05-08T12:16:18.918-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965377, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:880316, timeInactiveMicros:443, 880ms
2020-05-08T12:16:18.951-0700 I  TXN      [conn87] transaction parameters:{ lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965378, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:31202, timeActiveMicros:208147, timeInactiveMicros:1576, 209ms
2020-05-08T12:16:18.951-0700 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965376, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1414ms
2020-05-08T12:16:19.157-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-08T12:16:19.189-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965379, 37) } }, globalReadTimestamp:{ ts: Timestamp(1588965379, 37) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:96936, timeActiveMicros:131885, timeInactiveMicros:1330, 133ms
2020-05-08T12:16:19.233-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:19.534-0700 I  COMMAND  [conn87] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 168), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8") }, txnNumber: 12, autocommit: false } numYields:0 reslen:321 protocol:op_msg 213ms
2020-05-08T12:16:19.545-0700 I  SHARDING [conn87] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965373, 1), t: 6 }, now { ts: Timestamp(1588965379, 2), t: 9 }
2020-05-08T12:16:19.698-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:19.699-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:20.218-0700 I  NETWORK  [conn82] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:21.057-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:21.057-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:21.058-0700 I  COMMAND  [conn84] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 143), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 5, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1851ms
2020-05-08T12:16:21.062-0700 I  COMMAND  [conn87] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 108 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965380, 196), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8") }, txnNumber: 102, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:350 protocol:op_msg 139ms
2020-05-08T12:16:21.076-0700 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 9, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965379, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1846ms
2020-05-08T12:16:21.106-0700 I  TXN      [conn87] transaction parameters:{ lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 102, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965380, 196) } }, globalReadTimestamp:{ ts: Timestamp(1588965380, 196) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:43023, timeActiveMicros:186987, timeInactiveMicros:1079, 188ms
2020-05-08T12:16:21.295-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 75) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 75) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:145131, timeActiveMicros:180121, timeInactiveMicros:1523, 181ms
2020-05-08T12:16:21.295-0700 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 7, autocommit: false } numYields:0 reslen:214 protocol:op_msg 145ms
2020-05-08T12:16:21.583-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 214) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 215) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:153636, timeActiveMicros:197047, timeInactiveMicros:1177, 198ms
2020-05-08T12:16:21.583-0700 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 226), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 153ms
2020-05-08T12:16:21.607-0700 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 231) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 231) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:91051, timeActiveMicros:170061, timeInactiveMicros:2571, 172ms
2020-05-08T12:16:21.775-0700 I  TXN      [conn87] transaction parameters:{ lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 112, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 294) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 296) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:81018, timeActiveMicros:105865, timeInactiveMicros:1571, 107ms
2020-05-08T12:16:21.815-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 280) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:121367, timeActiveMicros:173030, timeInactiveMicros:2129, 175ms
2020-05-08T12:16:21.815-0700 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 304), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 12, autocommit: false } numYields:0 reslen:183 protocol:op_msg 121ms
2020-05-08T12:16:22.721-0700 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 72 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965381, 326), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 13, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 904ms
2020-05-08T12:16:22.721-0700 I  COMMAND  [conn87] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 123 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965381, 326), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8") }, txnNumber: 113, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 938ms
2020-05-08T12:16:22.725-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 326) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:907479, timeInactiveMicros:1009, 908ms
2020-05-08T12:16:22.746-0700 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 304) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:968711, timeActiveMicros:1050386, timeInactiveMicros:1902, 1052ms
2020-05-08T12:16:22.746-0700 I  COMMAND  [conn82] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 324), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c") }, txnNumber: 20, autocommit: false } numYields:0 reslen:214 protocol:op_msg 969ms
2020-05-08T12:16:22.950-0700 I  NETWORK  [conn87] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:22.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:23.031-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:23.451-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:23.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.297-0700 I  COMMAND  [conn84] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965383, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 37, autocommit: false } numYields:0 reslen:321 protocol:op_msg 870ms
2020-05-08T12:16:24.451-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:24.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.452-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:25.725-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57382 #92 (21 connections now open)
2020-05-08T12:16:25.726-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.1:57382 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:25.952-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:26.233-0700 I  NETWORK  [conn82] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:26.234-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:26.451-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:26.497-0700 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 72 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965384, 41), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 59, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965384, 41) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 1688ms
2020-05-08T12:16:26.498-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:26.499-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:26.500-0700 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965382, 13) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3752351, timeInactiveMicros:0, 3752ms
2020-05-08T12:16:26.501-0700 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965382, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c") }, txnNumber: 21, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3752ms
2020-05-08T12:16:26.501-0700 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 59, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965384, 41) } }, globalReadTimestamp:{ ts: Timestamp(1588965384, 41) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:1691954, timeInactiveMicros:774, 1692ms
2020-05-08T12:16:26.783-0700 I  NETWORK  [conn88] end connection 192.168.122.1:57152 (20 connections now open)
2020-05-08T12:16:26.784-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57452 #93 (21 connections now open)
2020-05-08T12:16:26.784-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57454 #94 (22 connections now open)
2020-05-08T12:16:26.784-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.1:57452 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.785-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.1:57454 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.817-0700 I  NETWORK  [conn85] end connection 192.168.122.1:57080 (21 connections now open)
2020-05-08T12:16:26.818-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57456 #95 (22 connections now open)
2020-05-08T12:16:26.818-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.1:57456 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.856-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57458 #96 (23 connections now open)
2020-05-08T12:16:26.857-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.1:57458 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:26.859-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:26.907-0700 I  NETWORK  [conn95] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:26.908-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:26.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:27.408-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:27.452-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:27.742-0700 I  COMMAND  [conn87] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965382, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f540a036-64b1-4207-92e4-d2213baf52d8") }, txnNumber: 113, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5015ms
2020-05-08T12:16:27.742-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:27.742-0700 I  NETWORK  [conn87] end connection 192.168.122.1:57148 (22 connections now open)
2020-05-08T12:16:27.748-0700 I  NETWORK  [conn83] end connection 192.168.122.1:57064 (21 connections now open)
2020-05-08T12:16:27.749-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57532 #98 (22 connections now open)
2020-05-08T12:16:27.749-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57534 #99 (23 connections now open)
2020-05-08T12:16:27.750-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.1:57532 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:27.750-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.1:57534 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:27.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:28.451-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:28.451-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:28.774-0700 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb736666-5677-4273-ae55-c8f245b5506f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 15035ms
2020-05-08T12:16:28.774-0700 I  NETWORK  [conn80] end connection 192.168.122.1:56880 (22 connections now open)
2020-05-08T12:16:29.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:30.696-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57662 #100 (23 connections now open)
2020-05-08T12:16:30.697-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.1:57662 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.407-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:31.407-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:31.408-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:16:31.409-0700 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965386, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5845745d-472a-46a2-96f6-f5498e64a53c") }, txnNumber: 21, autocommit: false } numYields:0 reslen:515 protocol:op_msg 4907ms
2020-05-08T12:16:31.409-0700 I  TXN      [conn95] transaction parameters:{ lsid: { id: UUID("3f6fa9eb-dce0-466e-ba7e-d53296378f6a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965386, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4550915, timeInactiveMicros:0, 4550ms
2020-05-08T12:16:31.410-0700 I  COMMAND  [conn95] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965386, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f6fa9eb-dce0-466e-ba7e-d53296378f6a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 4551ms
2020-05-08T12:16:31.410-0700 I  NETWORK  [conn82] end connection 192.168.122.1:57062 (22 connections now open)
2020-05-08T12:16:31.410-0700 I  COMMAND  [conn84] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965386, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60845c8d-3f36-4dcd-b692-6c67d9aeb91a") }, txnNumber: 59, autocommit: false } numYields:0 reslen:515 protocol:op_msg 4908ms
2020-05-08T12:16:31.411-0700 I  NETWORK  [conn84] end connection 192.168.122.1:57078 (21 connections now open)
2020-05-08T12:16:31.784-0700 I  NETWORK  [conn94] end connection 192.168.122.1:57454 (20 connections now open)
2020-05-08T12:16:31.785-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57772 #102 (21 connections now open)
2020-05-08T12:16:31.785-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57774 #103 (22 connections now open)
2020-05-08T12:16:31.785-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.1:57772 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.785-0700 I  NETWORK  [conn103] received client metadata from 192.168.122.1:57774 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.790-0700 I  -        [conn93] operation was interrupted because a client disconnected
2020-05-08T12:16:31.790-0700 I  CONNPOOL [conn93] Ending connection to host n5:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:16:31.791-0700 I  TXN      [conn93] transaction parameters:{ lsid: { id: UUID("e03104cc-f0da-4685-8fc1-23e2cc9c8f5a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965386, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005263, timeInactiveMicros:0, 5005ms
2020-05-08T12:16:31.791-0700 I  COMMAND  [conn93] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 127 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965386, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e03104cc-f0da-4685-8fc1-23e2cc9c8f5a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:16:31.791-0700 I  NETWORK  [conn93] end connection 192.168.122.1:57452 (21 connections now open)
2020-05-08T12:16:31.818-0700 I  NETWORK  [conn96] end connection 192.168.122.1:57458 (20 connections now open)
2020-05-08T12:16:31.819-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57778 #104 (21 connections now open)
2020-05-08T12:16:31.819-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57780 #105 (22 connections now open)
2020-05-08T12:16:31.819-0700 I  NETWORK  [conn104] received client metadata from 192.168.122.1:57778 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:31.820-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.1:57780 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:32.410-0700 I  COMMAND  [conn95] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965391, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f6fa9eb-dce0-466e-ba7e-d53296378f6a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 999ms
2020-05-08T12:16:32.411-0700 I  NETWORK  [conn95] end connection 192.168.122.1:57456 (21 connections now open)
2020-05-08T12:16:32.432-0700 I  TXN      [conn104] transaction parameters:{ lsid: { id: UUID("7f81419d-40b2-41cb-844a-aca12a5ecb6d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965391, 28) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:594804, timeInactiveMicros:0, 594ms
2020-05-08T12:16:32.432-0700 I  COMMAND  [conn104] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965391, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f81419d-40b2-41cb-844a-aca12a5ecb6d") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 595ms
2020-05-08T12:16:32.750-0700 I  NETWORK  [conn99] end connection 192.168.122.1:57534 (20 connections now open)
2020-05-08T12:16:32.751-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57854 #106 (21 connections now open)
2020-05-08T12:16:32.751-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57856 #107 (22 connections now open)
2020-05-08T12:16:32.751-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.1:57854 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:32.751-0700 I  NETWORK  [conn107] received client metadata from 192.168.122.1:57856 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:33.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:16:34.381-0700 I  NETWORK  [conn98] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:34.382-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:34.385-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:34.882-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:36.786-0700 I  NETWORK  [conn102] end connection 192.168.122.1:57772 (21 connections now open)
2020-05-08T12:16:36.787-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58050 #109 (22 connections now open)
2020-05-08T12:16:36.787-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58052 #110 (23 connections now open)
2020-05-08T12:16:36.787-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.1:58050 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.787-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.1:58052 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.790-0700 I  NETWORK  [conn109] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:36.791-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:36.838-0700 I  NETWORK  [conn105] end connection 192.168.122.1:57780 (22 connections now open)
2020-05-08T12:16:36.839-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58060 #111 (23 connections now open)
2020-05-08T12:16:36.839-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58062 #112 (24 connections now open)
2020-05-08T12:16:36.839-0700 I  NETWORK  [conn111] received client metadata from 192.168.122.1:58060 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.840-0700 I  NETWORK  [conn112] received client metadata from 192.168.122.1:58062 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:36.842-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.057-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:37.291-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.751-0700 I  NETWORK  [conn107] end connection 192.168.122.1:57856 (23 connections now open)
2020-05-08T12:16:37.752-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58140 #113 (24 connections now open)
2020-05-08T12:16:37.752-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58142 #114 (25 connections now open)
2020-05-08T12:16:37.753-0700 I  NETWORK  [conn113] received client metadata from 192.168.122.1:58140 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.753-0700 I  NETWORK  [conn114] received client metadata from 192.168.122.1:58142 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.756-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.791-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.292-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.792-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:38.840-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58170 #115 (26 connections now open)
2020-05-08T12:16:38.840-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.1:58170 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:38.882-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:38.883-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:38.884-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965389, 3), t: 9 }, now { ts: Timestamp(1588965397, 5), t: 11 }
2020-05-08T12:16:38.884-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:38.885-0700 I  COMMAND  [conn104] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965392, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f81419d-40b2-41cb-844a-aca12a5ecb6d") }, txnNumber: 2, autocommit: false } numYields:0 reslen:438 protocol:op_msg 6451ms
2020-05-08T12:16:38.885-0700 I  NETWORK  [conn104] end connection 192.168.122.1:57778 (25 connections now open)
2020-05-08T12:16:38.885-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:38.885-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:39.292-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.385-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:39.385-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:39.791-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn98] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965386, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fd048377-bc0d-4076-9450-4fd8818567c9") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 12153ms
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn103] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965391, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6bb42787-8c9c-4826-bf12-ecc778036768") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 8119ms
2020-05-08T12:16:39.905-0700 I  NETWORK  [conn98] end connection 192.168.122.1:57532 (24 connections now open)
2020-05-08T12:16:39.905-0700 I  COMMAND  [conn106] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965392, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("10c96e7b-f6f5-46a8-9a79-9209c15e4e23") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 7152ms
2020-05-08T12:16:39.905-0700 I  NETWORK  [conn103] end connection 192.168.122.1:57774 (23 connections now open)
2020-05-08T12:16:39.906-0700 I  NETWORK  [conn106] end connection 192.168.122.1:57854 (22 connections now open)
2020-05-08T12:16:40.041-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965397, 5), t: 11 }, now { ts: Timestamp(1588965399, 5), t: 12 }
2020-05-08T12:16:40.291-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.792-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:41.291-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:41.291-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:41.292-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:41.293-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:41.293-0700 I  TXN      [conn109] transaction parameters:{ lsid: { id: UUID("70b14cdf-7322-4ecb-a5bb-b0cb2cbeea20"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965392, 63) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:4504729, timeInactiveMicros:0, 4504ms
2020-05-08T12:16:41.293-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:41.294-0700 I  COMMAND  [conn109] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965392, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("70b14cdf-7322-4ecb-a5bb-b0cb2cbeea20") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 4505ms
2020-05-08T12:16:41.313-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965399, 5), t: 12 }, now { ts: Timestamp(1588965400, 2), t: 13 }
2020-05-08T12:16:41.643-0700 I  COMMAND  [conn109] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965401, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("70b14cdf-7322-4ecb-a5bb-b0cb2cbeea20") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 348ms
2020-05-08T12:16:41.646-0700 I  TXN      [conn113] transaction parameters:{ lsid: { id: UUID("395594bc-6a50-4bb7-997c-1852b8ddb596"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 9) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3891445, timeInactiveMicros:0, 3891ms
2020-05-08T12:16:41.646-0700 I  COMMAND  [conn113] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395594bc-6a50-4bb7-997c-1852b8ddb596") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 395594bc-6a50-4bb7-997c-1852b8ddb596:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588965395, 9) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:553 protocol:op_msg 3891ms
2020-05-08T12:16:41.647-0700 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("b87c467d-aba8-4493-93bb-71167f34321d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965395, 9) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4805327, timeInactiveMicros:0, 4805ms
2020-05-08T12:16:41.647-0700 I  COMMAND  [conn111] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 137 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b87c467d-aba8-4493-93bb-71167f34321d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction b87c467d-aba8-4493-93bb-71167f34321d:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965395, 9) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 4805ms
2020-05-08T12:16:41.670-0700 I  NETWORK  [conn111] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:41.787-0700 I  NETWORK  [conn110] end connection 192.168.122.1:58052 (21 connections now open)
2020-05-08T12:16:41.787-0700 I  NETWORK  [conn109] end connection 192.168.122.1:58050 (20 connections now open)
2020-05-08T12:16:41.788-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58312 #116 (21 connections now open)
2020-05-08T12:16:41.788-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58314 #117 (22 connections now open)
2020-05-08T12:16:41.788-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.1:58312 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.789-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.1:58314 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.839-0700 I  NETWORK  [conn112] end connection 192.168.122.1:58062 (21 connections now open)
2020-05-08T12:16:41.841-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58316 #118 (22 connections now open)
2020-05-08T12:16:41.841-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58318 #119 (23 connections now open)
2020-05-08T12:16:41.841-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.1:58316 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:41.842-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.1:58318 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:42.242-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:16:42.382-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:42.382-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:16:42.672-0700 I  COMMAND  [conn118] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3cca1669-c75d-4fb2-8ca8-1ea699776162") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 829ms
2020-05-08T12:16:42.673-0700 I  COMMAND  [conn116] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 140 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5e5a4e3-14c5-4334-9c97-f87ae436a37d") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:332 protocol:op_msg 882ms
2020-05-08T12:16:42.681-0700 I  COMMAND  [conn111] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 134 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b87c467d-aba8-4493-93bb-71167f34321d") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1012ms
2020-05-08T12:16:42.682-0700 I  NETWORK  [conn111] end connection 192.168.122.1:58060 (22 connections now open)
2020-05-08T12:16:42.719-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:42.753-0700 I  NETWORK  [conn114] end connection 192.168.122.1:58142 (21 connections now open)
2020-05-08T12:16:42.754-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58420 #122 (22 connections now open)
2020-05-08T12:16:42.754-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58422 #123 (23 connections now open)
2020-05-08T12:16:42.754-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:58420 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:42.755-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.1:58422 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:42.766-0700 I  NETWORK  [conn113] end connection 192.168.122.1:58140 (22 connections now open)
2020-05-08T12:16:42.968-0700 I  NETWORK  [conn118] Marking host n9:27018 as failed :: caused by :: PrimarySteppedDown: Received stepdown request while waiting for replication
2020-05-08T12:16:42.969-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:42.979-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:43.469-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:43.470-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:43.471-0700 I  COMMAND  [conn122] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965402, 206), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bc2a3ed1-acfa-434d-8181-94568dacca18") }, txnNumber: 5, autocommit: false } numYields:0 reslen:455 protocol:op_msg 539ms
2020-05-08T12:16:43.606-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdb5861abbf7eec2119 to 5eb5afdaa0224cfb413c7171; invalidating user cache
2020-05-08T12:16:43.996-0700 I  COMMAND  [conn116] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 147 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965402, 220), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5e5a4e3-14c5-4334-9c97-f87ae436a37d") }, txnNumber: 10, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 1034ms
2020-05-08T12:16:43.996-0700 I  COMMAND  [conn122] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965403, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bc2a3ed1-acfa-434d-8181-94568dacca18") }, txnNumber: 5, autocommit: false } numYields:0 reslen:395 protocol:op_msg 523ms
2020-05-08T12:16:43.997-0700 I  TXN      [conn118] transaction parameters:{ lsid: { id: UUID("3cca1669-c75d-4fb2-8ca8-1ea699776162"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965402, 185) } }, globalReadTimestamp:{ ts: Timestamp(1588965402, 185) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1125911, timeActiveMicros:1139042, timeInactiveMicros:2524, 1141ms
2020-05-08T12:16:43.997-0700 I  COMMAND  [conn118] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965402, 189), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3cca1669-c75d-4fb2-8ca8-1ea699776162") }, txnNumber: 6, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1126ms
2020-05-08T12:16:44.014-0700 I  TXN      [conn116] transaction parameters:{ lsid: { id: UUID("e5e5a4e3-14c5-4334-9c97-f87ae436a37d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965402, 220) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:15804, timeActiveMicros:1051335, timeInactiveMicros:1062, 1052ms
2020-05-08T12:16:44.082-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:44.431-0700 I  TXN      [conn118] transaction parameters:{ lsid: { id: UUID("3cca1669-c75d-4fb2-8ca8-1ea699776162"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965404, 74) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:248750, timeActiveMicros:251004, timeInactiveMicros:797, 251ms
2020-05-08T12:16:44.432-0700 I  COMMAND  [conn118] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965404, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3cca1669-c75d-4fb2-8ca8-1ea699776162") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 248ms
2020-05-08T12:16:45.990-0700 I  NETWORK  [conn118] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T12:16:46.817-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:46.991-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:47.491-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:47.491-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:47.560-0700 I  SHARDING [conn116] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965403, 8), t: 13 }, now { ts: Timestamp(1588965407, 1), t: 14 }
2020-05-08T12:16:47.560-0700 I  NETWORK  [conn116] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:47.561-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:47.565-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:47.760-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965407, 1), t: 14 }, now { ts: Timestamp(1588965407, 4), t: 15 }
2020-05-08T12:16:48.061-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:48.497-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:48.561-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:48.561-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:48.998-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:49.092-0700 I  NETWORK  [conn117] end connection 192.168.122.1:58314 (21 connections now open)
2020-05-08T12:16:49.093-0700 I  NETWORK  [conn123] end connection 192.168.122.1:58422 (20 connections now open)
2020-05-08T12:16:49.093-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58762 #125 (21 connections now open)
2020-05-08T12:16:49.094-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58766 #126 (22 connections now open)
2020-05-08T12:16:49.094-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.1:58762 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.094-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58770 #127 (23 connections now open)
2020-05-08T12:16:49.094-0700 I  NETWORK  [conn126] received client metadata from 192.168.122.1:58766 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.094-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58772 #128 (24 connections now open)
2020-05-08T12:16:49.094-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.1:58770 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.094-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.1:58772 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.096-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:49.138-0700 I  CONNPOOL [conn122] Ending connection to host n9:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T12:16:49.138-0700 I  COMMAND  [conn122] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965404, 60), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bc2a3ed1-acfa-434d-8181-94568dacca18") }, txnNumber: 11, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T12:16:49.138-0700 I  NETWORK  [conn122] end connection 192.168.122.1:58420 (23 connections now open)
2020-05-08T12:16:49.157-0700 I  -        [conn116] operation was interrupted because a client disconnected
2020-05-08T12:16:49.157-0700 I  CONNPOOL [conn116] Ending connection to host n9:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T12:16:49.158-0700 I  TXN      [conn116] transaction parameters:{ lsid: { id: UUID("e5e5a4e3-14c5-4334-9c97-f87ae436a37d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965404, 70) } }, globalReadTimestamp:{ ts: Timestamp(1588965404, 70) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003450, timeInactiveMicros:249, 5003ms
2020-05-08T12:16:49.158-0700 I  COMMAND  [conn116] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965404, 70), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5e5a4e3-14c5-4334-9c97-f87ae436a37d") }, txnNumber: 16, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T12:16:49.158-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:49.158-0700 I  NETWORK  [conn116] end connection 192.168.122.1:58312 (22 connections now open)
2020-05-08T12:16:49.577-0700 I  COMMAND  [conn126] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 159 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965408, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 479ms
2020-05-08T12:16:49.579-0700 I  TXN      [conn126] transaction parameters:{ lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965408, 7) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:481586, timeInactiveMicros:655, 482ms
2020-05-08T12:16:49.808-0700 I  NETWORK  [conn119] end connection 192.168.122.1:58318 (21 connections now open)
2020-05-08T12:16:49.809-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58810 #129 (22 connections now open)
2020-05-08T12:16:49.810-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58812 #130 (23 connections now open)
2020-05-08T12:16:49.810-0700 I  NETWORK  [conn129] received client metadata from 192.168.122.1:58810 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.810-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.1:58812 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:49.917-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:49.997-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:50.047-0700 I  NETWORK  [conn126] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:50.048-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:50.548-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:50.548-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:50.550-0700 I  COMMAND  [conn126] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965410, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c") }, txnNumber: 30, autocommit: false } numYields:0 reslen:439 protocol:op_msg 511ms
2020-05-08T12:16:50.721-0700 I  COMMAND  [conn126] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965410, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c") }, txnNumber: 30, autocommit: false } numYields:0 reslen:397 protocol:op_msg 170ms
2020-05-08T12:16:50.730-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n4:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:16:51.329-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:51.329-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:51.331-0700 I  COMMAND  [conn125] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 158 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965407, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 2235ms
2020-05-08T12:16:52.005-0700 I  COMMAND  [conn118] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 33, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965404, 128), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3cca1669-c75d-4fb2-8ca8-1ea699776162") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 7197ms
2020-05-08T12:16:52.005-0700 I  NETWORK  [conn118] end connection 192.168.122.1:58316 (22 connections now open)
2020-05-08T12:16:52.007-0700 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 160 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965409, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8ee09ce0-ac5a-4166-a17e-daced999fb28") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2195ms
2020-05-08T12:16:52.008-0700 I  TXN      [conn125] transaction parameters:{ lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965411, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:674949, timeInactiveMicros:0, 674ms
2020-05-08T12:16:52.008-0700 I  COMMAND  [conn125] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965411, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 675ms
2020-05-08T12:16:52.008-0700 I  TXN      [conn126] transaction parameters:{ lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965410, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1271079, timeInactiveMicros:0, 1271ms
2020-05-08T12:16:52.009-0700 I  COMMAND  [conn126] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965410, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c") }, txnNumber: 32, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1271ms
2020-05-08T12:16:52.014-0700 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("8ee09ce0-ac5a-4166-a17e-daced999fb28"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965409, 23) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2200544, timeInactiveMicros:2073, 2202ms
2020-05-08T12:16:52.068-0700 I  NETWORK  [conn126] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:52.069-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.121-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:52.569-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:53.069-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:53.070-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:53.071-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:53.072-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:53.072-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:16:53.073-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965410, 7), t: 15 }, now { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:16:53.928-0700 I  NETWORK  [conn126] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:53.929-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:54.401-0700 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 160 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965412, 59), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8ee09ce0-ac5a-4166-a17e-daced999fb28") }, txnNumber: 36, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 1676ms
2020-05-08T12:16:54.403-0700 I  NETWORK  [conn129] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:54.403-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:54.429-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:54.430-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:54.810-0700 I  NETWORK  [conn130] end connection 192.168.122.1:58812 (21 connections now open)
2020-05-08T12:16:54.810-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59084 #131 (22 connections now open)
2020-05-08T12:16:54.810-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59086 #132 (23 connections now open)
2020-05-08T12:16:54.811-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:59084 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.811-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.1:59086 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.813-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:16:54.950-0700 I  COMMAND  [conn126] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 164 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965412, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c") }, txnNumber: 34, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2882ms
2020-05-08T12:16:54.950-0700 I  COMMAND  [conn125] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 164 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965412, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2830ms
2020-05-08T12:16:54.950-0700 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 166 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965413, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b795c64d-b425-45e2-b831-a11ca69cbcf2") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 138ms
2020-05-08T12:16:54.953-0700 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("b795c64d-b425-45e2-b831-a11ca69cbcf2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965413, 5) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:140197, timeInactiveMicros:444, 140ms
2020-05-08T12:16:54.953-0700 I  TXN      [conn126] transaction parameters:{ lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 34, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965412, 18) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2885256, timeInactiveMicros:832, 2886ms
2020-05-08T12:16:54.980-0700 I  TXN      [conn125] transaction parameters:{ lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965412, 26) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:25678, timeActiveMicros:2858024, timeInactiveMicros:1590, 2859ms
2020-05-08T12:16:55.317-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:55.404-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.068-0700 I  NETWORK  [conn127] end connection 192.168.122.1:58770 (22 connections now open)
2020-05-08T12:16:57.069-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59208 #134 (23 connections now open)
2020-05-08T12:16:57.069-0700 I  NETWORK  [conn134] received client metadata from 192.168.122.1:59208 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:57.069-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59212 #135 (24 connections now open)
2020-05-08T12:16:57.070-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.1:59212 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:57.072-0700 I  NETWORK  [conn134] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:57.073-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:57.073-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:57.074-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:16:57.075-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:57.233-0700 I  NETWORK  [conn134] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:57.234-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.569-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:57.573-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:57.574-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:57.903-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:58.073-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:58.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:58.403-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:58.404-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:58.405-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:58.405-0700 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 167 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b795c64d-b425-45e2-b831-a11ca69cbcf2") }, txnNumber: 5, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 3274ms
2020-05-08T12:16:58.406-0700 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("8ee09ce0-ac5a-4166-a17e-daced999fb28"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965412, 59) } }, globalReadTimestamp:{ ts: Timestamp(1588965412, 59) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:5684137, timeInactiveMicros:1252, 5685ms
2020-05-08T12:16:58.407-0700 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 158 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965413, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8ee09ce0-ac5a-4166-a17e-daced999fb28") }, txnNumber: 36, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 36 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:438 protocol:op_msg 4004ms
2020-05-08T12:16:58.407-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:58.407-0700 I  NETWORK  [conn129] end connection 192.168.122.1:58810 (23 connections now open)
2020-05-08T12:16:58.407-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:58.408-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:58.409-0700 I  TXN      [conn126] transaction parameters:{ lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 35, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965414, 35) } }, globalReadTimestamp:{ ts: Timestamp(1588965414, 35) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3427049, timeInactiveMicros:592, 3427ms
2020-05-08T12:16:58.409-0700 I  COMMAND  [conn126] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965414, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b12c079-cd16-4857-8137-1c3c82804d3c") }, txnNumber: 35, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 3412ms
2020-05-08T12:16:58.409-0700 I  NETWORK  [conn126] end connection 192.168.122.1:58766 (22 connections now open)
2020-05-08T12:16:58.427-0700 I  NETWORK  [conn134] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:16:58.428-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:58.567-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n2:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:16:58.573-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:58.574-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.073-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.129-0700 I  COMMAND  [conn125] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 167 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4068ms
2020-05-08T12:16:59.142-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:59.155-0700 I  TXN      [conn125] transaction parameters:{ lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965415, 11) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:22715, timeActiveMicros:4093043, timeInactiveMicros:1601, 4094ms
2020-05-08T12:16:59.574-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:59.574-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:59.575-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:16:59.576-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.083-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.123-0700 I  NETWORK  [conn132] end connection 192.168.122.1:59086 (21 connections now open)
2020-05-08T12:17:00.124-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59342 #136 (22 connections now open)
2020-05-08T12:17:00.124-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59344 #137 (23 connections now open)
2020-05-08T12:17:00.124-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.1:59342 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:00.125-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.1:59344 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:00.241-0700 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("b795c64d-b425-45e2-b831-a11ca69cbcf2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965415, 29) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1835096, timeActiveMicros:5116757, timeInactiveMicros:1908, 5118ms
2020-05-08T12:17:00.244-0700 I  NETWORK  [conn131] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:00.244-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:00.244-0700 I  COMMAND  [conn134] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d36049de-bb3f-424b-ad56-bd69d56bc8e2") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:375 protocol:op_msg 3173ms
2020-05-08T12:17:00.247-0700 I  NETWORK  [conn134] end connection 192.168.122.1:59208 (22 connections now open)
2020-05-08T12:17:00.247-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59350 #138 (23 connections now open)
2020-05-08T12:17:00.248-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.1:59350 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:00.249-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:00.574-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:00.737-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n8:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:00.744-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:00.933-0700 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 188), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") }, txnNumber: 56, autocommit: false } numYields:0 reslen:321 protocol:op_msg 425ms
2020-05-08T12:17:01.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:01.116-0700 I  NETWORK  [conn125] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:01.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.244-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.346-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.575-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:01.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:01.745-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:01.874-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n8:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:02.070-0700 I  NETWORK  [conn135] end connection 192.168.122.1:59212 (22 connections now open)
2020-05-08T12:17:02.070-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59424 #139 (23 connections now open)
2020-05-08T12:17:02.070-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59426 #140 (24 connections now open)
2020-05-08T12:17:02.070-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:59424 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:02.070-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.1:59426 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:02.072-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:02.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:02.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:02.244-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:02.574-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:02.744-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:02.744-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:02.745-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:02.746-0700 I  COMMAND  [conn131] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965418, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b795c64d-b425-45e2-b831-a11ca69cbcf2") }, txnNumber: 5, autocommit: false } numYields:0 reslen:493 protocol:op_msg 4339ms
2020-05-08T12:17:02.746-0700 I  NETWORK  [conn131] end connection 192.168.122.1:59084 (23 connections now open)
2020-05-08T12:17:02.825-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:03.074-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:03.117-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.118-0700 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:03.119-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:03.120-0700 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 196), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") }, txnNumber: 57, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2182ms
2020-05-08T12:17:03.120-0700 I  TXN      [conn136] transaction parameters:{ lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965420, 189) } }, globalReadTimestamp:{ ts: Timestamp(1588965420, 189) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2608127, timeInactiveMicros:0, 2608ms
2020-05-08T12:17:03.120-0700 I  COMMAND  [conn136] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 189), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965420, 189) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2608ms
2020-05-08T12:17:03.257-0700 I  COMMAND  [conn138] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 77), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d36049de-bb3f-424b-ad56-bd69d56bc8e2") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3007ms
2020-05-08T12:17:03.257-0700 I  NETWORK  [conn138] end connection 192.168.122.1:59350 (22 connections now open)
2020-05-08T12:17:03.574-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:04.074-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:04.075-0700 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:04.075-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T12:17:04.159-0700 I  NETWORK  [conn128] end connection 192.168.122.1:58772 (21 connections now open)
2020-05-08T12:17:04.160-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59588 #147 (22 connections now open)
2020-05-08T12:17:04.160-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59590 #148 (23 connections now open)
2020-05-08T12:17:04.161-0700 I  NETWORK  [conn147] received client metadata from 192.168.122.1:59588 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:04.161-0700 I  NETWORK  [conn148] received client metadata from 192.168.122.1:59590 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:04.365-0700 I  COMMAND  [conn139] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467373ff-1485-4840-99b8-e862e469af2f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2293ms
2020-05-08T12:17:04.366-0700 I  COMMAND  [conn136] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872") }, txnNumber: 20, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1243ms
2020-05-08T12:17:04.367-0700 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e600cce5-87bb-4d8e-84dc-2d8d05c52f25") }, txnNumber: 57, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1246ms
2020-05-08T12:17:04.368-0700 I  NETWORK  [conn125] end connection 192.168.122.1:58762 (22 connections now open)
2020-05-08T12:17:04.368-0700 I  COMMAND  [conn147] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 176 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("69073d12-d7bf-481e-aa13-de0cf63469a7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 205ms
2020-05-08T12:17:04.370-0700 I  NETWORK  [conn139] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:04.371-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.373-0700 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("69073d12-d7bf-481e-aa13-de0cf63469a7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:209351, timeInactiveMicros:713, 210ms
2020-05-08T12:17:04.390-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.457-0700 I  NETWORK  [conn147] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:04.765-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965412, 1), t: 16 }, now { ts: Timestamp(1588965424, 57), t: 18 }
2020-05-08T12:17:04.871-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:04.900-0700 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(1588965412, 1), t: 16 }. :: caused by :: operation was interrupted
2020-05-08T12:17:05.371-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:05.871-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:06.371-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:06.870-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:06.871-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:06.872-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:06.873-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:07.177-0700 I  NETWORK  [conn147] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:07.297-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.373-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:07.382-0700 I  COMMAND  [conn139] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 2, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467373ff-1485-4840-99b8-e862e469af2f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3014ms
2020-05-08T12:17:07.385-0700 I  TXN      [conn136] transaction parameters:{ lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 21) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2995874, timeInactiveMicros:0, 2995ms
2020-05-08T12:17:07.385-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.385-0700 I  COMMAND  [conn136] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872") }, txnNumber: 22, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2996ms
2020-05-08T12:17:07.411-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.679-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.679-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.680-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:07.680-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:07.681-0700 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965424, 56), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("69073d12-d7bf-481e-aa13-de0cf63469a7") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3227ms
2020-05-08T12:17:07.681-0700 I  COMMAND  [conn136] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 177 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965427, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872") }, txnNumber: 23, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:328 protocol:op_msg 270ms
2020-05-08T12:17:07.992-0700 I  COMMAND  [conn139] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 180 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965426, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467373ff-1485-4840-99b8-e862e469af2f") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 608ms
2020-05-08T12:17:07.993-0700 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965427, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("69073d12-d7bf-481e-aa13-de0cf63469a7") }, txnNumber: 5, autocommit: false } numYields:0 reslen:396 protocol:op_msg 310ms
2020-05-08T12:17:07.999-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:17:08.020-0700 I  TXN      [conn139] transaction parameters:{ lsid: { id: UUID("467373ff-1485-4840-99b8-e862e469af2f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965427, 2) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:21776, timeActiveMicros:634778, timeInactiveMicros:1644, 636ms
2020-05-08T12:17:08.048-0700 I  TXN      [conn136] transaction parameters:{ lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965427, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588965427, 8) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:365661, timeActiveMicros:638888, timeInactiveMicros:2217, 641ms
2020-05-08T12:17:08.048-0700 I  COMMAND  [conn136] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965427, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872") }, txnNumber: 23, autocommit: false } numYields:0 reslen:214 protocol:op_msg 365ms
2020-05-08T12:17:08.505-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965424, 57), t: 18 }, now { ts: Timestamp(1588965427, 1), t: 20 }
2020-05-08T12:17:08.716-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n4:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:09.161-0700 I  NETWORK  [conn148] end connection 192.168.122.1:59590 (21 connections now open)
2020-05-08T12:17:09.163-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59784 #150 (22 connections now open)
2020-05-08T12:17:09.163-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59786 #151 (23 connections now open)
2020-05-08T12:17:09.163-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.1:59784 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:09.164-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.1:59786 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:09.341-0700 I  NETWORK  [conn150] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:10.177-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:10.341-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:10.342-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:10.343-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:10.343-0700 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965428, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("69073d12-d7bf-481e-aa13-de0cf63469a7") }, txnNumber: 13, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2009ms
2020-05-08T12:17:10.344-0700 I  COMMAND  [conn139] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965428, 192), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467373ff-1485-4840-99b8-e862e469af2f") }, txnNumber: 11, autocommit: false } numYields:0 reslen:470 protocol:op_msg 2000ms
2020-05-08T12:17:10.344-0700 I  NETWORK  [conn147] end connection 192.168.122.1:59588 (22 connections now open)
2020-05-08T12:17:10.344-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:10.844-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:10.845-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:11.839-0700 I  NETWORK  [conn150] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:12.673-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:12.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:12.908-0700 I  NETWORK  [conn136] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:12.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:12.919-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965427, 1), t: 20 }, now { ts: Timestamp(1588965430, 9), t: 22 }
2020-05-08T12:17:12.930-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.051-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n2:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:13.254-0700 I  NETWORK  [conn140] end connection 192.168.122.1:59426 (21 connections now open)
2020-05-08T12:17:13.255-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59904 #152 (22 connections now open)
2020-05-08T12:17:13.255-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59906 #153 (23 connections now open)
2020-05-08T12:17:13.256-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:59904 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.256-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:59906 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.259-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.340-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.363-0700 I  NETWORK  [conn137] end connection 192.168.122.1:59344 (22 connections now open)
2020-05-08T12:17:13.364-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59948 #154 (23 connections now open)
2020-05-08T12:17:13.365-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59950 #155 (24 connections now open)
2020-05-08T12:17:13.365-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.1:59948 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.365-0700 I  NETWORK  [conn155] received client metadata from 192.168.122.1:59950 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:13.368-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:13.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:13.606-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdbf50ef7b0538edfc4; invalidating user cache
2020-05-08T12:17:13.841-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:13.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.164-0700 I  NETWORK  [conn151] end connection 192.168.122.1:59786 (23 connections now open)
2020-05-08T12:17:14.165-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59964 #156 (24 connections now open)
2020-05-08T12:17:14.165-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59966 #157 (25 connections now open)
2020-05-08T12:17:14.165-0700 I  NETWORK  [conn156] received client metadata from 192.168.122.1:59964 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:14.166-0700 I  NETWORK  [conn157] received client metadata from 192.168.122.1:59966 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:14.169-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.186-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.186-0700 I  COMMAND  [conn150] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965429, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e85316b4-7035-423a-aac9-56ff9e761d44") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5013ms
2020-05-08T12:17:14.186-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.186-0700 I  NETWORK  [conn150] end connection 192.168.122.1:59784 (24 connections now open)
2020-05-08T12:17:14.186-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.188-0700 I  COMMAND  [conn139] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("467373ff-1485-4840-99b8-e862e469af2f") }, txnNumber: 11, autocommit: false } numYields:0 reslen:545 protocol:op_msg 3842ms
2020-05-08T12:17:14.189-0700 I  NETWORK  [conn139] end connection 192.168.122.1:59424 (23 connections now open)
2020-05-08T12:17:14.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:14.905-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:14.906-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:14.906-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:14.909-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:15.366-0700 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("4e4bfb9b-8904-431c-9e37-2fdf00177386"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2108706, timeInactiveMicros:0, 2108ms
2020-05-08T12:17:15.366-0700 I  COMMAND  [conn152] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4e4bfb9b-8904-431c-9e37-2fdf00177386") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2108ms
2020-05-08T12:17:15.409-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:15.857-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965433, 8), t: 22 }, now { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T12:17:15.909-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:15.910-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:15.910-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:17:15.911-0700 I  COMMAND  [conn136] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba7233e5-1cee-46eb-8ba9-d6f2e9a87872") }, txnNumber: 153, autocommit: false } numYields:0 reslen:440 protocol:op_msg 5760ms
2020-05-08T12:17:15.911-0700 I  NETWORK  [conn136] end connection 192.168.122.1:59342 (22 connections now open)
2020-05-08T12:17:16.821-0700 I  TXN      [conn154] transaction parameters:{ lsid: { id: UUID("f25e63d5-1b22-4954-a00d-ea5a7fe3c063"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3454170, timeInactiveMicros:0, 3454ms
2020-05-08T12:17:16.821-0700 I  TXN      [conn156] transaction parameters:{ lsid: { id: UUID("4a5f73ff-8b7c-4996-b8b4-fd8a8c169d29"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2653284, timeInactiveMicros:0, 2653ms
2020-05-08T12:17:16.821-0700 I  COMMAND  [conn154] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f25e63d5-1b22-4954-a00d-ea5a7fe3c063") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 3454ms
2020-05-08T12:17:16.821-0700 I  COMMAND  [conn156] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a5f73ff-8b7c-4996-b8b4-fd8a8c169d29") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2653ms
2020-05-08T12:17:17.819-0700 I  NETWORK  [conn154] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:17.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.256-0700 I  NETWORK  [conn153] end connection 192.168.122.1:59906 (21 connections now open)
2020-05-08T12:17:18.257-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60104 #159 (22 connections now open)
2020-05-08T12:17:18.257-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60106 #160 (23 connections now open)
2020-05-08T12:17:18.257-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.1:60104 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:18.257-0700 I  NETWORK  [conn160] received client metadata from 192.168.122.1:60106 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:18.261-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.263-0700 I  NETWORK  [conn152] end connection 192.168.122.1:59904 (22 connections now open)
2020-05-08T12:17:18.319-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.364-0700 I  NETWORK  [conn155] end connection 192.168.122.1:59950 (21 connections now open)
2020-05-08T12:17:18.365-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60144 #161 (22 connections now open)
2020-05-08T12:17:18.365-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60146 #162 (23 connections now open)
2020-05-08T12:17:18.365-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.1:60144 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:18.365-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.1:60146 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:18.366-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:18.819-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:18.820-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:18.820-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T12:17:18.821-0700 I  COMMAND  [conn156] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a5f73ff-8b7c-4996-b8b4-fd8a8c169d29") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1999ms
2020-05-08T12:17:18.821-0700 I  COMMAND  [conn154] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f25e63d5-1b22-4954-a00d-ea5a7fe3c063") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1999ms
2020-05-08T12:17:18.822-0700 I  NETWORK  [conn154] end connection 192.168.122.1:59948 (22 connections now open)
2020-05-08T12:17:18.822-0700 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 2 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965438, 54), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2280ae00-a7e5-41b6-a7b3-82df6dc58486") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:299 protocol:op_msg 456ms
2020-05-08T12:17:18.827-0700 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 199 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965438, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e43a8f4-d806-49ce-b9bf-e5944c73ef62") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 566ms
2020-05-08T12:17:18.861-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:18.863-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:18.918-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n7:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T12:17:19.166-0700 I  NETWORK  [conn157] end connection 192.168.122.1:59966 (21 connections now open)
2020-05-08T12:17:19.166-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60184 #165 (22 connections now open)
2020-05-08T12:17:19.166-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60182 #166 (23 connections now open)
2020-05-08T12:17:19.166-0700 I  NETWORK  [conn165] received client metadata from 192.168.122.1:60184 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:19.167-0700 I  NETWORK  [conn166] received client metadata from 192.168.122.1:60182 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:19.180-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n7:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:19.363-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:19.715-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:19.862-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.052-0700 I  COMMAND  [conn156] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965438, 125), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a5f73ff-8b7c-4996-b8b4-fd8a8c169d29") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1229ms
2020-05-08T12:17:20.052-0700 I  NETWORK  [conn156] end connection 192.168.122.1:59964 (22 connections now open)
2020-05-08T12:17:20.075-0700 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("2280ae00-a7e5-41b6-a7b3-82df6dc58486"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965438, 150) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:1146612, timeActiveMicros:1152850, timeInactiveMicros:819, 1153ms
2020-05-08T12:17:20.075-0700 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("74f6bdcd-3cce-46d4-b4e3-294f5c74c569"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965439, 33) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:860902, timeActiveMicros:868835, timeInactiveMicros:875, 869ms
2020-05-08T12:17:20.075-0700 I  COMMAND  [conn161] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965438, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2280ae00-a7e5-41b6-a7b3-82df6dc58486") }, txnNumber: 7, autocommit: false } numYields:0 reslen:183 protocol:op_msg 1146ms
2020-05-08T12:17:20.075-0700 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("0e43a8f4-d806-49ce-b9bf-e5944c73ef62"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965438, 52) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:1247611, timeActiveMicros:1815880, timeInactiveMicros:953, 1816ms
2020-05-08T12:17:20.075-0700 I  COMMAND  [conn166] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965439, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("74f6bdcd-3cce-46d4-b4e3-294f5c74c569") }, txnNumber: 3, autocommit: false } numYields:0 reslen:214 protocol:op_msg 861ms
2020-05-08T12:17:20.075-0700 I  COMMAND  [conn159] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965438, 129), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e43a8f4-d806-49ce-b9bf-e5944c73ef62") }, txnNumber: 1, autocommit: false } numYields:0 reslen:183 protocol:op_msg 1247ms
2020-05-08T12:17:20.150-0700 I  NETWORK  [conn159] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:20.150-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:20.199-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:20.199-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:20.200-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.362-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:20.862-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:21.062-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n4:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:21.362-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:21.363-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:22.318-0700 I  NETWORK  [conn166] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:22.319-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:22.512-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:22.515-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:22.517-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:22.518-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:22.746-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n4:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T12:17:22.819-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:23.014-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:23.320-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:23.320-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:23.321-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:23.513-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:24.013-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:24.319-0700 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("74f6bdcd-3cce-46d4-b4e3-294f5c74c569"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 89) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:4116451, timeActiveMicros:4121411, timeInactiveMicros:2093, 4123ms
2020-05-08T12:17:24.320-0700 I  NETWORK  [conn166] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:24.321-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:24.470-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:17:24.513-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:24.513-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:24.514-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T12:17:24.821-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:25.020-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.020-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.023-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.024-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.102-0700 I  NETWORK  [conn160] end connection 192.168.122.1:60106 (21 connections now open)
2020-05-08T12:17:25.102-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60392 #171 (22 connections now open)
2020-05-08T12:17:25.103-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60394 #172 (23 connections now open)
2020-05-08T12:17:25.103-0700 I  NETWORK  [conn171] received client metadata from 192.168.122.1:60392 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.103-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.1:60394 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.118-0700 I  NETWORK  [conn162] end connection 192.168.122.1:60146 (22 connections now open)
2020-05-08T12:17:25.119-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60398 #173 (23 connections now open)
2020-05-08T12:17:25.119-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60400 #174 (24 connections now open)
2020-05-08T12:17:25.119-0700 I  NETWORK  [conn173] received client metadata from 192.168.122.1:60398 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.120-0700 I  NETWORK  [conn174] received client metadata from 192.168.122.1:60400 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.122-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:25.122-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:25.124-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.196-0700 I  NETWORK  [conn165] end connection 192.168.122.1:60184 (23 connections now open)
2020-05-08T12:17:25.197-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60448 #175 (24 connections now open)
2020-05-08T12:17:25.197-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60450 #176 (25 connections now open)
2020-05-08T12:17:25.197-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.1:60448 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.197-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.1:60450 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.199-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:25.213-0700 I  CONNPOOL [conn166] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:25.214-0700 I  COMMAND  [conn166] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("74f6bdcd-3cce-46d4-b4e3-294f5c74c569") }, txnNumber: 8, autocommit: false } numYields:0 reslen:493 protocol:op_msg 5010ms
2020-05-08T12:17:25.214-0700 I  NETWORK  [conn166] end connection 192.168.122.1:60182 (24 connections now open)
2020-05-08T12:17:25.522-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:25.863-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:26.022-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:26.522-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:26.989-0700 I  COMMAND  [conn173] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 210 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a67cfc9a-fb04-4202-8e24-dedad163aa0b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1868ms
2020-05-08T12:17:26.990-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:27.022-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:27.470-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:17:27.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:17:27.522-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:27.522-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:27.560-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.561-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:27.561-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:27.561-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:28.022-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:28.522-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:28.522-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:29.007-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965434, 11), t: 23 }, now { ts: Timestamp(1588965448, 18), t: 28 }
2020-05-08T12:17:30.103-0700 I  NETWORK  [conn172] end connection 192.168.122.1:60394 (23 connections now open)
2020-05-08T12:17:30.103-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60700 #181 (24 connections now open)
2020-05-08T12:17:30.104-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60702 #182 (25 connections now open)
2020-05-08T12:17:30.104-0700 I  NETWORK  [conn181] received client metadata from 192.168.122.1:60700 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.104-0700 I  NETWORK  [conn182] received client metadata from 192.168.122.1:60702 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.105-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:30.109-0700 I  -        [conn171] operation was interrupted because a client disconnected
2020-05-08T12:17:30.109-0700 I  CONNPOOL [conn171] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T12:17:30.109-0700 I  COMMAND  [conn171] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f27b992-cc4a-443c-b756-fe13abd0b0bb") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:17:30.110-0700 I  NETWORK  [conn171] end connection 192.168.122.1:60392 (24 connections now open)
2020-05-08T12:17:30.119-0700 I  NETWORK  [conn174] end connection 192.168.122.1:60400 (23 connections now open)
2020-05-08T12:17:30.120-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60706 #183 (24 connections now open)
2020-05-08T12:17:30.120-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60708 #184 (25 connections now open)
2020-05-08T12:17:30.120-0700 I  NETWORK  [conn183] received client metadata from 192.168.122.1:60706 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.120-0700 I  NETWORK  [conn184] received client metadata from 192.168.122.1:60708 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.197-0700 I  NETWORK  [conn176] end connection 192.168.122.1:60450 (24 connections now open)
2020-05-08T12:17:30.197-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60748 #185 (25 connections now open)
2020-05-08T12:17:30.198-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60750 #186 (26 connections now open)
2020-05-08T12:17:30.198-0700 I  NETWORK  [conn185] received client metadata from 192.168.122.1:60748 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.198-0700 I  NETWORK  [conn186] received client metadata from 192.168.122.1:60750 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:30.204-0700 I  -        [conn175] operation was interrupted because a client disconnected
2020-05-08T12:17:30.204-0700 I  CONNPOOL [conn175] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:30.204-0700 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("17c7a901-f1a8-4547-a09b-21d819e32d91"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965445, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005452, timeInactiveMicros:0, 5005ms
2020-05-08T12:17:30.204-0700 I  COMMAND  [conn175] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965445, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("17c7a901-f1a8-4547-a09b-21d819e32d91") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T12:17:30.205-0700 I  NETWORK  [conn175] end connection 192.168.122.1:60448 (25 connections now open)
2020-05-08T12:17:30.470-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T12:17:30.471-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T12:17:31.995-0700 I  -        [conn173] operation was interrupted because a client disconnected
2020-05-08T12:17:31.995-0700 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("a67cfc9a-fb04-4202-8e24-dedad163aa0b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965444, 5) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:6874131, timeInactiveMicros:441, 6874ms
2020-05-08T12:17:31.996-0700 I  COMMAND  [conn173] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965446, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a67cfc9a-fb04-4202-8e24-dedad163aa0b") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:17:31.996-0700 I  NETWORK  [conn173] end connection 192.168.122.1:60398 (24 connections now open)
2020-05-08T12:17:33.154-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:34.381-0700 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T12:17:35.104-0700 I  NETWORK  [conn182] end connection 192.168.122.1:60702 (23 connections now open)
2020-05-08T12:17:35.105-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60966 #192 (24 connections now open)
2020-05-08T12:17:35.105-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60968 #193 (25 connections now open)
2020-05-08T12:17:35.105-0700 I  NETWORK  [conn192] received client metadata from 192.168.122.1:60966 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.105-0700 I  NETWORK  [conn193] received client metadata from 192.168.122.1:60968 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.108-0700 I  NETWORK  [conn192] Marking host n9:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T12:17:35.109-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:35.110-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:35.110-0700 I  -        [conn181] operation was interrupted because a client disconnected
2020-05-08T12:17:35.110-0700 I  CONNPOOL [conn181] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:35.110-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:35.111-0700 I  TXN      [conn181] transaction parameters:{ lsid: { id: UUID("d3d32994-5212-4294-adc5-df91c584c654"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965448, 18) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005819, timeInactiveMicros:0, 5005ms
2020-05-08T12:17:35.111-0700 I  COMMAND  [conn181] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 216 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3d32994-5212-4294-adc5-df91c584c654") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T12:17:35.111-0700 I  NETWORK  [conn181] end connection 192.168.122.1:60700 (24 connections now open)
2020-05-08T12:17:35.111-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:35.112-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:35.113-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965448, 18), t: 28 }, now { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T12:17:35.121-0700 I  NETWORK  [conn184] end connection 192.168.122.1:60708 (23 connections now open)
2020-05-08T12:17:35.121-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60970 #194 (24 connections now open)
2020-05-08T12:17:35.121-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60972 #195 (25 connections now open)
2020-05-08T12:17:35.122-0700 I  NETWORK  [conn194] received client metadata from 192.168.122.1:60970 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.122-0700 I  NETWORK  [conn195] received client metadata from 192.168.122.1:60972 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.125-0700 I  -        [conn183] operation was interrupted because a client disconnected
2020-05-08T12:17:35.125-0700 I  CONNPOOL [conn183] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T12:17:35.125-0700 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("58f7fe96-62ba-4a44-b098-30d986a2ee72"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965448, 18) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004141, timeInactiveMicros:0, 5004ms
2020-05-08T12:17:35.125-0700 I  COMMAND  [conn183] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 217 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58f7fe96-62ba-4a44-b098-30d986a2ee72") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:35.126-0700 I  NETWORK  [conn183] end connection 192.168.122.1:60706 (24 connections now open)
2020-05-08T12:17:35.198-0700 I  NETWORK  [conn186] end connection 192.168.122.1:60750 (23 connections now open)
2020-05-08T12:17:35.199-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32778 #196 (24 connections now open)
2020-05-08T12:17:35.199-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32780 #197 (25 connections now open)
2020-05-08T12:17:35.200-0700 I  NETWORK  [conn196] received client metadata from 192.168.122.1:32778 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.200-0700 I  NETWORK  [conn197] received client metadata from 192.168.122.1:32780 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.201-0700 I  -        [conn185] operation was interrupted because a client disconnected
2020-05-08T12:17:35.201-0700 I  CONNPOOL [conn185] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T12:17:35.201-0700 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("ec28436c-067c-4759-926b-df75124de179"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965448, 18) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002414, timeInactiveMicros:0, 5002ms
2020-05-08T12:17:35.201-0700 I  COMMAND  [conn185] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 216 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965448, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ec28436c-067c-4759-926b-df75124de179") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T12:17:35.202-0700 I  NETWORK  [conn185] end connection 192.168.122.1:60748 (24 connections now open)
2020-05-08T12:17:35.524-0700 I  COMMAND  [conn194] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 221 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 401ms
2020-05-08T12:17:35.524-0700 I  COMMAND  [conn192] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("72c93f2a-87a1-431c-9fee-174dfd3b5fd9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 412ms
2020-05-08T12:17:35.525-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:35.525-0700 I  TXN      [conn196] transaction parameters:{ lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965453, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:318919, timeInactiveMicros:0, 318ms
2020-05-08T12:17:35.525-0700 I  COMMAND  [conn196] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 319ms
2020-05-08T12:17:35.527-0700 I  TXN      [conn194] transaction parameters:{ lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965453, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:403106, timeInactiveMicros:745, 403ms
2020-05-08T12:17:35.611-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:35.613-0700 I  NETWORK  [conn194] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:35.614-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:36.114-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:36.115-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:36.116-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:36.116-0700 I  COMMAND  [conn194] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 588ms
2020-05-08T12:17:36.116-0700 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 590ms
2020-05-08T12:17:36.615-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:36.648-0700 I  NETWORK  [conn196] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:36.649-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:37.115-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:37.149-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:37.615-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:37.649-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:37.649-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:37.650-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:37.650-0700 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965455, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1532ms
2020-05-08T12:17:37.650-0700 I  COMMAND  [conn194] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965455, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 1532ms
2020-05-08T12:17:38.115-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:38.616-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:38.663-0700 I  COMMAND  [conn194] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 221 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965457, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965457, 1) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1010ms
2020-05-08T12:17:38.663-0700 I  COMMAND  [conn196] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965457, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965457, 1) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1011ms
2020-05-08T12:17:38.666-0700 I  TXN      [conn194] transaction parameters:{ lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965457, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588965457, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1013452, timeInactiveMicros:784, 1014ms
2020-05-08T12:17:38.668-0700 I  TXN      [conn196] transaction parameters:{ lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965457, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588965457, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1015060, timeInactiveMicros:1521, 1016ms
2020-05-08T12:17:39.011-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:39.035-0700 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965458, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 11, autocommit: false } numYields:0 reslen:321 protocol:op_msg 210ms
2020-05-08T12:17:39.035-0700 I  COMMAND  [conn194] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965458, 46), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 10, autocommit: false } numYields:0 reslen:352 protocol:op_msg 207ms
2020-05-08T12:17:39.116-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:39.338-0700 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965459, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 17, autocommit: false } numYields:0 reslen:321 protocol:op_msg 217ms
2020-05-08T12:17:39.348-0700 I  COMMAND  [conn194] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965459, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 16, autocommit: false } numYields:0 reslen:352 protocol:op_msg 218ms
2020-05-08T12:17:39.615-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:39.864-0700 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965459, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("59ad3cd7-671b-4023-863f-75763ce1fe44") }, txnNumber: 24, autocommit: false } numYields:0 reslen:321 protocol:op_msg 422ms
2020-05-08T12:17:39.872-0700 I  COMMAND  [conn194] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965459, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("87b60888-d464-475f-92f0-0de71590ea43") }, txnNumber: 22, autocommit: false } numYields:0 reslen:352 protocol:op_msg 424ms
2020-05-08T12:17:40.112-0700 I  NETWORK  [conn193] end connection 192.168.122.1:60968 (23 connections now open)
2020-05-08T12:17:40.112-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33054 #199 (24 connections now open)
2020-05-08T12:17:40.113-0700 I  NETWORK  [conn199] received client metadata from 192.168.122.1:33054 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.113-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33056 #200 (25 connections now open)
2020-05-08T12:17:40.113-0700 I  NETWORK  [conn200] received client metadata from 192.168.122.1:33056 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.114-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T12:17:40.115-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:40.122-0700 I  NETWORK  [conn195] end connection 192.168.122.1:60972 (24 connections now open)
2020-05-08T12:17:40.122-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33062 #201 (25 connections now open)
2020-05-08T12:17:40.122-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33064 #202 (26 connections now open)
2020-05-08T12:17:40.122-0700 I  NETWORK  [conn201] received client metadata from 192.168.122.1:33062 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.123-0700 I  NETWORK  [conn194] end connection 192.168.122.1:60970 (25 connections now open)
2020-05-08T12:17:40.123-0700 I  NETWORK  [conn202] received client metadata from 192.168.122.1:33064 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.207-0700 I  NETWORK  [conn197] end connection 192.168.122.1:32780 (24 connections now open)
2020-05-08T12:17:40.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33094 #203 (25 connections now open)
2020-05-08T12:17:40.208-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33096 #204 (26 connections now open)
2020-05-08T12:17:40.208-0700 I  NETWORK  [conn203] received client metadata from 192.168.122.1:33094 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.208-0700 I  NETWORK  [conn204] received client metadata from 192.168.122.1:33096 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:40.222-0700 I  NETWORK  [conn196] end connection 192.168.122.1:32778 (25 connections now open)
2020-05-08T12:17:40.529-0700 I  -        [conn192] operation was interrupted because a client disconnected
2020-05-08T12:17:40.529-0700 I  CONNPOOL [conn192] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T12:17:40.529-0700 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("72c93f2a-87a1-431c-9fee-174dfd3b5fd9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965453, 12) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5417087, timeInactiveMicros:456, 5417ms
2020-05-08T12:17:40.530-0700 I  COMMAND  [conn192] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 220 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("72c93f2a-87a1-431c-9fee-174dfd3b5fd9") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:40.530-0700 I  NETWORK  [conn192] end connection 192.168.122.1:60966 (24 connections now open)
2020-05-08T12:17:40.615-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:41.115-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:41.303-0700 I  COMMAND  [conn201] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965460, 176), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("22c77775-58bd-4637-ad15-fbb0212e56ad") }, txnNumber: 46, autocommit: false } numYields:0 reslen:321 protocol:op_msg 429ms
2020-05-08T12:17:41.615-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:41.615-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:42.063-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:42.063-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:42.065-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:42.115-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:42.615-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:43.098-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:43.099-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:43.099-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T12:17:43.608-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdbf50ef7b0538edfc4 to 5eb5afdb5861abbf7eec2119; invalidating user cache
2020-05-08T12:17:43.630-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:43.631-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:43.633-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:43.892-0700 I  NETWORK  [conn201] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T12:17:43.893-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:44.083-0700 I  CONNPOOL [ShardRegistry] Ending idle connection to host n6:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T12:17:44.131-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:44.393-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:44.393-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:44.394-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:44.394-0700 I  COMMAND  [conn201] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965462, 167), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("22c77775-58bd-4637-ad15-fbb0212e56ad") }, txnNumber: 145, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1515ms
2020-05-08T12:17:44.631-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:44.753-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.113-0700 I  NETWORK  [conn200] end connection 192.168.122.1:33056 (23 connections now open)
2020-05-08T12:17:45.114-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33336 #211 (24 connections now open)
2020-05-08T12:17:45.114-0700 I  NETWORK  [conn211] received client metadata from 192.168.122.1:33336 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.114-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33338 #212 (25 connections now open)
2020-05-08T12:17:45.115-0700 I  NETWORK  [conn212] received client metadata from 192.168.122.1:33338 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.117-0700 I  -        [conn199] operation was interrupted because a client disconnected
2020-05-08T12:17:45.117-0700 I  CONNPOOL [conn199] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T12:17:45.117-0700 I  TXN      [conn199] transaction parameters:{ lsid: { id: UUID("40cad855-d3d2-4ce6-9259-f223ed2bb919"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965460, 26) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003206, timeInactiveMicros:0, 5003ms
2020-05-08T12:17:45.117-0700 I  COMMAND  [conn199] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 227 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965460, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40cad855-d3d2-4ce6-9259-f223ed2bb919") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T12:17:45.117-0700 I  NETWORK  [conn199] end connection 192.168.122.1:33054 (24 connections now open)
2020-05-08T12:17:45.118-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.123-0700 I  NETWORK  [conn202] end connection 192.168.122.1:33064 (23 connections now open)
2020-05-08T12:17:45.124-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33340 #213 (24 connections now open)
2020-05-08T12:17:45.124-0700 I  NETWORK  [conn213] received client metadata from 192.168.122.1:33340 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.124-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33342 #214 (25 connections now open)
2020-05-08T12:17:45.124-0700 I  NETWORK  [conn214] received client metadata from 192.168.122.1:33342 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.131-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:45.132-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:45.262-0700 I  NETWORK  [conn204] end connection 192.168.122.1:33096 (24 connections now open)
2020-05-08T12:17:45.262-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33384 #215 (25 connections now open)
2020-05-08T12:17:45.263-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33386 #216 (26 connections now open)
2020-05-08T12:17:45.263-0700 I  NETWORK  [conn215] received client metadata from 192.168.122.1:33384 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.263-0700 I  NETWORK  [conn216] received client metadata from 192.168.122.1:33386 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.265-0700 I  -        [conn203] operation was interrupted because a client disconnected
2020-05-08T12:17:45.265-0700 I  CONNPOOL [conn203] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T12:17:45.266-0700 I  TXN      [conn203] transaction parameters:{ lsid: { id: UUID("fea8ef0f-af05-4e2f-9007-ea1b9b66bd9d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965460, 63) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003936, timeInactiveMicros:0, 5003ms
2020-05-08T12:17:45.266-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.266-0700 I  COMMAND  [conn203] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 224 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965460, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fea8ef0f-af05-4e2f-9007-ea1b9b66bd9d") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:45.266-0700 I  NETWORK  [conn203] end connection 192.168.122.1:33094 (25 connections now open)
2020-05-08T12:17:45.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T12:17:45.468-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T12:17:45.656-0700 I  NETWORK  [conn215] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:45.657-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:45.658-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.156-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.199-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:46.199-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:46.202-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:46.202-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:46.465-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:46.657-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:46.699-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:47.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.156-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:47.156-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:47.157-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:47.157-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:47.158-0700 I  COMMAND  [conn201] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("22c77775-58bd-4637-ad15-fbb0212e56ad") }, txnNumber: 145, autocommit: false } numYields:0 reslen:516 protocol:op_msg 2761ms
2020-05-08T12:17:47.158-0700 I  COMMAND  [conn213] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965464, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1423a154-4c53-425d-b382-f9b81610590a") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 2031ms
2020-05-08T12:17:47.158-0700 I  COMMAND  [conn215] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965464, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ed720311-4dda-447b-9d47-29b15d510125") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 1893ms
2020-05-08T12:17:47.158-0700 I  TXN      [conn211] transaction parameters:{ lsid: { id: UUID("24a26328-c79a-4256-aad3-2d204183a687"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965464, 4) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2042123, timeInactiveMicros:0, 2042ms
2020-05-08T12:17:47.158-0700 I  COMMAND  [conn211] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24a26328-c79a-4256-aad3-2d204183a687") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2042ms
2020-05-08T12:17:47.158-0700 I  NETWORK  [conn201] end connection 192.168.122.1:33062 (24 connections now open)
2020-05-08T12:17:47.161-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.189-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.191-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.406-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:47.406-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:47.407-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:47.618-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:47.908-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:48.407-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:48.533-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:48.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:48.907-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:49.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.407-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:49.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:49.907-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:50.114-0700 I  NETWORK  [conn212] end connection 192.168.122.1:33338 (23 connections now open)
2020-05-08T12:17:50.116-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33528 #219 (24 connections now open)
2020-05-08T12:17:50.116-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33530 #220 (25 connections now open)
2020-05-08T12:17:50.116-0700 I  NETWORK  [conn219] received client metadata from 192.168.122.1:33528 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.116-0700 I  NETWORK  [conn220] received client metadata from 192.168.122.1:33530 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:50.117-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.119-0700 I  NETWORK  [conn219] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T12:17:50.120-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:50.124-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:50.125-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:50.131-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:50.407-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:50.907-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:51.408-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:51.907-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T12:17:52.161-0700 I  -        [conn215] operation was interrupted because a client disconnected
2020-05-08T12:17:52.162-0700 I  COMMAND  [conn215] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 233 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965466, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ed720311-4dda-447b-9d47-29b15d510125") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T12:17:52.162-0700 I  NETWORK  [conn215] end connection 192.168.122.1:33384 (24 connections now open)
2020-05-08T12:17:52.194-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33614 #221 (25 connections now open)
2020-05-08T12:17:52.195-0700 I  NETWORK  [conn221] received client metadata from 192.168.122.1:33614 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:52.407-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:52.407-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T12:17:53.338-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965453, 11), t: 29 }, now { ts: Timestamp(1588965471, 2), t: 35 }
2020-05-08T12:17:55.133-0700 I  -        [conn219] operation was interrupted because a client disconnected
2020-05-08T12:17:55.134-0700 I  TXN      [conn219] transaction parameters:{ lsid: { id: UUID("ef284f6a-eb38-42ee-9c9b-9191fade821d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965467, 12) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5014770, timeInactiveMicros:638, 5015ms
2020-05-08T12:17:55.134-0700 I  COMMAND  [conn219] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 232 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965470, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef284f6a-eb38-42ee-9c9b-9191fade821d") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T12:17:55.134-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33648 #222 (26 connections now open)
2020-05-08T12:17:55.134-0700 I  NETWORK  [conn219] end connection 192.168.122.1:33528 (25 connections now open)
2020-05-08T12:17:55.134-0700 I  NETWORK  [conn222] received client metadata from 192.168.122.1:33648 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.245-0700 I  NETWORK  [conn220] end connection 192.168.122.1:33530 (24 connections now open)
2020-05-08T12:17:55.245-0700 I  NETWORK  [conn214] end connection 192.168.122.1:33342 (23 connections now open)
2020-05-08T12:17:55.246-0700 I  NETWORK  [conn216] end connection 192.168.122.1:33386 (22 connections now open)
2020-05-08T12:17:55.252-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33672 #223 (23 connections now open)
2020-05-08T12:17:55.252-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:33676 #224 (24 connections now open)
2020-05-08T12:17:55.252-0700 I  NETWORK  [conn223] received client metadata from 192.168.122.1:33672 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:55.252-0700 I  NETWORK  [conn224] end connection 192.168.122.1:33676 (23 connections now open)
2020-05-08T12:17:55.253-0700 I  NETWORK  [conn223] end connection 192.168.122.1:33672 (22 connections now open)
2020-05-08T12:17:55.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:55.617-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:17:55.617-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:17:55.617-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:55.617-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
