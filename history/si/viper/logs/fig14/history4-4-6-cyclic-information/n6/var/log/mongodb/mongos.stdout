2020-05-08 14:15:41 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T14:15:41.265-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T14:15:41.266-0500 I  CONTROL  [main] 
2020-05-08T14:15:41.266-0500 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T14:15:41.266-0500 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T14:15:41.266-0500 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T14:15:41.266-0500 I  CONTROL  [main] 
2020-05-08T14:15:41.267-0500 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] modules: none
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] build environment:
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T14:15:41.267-0500 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-08T14:15:41.268-0500 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:15:41.268-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-08T14:15:41.269-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-08T14:15:41.269-0500 I  SHARDING [thread1] creating distributed lock ping thread for process n6:27017:1588965341:-562014436095676681 (sleeping for 30000ms)
2020-05-08T14:15:41.269-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-08T14:15:41.270-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:41.769-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:15:41.769-0500 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:15:41.838-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588965340, 4), t: 1 }
2020-05-08T14:15:42.608-0500 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T14:15:42.897-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T14:15:43.842-0500 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T14:15:43.843-0500 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T14:15:43.847-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("c4a29560-278b-46e7-b647-ed111b19e39f"), lastMod: 0 } took 0 ms
2020-05-08T14:15:43.847-0500 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T14:15:43.847-0500 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T14:15:43.847-0500 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T14:15:43.848-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54672 #9 (1 connection now open)
2020-05-08T14:15:43.848-0500 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T14:15:43.848-0500 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T14:15:43.849-0500 I  NETWORK  [conn9] received client metadata from 192.168.122.1:54672 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:43.850-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54682 #10 (2 connections now open)
2020-05-08T14:15:43.850-0500 I  NETWORK  [conn10] received client metadata from 192.168.122.1:54682 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:45.266-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54700 #11 (3 connections now open)
2020-05-08T14:15:45.267-0500 I  NETWORK  [conn11] received client metadata from 192.168.122.1:54700 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:45.378-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54762 #12 (4 connections now open)
2020-05-08T14:15:45.378-0500 I  NETWORK  [conn12] received client metadata from 192.168.122.1:54762 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:45.664-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54898 #13 (5 connections now open)
2020-05-08T14:15:45.665-0500 I  NETWORK  [conn13] received client metadata from 192.168.122.1:54898 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:45.666-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54902 #14 (6 connections now open)
2020-05-08T14:15:45.667-0500 I  NETWORK  [conn14] received client metadata from 192.168.122.1:54902 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:45.744-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54920 #15 (7 connections now open)
2020-05-08T14:15:45.745-0500 I  NETWORK  [conn15] received client metadata from 192.168.122.1:54920 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:46.899-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:54974 #16 (8 connections now open)
2020-05-08T14:15:46.900-0500 I  NETWORK  [conn16] received client metadata from 192.168.122.1:54974 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:48.025-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55034 #17 (9 connections now open)
2020-05-08T14:15:48.025-0500 I  NETWORK  [conn17] received client metadata from 192.168.122.1:55034 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:48.170-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55046 #18 (10 connections now open)
2020-05-08T14:15:48.171-0500 I  NETWORK  [conn18] received client metadata from 192.168.122.1:55046 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:48.789-0500 I  COMMAND  [conn13] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8191e4f2-c2b9-4af1-9481-1737afdaf4ff") } } numYields:0 reslen:163 protocol:op_msg 3118ms
2020-05-08T14:15:48.791-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 1 ms
2020-05-08T14:15:48.794-0500 I  NETWORK  [conn13] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:15:48.794-0500 I  NETWORK  [conn13] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:15:48.794-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T14:15:48.794-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T14:15:48.794-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T14:15:48.794-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-08T14:15:48.794-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-08T14:15:48.794-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-08T14:15:48.830-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:15:48.830-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:15:48.831-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:15:48.831-0500 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:15:48.831-0500 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T14:15:48.863-0500 I  NETWORK  [conn13] end connection 192.168.122.1:54898 (9 connections now open)
2020-05-08T14:15:48.863-0500 I  NETWORK  [conn14] end connection 192.168.122.1:54902 (8 connections now open)
2020-05-08T14:15:48.867-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55098 #26 (9 connections now open)
2020-05-08T14:15:48.867-0500 I  NETWORK  [conn26] received client metadata from 192.168.122.1:55098 conn26: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.465-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55226 #27 (10 connections now open)
2020-05-08T14:15:50.465-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55232 #28 (11 connections now open)
2020-05-08T14:15:50.465-0500 I  NETWORK  [conn27] received client metadata from 192.168.122.1:55226 conn27: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.466-0500 I  NETWORK  [conn28] received client metadata from 192.168.122.1:55232 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.466-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55240 #29 (12 connections now open)
2020-05-08T14:15:50.466-0500 I  NETWORK  [conn29] received client metadata from 192.168.122.1:55240 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.466-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55246 #30 (13 connections now open)
2020-05-08T14:15:50.467-0500 I  NETWORK  [conn30] received client metadata from 192.168.122.1:55246 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.467-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55254 #31 (14 connections now open)
2020-05-08T14:15:50.468-0500 I  NETWORK  [conn31] received client metadata from 192.168.122.1:55254 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.469-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55278 #32 (15 connections now open)
2020-05-08T14:15:50.470-0500 I  NETWORK  [conn32] received client metadata from 192.168.122.1:55278 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.478-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 3 ms
2020-05-08T14:15:50.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:15:50.825-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55404 #37 (16 connections now open)
2020-05-08T14:15:50.826-0500 I  NETWORK  [conn37] received client metadata from 192.168.122.1:55404 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:50.870-0500 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965350, 182) } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 182) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:49671, timeActiveMicros:99319, timeInactiveMicros:1151, 100ms
2020-05-08T14:15:50.873-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T14:15:50.922-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55458 #40 (17 connections now open)
2020-05-08T14:15:50.922-0500 I  NETWORK  [conn40] received client metadata from 192.168.122.1:55458 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:51.116-0500 I  COMMAND  [conn30] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 227), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 9, autocommit: false } numYields:0 reslen:320 protocol:op_msg 231ms
2020-05-08T14:15:51.117-0500 I  COMMAND  [conn27] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 228), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("72f28b2a-42a5-4e26-9cbd-7a8107c8d5ee") }, txnNumber: 9, autocommit: false } numYields:0 reslen:320 protocol:op_msg 232ms
2020-05-08T14:15:51.136-0500 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 222) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:239102, timeActiveMicros:262109, timeInactiveMicros:1285, 263ms
2020-05-08T14:15:51.136-0500 I  COMMAND  [conn29] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965350, 243), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749") }, txnNumber: 7, autocommit: false } numYields:0 reslen:214 protocol:op_msg 239ms
2020-05-08T14:15:51.245-0500 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965350, 256) } }, globalReadTimestamp:{ ts: Timestamp(1588965350, 256) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:114986, timeActiveMicros:126132, timeInactiveMicros:1764, 127ms
2020-05-08T14:15:51.245-0500 I  COMMAND  [conn30] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 115ms
2020-05-08T14:15:51.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:15:51.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:15:51.514-0500 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 126) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:140264, timeActiveMicros:169599, timeInactiveMicros:1131, 170ms
2020-05-08T14:15:51.514-0500 I  COMMAND  [conn30] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 145), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 12, autocommit: false } numYields:0 reslen:214 protocol:op_msg 140ms
2020-05-08T14:15:51.873-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T14:15:51.873-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T14:15:52.003-0500 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 264) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:425651, timeInactiveMicros:0, 425ms
2020-05-08T14:15:52.003-0500 I  COMMAND  [conn30] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965351, 264), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 15, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 425ms
2020-05-08T14:15:52.023-0500 I  COMMAND  [conn27] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965351, 272), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("72f28b2a-42a5-4e26-9cbd-7a8107c8d5ee") }, txnNumber: 21, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 417ms
2020-05-08T14:15:52.071-0500 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965351, 166) } }, globalReadTimestamp:{ ts: Timestamp(1588965351, 166) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:645582, timeActiveMicros:657486, timeInactiveMicros:594, 658ms
2020-05-08T14:15:52.071-0500 I  COMMAND  [conn29] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749") }, txnNumber: 17, autocommit: false } numYields:0 reslen:214 protocol:op_msg 645ms
2020-05-08T14:15:52.400-0500 I  COMMAND  [conn30] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965351, 299), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 15, autocommit: false } numYields:0 reslen:321 protocol:op_msg 397ms
2020-05-08T14:15:52.420-0500 I  COMMAND  [conn29] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749") }, txnNumber: 18, autocommit: false } numYields:0 reslen:321 protocol:op_msg 324ms
2020-05-08T14:15:52.512-0500 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 28) } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 28) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:110490, timeInactiveMicros:0, 110ms
2020-05-08T14:15:52.512-0500 I  COMMAND  [conn30] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 16, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 28) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 110ms
2020-05-08T14:15:53.860-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:15:53.861-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:54.361-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:54.861-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:55.361-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:55.861-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:56.361-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:56.577-0500 I  NETWORK  [conn32] end connection 192.168.122.1:55278 (16 connections now open)
2020-05-08T14:15:56.577-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55880 #50 (17 connections now open)
2020-05-08T14:15:56.577-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55882 #51 (18 connections now open)
2020-05-08T14:15:56.578-0500 I  NETWORK  [conn50] received client metadata from 192.168.122.1:55880 conn50: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:56.578-0500 I  NETWORK  [conn51] received client metadata from 192.168.122.1:55882 conn51: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:56.579-0500 I  NETWORK  [conn50] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:15:56.580-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:56.605-0500 I  NETWORK  [conn28] end connection 192.168.122.1:55232 (17 connections now open)
2020-05-08T14:15:56.606-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55884 #52 (18 connections now open)
2020-05-08T14:15:56.606-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55886 #53 (19 connections now open)
2020-05-08T14:15:56.606-0500 I  NETWORK  [conn52] received client metadata from 192.168.122.1:55884 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:56.606-0500 I  NETWORK  [conn53] received client metadata from 192.168.122.1:55886 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:56.608-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:56.827-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55898 #54 (20 connections now open)
2020-05-08T14:15:56.828-0500 I  NETWORK  [conn54] received client metadata from 192.168.122.1:55898 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:56.860-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:15:57.041-0500 I  CONNPOOL [conn27] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T14:15:57.041-0500 I  COMMAND  [conn27] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965352, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("72f28b2a-42a5-4e26-9cbd-7a8107c8d5ee") }, txnNumber: 21, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5012ms
2020-05-08T14:15:57.041-0500 I  NETWORK  [conn27] end connection 192.168.122.1:55226 (19 connections now open)
2020-05-08T14:15:57.073-0500 I  NETWORK  [conn31] end connection 192.168.122.1:55254 (18 connections now open)
2020-05-08T14:15:57.074-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55964 #55 (19 connections now open)
2020-05-08T14:15:57.074-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:55966 #56 (20 connections now open)
2020-05-08T14:15:57.075-0500 I  NETWORK  [conn55] received client metadata from 192.168.122.1:55964 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:57.075-0500 I  NETWORK  [conn56] received client metadata from 192.168.122.1:55966 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:15:57.077-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:57.079-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:57.361-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:15:57.361-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:15:57.579-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:58.080-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:58.497-0500 I  NETWORK  [conn29] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:15:58.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:15:58.567-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965350, 10), t: 1 }, now { ts: Timestamp(1588965357, 6), t: 4 }
2020-05-08T14:15:58.579-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:15:59.079-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:15:59.079-0500 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:15:59.079-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-08T14:15:59.413-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:15:59.413-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:15:59.415-0500 I  TXN      [conn29] transaction parameters:{ lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965352, 66) } }, globalReadTimestamp:{ ts: Timestamp(1588965352, 66) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6837441, timeInactiveMicros:638, 6838ms
2020-05-08T14:15:59.415-0500 I  COMMAND  [conn29] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965352, 66), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79cf3d98-6eb5-4a14-9cf3-b962e75d5749") }, txnNumber: 20, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 6836ms
2020-05-08T14:15:59.415-0500 I  NETWORK  [conn29] end connection 192.168.122.1:55240 (19 connections now open)
2020-05-08T14:15:59.495-0500 I  COMMAND  [conn50] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 35 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2916ms
2020-05-08T14:15:59.495-0500 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 38 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2887ms
2020-05-08T14:15:59.497-0500 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965354, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2421416, timeInactiveMicros:0, 2421ms
2020-05-08T14:15:59.498-0500 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2421ms
2020-05-08T14:15:59.499-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965354, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2919598, timeInactiveMicros:1112, 2920ms
2020-05-08T14:15:59.499-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965354, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2890977, timeInactiveMicros:1164, 2892ms
2020-05-08T14:15:59.872-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T14:15:59.873-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-08T14:16:00.179-0500 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965359, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 679ms
2020-05-08T14:16:00.179-0500 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965359, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 680ms
2020-05-08T14:16:00.180-0500 I  COMMAND  [conn52] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965359, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 679ms
2020-05-08T14:16:00.215-0500 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T14:16:00.459-0500 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 40 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965360, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 218ms
2020-05-08T14:16:00.462-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 23) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:221009, timeInactiveMicros:774, 221ms
2020-05-08T14:16:00.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:16:00.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:16:00.486-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 29) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:222347, timeInactiveMicros:0, 222ms
2020-05-08T14:16:00.486-0500 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965360, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 222ms
2020-05-08T14:16:00.866-0500 I  TXN      [conn30] transaction parameters:{ lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965354, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588965354, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:6692352, timeInactiveMicros:0, 6692ms
2020-05-08T14:16:00.867-0500 I  COMMAND  [conn30] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965354, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7bdd5bda-82de-4143-b28c-e2b213e771f4") }, txnNumber: 80, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965354, 12) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 6692ms
2020-05-08T14:16:00.867-0500 I  NETWORK  [conn30] end connection 192.168.122.1:55246 (18 connections now open)
2020-05-08T14:16:00.878-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56268 #66 (19 connections now open)
2020-05-08T14:16:00.879-0500 I  NETWORK  [conn66] received client metadata from 192.168.122.1:56268 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:01.879-0500 I  NETWORK  [conn50] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:01.880-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:02.379-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:02.625-0500 I  SHARDING [conn52] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965357, 6), t: 4 }, now { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T14:16:02.625-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965360, 222) } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 222) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1931169, timeActiveMicros:1965580, timeInactiveMicros:1696, 1967ms
2020-05-08T14:16:02.625-0500 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 246), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 9, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1931ms
2020-05-08T14:16:02.672-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:02.672-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:02.672-0500 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T14:16:02.673-0500 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 312), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 11, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1861ms
2020-05-08T14:16:02.674-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:02.675-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:02.675-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:02.696-0500 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965360, 298) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:1897416, timeActiveMicros:1914249, timeInactiveMicros:925, 1915ms
2020-05-08T14:16:02.697-0500 I  COMMAND  [conn55] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965360, 301), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") }, txnNumber: 22, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1898ms
2020-05-08T14:16:02.723-0500 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-08T14:16:02.828-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965362, 81) } }, globalReadTimestamp:{ ts: Timestamp(1588965362, 84) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:140804, timeActiveMicros:152468, timeInactiveMicros:1564, 154ms
2020-05-08T14:16:02.828-0500 I  COMMAND  [conn50] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965362, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 12, autocommit: false } numYields:0 reslen:214 protocol:op_msg 141ms
2020-05-08T14:16:03.125-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965362, 198) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:158063, timeActiveMicros:164806, timeInactiveMicros:598, 165ms
2020-05-08T14:16:03.125-0500 I  COMMAND  [conn50] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965362, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 17, autocommit: false } numYields:0 reslen:214 protocol:op_msg 158ms
2020-05-08T14:16:03.980-0500 I  NETWORK  [conn55] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T14:16:03.982-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:03.982-0500 I  NETWORK  [conn52] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T14:16:03.983-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:04.481-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:04.482-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:04.483-0500 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 320), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 55, autocommit: false } numYields:0 reslen:439 protocol:op_msg 510ms
2020-05-08T14:16:04.495-0500 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 38, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965363, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1197ms
2020-05-08T14:16:04.496-0500 I  COMMAND  [conn52] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965363, 322), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 60, autocommit: false } numYields:0 reslen:397 protocol:op_msg 522ms
2020-05-08T14:16:05.377-0500 I  NETWORK  [conn50] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:05.378-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:05.441-0500 I  NETWORK  [conn55] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:05.442-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:05.878-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:06.378-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:07.089-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:07.378-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:07.379-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:07.380-0500 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 43, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965364, 30) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2814715, timeInactiveMicros:0, 2814ms
2020-05-08T14:16:07.380-0500 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 65 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:299 protocol:op_msg 2846ms
2020-05-08T14:16:07.381-0500 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") }, txnNumber: 43, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 2815ms
2020-05-08T14:16:07.382-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 56, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965364, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588965364, 15) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2878352, timeInactiveMicros:641, 2878ms
2020-05-08T14:16:07.382-0500 I  COMMAND  [conn50] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 3 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965364, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 56, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 78d45b99-379c-4f08-916f-e29158f00ed0:56 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588965364, 15) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 2871ms
2020-05-08T14:16:07.499-0500 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 56, autocommit: false } numYields:0 reslen:352 protocol:op_msg 115ms
2020-05-08T14:16:07.560-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:07.561-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:07.714-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 57, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965367, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 11) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:199208, timeActiveMicros:212902, timeInactiveMicros:1674, 214ms
2020-05-08T14:16:07.714-0500 I  COMMAND  [conn50] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 57, autocommit: false } numYields:0 reslen:214 protocol:op_msg 199ms
2020-05-08T14:16:07.734-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 36) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:41746, timeActiveMicros:117600, timeInactiveMicros:2393, 119ms
2020-05-08T14:16:07.849-0500 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 58, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 49) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:87649, timeActiveMicros:131778, timeInactiveMicros:1212, 132ms
2020-05-08T14:16:08.061-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:08.358-0500 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 59, autocommit: false } numYields:0 reslen:352 protocol:op_msg 473ms
2020-05-08T14:16:08.365-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965367, 63) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:550186, timeActiveMicros:596821, timeInactiveMicros:760, 597ms
2020-05-08T14:16:08.366-0500 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 73), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 70, autocommit: false } numYields:0 reslen:214 protocol:op_msg 551ms
2020-05-08T14:16:08.366-0500 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965367, 90), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") }, txnNumber: 46, autocommit: false } numYields:0 reslen:321 protocol:op_msg 484ms
2020-05-08T14:16:08.525-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 72, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 34) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:68122, timeActiveMicros:117624, timeInactiveMicros:963, 118ms
2020-05-08T14:16:08.561-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:08.571-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:09.027-0500 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 144) } }, globalReadTimestamp:{ ts: Timestamp(1588965368, 146) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:158034, timeActiveMicros:229052, timeInactiveMicros:1216, 230ms
2020-05-08T14:16:09.027-0500 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965368, 165), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") }, txnNumber: 77, autocommit: false } numYields:0 reslen:214 protocol:op_msg 158ms
2020-05-08T14:16:09.061-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:09.061-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:09.566-0500 I  NETWORK  [conn56] end connection 192.168.122.1:55966 (18 connections now open)
2020-05-08T14:16:09.567-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56636 #71 (19 connections now open)
2020-05-08T14:16:09.568-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56638 #72 (20 connections now open)
2020-05-08T14:16:09.568-0500 I  NETWORK  [conn71] received client metadata from 192.168.122.1:56636 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:09.568-0500 I  NETWORK  [conn72] received client metadata from 192.168.122.1:56638 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:09.573-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:09.692-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965361, 1), t: 5 }, now { ts: Timestamp(1588965369, 16), t: 6 }
2020-05-08T14:16:10.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:16:10.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:16:10.882-0500 I  NETWORK  [conn71] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:10.884-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:10.884-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:10.885-0500 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965369, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67543974-9f3e-41d2-9a28-8f1d0b794fc3") }, txnNumber: 53, autocommit: false } numYields:0 reslen:470 protocol:op_msg 1866ms
2020-05-08T14:16:10.885-0500 I  TXN      [conn71] transaction parameters:{ lsid: { id: UUID("406e129c-8f60-40dd-9d72-844d1a796f9d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965369, 28) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1312413, timeInactiveMicros:0, 1312ms
2020-05-08T14:16:10.886-0500 I  COMMAND  [conn71] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965369, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("406e129c-8f60-40dd-9d72-844d1a796f9d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1312ms
2020-05-08T14:16:10.886-0500 I  NETWORK  [conn55] end connection 192.168.122.1:55964 (19 connections now open)
2020-05-08T14:16:10.913-0500 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:11.879-0500 I  NETWORK  [conn52] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:13.380-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:13.394-0500 I  NETWORK  [conn51] end connection 192.168.122.1:55882 (18 connections now open)
2020-05-08T14:16:13.395-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56844 #75 (19 connections now open)
2020-05-08T14:16:13.395-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56846 #76 (20 connections now open)
2020-05-08T14:16:13.395-0500 I  NETWORK  [conn75] received client metadata from 192.168.122.1:56844 conn75: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:13.396-0500 I  NETWORK  [conn76] received client metadata from 192.168.122.1:56846 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:13.846-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdb5861abbf7eec2119; invalidating user cache
2020-05-08T14:16:13.880-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:14.029-0500 I  NETWORK  [conn53] end connection 192.168.122.1:55886 (19 connections now open)
2020-05-08T14:16:14.030-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56956 #77 (20 connections now open)
2020-05-08T14:16:14.030-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56960 #78 (21 connections now open)
2020-05-08T14:16:14.030-0500 I  NETWORK  [conn77] received client metadata from 192.168.122.1:56956 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:14.030-0500 I  NETWORK  [conn78] received client metadata from 192.168.122.1:56960 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:14.380-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:14.380-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:14.382-0500 I  COMMAND  [conn71] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965370, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("406e129c-8f60-40dd-9d72-844d1a796f9d") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3494ms
2020-05-08T14:16:14.574-0500 I  NETWORK  [conn72] end connection 192.168.122.1:56638 (20 connections now open)
2020-05-08T14:16:14.575-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56990 #79 (21 connections now open)
2020-05-08T14:16:14.575-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:56992 #80 (22 connections now open)
2020-05-08T14:16:14.575-0500 I  NETWORK  [conn79] received client metadata from 192.168.122.1:56990 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:14.576-0500 I  NETWORK  [conn80] received client metadata from 192.168.122.1:56992 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:15.713-0500 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965368, 201), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78d45b99-379c-4f08-916f-e29158f00ed0") }, txnNumber: 67, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965368, 201) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 6705ms
2020-05-08T14:16:15.713-0500 I  NETWORK  [conn50] end connection 192.168.122.1:55880 (21 connections now open)
2020-05-08T14:16:17.025-0500 I  NETWORK  [conn52] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:17.026-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:17.949-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:18.025-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:18.396-0500 I  NETWORK  [conn76] end connection 192.168.122.1:56846 (20 connections now open)
2020-05-08T14:16:18.397-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57112 #82 (21 connections now open)
2020-05-08T14:16:18.397-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57114 #83 (22 connections now open)
2020-05-08T14:16:18.397-0500 I  NETWORK  [conn82] received client metadata from 192.168.122.1:57112 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:18.397-0500 I  NETWORK  [conn83] received client metadata from 192.168.122.1:57114 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:18.399-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-08T14:16:18.401-0500 I  -        [conn75] operation was interrupted because a client disconnected
2020-05-08T14:16:18.401-0500 I  CONNPOOL [conn75] Ending connection to host n7:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T14:16:18.402-0500 I  TXN      [conn75] transaction parameters:{ lsid: { id: UUID("1eca8da6-760e-472a-8bc4-0198f9590d2c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965373, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004755, timeInactiveMicros:0, 5004ms
2020-05-08T14:16:18.402-0500 I  COMMAND  [conn75] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 91 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1eca8da6-760e-472a-8bc4-0198f9590d2c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T14:16:18.402-0500 I  NETWORK  [conn75] end connection 192.168.122.1:56844 (21 connections now open)
2020-05-08T14:16:18.525-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:18.526-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:18.527-0500 I  COMMAND  [conn71] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965374, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("406e129c-8f60-40dd-9d72-844d1a796f9d") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 4143ms
2020-05-08T14:16:18.528-0500 I  NETWORK  [conn71] end connection 192.168.122.1:56636 (20 connections now open)
2020-05-08T14:16:18.733-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:18.734-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:18.898-0500 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 78, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965369, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("66b16b20-4039-4603-85b8-78e065b29b58") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 9869ms
2020-05-08T14:16:18.898-0500 I  NETWORK  [conn52] end connection 192.168.122.1:55884 (19 connections now open)
2020-05-08T14:16:18.913-0500 I  COMMAND  [conn82] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 90 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965376, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 514ms
2020-05-08T14:16:18.913-0500 I  COMMAND  [conn79] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 90 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965374, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4336ms
2020-05-08T14:16:18.916-0500 I  COMMAND  [conn77] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 95 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965373, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4884ms
2020-05-08T14:16:18.918-0500 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965376, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:519104, timeInactiveMicros:440, 519ms
2020-05-08T14:16:18.951-0500 I  TXN      [conn77] transaction parameters:{ lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965373, 1) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:32471, timeActiveMicros:4918533, timeInactiveMicros:1035, 4919ms
2020-05-08T14:16:18.951-0500 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965374, 2) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:36268, timeActiveMicros:4373108, timeInactiveMicros:883, 4373ms
2020-05-08T14:16:19.234-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:19.698-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:19.698-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:19.699-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965373, 1), t: 6 }, now { ts: Timestamp(1588965379, 2), t: 9 }
2020-05-08T14:16:20.901-0500 I  NETWORK  [conn82] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:20.902-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:20.902-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:20.903-0500 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965379, 156) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1669702, timeInactiveMicros:422, 1670ms
2020-05-08T14:16:20.904-0500 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965379, 157), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646") }, txnNumber: 9, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1664ms
2020-05-08T14:16:21.058-0500 I  COMMAND  [conn79] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 141), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5") }, txnNumber: 6, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1852ms
2020-05-08T14:16:21.062-0500 I  COMMAND  [conn77] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965379, 141), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09") }, txnNumber: 7, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1855ms
2020-05-08T14:16:21.253-0500 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 77) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 78) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:123859, timeActiveMicros:136147, timeInactiveMicros:947, 137ms
2020-05-08T14:16:21.253-0500 I  COMMAND  [conn82] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 85), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646") }, txnNumber: 15, autocommit: false } numYields:0 reslen:214 protocol:op_msg 124ms
2020-05-08T14:16:21.411-0500 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 128) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 128) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:166178, timeActiveMicros:204140, timeInactiveMicros:1377, 205ms
2020-05-08T14:16:21.411-0500 I  COMMAND  [conn79] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 148), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 166ms
2020-05-08T14:16:21.582-0500 I  TXN      [conn77] transaction parameters:{ lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 241) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 241) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:69708, timeActiveMicros:101571, timeInactiveMicros:1698, 103ms
2020-05-08T14:16:21.836-0500 I  TXN      [conn77] transaction parameters:{ lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 280) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:145306, timeActiveMicros:194750, timeInactiveMicros:1261, 196ms
2020-05-08T14:16:21.836-0500 I  COMMAND  [conn77] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 302), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09") }, txnNumber: 18, autocommit: false } numYields:0 reslen:214 protocol:op_msg 145ms
2020-05-08T14:16:22.532-0500 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965381, 303) } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 303) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:780926, timeActiveMicros:836551, timeInactiveMicros:909, 837ms
2020-05-08T14:16:22.532-0500 I  COMMAND  [conn79] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 315), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 781ms
2020-05-08T14:16:22.724-0500 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 331), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646") }, txnNumber: 21, autocommit: false } numYields:0 reslen:321 protocol:op_msg 902ms
2020-05-08T14:16:22.950-0500 I  NETWORK  [conn79] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:22.951-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:22.952-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:23.451-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:23.950-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:24.451-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:24.950-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:25.451-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:25.725-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57386 #85 (20 connections now open)
2020-05-08T14:16:25.726-0500 I  NETWORK  [conn85] received client metadata from 192.168.122.1:57386 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:25.951-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:26.351-0500 I  NETWORK  [conn83] end connection 192.168.122.1:57114 (19 connections now open)
2020-05-08T14:16:26.352-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57420 #86 (20 connections now open)
2020-05-08T14:16:26.352-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57422 #87 (21 connections now open)
2020-05-08T14:16:26.352-0500 I  NETWORK  [conn86] received client metadata from 192.168.122.1:57420 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:26.352-0500 I  NETWORK  [conn87] received client metadata from 192.168.122.1:57422 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:26.355-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:26.450-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:26.838-0500 I  NETWORK  [conn78] end connection 192.168.122.1:56960 (20 connections now open)
2020-05-08T14:16:26.839-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57466 #88 (21 connections now open)
2020-05-08T14:16:26.839-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57468 #89 (22 connections now open)
2020-05-08T14:16:26.840-0500 I  NETWORK  [conn88] received client metadata from 192.168.122.1:57466 conn88: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:26.840-0500 I  NETWORK  [conn89] received client metadata from 192.168.122.1:57468 conn89: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:26.951-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:27.451-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:27.534-0500 I  NETWORK  [conn80] end connection 192.168.122.1:56992 (21 connections now open)
2020-05-08T14:16:27.535-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57510 #90 (22 connections now open)
2020-05-08T14:16:27.536-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57512 #91 (23 connections now open)
2020-05-08T14:16:27.536-0500 I  NETWORK  [conn90] received client metadata from 192.168.122.1:57510 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:27.536-0500 I  NETWORK  [conn91] received client metadata from 192.168.122.1:57512 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:27.542-0500 I  -        [conn79] operation was interrupted because a client disconnected
2020-05-08T14:16:27.543-0500 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965381, 354) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5008067, timeInactiveMicros:659, 5008ms
2020-05-08T14:16:27.543-0500 I  COMMAND  [conn79] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 126 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965381, 356), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7254238d-21aa-4dcb-a66b-266340ae51c5") }, txnNumber: 15, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T14:16:27.543-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:27.543-0500 I  NETWORK  [conn79] end connection 192.168.122.1:56990 (22 connections now open)
2020-05-08T14:16:27.742-0500 I  NETWORK  [Uptime-reporter] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965379, 197), t: 9 }, current relevant optime is { ts: Timestamp(1588965373, 1), t: 6 }. :: caused by :: operation was interrupted
2020-05-08T14:16:27.950-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:28.450-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:28.450-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:28.452-0500 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965382, 9) } }, globalReadTimestamp:{ ts: Timestamp(1588965382, 9) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:5726323, timeInactiveMicros:563, 5726ms
2020-05-08T14:16:28.452-0500 I  COMMAND  [conn77] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965381, 354), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("196d3c02-16ce-487a-b0ce-271f97e35c09") }, txnNumber: 20, autocommit: false } numYields:0 reslen:439 protocol:op_msg 6511ms
2020-05-08T14:16:28.452-0500 I  COMMAND  [conn86] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 124 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965382, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e1e8868-be93-45bf-85a7-9263bb0904d1") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:288 protocol:op_msg 2098ms
2020-05-08T14:16:28.452-0500 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965382, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ededa622-0524-430e-993e-d06a290c3646") }, txnNumber: 22, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 5704ms
2020-05-08T14:16:28.453-0500 I  NETWORK  [conn77] end connection 192.168.122.1:56956 (21 connections now open)
2020-05-08T14:16:28.453-0500 I  NETWORK  [conn82] end connection 192.168.122.1:57112 (20 connections now open)
2020-05-08T14:16:30.696-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57660 #92 (21 connections now open)
2020-05-08T14:16:30.697-0500 I  NETWORK  [conn92] received client metadata from 192.168.122.1:57660 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:31.840-0500 I  NETWORK  [conn89] end connection 192.168.122.1:57468 (20 connections now open)
2020-05-08T14:16:31.840-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57790 #93 (21 connections now open)
2020-05-08T14:16:31.841-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57792 #94 (22 connections now open)
2020-05-08T14:16:31.841-0500 I  NETWORK  [conn93] received client metadata from 192.168.122.1:57790 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:31.841-0500 I  NETWORK  [conn94] received client metadata from 192.168.122.1:57792 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:32.537-0500 I  NETWORK  [conn91] end connection 192.168.122.1:57512 (21 connections now open)
2020-05-08T14:16:32.538-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57832 #95 (22 connections now open)
2020-05-08T14:16:32.538-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57834 #96 (23 connections now open)
2020-05-08T14:16:32.538-0500 I  NETWORK  [conn95] received client metadata from 192.168.122.1:57832 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:32.538-0500 I  NETWORK  [conn96] received client metadata from 192.168.122.1:57834 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:32.545-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:33.455-0500 I  NETWORK  [conn87] end connection 192.168.122.1:57422 (22 connections now open)
2020-05-08T14:16:33.456-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57888 #97 (23 connections now open)
2020-05-08T14:16:33.457-0500 I  NETWORK  [conn97] received client metadata from 192.168.122.1:57888 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:33.457-0500 I  -        [conn86] operation was interrupted because a client disconnected
2020-05-08T14:16:33.457-0500 I  CONNPOOL [conn86] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T14:16:33.458-0500 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("9e1e8868-be93-45bf-85a7-9263bb0904d1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965388, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003257, timeInactiveMicros:0, 5003ms
2020-05-08T14:16:33.458-0500 I  COMMAND  [conn86] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 130 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965388, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e1e8868-be93-45bf-85a7-9263bb0904d1") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T14:16:33.458-0500 I  NETWORK  [conn86] end connection 192.168.122.1:57420 (22 connections now open)
2020-05-08T14:16:33.476-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:57890 #98 (23 connections now open)
2020-05-08T14:16:33.477-0500 I  NETWORK  [conn98] received client metadata from 192.168.122.1:57890 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:34.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:16:34.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:16:36.841-0500 I  NETWORK  [conn94] end connection 192.168.122.1:57792 (22 connections now open)
2020-05-08T14:16:36.842-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58070 #103 (23 connections now open)
2020-05-08T14:16:36.842-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58072 #104 (24 connections now open)
2020-05-08T14:16:36.842-0500 I  NETWORK  [conn103] received client metadata from 192.168.122.1:58070 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:36.843-0500 I  NETWORK  [conn104] received client metadata from 192.168.122.1:58072 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:36.846-0500 I  NETWORK  [conn103] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:36.847-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:36.848-0500 I  -        [conn93] operation was interrupted because a client disconnected
2020-05-08T14:16:36.848-0500 I  CONNPOOL [conn93] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T14:16:36.849-0500 I  TXN      [conn93] transaction parameters:{ lsid: { id: UUID("a8623927-475a-4d51-b84a-d147b6032aaa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965388, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006021, timeInactiveMicros:0, 5006ms
2020-05-08T14:16:36.849-0500 I  COMMAND  [conn93] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 135 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965388, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a8623927-475a-4d51-b84a-d147b6032aaa") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T14:16:36.849-0500 I  NETWORK  [conn93] end connection 192.168.122.1:57790 (23 connections now open)
2020-05-08T14:16:37.347-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:37.538-0500 I  NETWORK  [conn96] end connection 192.168.122.1:57834 (22 connections now open)
2020-05-08T14:16:37.539-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58122 #105 (23 connections now open)
2020-05-08T14:16:37.539-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58124 #106 (24 connections now open)
2020-05-08T14:16:37.539-0500 I  NETWORK  [conn105] received client metadata from 192.168.122.1:58122 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:37.540-0500 I  NETWORK  [conn106] received client metadata from 192.168.122.1:58124 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:37.541-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:37.747-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965389, 3), t: 9 }, now { ts: Timestamp(1588965397, 1), t: 11 }
2020-05-08T14:16:37.748-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:37.749-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:37.749-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:37.847-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:38.347-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:38.457-0500 I  NETWORK  [conn98] end connection 192.168.122.1:57890 (23 connections now open)
2020-05-08T14:16:38.458-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58160 #107 (24 connections now open)
2020-05-08T14:16:38.459-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58162 #108 (25 connections now open)
2020-05-08T14:16:38.459-0500 I  NETWORK  [conn107] received client metadata from 192.168.122.1:58160 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:38.459-0500 I  NETWORK  [conn108] received client metadata from 192.168.122.1:58162 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:38.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:38.486-0500 I  -        [conn97] operation was interrupted because a client disconnected
2020-05-08T14:16:38.487-0500 I  CONNPOOL [conn97] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T14:16:38.487-0500 I  TXN      [conn97] transaction parameters:{ lsid: { id: UUID("8bb82448-88f7-4d21-b33f-f25bfa075707"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965392, 50) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5008078, timeInactiveMicros:685, 5008ms
2020-05-08T14:16:38.487-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:38.487-0500 I  COMMAND  [conn97] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 136 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965393, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8bb82448-88f7-4d21-b33f-f25bfa075707") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T14:16:38.487-0500 I  NETWORK  [conn97] end connection 192.168.122.1:57888 (24 connections now open)
2020-05-08T14:16:38.839-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58174 #109 (25 connections now open)
2020-05-08T14:16:38.840-0500 I  NETWORK  [conn109] received client metadata from 192.168.122.1:58174 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:38.847-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:39.347-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:39.848-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:40.348-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:40.848-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:41.348-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:41.348-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:41.349-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965397, 5), t: 11 }, now { ts: Timestamp(1588965399, 5), t: 12 }
2020-05-08T14:16:41.349-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:41.350-0500 I  SHARDING [conn103] Received reply from shard n9:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965399, 5), t: 12 }, now { ts: Timestamp(1588965400, 2), t: 13 }
2020-05-08T14:16:41.350-0500 I  TXN      [conn103] transaction parameters:{ lsid: { id: UUID("cb0675d8-3f7b-4f76-b243-2186b3d23778"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965393, 11) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:4505398, timeInactiveMicros:0, 4505ms
2020-05-08T14:16:41.350-0500 I  COMMAND  [conn103] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965393, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb0675d8-3f7b-4f76-b243-2186b3d23778") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 4505ms
2020-05-08T14:16:41.350-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:41.350-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:41.644-0500 I  COMMAND  [conn107] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 138 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965397, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9077a941-33d3-4b30-af94-a37b5c311bd5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3182ms
2020-05-08T14:16:41.644-0500 I  COMMAND  [conn103] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965401, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb0675d8-3f7b-4f76-b243-2186b3d23778") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 291ms
2020-05-08T14:16:41.644-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:41.843-0500 I  NETWORK  [conn104] end connection 192.168.122.1:58072 (24 connections now open)
2020-05-08T14:16:41.843-0500 I  NETWORK  [conn103] end connection 192.168.122.1:58070 (23 connections now open)
2020-05-08T14:16:41.844-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58326 #111 (24 connections now open)
2020-05-08T14:16:41.844-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58328 #112 (25 connections now open)
2020-05-08T14:16:41.844-0500 I  NETWORK  [conn111] received client metadata from 192.168.122.1:58326 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:41.845-0500 I  NETWORK  [conn112] received client metadata from 192.168.122.1:58328 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:42.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:16:42.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:16:42.540-0500 I  NETWORK  [conn106] end connection 192.168.122.1:58124 (24 connections now open)
2020-05-08T14:16:42.541-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58380 #116 (25 connections now open)
2020-05-08T14:16:42.541-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58382 #117 (26 connections now open)
2020-05-08T14:16:42.541-0500 I  NETWORK  [conn116] received client metadata from 192.168.122.1:58380 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:42.542-0500 I  NETWORK  [conn117] received client metadata from 192.168.122.1:58382 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:42.545-0500 I  -        [conn105] operation was interrupted because a client disconnected
2020-05-08T14:16:42.545-0500 I  CONNPOOL [conn105] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T14:16:42.545-0500 I  COMMAND  [conn105] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 134 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965395, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b0564b7d-11c3-47e6-b182-52e5320099e9") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T14:16:42.545-0500 I  NETWORK  [conn105] end connection 192.168.122.1:58122 (25 connections now open)
2020-05-08T14:16:43.459-0500 I  NETWORK  [conn108] end connection 192.168.122.1:58162 (24 connections now open)
2020-05-08T14:16:43.460-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58446 #119 (25 connections now open)
2020-05-08T14:16:43.461-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58448 #120 (26 connections now open)
2020-05-08T14:16:43.461-0500 I  NETWORK  [conn119] received client metadata from 192.168.122.1:58446 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:43.461-0500 I  NETWORK  [conn120] received client metadata from 192.168.122.1:58448 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:43.464-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:43.846-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdb5861abbf7eec2119 to 5eb5afdaa0224cfb413c7171; invalidating user cache
2020-05-08T14:16:46.649-0500 I  -        [conn107] operation was interrupted because a client disconnected
2020-05-08T14:16:46.649-0500 I  CONNPOOL [conn107] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T14:16:46.650-0500 I  TXN      [conn107] transaction parameters:{ lsid: { id: UUID("9077a941-33d3-4b30-af94-a37b5c311bd5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965397, 5) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:8188410, timeInactiveMicros:655, 8189ms
2020-05-08T14:16:46.650-0500 I  COMMAND  [conn107] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 133 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9077a941-33d3-4b30-af94-a37b5c311bd5") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T14:16:46.650-0500 I  NETWORK  [conn107] end connection 192.168.122.1:58160 (25 connections now open)
2020-05-08T14:16:46.844-0500 I  NETWORK  [conn112] end connection 192.168.122.1:58328 (24 connections now open)
2020-05-08T14:16:46.845-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58636 #125 (25 connections now open)
2020-05-08T14:16:46.846-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58638 #126 (26 connections now open)
2020-05-08T14:16:46.846-0500 I  NETWORK  [conn125] received client metadata from 192.168.122.1:58636 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:46.846-0500 I  NETWORK  [conn126] received client metadata from 192.168.122.1:58638 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:46.848-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:46.849-0500 I  -        [conn111] operation was interrupted because a client disconnected
2020-05-08T14:16:46.849-0500 I  CONNPOOL [conn111] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T14:16:46.850-0500 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("9823b1b0-99b1-4d62-b29c-8cff864656d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965401, 83) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003930, timeInactiveMicros:0, 5003ms
2020-05-08T14:16:46.850-0500 I  COMMAND  [conn111] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 140 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965401, 83), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9823b1b0-99b1-4d62-b29c-8cff864656d2") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T14:16:46.850-0500 I  NETWORK  [conn111] end connection 192.168.122.1:58326 (25 connections now open)
2020-05-08T14:16:47.541-0500 I  NETWORK  [conn117] end connection 192.168.122.1:58382 (24 connections now open)
2020-05-08T14:16:47.542-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58694 #128 (25 connections now open)
2020-05-08T14:16:47.542-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58696 #129 (26 connections now open)
2020-05-08T14:16:47.543-0500 I  NETWORK  [conn128] received client metadata from 192.168.122.1:58694 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:47.543-0500 I  NETWORK  [conn129] received client metadata from 192.168.122.1:58696 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:47.779-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965403, 8), t: 13 }, now { ts: Timestamp(1588965407, 8), t: 15 }
2020-05-08T14:16:48.461-0500 I  NETWORK  [conn120] end connection 192.168.122.1:58448 (25 connections now open)
2020-05-08T14:16:48.462-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58748 #130 (26 connections now open)
2020-05-08T14:16:48.463-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58750 #131 (27 connections now open)
2020-05-08T14:16:48.463-0500 I  NETWORK  [conn130] received client metadata from 192.168.122.1:58748 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:48.463-0500 I  NETWORK  [conn131] received client metadata from 192.168.122.1:58750 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:48.465-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:16:48.465-0500 I  -        [conn119] operation was interrupted because a client disconnected
2020-05-08T14:16:48.465-0500 I  CONNPOOL [conn119] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T14:16:48.466-0500 I  TXN      [conn119] transaction parameters:{ lsid: { id: UUID("b5f2039b-d8fe-4dfb-8a61-b2b7d746112a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965403, 3) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002852, timeInactiveMicros:0, 5002ms
2020-05-08T14:16:48.466-0500 I  COMMAND  [conn119] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 143 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965403, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5f2039b-d8fe-4dfb-8a61-b2b7d746112a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T14:16:48.466-0500 I  NETWORK  [conn119] end connection 192.168.122.1:58446 (26 connections now open)
2020-05-08T14:16:48.834-0500 I  CONNPOOL [ShardRegistry] Ending idle connection to host n1:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T14:16:51.402-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:51.403-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:51.480-0500 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n6:27018 because the pool meets constraints; 6 connections to that host remain open
2020-05-08T14:16:51.481-0500 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 6 connections to that host remain open
2020-05-08T14:16:51.846-0500 I  NETWORK  [conn126] end connection 192.168.122.1:58638 (25 connections now open)
2020-05-08T14:16:51.847-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58910 #134 (26 connections now open)
2020-05-08T14:16:51.848-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58912 #135 (27 connections now open)
2020-05-08T14:16:51.848-0500 I  NETWORK  [conn134] received client metadata from 192.168.122.1:58910 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:51.848-0500 I  NETWORK  [conn135] received client metadata from 192.168.122.1:58912 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:51.851-0500 I  NETWORK  [conn134] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:51.852-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:52.353-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:52.481-0500 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n6:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T14:16:52.543-0500 I  NETWORK  [conn129] end connection 192.168.122.1:58696 (26 connections now open)
2020-05-08T14:16:52.544-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58936 #136 (27 connections now open)
2020-05-08T14:16:52.544-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:58938 #137 (28 connections now open)
2020-05-08T14:16:52.544-0500 I  NETWORK  [conn136] received client metadata from 192.168.122.1:58936 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:52.544-0500 I  NETWORK  [conn137] received client metadata from 192.168.122.1:58938 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:52.547-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:52.853-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:53.352-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:53.352-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:53.353-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:53.354-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:53.354-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:16:53.355-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965410, 7), t: 15 }, now { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T14:16:53.463-0500 I  NETWORK  [conn131] end connection 192.168.122.1:58750 (27 connections now open)
2020-05-08T14:16:53.463-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59004 #138 (28 connections now open)
2020-05-08T14:16:53.463-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59006 #139 (29 connections now open)
2020-05-08T14:16:53.463-0500 I  NETWORK  [conn138] received client metadata from 192.168.122.1:59004 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:53.464-0500 I  NETWORK  [conn139] received client metadata from 192.168.122.1:59006 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:53.469-0500 I  -        [conn130] operation was interrupted because a client disconnected
2020-05-08T14:16:53.469-0500 I  CONNPOOL [conn130] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T14:16:53.469-0500 I  COMMAND  [conn130] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 157 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965407, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("843a677c-1ab9-4c22-9708-021dabb2da56") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T14:16:53.469-0500 I  NETWORK  [conn130] end connection 192.168.122.1:58748 (28 connections now open)
2020-05-08T14:16:53.927-0500 I  NETWORK  [conn134] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:53.929-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:53.929-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:54.429-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:54.429-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:54.431-0500 I  TXN      [conn136] transaction parameters:{ lsid: { id: UUID("e5eb4583-12f9-43d2-a84f-89fb5704e537"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965410, 13) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1884599, timeInactiveMicros:0, 1884ms
2020-05-08T14:16:54.431-0500 I  COMMAND  [conn136] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965410, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5eb4583-12f9-43d2-a84f-89fb5704e537") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1885ms
2020-05-08T14:16:54.950-0500 I  COMMAND  [conn134] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 161 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965410, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3100ms
2020-05-08T14:16:54.950-0500 I  COMMAND  [conn138] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 165 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965413, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99f3a024-9990-4837-96cf-d9a4b9cc7591") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1485ms
2020-05-08T14:16:54.951-0500 I  COMMAND  [conn136] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965414, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5eb4583-12f9-43d2-a84f-89fb5704e537") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 518ms
2020-05-08T14:16:54.989-0500 I  TXN      [conn134] transaction parameters:{ lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965410, 12) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:33304, timeActiveMicros:3136782, timeInactiveMicros:2033, 3138ms
2020-05-08T14:16:54.995-0500 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("99f3a024-9990-4837-96cf-d9a4b9cc7591"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965413, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:39317, timeActiveMicros:1527967, timeInactiveMicros:1908, 1529ms
2020-05-08T14:16:54.996-0500 I  NETWORK  [conn138] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:55.417-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:55.496-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:55.996-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:55.997-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:55.998-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:55.999-0500 I  COMMAND  [conn136] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 163 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 60), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5eb4583-12f9-43d2-a84f-89fb5704e537") }, txnNumber: 10, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:328 protocol:op_msg 665ms
2020-05-08T14:16:55.999-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:56.000-0500 I  TXN      [conn134] transaction parameters:{ lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965415, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:974669, timeInactiveMicros:0, 974ms
2020-05-08T14:16:56.000-0500 I  COMMAND  [conn134] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965415, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 974ms
2020-05-08T14:16:56.001-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T14:16:56.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:56.861-0500 I  NETWORK  [conn136] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:56.863-0500 I  NETWORK  [conn138] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:16:56.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:57.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:57.544-0500 I  NETWORK  [conn137] end connection 192.168.122.1:58938 (27 connections now open)
2020-05-08T14:16:57.545-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59260 #141 (28 connections now open)
2020-05-08T14:16:57.545-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59262 #142 (29 connections now open)
2020-05-08T14:16:57.545-0500 I  NETWORK  [conn141] received client metadata from 192.168.122.1:59260 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:57.546-0500 I  NETWORK  [conn142] received client metadata from 192.168.122.1:59262 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:16:57.861-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:16:57.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:58.361-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:58.361-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:16:58.362-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:58.362-0500 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965415, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2361ms
2020-05-08T14:16:58.474-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:58.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:58.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:59.128-0500 I  TXN      [conn136] transaction parameters:{ lsid: { id: UUID("e5eb4583-12f9-43d2-a84f-89fb5704e537"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965415, 60) } }, globalReadTimestamp:{ ts: Timestamp(1588965415, 60) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3126808, timeActiveMicros:3812217, timeInactiveMicros:2056, 3814ms
2020-05-08T14:16:59.128-0500 I  COMMAND  [conn138] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 2, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965414, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99f3a024-9990-4837-96cf-d9a4b9cc7591") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 4132ms
2020-05-08T14:16:59.129-0500 I  NETWORK  [conn136] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:16:59.129-0500 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965418, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 3, autocommit: false } numYields:0 reslen:396 protocol:op_msg 766ms
2020-05-08T14:16:59.130-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:59.131-0500 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("229484bf-6451-4783-912f-30517d2ec562"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965416, 15) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1584116, timeInactiveMicros:0, 1584ms
2020-05-08T14:16:59.131-0500 I  COMMAND  [conn141] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965416, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("229484bf-6451-4783-912f-30517d2ec562") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1584ms
2020-05-08T14:16:59.202-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:16:59.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:59.630-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:59.631-0500 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:16:59.632-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:16:59.632-0500 I  COMMAND  [conn136] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965415, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e5eb4583-12f9-43d2-a84f-89fb5704e537") }, txnNumber: 10, autocommit: false } numYields:0 reslen:428 protocol:op_msg 3631ms
2020-05-08T14:16:59.633-0500 I  NETWORK  [conn136] end connection 192.168.122.1:58936 (28 connections now open)
2020-05-08T14:16:59.633-0500 I  COMMAND  [conn134] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 175 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965419, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 6, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 432ms
2020-05-08T14:16:59.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:00.243-0500 I  NETWORK  [conn134] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:00.244-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:00.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:00.580-0500 I  CONNPOOL [ShardRegistry] Ending idle connection to host n8:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T14:17:00.744-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:00.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:01.119-0500 I  NETWORK  [conn138] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T14:17:01.121-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:01.244-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:01.499-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:01.620-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:01.744-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:01.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:02.120-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:02.245-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:02.498-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:02.546-0500 I  NETWORK  [conn142] end connection 192.168.122.1:59262 (27 connections now open)
2020-05-08T14:17:02.547-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59460 #143 (28 connections now open)
2020-05-08T14:17:02.547-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59462 #144 (29 connections now open)
2020-05-08T14:17:02.547-0500 I  NETWORK  [conn143] received client metadata from 192.168.122.1:59460 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:02.547-0500 I  NETWORK  [conn144] received client metadata from 192.168.122.1:59462 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:02.723-0500 I  CONNPOOL [ShardRegistry] Ending idle connection to host n9:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T14:17:02.744-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:02.745-0500 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:02.745-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:02.965-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:02.998-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:03.120-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:03.121-0500 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:03.123-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:03.123-0500 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 190), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("229484bf-6451-4783-912f-30517d2ec562") }, txnNumber: 51, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2607ms
2020-05-08T14:17:03.123-0500 I  NETWORK  [conn141] end connection 192.168.122.1:59260 (28 connections now open)
2020-05-08T14:17:03.129-0500 I  COMMAND  [conn138] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965420, 195), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99f3a024-9990-4837-96cf-d9a4b9cc7591") }, txnNumber: 50, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2611ms
2020-05-08T14:17:03.257-0500 I  TXN      [conn134] transaction parameters:{ lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965419, 19) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3621565, timeActiveMicros:4065359, timeInactiveMicros:1954, 4067ms
2020-05-08T14:17:03.258-0500 I  COMMAND  [conn134] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965419, 85), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 6, autocommit: false } numYields:0 reslen:426 protocol:op_msg 3623ms
2020-05-08T14:17:03.499-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:03.998-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:03.999-0500 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:03.999-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-08T14:17:04.130-0500 I  NETWORK  [conn139] end connection 192.168.122.1:59006 (27 connections now open)
2020-05-08T14:17:04.131-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59584 #150 (28 connections now open)
2020-05-08T14:17:04.131-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59588 #151 (29 connections now open)
2020-05-08T14:17:04.131-0500 I  NETWORK  [conn150] received client metadata from 192.168.122.1:59584 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:04.132-0500 I  NETWORK  [conn151] received client metadata from 192.168.122.1:59588 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:04.190-0500 I  NETWORK  [conn135] end connection 192.168.122.1:58912 (28 connections now open)
2020-05-08T14:17:04.191-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59598 #152 (29 connections now open)
2020-05-08T14:17:04.191-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59600 #153 (30 connections now open)
2020-05-08T14:17:04.191-0500 I  NETWORK  [conn152] received client metadata from 192.168.122.1:59598 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:04.192-0500 I  NETWORK  [conn153] received client metadata from 192.168.122.1:59600 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:04.365-0500 I  COMMAND  [conn143] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965420, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("429e27e2-3ddc-40d9-a5cd-b15114f1ddbe") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1816ms
2020-05-08T14:17:04.366-0500 I  COMMAND  [conn138] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965423, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99f3a024-9990-4837-96cf-d9a4b9cc7591") }, txnNumber: 50, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1237ms
2020-05-08T14:17:04.367-0500 I  NETWORK  [conn138] end connection 192.168.122.1:59004 (29 connections now open)
2020-05-08T14:17:04.369-0500 I  COMMAND  [conn152] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 175ms
2020-05-08T14:17:04.369-0500 I  COMMAND  [conn150] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 174 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 235ms
2020-05-08T14:17:04.369-0500 I  NETWORK  [conn143] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:04.370-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:04.370-0500 I  TXN      [conn134] transaction parameters:{ lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965423, 11) } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1111078, timeInactiveMicros:0, 1111ms
2020-05-08T14:17:04.370-0500 I  COMMAND  [conn134] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7a8bbc88-74c6-4cc9-b115-8e42eba2754e") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965423, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1111ms
2020-05-08T14:17:04.371-0500 I  NETWORK  [conn134] end connection 192.168.122.1:58910 (28 connections now open)
2020-05-08T14:17:04.373-0500 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:238664, timeInactiveMicros:1250, 239ms
2020-05-08T14:17:04.374-0500 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:179195, timeInactiveMicros:1290, 180ms
2020-05-08T14:17:04.411-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:04.457-0500 I  NETWORK  [conn150] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T14:17:04.458-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:04.764-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965412, 1), t: 16 }, now { ts: Timestamp(1588965424, 57), t: 18 }
2020-05-08T14:17:04.870-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:04.900-0500 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T14:17:04.957-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:05.370-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:05.458-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:05.870-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:05.957-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:05.957-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:05.959-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:05.959-0500 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965424, 53) } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 53) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1509758, timeInactiveMicros:1371, 1511ms
2020-05-08T14:17:05.959-0500 I  COMMAND  [conn150] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8") }, txnNumber: 5, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1507ms
2020-05-08T14:17:05.960-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:05.960-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:06.370-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:06.421-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:06.422-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:06.459-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:06.870-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:06.870-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:06.871-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:06.871-0500 I  COMMAND  [conn152] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 178 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965424, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef") }, txnNumber: 3, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 2460ms
2020-05-08T14:17:06.959-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:06.967-0500 I  NETWORK  [conn150] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:07.383-0500 I  COMMAND  [conn143] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 178 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965423, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("429e27e2-3ddc-40d9-a5cd-b15114f1ddbe") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3015ms
2020-05-08T14:17:07.387-0500 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("429e27e2-3ddc-40d9-a5cd-b15114f1ddbe"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965423, 18) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3018334, timeInactiveMicros:1047, 3019ms
2020-05-08T14:17:07.395-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:07.459-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:07.467-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:07.959-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:07.959-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:07.967-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:07.967-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:07.968-0500 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T14:17:07.969-0500 I  COMMAND  [conn150] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965425, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2008ms
2020-05-08T14:17:07.991-0500 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965424, 35) } }, globalReadTimestamp:{ ts: Timestamp(1588965424, 35) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1118888, timeActiveMicros:3582596, timeInactiveMicros:2145, 3584ms
2020-05-08T14:17:07.993-0500 I  COMMAND  [conn152] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965426, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef") }, txnNumber: 3, autocommit: false } numYields:0 reslen:427 protocol:op_msg 1120ms
2020-05-08T14:17:08.506-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965424, 57), t: 18 }, now { ts: Timestamp(1588965427, 1), t: 20 }
2020-05-08T14:17:09.192-0500 I  NETWORK  [conn153] end connection 192.168.122.1:59600 (27 connections now open)
2020-05-08T14:17:09.193-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59794 #155 (28 connections now open)
2020-05-08T14:17:09.193-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59796 #156 (29 connections now open)
2020-05-08T14:17:09.193-0500 I  NETWORK  [conn155] received client metadata from 192.168.122.1:59794 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:09.194-0500 I  NETWORK  [conn156] received client metadata from 192.168.122.1:59796 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:09.692-0500 I  CONNPOOL [ShardRegistry] Ending idle connection to host n2:27019 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T14:17:10.017-0500 I  NETWORK  [conn152] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:10.081-0500 I  COMMAND  [conn150] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 183), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8") }, txnNumber: 13, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 182) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1759ms
2020-05-08T14:17:10.145-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:10.518-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:10.519-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:10.520-0500 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 187) } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 187) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2193461, timeInactiveMicros:0, 2193ms
2020-05-08T14:17:10.520-0500 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("429e27e2-3ddc-40d9-a5cd-b15114f1ddbe"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 50, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 183) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2198716, timeInactiveMicros:0, 2198ms
2020-05-08T14:17:10.520-0500 I  COMMAND  [conn143] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 181), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("429e27e2-3ddc-40d9-a5cd-b15114f1ddbe") }, txnNumber: 50, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2198ms
2020-05-08T14:17:10.520-0500 I  COMMAND  [conn152] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965428, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50cdee88-0111-47ea-9ce8-727893ff86ef") }, txnNumber: 12, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 187) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 2193ms
2020-05-08T14:17:10.520-0500 I  NETWORK  [conn152] end connection 192.168.122.1:59598 (28 connections now open)
2020-05-08T14:17:10.522-0500 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965428, 182) } }, globalReadTimestamp:{ ts: Timestamp(1588965428, 183) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2199702, timeInactiveMicros:804, 2200ms
2020-05-08T14:17:10.522-0500 I  COMMAND  [conn150] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 182 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965429, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8") }, txnNumber: 13, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 13 does not match any in-progress transactions. The active transaction number is 7" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 440ms
2020-05-08T14:17:12.920-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965427, 1), t: 20 }, now { ts: Timestamp(1588965430, 9), t: 22 }
2020-05-08T14:17:12.932-0500 I  NETWORK  [conn155] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T14:17:12.934-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:13.180-0500 I  NETWORK  [conn151] end connection 192.168.122.1:59588 (27 connections now open)
2020-05-08T14:17:13.181-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59890 #157 (28 connections now open)
2020-05-08T14:17:13.181-0500 I  NETWORK  [conn157] received client metadata from 192.168.122.1:59890 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:13.182-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59892 #158 (29 connections now open)
2020-05-08T14:17:13.182-0500 I  NETWORK  [conn158] received client metadata from 192.168.122.1:59892 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:13.185-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:13.322-0500 I  NETWORK  [conn144] end connection 192.168.122.1:59462 (28 connections now open)
2020-05-08T14:17:13.323-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59932 #159 (29 connections now open)
2020-05-08T14:17:13.324-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59934 #160 (30 connections now open)
2020-05-08T14:17:13.324-0500 I  NETWORK  [conn159] received client metadata from 192.168.122.1:59932 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:13.324-0500 I  NETWORK  [conn160] received client metadata from 192.168.122.1:59934 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:13.327-0500 I  NETWORK  [conn159] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:13.329-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:13.434-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:13.829-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:13.846-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdaa0224cfb413c7171 to 5eb5afdbf50ef7b0538edfc4; invalidating user cache
2020-05-08T14:17:13.934-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:14.198-0500 I  NETWORK  [conn156] end connection 192.168.122.1:59796 (29 connections now open)
2020-05-08T14:17:14.198-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59974 #161 (30 connections now open)
2020-05-08T14:17:14.198-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:59976 #162 (31 connections now open)
2020-05-08T14:17:14.199-0500 I  NETWORK  [conn161] received client metadata from 192.168.122.1:59974 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:14.199-0500 I  NETWORK  [conn162] received client metadata from 192.168.122.1:59976 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:14.201-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:14.201-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T14:17:14.202-0500 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("429e27e2-3ddc-40d9-a5cd-b15114f1ddbe") }, txnNumber: 50, autocommit: false } numYields:0 reslen:515 protocol:op_msg 3681ms
2020-05-08T14:17:14.202-0500 I  COMMAND  [conn150] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965430, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ee7f101c-347b-4ab1-bbdb-7b1ecb949cd8") }, txnNumber: 13, autocommit: false } numYields:0 reslen:545 protocol:op_msg 3678ms
2020-05-08T14:17:14.202-0500 I  COMMAND  [conn155] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 182 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965429, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c301781d-98da-48bf-9522-c89ff882c060") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 5001ms
2020-05-08T14:17:14.202-0500 I  NETWORK  [conn150] end connection 192.168.122.1:59584 (30 connections now open)
2020-05-08T14:17:14.202-0500 I  NETWORK  [conn143] end connection 192.168.122.1:59460 (29 connections now open)
2020-05-08T14:17:14.202-0500 I  NETWORK  [conn155] end connection 192.168.122.1:59794 (28 connections now open)
2020-05-08T14:17:14.329-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:14.829-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:14.905-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:14.906-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:14.906-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:15.328-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:15.365-0500 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 196 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("433610a9-052b-4d5d-a587-1b36fe993b9e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1165ms
2020-05-08T14:17:15.366-0500 I  COMMAND  [conn157] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 171 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b03252b-5ba4-48cb-b688-25e4a3d7879c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 2181ms
2020-05-08T14:17:15.367-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:15.368-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:15.828-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:15.829-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:15.830-0500 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("021b9e0d-5940-408e-bdad-8f7c1b78a4bb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2504224, timeInactiveMicros:0, 2504ms
2020-05-08T14:17:15.830-0500 I  COMMAND  [conn159] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("021b9e0d-5940-408e-bdad-8f7c1b78a4bb") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 2504ms
2020-05-08T14:17:15.830-0500 I  COMMAND  [conn161] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("433610a9-052b-4d5d-a587-1b36fe993b9e") }, txnNumber: 1, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 464ms
2020-05-08T14:17:15.832-0500 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("8b03252b-5ba4-48cb-b688-25e4a3d7879c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2647555, timeInactiveMicros:927, 2648ms
2020-05-08T14:17:15.833-0500 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b03252b-5ba4-48cb-b688-25e4a3d7879c") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 466ms
2020-05-08T14:17:15.857-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965433, 8), t: 22 }, now { ts: Timestamp(1588965434, 11), t: 23 }
2020-05-08T14:17:16.819-0500 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965435, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("021b9e0d-5940-408e-bdad-8f7c1b78a4bb") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 986ms
2020-05-08T14:17:16.819-0500 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965435, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b03252b-5ba4-48cb-b688-25e4a3d7879c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 985ms
2020-05-08T14:17:16.863-0500 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-08T14:17:17.819-0500 I  NETWORK  [conn157] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:17.819-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:18.182-0500 I  NETWORK  [conn158] end connection 192.168.122.1:59892 (27 connections now open)
2020-05-08T14:17:18.182-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60102 #164 (28 connections now open)
2020-05-08T14:17:18.183-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60104 #165 (29 connections now open)
2020-05-08T14:17:18.183-0500 I  NETWORK  [conn164] received client metadata from 192.168.122.1:60102 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:18.183-0500 I  NETWORK  [conn165] received client metadata from 192.168.122.1:60104 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:18.185-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:18.319-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:18.324-0500 I  NETWORK  [conn160] end connection 192.168.122.1:59934 (28 connections now open)
2020-05-08T14:17:18.325-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60130 #166 (29 connections now open)
2020-05-08T14:17:18.325-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60132 #167 (30 connections now open)
2020-05-08T14:17:18.326-0500 I  NETWORK  [conn166] received client metadata from 192.168.122.1:60130 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:18.326-0500 I  NETWORK  [conn167] received client metadata from 192.168.122.1:60132 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:18.328-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:18.819-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:18.820-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:18.821-0500 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("021b9e0d-5940-408e-bdad-8f7c1b78a4bb") }, txnNumber: 2, autocommit: false } numYields:0 reslen:351 protocol:op_msg 1963ms
2020-05-08T14:17:18.822-0500 I  NETWORK  [conn159] end connection 192.168.122.1:59932 (29 connections now open)
2020-05-08T14:17:18.863-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:18.863-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:19.199-0500 I  NETWORK  [conn162] end connection 192.168.122.1:59976 (28 connections now open)
2020-05-08T14:17:19.200-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60192 #168 (29 connections now open)
2020-05-08T14:17:19.200-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60194 #169 (30 connections now open)
2020-05-08T14:17:19.200-0500 I  NETWORK  [conn168] received client metadata from 192.168.122.1:60192 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:19.200-0500 I  NETWORK  [conn169] received client metadata from 192.168.122.1:60194 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:19.330-0500 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T14:17:19.363-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:19.863-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:20.051-0500 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("8b03252b-5ba4-48cb-b688-25e4a3d7879c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965436, 155) } }, globalReadTimestamp:{ ts: Timestamp(1588965436, 155) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:3212013, timeActiveMicros:3230088, timeInactiveMicros:838, 3230ms
2020-05-08T14:17:20.051-0500 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("433610a9-052b-4d5d-a587-1b36fe993b9e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965433, 8) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:4219566, timeActiveMicros:5849419, timeInactiveMicros:1398, 5850ms
2020-05-08T14:17:20.051-0500 I  COMMAND  [conn157] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965436, 165), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b03252b-5ba4-48cb-b688-25e4a3d7879c") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3212ms
2020-05-08T14:17:20.051-0500 I  COMMAND  [conn161] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965435, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("433610a9-052b-4d5d-a587-1b36fe993b9e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 4219ms
2020-05-08T14:17:20.051-0500 I  COMMAND  [conn166] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 183 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965437, 200), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("334ac8dd-4565-4b66-b0e9-c13b3540ca85") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1724ms
2020-05-08T14:17:20.051-0500 I  NETWORK  [conn161] end connection 192.168.122.1:59974 (29 connections now open)
2020-05-08T14:17:20.051-0500 I  NETWORK  [conn157] end connection 192.168.122.1:59890 (28 connections now open)
2020-05-08T14:17:20.052-0500 I  COMMAND  [conn164] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 199 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965437, 200), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cdeda527-ecb0-4198-9b44-3490c0bf4170") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1867ms
2020-05-08T14:17:20.062-0500 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("334ac8dd-4565-4b66-b0e9-c13b3540ca85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965437, 200) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1734408, timeInactiveMicros:473, 1734ms
2020-05-08T14:17:20.062-0500 I  TXN      [conn164] transaction parameters:{ lsid: { id: UUID("cdeda527-ecb0-4198-9b44-3490c0bf4170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965437, 200) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1877243, timeInactiveMicros:768, 1878ms
2020-05-08T14:17:20.087-0500 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("096e11be-6fa9-4b01-8f7e-4f0405fbbce6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965439, 63) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:756815, timeActiveMicros:763116, timeInactiveMicros:1097, 764ms
2020-05-08T14:17:20.087-0500 I  COMMAND  [conn168] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965439, 64), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("096e11be-6fa9-4b01-8f7e-4f0405fbbce6") }, txnNumber: 8, autocommit: false } numYields:0 reslen:214 protocol:op_msg 756ms
2020-05-08T14:17:20.150-0500 I  NETWORK  [conn166] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 334ac8dd-4565-4b66-b0e9-c13b3540ca85:2 stopped due to: Transaction coordinator service stepping down
2020-05-08T14:17:20.151-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:20.162-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:20.363-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:20.651-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:20.651-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:20.653-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:20.653-0500 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("096e11be-6fa9-4b01-8f7e-4f0405fbbce6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965440, 67) } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 67) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:517492, timeInactiveMicros:676, 518ms
2020-05-08T14:17:20.653-0500 I  COMMAND  [conn168] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965440, 76), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("096e11be-6fa9-4b01-8f7e-4f0405fbbce6") }, txnNumber: 10, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 507ms
2020-05-08T14:17:20.654-0500 I  TXN      [conn164] transaction parameters:{ lsid: { id: UUID("cdeda527-ecb0-4198-9b44-3490c0bf4170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965440, 66) } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 67) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:518884, timeInactiveMicros:1032, 519ms
2020-05-08T14:17:20.655-0500 I  COMMAND  [conn164] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965440, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cdeda527-ecb0-4198-9b44-3490c0bf4170") }, txnNumber: 3, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Given transaction number 3 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:445 protocol:op_msg 493ms
2020-05-08T14:17:20.863-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:20.901-0500 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T14:17:21.057-0500 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n5:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T14:17:21.148-0500 I  CONNPOOL [ShardRegistry] Ending idle connection to host n7:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T14:17:21.363-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:21.364-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:21.775-0500 I  CONNPOOL [ShardRegistry] Ending idle connection to host n4:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T14:17:22.319-0500 I  NETWORK  [conn164] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:22.321-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:22.513-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:22.516-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:22.820-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:22.950-0500 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host n7:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T14:17:23.014-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:23.183-0500 I  NETWORK  [conn165] end connection 192.168.122.1:60104 (27 connections now open)
2020-05-08T14:17:23.184-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60302 #171 (28 connections now open)
2020-05-08T14:17:23.185-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60304 #172 (29 connections now open)
2020-05-08T14:17:23.185-0500 I  NETWORK  [conn171] received client metadata from 192.168.122.1:60302 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:23.185-0500 I  NETWORK  [conn172] received client metadata from 192.168.122.1:60304 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:23.320-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:23.321-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:23.322-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:23.322-0500 I  COMMAND  [conn168] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 120), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("096e11be-6fa9-4b01-8f7e-4f0405fbbce6") }, txnNumber: 10, autocommit: false } numYields:0 reslen:321 protocol:op_msg 2667ms
2020-05-08T14:17:23.322-0500 I  COMMAND  [conn164] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 125), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cdeda527-ecb0-4198-9b44-3490c0bf4170") }, txnNumber: 3, autocommit: false } numYields:0 reslen:320 protocol:op_msg 2666ms
2020-05-08T14:17:23.322-0500 I  NETWORK  [conn164] end connection 192.168.122.1:60102 (28 connections now open)
2020-05-08T14:17:23.326-0500 I  NETWORK  [conn167] end connection 192.168.122.1:60132 (27 connections now open)
2020-05-08T14:17:23.327-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60318 #173 (28 connections now open)
2020-05-08T14:17:23.327-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60320 #174 (29 connections now open)
2020-05-08T14:17:23.327-0500 I  NETWORK  [conn173] received client metadata from 192.168.122.1:60318 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:23.327-0500 I  NETWORK  [conn174] received client metadata from 192.168.122.1:60320 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:23.514-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:24.014-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:24.319-0500 I  NETWORK  [conn173] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:24.320-0500 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("334ac8dd-4565-4b66-b0e9-c13b3540ca85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965440, 33) } }, globalReadTimestamp:{ ts: Timestamp(1588965440, 33) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:4206004, timeActiveMicros:4234797, timeInactiveMicros:1402, 4236ms
2020-05-08T14:17:24.320-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:24.320-0500 I  COMMAND  [conn166] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965440, 46), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("334ac8dd-4565-4b66-b0e9-c13b3540ca85") }, txnNumber: 2, autocommit: false } numYields:0 reslen:311 protocol:op_msg 4206ms
2020-05-08T14:17:24.321-0500 I  NETWORK  [conn166] end connection 192.168.122.1:60130 (28 connections now open)
2020-05-08T14:17:24.514-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:24.514-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:24.515-0500 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T14:17:24.820-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:25.021-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:25.022-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:25.023-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:25.023-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:25.088-0500 I  NETWORK  [conn169] end connection 192.168.122.1:60194 (27 connections now open)
2020-05-08T14:17:25.089-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60394 #176 (28 connections now open)
2020-05-08T14:17:25.089-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60396 #177 (29 connections now open)
2020-05-08T14:17:25.089-0500 I  NETWORK  [conn176] received client metadata from 192.168.122.1:60394 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:25.090-0500 I  NETWORK  [conn177] received client metadata from 192.168.122.1:60396 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:25.321-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:25.321-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:25.322-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:25.521-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:25.863-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:26.021-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:26.521-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:26.989-0500 I  COMMAND  [conn168] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 206 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965443, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("096e11be-6fa9-4b01-8f7e-4f0405fbbce6") }, txnNumber: 11, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588965443, 3) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 3666ms
2020-05-08T14:17:26.989-0500 I  COMMAND  [conn173] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 210 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965443, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4d256e84-3e21-4e11-a07b-185810f540c6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3660ms
2020-05-08T14:17:26.990-0500 I  NETWORK  [conn168] end connection 192.168.122.1:60192 (28 connections now open)
2020-05-08T14:17:27.021-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:27.521-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:27.521-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:27.560-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:27.561-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:27.561-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:28.021-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:28.185-0500 I  NETWORK  [conn172] end connection 192.168.122.1:60304 (27 connections now open)
2020-05-08T14:17:28.186-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60592 #178 (28 connections now open)
2020-05-08T14:17:28.186-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60594 #179 (29 connections now open)
2020-05-08T14:17:28.186-0500 I  NETWORK  [conn178] received client metadata from 192.168.122.1:60592 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:28.186-0500 I  NETWORK  [conn179] received client metadata from 192.168.122.1:60594 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:28.189-0500 I  -        [conn171] operation was interrupted because a client disconnected
2020-05-08T14:17:28.189-0500 I  NETWORK  [conn178] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:28.189-0500 I  CONNPOOL [conn171] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T14:17:28.189-0500 I  COMMAND  [conn171] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 211 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965442, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d2bbe2f-a950-477b-976c-f4106edb5546") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T14:17:28.189-0500 I  NETWORK  [conn171] end connection 192.168.122.1:60302 (28 connections now open)
2020-05-08T14:17:28.190-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:28.190-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:28.191-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:28.191-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:28.191-0500 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-08T14:17:28.328-0500 I  NETWORK  [conn174] end connection 192.168.122.1:60320 (27 connections now open)
2020-05-08T14:17:28.329-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60602 #181 (28 connections now open)
2020-05-08T14:17:28.329-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60606 #182 (29 connections now open)
2020-05-08T14:17:28.329-0500 I  NETWORK  [conn181] received client metadata from 192.168.122.1:60602 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:28.330-0500 I  NETWORK  [conn182] received client metadata from 192.168.122.1:60606 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:28.348-0500 I  COMMAND  [conn178] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 215 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c03a90b7-5d9d-46a6-b497-0656cbb40e85") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 160ms
2020-05-08T14:17:29.006-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965434, 11), t: 23 }, now { ts: Timestamp(1588965448, 18), t: 28 }
2020-05-08T14:17:29.365-0500 I  NETWORK  [conn178] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:29.366-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:29.367-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:29.567-0500 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588965448, 18), t: 28 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T14:17:29.867-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:29.867-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:29.869-0500 I  COMMAND  [conn181] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965448, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3aac1b9c-5008-4f17-a38b-aad92b741732") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1517ms
2020-05-08T14:17:30.090-0500 I  NETWORK  [conn177] end connection 192.168.122.1:60396 (28 connections now open)
2020-05-08T14:17:30.091-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60702 #183 (29 connections now open)
2020-05-08T14:17:30.091-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60704 #184 (30 connections now open)
2020-05-08T14:17:30.091-0500 I  NETWORK  [conn183] received client metadata from 192.168.122.1:60702 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:30.091-0500 I  NETWORK  [conn184] received client metadata from 192.168.122.1:60704 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:30.095-0500 I  -        [conn176] operation was interrupted because a client disconnected
2020-05-08T14:17:30.095-0500 I  CONNPOOL [conn176] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T14:17:30.095-0500 I  TXN      [conn176] transaction parameters:{ lsid: { id: UUID("09c945d0-7547-454a-a9b5-65d2eb5865f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965444, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004679, timeInactiveMicros:0, 5004ms
2020-05-08T14:17:30.096-0500 I  COMMAND  [conn176] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965444, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("09c945d0-7547-454a-a9b5-65d2eb5865f8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T14:17:30.096-0500 I  NETWORK  [conn176] end connection 192.168.122.1:60394 (29 connections now open)
2020-05-08T14:17:30.451-0500 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("c03a90b7-5d9d-46a6-b497-0656cbb40e85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965447, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2099797, timeActiveMicros:2262219, timeInactiveMicros:1349, 2263ms
2020-05-08T14:17:30.451-0500 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965448, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c03a90b7-5d9d-46a6-b497-0656cbb40e85") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2100ms
2020-05-08T14:17:30.452-0500 I  COMMAND  [conn181] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965449, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3aac1b9c-5008-4f17-a38b-aad92b741732") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 581ms
2020-05-08T14:17:31.453-0500 I  NETWORK  [conn181] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:31.453-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:31.953-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:32.453-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:32.954-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:33.330-0500 I  NETWORK  [conn182] end connection 192.168.122.1:60606 (28 connections now open)
2020-05-08T14:17:33.330-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60880 #185 (29 connections now open)
2020-05-08T14:17:33.331-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60882 #186 (30 connections now open)
2020-05-08T14:17:33.331-0500 I  NETWORK  [conn185] received client metadata from 192.168.122.1:60880 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:33.331-0500 I  NETWORK  [conn186] received client metadata from 192.168.122.1:60882 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:33.334-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:33.334-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:33.335-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:33.336-0500 I  COMMAND  [conn181] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965449, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3aac1b9c-5008-4f17-a38b-aad92b741732") }, txnNumber: 2, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2876ms
2020-05-08T14:17:33.336-0500 I  NETWORK  [conn181] end connection 192.168.122.1:60602 (29 connections now open)
2020-05-08T14:17:33.337-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:33.464-0500 I  COMMAND  [conn185] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 206 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965450, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0cc366c-a00f-4ea6-9568-d16022a3505b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 131ms
2020-05-08T14:17:33.465-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:17:33.836-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:34.336-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:34.337-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:34.338-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965448, 18), t: 28 }, now { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T14:17:35.091-0500 I  NETWORK  [conn184] end connection 192.168.122.1:60704 (28 connections now open)
2020-05-08T14:17:35.092-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60966 #188 (29 connections now open)
2020-05-08T14:17:35.092-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:60968 #189 (30 connections now open)
2020-05-08T14:17:35.092-0500 I  NETWORK  [conn188] received client metadata from 192.168.122.1:60966 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:35.092-0500 I  NETWORK  [conn189] received client metadata from 192.168.122.1:60968 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:35.094-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:17:35.453-0500 I  NETWORK  [conn179] end connection 192.168.122.1:60594 (29 connections now open)
2020-05-08T14:17:35.454-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:32814 #191 (30 connections now open)
2020-05-08T14:17:35.454-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:32818 #192 (31 connections now open)
2020-05-08T14:17:35.455-0500 I  NETWORK  [conn191] received client metadata from 192.168.122.1:32814 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:35.455-0500 I  NETWORK  [conn192] received client metadata from 192.168.122.1:32818 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:35.457-0500 I  NETWORK  [conn191] Marking host n9:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T14:17:35.458-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:35.459-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:35.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:17:35.959-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:35.959-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:35.960-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:35.961-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:36.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:36.961-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:37.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:37.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:38.331-0500 I  NETWORK  [conn186] end connection 192.168.122.1:60882 (30 connections now open)
2020-05-08T14:17:38.332-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:32914 #194 (31 connections now open)
2020-05-08T14:17:38.332-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:32916 #195 (32 connections now open)
2020-05-08T14:17:38.333-0500 I  NETWORK  [conn194] received client metadata from 192.168.122.1:32914 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:38.333-0500 I  NETWORK  [conn195] received client metadata from 192.168.122.1:32916 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:38.335-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:17:38.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:38.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:17:38.497-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:17:38.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:39.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:39.572-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:39.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:40.093-0500 I  NETWORK  [conn189] end connection 192.168.122.1:60968 (31 connections now open)
2020-05-08T14:17:40.093-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33054 #201 (32 connections now open)
2020-05-08T14:17:40.094-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33056 #202 (33 connections now open)
2020-05-08T14:17:40.094-0500 I  NETWORK  [conn201] received client metadata from 192.168.122.1:33054 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:40.094-0500 I  NETWORK  [conn202] received client metadata from 192.168.122.1:33056 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:40.096-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-08T14:17:40.461-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:40.462-0500 I  NETWORK  [conn192] end connection 192.168.122.1:32818 (32 connections now open)
2020-05-08T14:17:40.462-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33126 #204 (33 connections now open)
2020-05-08T14:17:40.462-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33128 #205 (34 connections now open)
2020-05-08T14:17:40.462-0500 I  NETWORK  [conn204] received client metadata from 192.168.122.1:33126 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:40.463-0500 I  NETWORK  [conn205] received client metadata from 192.168.122.1:33128 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:40.464-0500 I  NETWORK  [conn204] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:40.465-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:40.465-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:40.466-0500 I  -        [conn191] operation was interrupted because a client disconnected
2020-05-08T14:17:40.466-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:40.466-0500 I  CONNPOOL [conn191] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T14:17:40.467-0500 I  TXN      [conn191] transaction parameters:{ lsid: { id: UUID("d26f180b-cfac-4471-b00e-d3504942f394"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965453, 12) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005842, timeInactiveMicros:0, 5005ms
2020-05-08T14:17:40.467-0500 I  COMMAND  [conn191] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 223 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965453, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d26f180b-cfac-4471-b00e-d3504942f394") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T14:17:40.467-0500 I  NETWORK  [conn191] end connection 192.168.122.1:32814 (33 connections now open)
2020-05-08T14:17:40.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:41.461-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:41.462-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:41.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-08T14:17:41.479-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-08T14:17:42.062-0500 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:42.064-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:42.562-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:43.063-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:43.076-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:43.076-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:43.076-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-08T14:17:43.333-0500 I  NETWORK  [conn195] end connection 192.168.122.1:32916 (32 connections now open)
2020-05-08T14:17:43.334-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33252 #212 (33 connections now open)
2020-05-08T14:17:43.334-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33254 #213 (34 connections now open)
2020-05-08T14:17:43.334-0500 I  NETWORK  [conn212] received client metadata from 192.168.122.1:33252 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:43.334-0500 I  NETWORK  [conn213] received client metadata from 192.168.122.1:33254 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:43.340-0500 I  -        [conn194] operation was interrupted because a client disconnected
2020-05-08T14:17:43.340-0500 I  CONNPOOL [conn194] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T14:17:43.341-0500 I  COMMAND  [conn194] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 223 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965455, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("61045eb7-f09e-42be-b463-25442a77bdf7") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T14:17:43.341-0500 I  NETWORK  [conn194] end connection 192.168.122.1:32914 (33 connections now open)
2020-05-08T14:17:43.626-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:43.630-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:43.632-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:43.632-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:43.846-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5afdbf50ef7b0538edfc4 to 5eb5afdaa0224cfb413c7171; invalidating user cache
2020-05-08T14:17:43.885-0500 I  NETWORK  [conn212] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:43.886-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:44.127-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:44.385-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:44.386-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:44.387-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:44.435-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:44.627-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:45.094-0500 I  NETWORK  [conn202] end connection 192.168.122.1:33056 (32 connections now open)
2020-05-08T14:17:45.095-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33334 #214 (33 connections now open)
2020-05-08T14:17:45.095-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33336 #215 (34 connections now open)
2020-05-08T14:17:45.095-0500 I  NETWORK  [conn214] received client metadata from 192.168.122.1:33334 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:45.096-0500 I  NETWORK  [conn215] received client metadata from 192.168.122.1:33336 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:45.101-0500 I  -        [conn201] operation was interrupted because a client disconnected
2020-05-08T14:17:45.101-0500 I  CONNPOOL [conn201] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T14:17:45.101-0500 I  TXN      [conn201] transaction parameters:{ lsid: { id: UUID("de0f15aa-0b1f-44b0-8947-c0c096157cb6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965455, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005549, timeInactiveMicros:0, 5005ms
2020-05-08T14:17:45.101-0500 I  COMMAND  [conn201] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 224 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965455, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de0f15aa-0b1f-44b0-8947-c0c096157cb6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T14:17:45.102-0500 I  NETWORK  [conn201] end connection 192.168.122.1:33054 (33 connections now open)
2020-05-08T14:17:45.102-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:45.127-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:45.127-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:45.477-0500 I  NETWORK  [conn205] end connection 192.168.122.1:33128 (32 connections now open)
2020-05-08T14:17:45.478-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33418 #216 (33 connections now open)
2020-05-08T14:17:45.479-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33420 #217 (34 connections now open)
2020-05-08T14:17:45.479-0500 I  NETWORK  [conn216] received client metadata from 192.168.122.1:33418 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:45.479-0500 I  NETWORK  [conn217] received client metadata from 192.168.122.1:33420 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:45.482-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:45.484-0500 I  -        [conn204] operation was interrupted because a client disconnected
2020-05-08T14:17:45.484-0500 I  CONNPOOL [conn204] Ending connection to host n6:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T14:17:45.486-0500 I  TXN      [conn204] transaction parameters:{ lsid: { id: UUID("f7f6dd50-b289-4992-9295-5a773637d8f4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965460, 103) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5008763, timeInactiveMicros:415, 5009ms
2020-05-08T14:17:45.486-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:45.486-0500 I  COMMAND  [conn204] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 202 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965460, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f7f6dd50-b289-4992-9295-5a773637d8f4") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5007ms
2020-05-08T14:17:45.486-0500 I  NETWORK  [conn204] end connection 192.168.122.1:33126 (33 connections now open)
2020-05-08T14:17:45.601-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:45.656-0500 I  TXN      [conn212] transaction parameters:{ lsid: { id: UUID("fc9128e0-3d43-4d8a-a073-cc9f194eeaf9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965462, 14) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2312529, timeActiveMicros:2317723, timeInactiveMicros:2011, 2319ms
2020-05-08T14:17:45.657-0500 I  NETWORK  [conn212] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T14:17:45.657-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:46.157-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:46.199-0500 I  NETWORK  [replSetDistLockPinger] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:46.201-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:46.202-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/n7:27018,n8:27018,n9:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:46.309-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:46.601-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:46.657-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T14:17:46.699-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:47.101-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:47.157-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:47.157-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T14:17:47.158-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:47.158-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:47.158-0500 I  COMMAND  [conn212] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588965462, 169), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc9128e0-3d43-4d8a-a073-cc9f194eeaf9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:494 protocol:op_msg 3814ms
2020-05-08T14:17:47.159-0500 I  COMMAND  [conn214] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 230 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588965463, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de251c5f-a69c-4f44-9333-9f7343381840") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2061ms
2020-05-08T14:17:47.161-0500 I  TXN      [conn214] transaction parameters:{ lsid: { id: UUID("de251c5f-a69c-4f44-9333-9f7343381840"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588965463, 21) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2063370, timeInactiveMicros:731, 2064ms
2020-05-08T14:17:47.210-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:47.215-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:47.403-0500 I  NETWORK  [replSetDistLockPinger] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:47.403-0500 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T14:17:47.407-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:47.601-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:47.904-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:48.403-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:48.517-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:48.601-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:48.904-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:49.102-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:49.404-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:49.601-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:49.904-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:50.101-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:50.404-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:50.904-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:51.404-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:51.903-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T14:17:52.214-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33624 #218 (34 connections now open)
2020-05-08T14:17:52.215-0500 I  NETWORK  [conn218] received client metadata from 192.168.122.1:33624 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:52.218-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33628 #219 (35 connections now open)
2020-05-08T14:17:52.219-0500 I  NETWORK  [conn219] received client metadata from 192.168.122.1:33628 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:52.403-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:52.403-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-08T14:17:53.339-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588965453, 11), t: 29 }, now { ts: Timestamp(1588965471, 2), t: 35 }
2020-05-08T14:17:55.244-0500 I  NETWORK  [conn213] end connection 192.168.122.1:33254 (34 connections now open)
2020-05-08T14:17:55.244-0500 I  NETWORK  [conn215] end connection 192.168.122.1:33336 (33 connections now open)
2020-05-08T14:17:55.246-0500 I  NETWORK  [conn217] end connection 192.168.122.1:33420 (32 connections now open)
2020-05-08T14:17:55.252-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33680 #220 (33 connections now open)
2020-05-08T14:17:55.252-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:33688 #221 (34 connections now open)
2020-05-08T14:17:55.252-0500 I  NETWORK  [conn220] received client metadata from 192.168.122.1:33680 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:55.252-0500 I  NETWORK  [conn221] received client metadata from 192.168.122.1:33688 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T14:17:55.252-0500 I  NETWORK  [conn220] end connection 192.168.122.1:33680 (33 connections now open)
2020-05-08T14:17:55.253-0500 I  NETWORK  [conn221] end connection 192.168.122.1:33688 (32 connections now open)
2020-05-08T14:17:55.601-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n5:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 4094 timed out, deadline was 2020-05-08T14:17:55.601-0500, op was RemoteCommand 4094 -- target:[n5:27018] db:admin expDate:2020-05-08T14:17:55.601-0500 cmd:{ isMaster: 1 }
2020-05-08T14:17:55.601-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T14:17:55.601-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T14:17:55.601-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T14:17:55.601-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n5:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T14:17:55.602-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
