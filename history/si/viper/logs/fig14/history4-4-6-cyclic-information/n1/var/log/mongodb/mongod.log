2020-05-08T12:15:36.244-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T12:15:36.263-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=677173 port=27019 dbpath=/var/lib/mongodb 64-bit host=n1
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] modules: none
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] build environment:
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-08T12:15:36.263-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-08T12:15:36.264-0700 I  STORAGE  [initandlisten] 
2020-05-08T12:15:36.264-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-08T12:15:36.264-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-08T12:15:36.264-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-08T12:15:37.019-0700 I  STORAGE  [initandlisten] WiredTiger message [1588965337:19290][677173:0x7f656a8e0140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-08T12:15:37.071-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-08T12:15:37.116-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-08T12:15:37.140-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-08T12:15:37.142-0700 I  CONTROL  [initandlisten] 
2020-05-08T12:15:37.143-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-08T12:15:37.143-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-08T12:15:37.143-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-08T12:15:37.144-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-08T12:15:37.144-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 50560dbf-439f-4624-91ba-d99c60b84aa0 and options: { capped: true, size: 10485760 }
2020-05-08T12:15:37.195-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-08T12:15:37.196-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-08T12:15:37.196-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-08T12:15:37.202-0700 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-05-08T12:15:37.202-0700 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-05-08T12:15:37.202-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 1756a840-36be-4be7-82cd-1fb778e5d988 and options: {}
2020-05-08T12:15:37.252-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-08T12:15:37.252-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 94368f12-06e0-49cd-a456-a8431f2afa2e and options: {}
2020-05-08T12:15:37.306-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-08T12:15:37.306-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-08T12:15:37.306-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 8944fc99-12f3-46e3-8dd7-b65da1bd8019 and options: {}
2020-05-08T12:15:37.363-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-08T12:15:37.363-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-08T12:15:37.363-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-08T12:15:37.363-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-08T12:15:37.363-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 92ea7c76-198f-403d-b7c5-56541abb6346 and options: {}
2020-05-08T12:15:37.415-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-08T12:15:37.416-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-08T12:15:37.416-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-08T12:15:37.416-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-08T12:15:37.418-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("47d024d8-75de-4a8b-8586-af5c36d9e1fc"), lastMod: 0 } took 0 ms
2020-05-08T12:15:37.418-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-05-08T12:15:37.418-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T12:15:37.418-0700 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-05-08T12:15:37.418-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-05-08T12:15:37.418-0700 I  NETWORK  [listener] waiting for connections on port 27019
2020-05-08T12:15:37.418-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-05-08T12:15:38.000-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-08T12:15:38.295-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42332 #1 (1 connection now open)
2020-05-08T12:15:38.296-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:42332 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:38.297-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42346 #2 (2 connections now open)
2020-05-08T12:15:38.297-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:42346 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:38.300-0700 I  NETWORK  [conn1] end connection 192.168.122.1:42332 (1 connection now open)
2020-05-08T12:15:38.300-0700 I  NETWORK  [conn2] end connection 192.168.122.1:42346 (0 connections now open)
2020-05-08T12:15:38.302-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42356 #3 (1 connection now open)
2020-05-08T12:15:38.302-0700 I  NETWORK  [conn3] received client metadata from 192.168.122.1:42356 conn3: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:38.302-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42362 #4 (2 connections now open)
2020-05-08T12:15:38.302-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.1:42362 conn4: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:38.310-0700 I  REPL     [conn3] replSetInitiate admin command received from client
2020-05-08T12:15:38.335-0700 I  REPL     [conn3] replSetInitiate config object with 3 members parses ok
2020-05-08T12:15:38.335-0700 I  REPL     [conn3] Scheduling remote command request for initiate quorum check: RemoteCommand 1 -- target:n2:27019 db:admin cmd:{ replSetHeartbeat: "rs_config", checkEmpty: true, configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 0 }
2020-05-08T12:15:38.335-0700 I  REPL     [conn3] Scheduling remote command request for initiate quorum check: RemoteCommand 2 -- target:n3:27019 db:admin cmd:{ replSetHeartbeat: "rs_config", checkEmpty: true, configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 0 }
2020-05-08T12:15:38.336-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:15:38.336-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:15:38.338-0700 I  REPL     [conn3] ******
2020-05-08T12:15:38.338-0700 I  REPL     [conn3] creating replication oplog of size: 36644MB...
2020-05-08T12:15:38.338-0700 I  STORAGE  [conn3] createCollection: local.oplog.rs with generated UUID: f7f62259-cbe7-4829-8f23-1a29f926096a and options: { capped: true, size: 38424031027.0, autoIndexId: false }
2020-05-08T12:15:38.340-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40308 #9 (3 connections now open)
2020-05-08T12:15:38.343-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58244 #10 (4 connections now open)
2020-05-08T12:15:38.343-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.12:40308 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:38.344-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.13:58244 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:38.361-0700 I  STORAGE  [conn3] Starting OplogTruncaterThread local.oplog.rs
2020-05-08T12:15:38.361-0700 I  STORAGE  [conn3] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-08T12:15:38.361-0700 I  STORAGE  [conn3] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:15:38.361-0700 I  STORAGE  [conn3] WiredTiger record store oplog processing took 0ms
2020-05-08T12:15:38.490-0700 I  REPL     [conn3] ******
2020-05-08T12:15:38.490-0700 I  STORAGE  [conn3] createCollection: local.system.replset with generated UUID: 572881be-8ec6-4bc0-abe7-8c0dd4cf36f3 and options: {}
2020-05-08T12:15:38.532-0700 I  INDEX    [conn3] index build: done building index _id_ on ns local.system.replset
2020-05-08T12:15:38.535-0700 I  SHARDING [conn3] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-08T12:15:38.536-0700 I  STORAGE  [conn3] createCollection: admin.system.version with provided UUID: 9776b654-fbe0-4ade-a717-5da68907cd8a and options: { uuid: UUID("9776b654-fbe0-4ade-a717-5da68907cd8a") }
2020-05-08T12:15:38.586-0700 I  INDEX    [conn3] index build: done building index _id_ on ns admin.system.version
2020-05-08T12:15:38.586-0700 I  COMMAND  [conn3] setting featureCompatibilityVersion to 4.2
2020-05-08T12:15:38.586-0700 I  NETWORK  [conn3] Skip closing connection for connection # 10
2020-05-08T12:15:38.586-0700 I  NETWORK  [conn3] Skip closing connection for connection # 9
2020-05-08T12:15:38.586-0700 I  NETWORK  [conn3] Skip closing connection for connection # 4
2020-05-08T12:15:38.586-0700 I  NETWORK  [conn3] Skip closing connection for connection # 3
2020-05-08T12:15:38.586-0700 I  REPL     [conn3] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n1:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n2:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n3:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb5afdaa0224cfb413c716c') } }
2020-05-08T12:15:38.586-0700 I  REPL     [conn3] This node is n1:27019 in the config
2020-05-08T12:15:38.587-0700 I  REPL     [conn3] transition to STARTUP2 from STARTUP
2020-05-08T12:15:38.587-0700 I  REPL     [conn3] Starting replication storage threads
2020-05-08T12:15:38.588-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP
2020-05-08T12:15:38.588-0700 I  REPL     [replexec-1] Member n3:27019 is now in state STARTUP
2020-05-08T12:15:38.590-0700 I  REPL     [conn3] transition to RECOVERING from STARTUP2
2020-05-08T12:15:38.590-0700 I  REPL     [conn3] Starting replication fetcher thread
2020-05-08T12:15:38.590-0700 I  REPL     [conn3] Starting replication applier thread
2020-05-08T12:15:38.591-0700 I  REPL     [conn3] Starting replication reporter thread
2020-05-08T12:15:38.591-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-08T12:15:38.591-0700 I  COMMAND  [conn3] command local.oplog.rs command: replSetInitiate { replSetInitiate: { _id: "rs_config", configsvr: true, settings: { heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000 }, members: [ { _id: 0, priority: 3, host: "n1:27019" }, { _id: 1, priority: 2, host: "n2:27019" }, { _id: 2, priority: 1, host: "n3:27019" } ] }, $db: "admin", $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "primaryPreferred" } } numYields:0 reslen:252 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 19 } }, ReplicationStateTransition: { acquireCount: { w: 19 } }, Global: { acquireCount: { r: 4, w: 13, W: 2 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 64 } }, Database: { acquireCount: { r: 2, w: 9, W: 4 } }, Collection: { acquireCount: { r: 2, w: 2, W: 13 } }, Mutex: { acquireCount: { r: 16 } }, oplog: { acquireCount: { r: 1, w: 1, W: 1 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 280ms
2020-05-08T12:15:38.591-0700 I  REPL     [rsBackgroundSync] waiting for 2 pings from other members before syncing
2020-05-08T12:15:38.591-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-08T12:15:38.591-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-08T12:15:38.870-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40362 #11 (5 connections now open)
2020-05-08T12:15:38.871-0700 I  NETWORK  [conn11] end connection 192.168.122.12:40362 (4 connections now open)
2020-05-08T12:15:38.877-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58302 #12 (5 connections now open)
2020-05-08T12:15:38.877-0700 I  NETWORK  [conn12] end connection 192.168.122.13:58302 (4 connections now open)
2020-05-08T12:15:39.088-0700 I  REPL     [replexec-1] Member n2:27019 is now in state STARTUP2
2020-05-08T12:15:39.089-0700 I  REPL     [replexec-0] Member n3:27019 is now in state STARTUP2
2020-05-08T12:15:39.469-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40392 #13 (5 connections now open)
2020-05-08T12:15:39.469-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.12:40392 conn13: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:39.470-0700 I  SHARDING [conn13] Marking collection config.transactions as collection version: <unsharded>
2020-05-08T12:15:39.472-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40396 #14 (6 connections now open)
2020-05-08T12:15:39.472-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.12:40396 conn14: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:39.480-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58334 #15 (7 connections now open)
2020-05-08T12:15:39.481-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.13:58334 conn15: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:39.483-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58336 #16 (8 connections now open)
2020-05-08T12:15:39.483-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.13:58336 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:39.601-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40414 #17 (9 connections now open)
2020-05-08T12:15:39.601-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.12:40414 conn17: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:39.603-0700 I  NETWORK  [conn17] end connection 192.168.122.12:40414 (8 connections now open)
2020-05-08T12:15:39.615-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58350 #18 (9 connections now open)
2020-05-08T12:15:39.615-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.13:58350 conn18: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:39.616-0700 I  NETWORK  [conn18] end connection 192.168.122.13:58350 (8 connections now open)
2020-05-08T12:15:39.676-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:15:39.676-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 0
2020-05-08T12:15:39.676-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 9 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965338, 1), t: -1 } }
2020-05-08T12:15:39.676-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 10 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965338, 1), t: -1 } }
2020-05-08T12:15:39.678-0700 I  ELECTION [replexec-1] VoteRequester(term 0 dry run) received a yes vote from n2:27019; response message: { term: 0, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1588965338, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965338, 1) }
2020-05-08T12:15:39.678-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 1
2020-05-08T12:15:39.694-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 11 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965338, 1), t: -1 } }
2020-05-08T12:15:39.694-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 12 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965338, 1), t: -1 } }
2020-05-08T12:15:39.708-0700 I  ELECTION [replexec-2] VoteRequester(term 1) received a yes vote from n2:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1588965338, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965338, 1) }
2020-05-08T12:15:39.709-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 1
2020-05-08T12:15:39.709-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-08T12:15:39.709-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-08T12:15:39.709-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-08T12:15:39.710-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-08T12:15:39.711-0700 I  REPL     [replexec-2] Member n3:27019 is now in state SECONDARY
2020-05-08T12:15:39.711-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965338, 1), t: -1 }. My Last Applied: { ts: Timestamp(1588965338, 1), t: -1 }
2020-05-08T12:15:39.711-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-08T12:15:39.711-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-08T12:15:39.711-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 1
2020-05-08T12:15:39.711-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:15:39.712-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:15:39.712-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-08T12:15:39.712-0700 I  STORAGE  [rsSync-0] createCollection: config.transactions with generated UUID: 102592d2-904e-4bad-918e-733bcd99a988 and options: {}
2020-05-08T12:15:39.800-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.transactions
2020-05-08T12:15:39.801-0700 I  STORAGE  [rsSync-0] createCollection: config.chunks with provided UUID: 2d652394-987f-4aa4-a6e9-0606d5d5533d and options: { uuid: UUID("2d652394-987f-4aa4-a6e9-0606d5d5533d") }
2020-05-08T12:15:39.856-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.chunks
2020-05-08T12:15:39.856-0700 I  SHARDING [rsSync-0] Marking collection config.chunks as collection version: <unsharded>
2020-05-08T12:15:39.936-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-08T12:15:39.937-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:39.937-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:39.938-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:39.953-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-05-08T12:15:39.968-0700 I  COMMAND  [rsSync-0] command config.chunks command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 167ms
2020-05-08T12:15:40.044-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-08T12:15:40.044-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.044-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.046-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.053-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-05-08T12:15:40.071-0700 I  COMMAND  [rsSync-0] command config.chunks command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_shard_1_min_1", key: { ns: 1, shard: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 2, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 102ms
2020-05-08T12:15:40.141-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-05-08T12:15:40.141-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.141-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.143-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.152-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-05-08T12:15:40.166-0700 I  STORAGE  [rsSync-0] createCollection: config.migrations with provided UUID: 2a55a29f-6ce9-4f79-b893-278af01d545c and options: { uuid: UUID("2a55a29f-6ce9-4f79-b893-278af01d545c") }
2020-05-08T12:15:40.214-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.migrations
2020-05-08T12:15:40.214-0700 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-05-08T12:15:40.290-0700 I  INDEX    [rsSync-0] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-05-08T12:15:40.291-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.291-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.292-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.303-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.migrations
2020-05-08T12:15:40.319-0700 I  COMMAND  [rsSync-0] command config.migrations command: createIndexes { createIndexes: "migrations", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 152ms
2020-05-08T12:15:40.319-0700 I  STORAGE  [rsSync-0] createCollection: config.shards with provided UUID: f0fccbd1-5de7-40cd-aa99-5999ae922b22 and options: { uuid: UUID("f0fccbd1-5de7-40cd-aa99-5999ae922b22") }
2020-05-08T12:15:40.364-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.shards
2020-05-08T12:15:40.364-0700 I  SHARDING [rsSync-0] Marking collection config.shards as collection version: <unsharded>
2020-05-08T12:15:40.437-0700 I  INDEX    [rsSync-0] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-05-08T12:15:40.437-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.438-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.439-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.449-0700 I  INDEX    [rsSync-0] index build: done building index host_1 on ns config.shards
2020-05-08T12:15:40.463-0700 I  COMMAND  [rsSync-0] command config.shards command: createIndexes { createIndexes: "shards", indexes: [ { name: "host_1", key: { host: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 144ms
2020-05-08T12:15:40.463-0700 I  STORAGE  [rsSync-0] createCollection: config.locks with provided UUID: f67e3cf8-f609-40d5-b10f-51cc8df9bd92 and options: { uuid: UUID("f67e3cf8-f609-40d5-b10f-51cc8df9bd92") }
2020-05-08T12:15:40.522-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.locks
2020-05-08T12:15:40.594-0700 I  INDEX    [rsSync-0] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-05-08T12:15:40.594-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.594-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.595-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.596-0700 I  NETWORK  [conn3] end connection 192.168.122.1:42356 (7 connections now open)
2020-05-08T12:15:40.597-0700 I  NETWORK  [conn4] end connection 192.168.122.1:42362 (6 connections now open)
2020-05-08T12:15:40.603-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42528 #19 (7 connections now open)
2020-05-08T12:15:40.603-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:42528 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:40.604-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42544 #20 (8 connections now open)
2020-05-08T12:15:40.605-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:42544 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:40.611-0700 I  NETWORK  [conn19] end connection 192.168.122.1:42528 (7 connections now open)
2020-05-08T12:15:40.611-0700 I  NETWORK  [conn20] end connection 192.168.122.1:42544 (6 connections now open)
2020-05-08T12:15:40.611-0700 I  INDEX    [rsSync-0] index build: done building index ts_1 on ns config.locks
2020-05-08T12:15:40.622-0700 I  COMMAND  [rsSync-0] command config.locks command: createIndexes { createIndexes: "locks", indexes: [ { name: "ts_1", key: { ts: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 158ms
2020-05-08T12:15:40.724-0700 I  INDEX    [rsSync-0] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-05-08T12:15:40.725-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.725-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.729-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.747-0700 I  INDEX    [rsSync-0] index build: done building index state_1_process_1 on ns config.locks
2020-05-08T12:15:40.772-0700 I  COMMAND  [rsSync-0] command config.locks command: createIndexes { createIndexes: "locks", indexes: [ { name: "state_1_process_1", key: { state: 1, process: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 2, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 149ms
2020-05-08T12:15:40.772-0700 I  STORAGE  [rsSync-0] createCollection: config.lockpings with provided UUID: 81acf486-601b-4e2b-8ee1-bbf74a1edd96 and options: { uuid: UUID("81acf486-601b-4e2b-8ee1-bbf74a1edd96") }
2020-05-08T12:15:40.873-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.lockpings
2020-05-08T12:15:40.973-0700 I  INDEX    [rsSync-0] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-05-08T12:15:40.974-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:40.974-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:40.976-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:40.998-0700 I  INDEX    [rsSync-0] index build: done building index ping_1 on ns config.lockpings
2020-05-08T12:15:41.012-0700 I  COMMAND  [rsSync-0] command config.lockpings command: createIndexes { createIndexes: "lockpings", indexes: [ { name: "ping_1", key: { ping: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 240ms
2020-05-08T12:15:41.012-0700 I  STORAGE  [rsSync-0] createCollection: config.tags with provided UUID: bc4858df-e110-456c-83bd-e519d850f168 and options: { uuid: UUID("bc4858df-e110-456c-83bd-e519d850f168") }
2020-05-08T12:15:41.054-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.tags
2020-05-08T12:15:41.054-0700 I  SHARDING [rsSync-0] Marking collection config.tags as collection version: <unsharded>
2020-05-08T12:15:41.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:38926 #21 (7 connections now open)
2020-05-08T12:15:41.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58440 #22 (8 connections now open)
2020-05-08T12:15:41.269-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.11:38926 conn21: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.269-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.13:58440 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:46882 #23 (9 connections now open)
2020-05-08T12:15:41.270-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.16:46882 conn23: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58456 #24 (10 connections now open)
2020-05-08T12:15:41.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:38954 #25 (11 connections now open)
2020-05-08T12:15:41.270-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.13:58456 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.271-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.11:38954 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.271-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:46898 #26 (12 connections now open)
2020-05-08T12:15:41.271-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.16:46898 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.275-0700 I  INDEX    [rsSync-0] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-05-08T12:15:41.275-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:41.275-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:41.276-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:41.287-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.tags
2020-05-08T12:15:41.289-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38570 #27 (13 connections now open)
2020-05-08T12:15:41.289-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.15:38570 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.290-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45508 #28 (14 connections now open)
2020-05-08T12:15:41.290-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.14:45508 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.290-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38582 #29 (15 connections now open)
2020-05-08T12:15:41.291-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38584 #30 (16 connections now open)
2020-05-08T12:15:41.291-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.15:38582 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.291-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.15:38584 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.296-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36172 #31 (17 connections now open)
2020-05-08T12:15:41.297-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.19:36172 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.298-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43856 #32 (18 connections now open)
2020-05-08T12:15:41.298-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.18:43856 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.300-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33140 #33 (19 connections now open)
2020-05-08T12:15:41.300-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.17:33140 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.303-0700 I  COMMAND  [rsSync-0] command config.tags command: createIndexes { createIndexes: "tags", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 290ms
2020-05-08T12:15:41.313-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40572 #34 (20 connections now open)
2020-05-08T12:15:41.313-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.12:40572 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.339-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36226 #35 (21 connections now open)
2020-05-08T12:15:41.340-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45576 #36 (22 connections now open)
2020-05-08T12:15:41.340-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.19:36226 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.340-0700 I  NETWORK  [conn36] received client metadata from 192.168.122.14:45576 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.340-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33204 #37 (23 connections now open)
2020-05-08T12:15:41.340-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40632 #38 (24 connections now open)
2020-05-08T12:15:41.340-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.17:33204 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.341-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.12:40632 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.341-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40636 #39 (25 connections now open)
2020-05-08T12:15:41.341-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.12:40636 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.354-0700 I  INDEX    [rsSync-0] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-05-08T12:15:41.354-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-08T12:15:41.354-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-08T12:15:41.356-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-08T12:15:41.365-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-05-08T12:15:41.374-0700 I  SHARDING [rsSync-0] Marking collection config.version as collection version: <unsharded>
2020-05-08T12:15:41.375-0700 I  STORAGE  [rsSync-0] createCollection: config.version with generated UUID: bed99a80-dcc6-4152-9366-8222f3d1172a and options: {}
2020-05-08T12:15:41.404-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.version
2020-05-08T12:15:41.405-0700 I  SHARDING [rsSync-0] Marking collection config.locks as collection version: <unsharded>
2020-05-08T12:15:41.406-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:15:41.406-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-05-08T12:15:41.407-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:15:41.407-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Marking collection config.collections as collection version: <unsharded>
2020-05-08T12:15:41.407-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-05-08T12:15:41.407-0700 I  NETWORK  [conn13] end connection 192.168.122.12:40392 (23 connections now open)
2020-05-08T12:15:41.407-0700 I  NETWORK  [conn16] end connection 192.168.122.13:58336 (24 connections now open)
2020-05-08T12:15:41.408-0700 I  COMMAND  [conn14] command local.oplog.rs command: find { find: "oplog.rs", limit: 1, sort: { $natural: 1 }, projection: { ts: 1, t: 1 }, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1588965340, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 queryHash:B04BA76E planCacheKey:B04BA76E reslen:337 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 750008 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 750ms
2020-05-08T12:15:41.408-0700 I  COMMAND  [conn15] command local.oplog.rs command: find { find: "oplog.rs", limit: 1, sort: { $natural: 1 }, projection: { ts: 1, t: 1 }, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1588965340, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 queryHash:B04BA76E planCacheKey:B04BA76E reslen:337 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 726902 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 727ms
2020-05-08T12:15:41.409-0700 I  COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after electionMetrics: 0, after extra_info: 0, after flowControl: 0, after freeMonitoring: 0, after globalLock: 0, after locks: 0, after logicalSessionRecordCache: 0, after network: 0, after opLatencies: 0, after opReadConcernCounters: 0, after opcounters: 0, after opcountersRepl: 0, after oplogTruncation: 1407, after repl: 1407, after security: 1407, after shardedIndexConsistency: 1407, after shardingStatistics: 1407, after storageEngine: 1407, after tcmalloc: 1407, after trafficRecording: 1407, after transactions: 1407, after transportSecurity: 1407, after twoPhaseCommitCoordinator: 1407, after wiredTiger: 1408, at end: 1408 }
2020-05-08T12:15:41.411-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40644 #40 (24 connections now open)
2020-05-08T12:15:41.411-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.12:40644 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.463-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58580 #41 (25 connections now open)
2020-05-08T12:15:41.464-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.13:58580 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.464-0700 I  STORAGE  [conn14] Triggering the first stable checkpoint. Initial Data: Timestamp(1588965338, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1588965339, 3)
2020-05-08T12:15:41.464-0700 I  SHARDING [conn24] Marking collection admin.system.keys as collection version: <unsharded>
2020-05-08T12:15:41.464-0700 I  COMMAND  [conn37] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 123ms
2020-05-08T12:15:41.464-0700 I  COMMAND  [conn24] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 193ms
2020-05-08T12:15:41.769-0700 I  SHARDING [conn24] Marking collection config.lockpings as collection version: <unsharded>
2020-05-08T12:15:41.769-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39074 #42 (26 connections now open)
2020-05-08T12:15:41.770-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.11:39074 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.770-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:47016 #43 (27 connections now open)
2020-05-08T12:15:41.771-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.16:47016 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.790-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38686 #44 (28 connections now open)
2020-05-08T12:15:41.790-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.15:38686 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.790-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45618 #45 (29 connections now open)
2020-05-08T12:15:41.791-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.14:45618 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.798-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36272 #46 (30 connections now open)
2020-05-08T12:15:41.798-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.19:36272 conn46: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.799-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43950 #47 (31 connections now open)
2020-05-08T12:15:41.799-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.18:43950 conn47: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:41.814-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40660 #48 (32 connections now open)
2020-05-08T12:15:41.815-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.12:40660 conn48: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.042-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36296 #49 (33 connections now open)
2020-05-08T12:15:42.042-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40682 #50 (34 connections now open)
2020-05-08T12:15:42.043-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.19:36296 conn49: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.043-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.12:40682 conn50: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.066-0700 I  COMMAND  [conn30] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 775ms
2020-05-08T12:15:42.066-0700 I  COMMAND  [conn25] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 795ms
2020-05-08T12:15:42.066-0700 I  COMMAND  [conn26] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 794ms
2020-05-08T12:15:42.067-0700 I  COMMAND  [conn38] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 725ms
2020-05-08T12:15:42.067-0700 I  COMMAND  [conn36] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 726ms
2020-05-08T12:15:42.070-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:58618 #51 (35 connections now open)
2020-05-08T12:15:42.070-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33260 #52 (36 connections now open)
2020-05-08T12:15:42.070-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.13:58618 conn51: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.070-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.17:33260 conn52: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.243-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43980 #53 (37 connections now open)
2020-05-08T12:15:42.243-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.18:43980 conn53: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:42.597-0700 I  COMMAND  [conn29] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:550 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 1306ms
2020-05-08T12:15:42.597-0700 I  COMMAND  [conn39] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:550 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 1255ms
2020-05-08T12:15:42.597-0700 I  COMMAND  [conn35] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:1 nreturned:0 reslen:550 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 1256ms
2020-05-08T12:15:42.607-0700 I  SHARDING [Balancer] Marking collection config.settings as collection version: <unsharded>
2020-05-08T12:15:42.607-0700 I  COMMAND  [conn45] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27017:1588965341:3187934225528271170" }, update: { $set: { ping: new Date(1588965341289) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 816ms
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn37] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27017:1588965341:6871791939861018853" }, update: { $set: { ping: new Date(1588965341300) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965341, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(1588965340, 1), t: 1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 807ms
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn43] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27017:1588965341:-562014436095676681" }, update: { $set: { ping: new Date(1588965341269) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 836ms
2020-05-08T12:15:42.608-0700 I  STORAGE  [monitoring-keys-for-HMAC] createCollection: admin.system.keys with generated UUID: d89be7fe-6053-4310-be2b-4bff25fadfb8 and options: {}
2020-05-08T12:15:42.608-0700 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn44] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27017:1588965341:-4005854753316312821" }, update: { $set: { ping: new Date(1588965341288) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 817ms
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn48] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n2:27017:1588965341:-7408192429411933944" }, update: { $set: { ping: new Date(1588965341312) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 792ms
2020-05-08T12:15:42.608-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn24] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n3:27017:1588965341:-8033712167525645570" }, update: { $set: { ping: new Date(1588965341268) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965341, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(1588965340, 1), t: 1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 839ms
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn42] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1588965341:7325128125104408104" }, update: { $set: { ping: new Date(1588965341268) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 837ms
2020-05-08T12:15:42.608-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn46] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27017:1588965341:2106346409928220643" }, update: { $set: { ping: new Date(1588965341296) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 808ms
2020-05-08T12:15:42.608-0700 I  COMMAND  [conn47] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27017:1588965341:-4138072281809841771" }, update: { $set: { ping: new Date(1588965341297) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 807ms
2020-05-08T12:15:42.608-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:15:42.608-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:15:42.645-0700 I  INDEX    [monitoring-keys-for-HMAC] index build: done building index _id_ on ns admin.system.keys
2020-05-08T12:15:43.606-0700 I  SHARDING [conn48] Marking collection config.mongos as collection version: <unsharded>
2020-05-08T12:15:43.606-0700 I  STORAGE  [conn48] createCollection: config.mongos with generated UUID: ed1a62fa-1d96-460b-b917-f8098f56b82b and options: {}
2020-05-08T12:15:43.647-0700 I  INDEX    [conn48] index build: done building index _id_ on ns config.mongos
2020-05-08T12:15:45.363-0700 I  NETWORK  [conn42] Starting new replica set monitor for rs_shard1/n4:27018
2020-05-08T12:15:45.363-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-08T12:15:45.366-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:15:45.366-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-08T12:15:45.366-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-08T12:15:45.375-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45804 #58 (38 connections now open)
2020-05-08T12:15:45.376-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.14:45804 conn58: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.378-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45818 #59 (39 connections now open)
2020-05-08T12:15:45.378-0700 I  NETWORK  [conn59] received client metadata from 192.168.122.14:45818 conn59: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.378-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45826 #60 (40 connections now open)
2020-05-08T12:15:45.379-0700 I  NETWORK  [conn60] received client metadata from 192.168.122.14:45826 conn60: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.382-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38900 #61 (41 connections now open)
2020-05-08T12:15:45.382-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:47238 #62 (42 connections now open)
2020-05-08T12:15:45.383-0700 I  NETWORK  [conn61] received client metadata from 192.168.122.15:38900 conn61: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.383-0700 I  NETWORK  [conn62] received client metadata from 192.168.122.16:47238 conn62: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.384-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38912 #63 (43 connections now open)
2020-05-08T12:15:45.385-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38914 #64 (44 connections now open)
2020-05-08T12:15:45.385-0700 I  NETWORK  [conn63] received client metadata from 192.168.122.15:38912 conn63: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.385-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.15:38914 conn64: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.385-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:47248 #65 (45 connections now open)
2020-05-08T12:15:45.386-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.16:47248 conn65: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.386-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:47250 #66 (46 connections now open)
2020-05-08T12:15:45.386-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38920 #67 (47 connections now open)
2020-05-08T12:15:45.386-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.16:47250 conn66: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.386-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.15:38920 conn67: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.413-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:45854 #68 (48 connections now open)
2020-05-08T12:15:45.414-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.14:45854 conn68: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.446-0700 I  SHARDING [conn42] going to insert new entry for shard into config.shards: { _id: "rs_shard1", host: "rs_shard1/n4:27018,n5:27018,n6:27018", state: 1 }
2020-05-08T12:15:45.449-0700 I  STORAGE  [conn42] createCollection: config.changelog with generated UUID: b5b04cc3-7329-463d-9284-d3319d7ed8dd and options: { capped: true, size: 209715200 }
2020-05-08T12:15:45.491-0700 I  INDEX    [conn42] index build: done building index _id_ on ns config.changelog
2020-05-08T12:15:45.539-0700 I  SHARDING [conn42] about to log metadata event into changelog: { _id: "n1:27019-2020-05-08T12:15:45.539-0700-5eb5afe1a0224cfb413c73b5", server: "n1:27019", shard: "config", clientAddr: "192.168.122.11:39074", time: new Date(1588965345539), what: "addShard", ns: "", details: { name: "rs_shard1", host: "rs_shard1/n4:27018" } }
2020-05-08T12:15:45.539-0700 I  SHARDING [conn42] Marking collection config.changelog as collection version: <unsharded>
2020-05-08T12:15:45.550-0700 I  COMMAND  [conn42] command admin.$cmd command: _configsvrAddShard { _configsvrAddShard: "rs_shard1/n4:27018", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("38c4fcd1-3381-4c7e-b908-36854209da84"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:60616", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 7), t: 1 } }, $db: "admin" } numYields:0 reslen:531 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 6 } }, Global: { acquireCount: { r: 3, w: 3 } }, Database: { acquireCount: { r: 3, w: 3 } }, Collection: { acquireCount: { r: 4, w: 2, W: 1 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 10, W: 1 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 188ms
2020-05-08T12:15:45.555-0700 I  NETWORK  [conn42] Starting new replica set monitor for rs_shard2/n7:27018
2020-05-08T12:15:45.555-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-08T12:15:45.558-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:15:45.558-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-08T12:15:45.558-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-08T12:15:45.567-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33488 #73 (49 connections now open)
2020-05-08T12:15:45.568-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.17:33488 conn73: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.570-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33490 #74 (50 connections now open)
2020-05-08T12:15:45.570-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.17:33490 conn74: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.570-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33494 #75 (51 connections now open)
2020-05-08T12:15:45.571-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.17:33494 conn75: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.571-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:44214 #76 (52 connections now open)
2020-05-08T12:15:45.572-0700 I  NETWORK  [conn76] received client metadata from 192.168.122.18:44214 conn76: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.572-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36548 #77 (53 connections now open)
2020-05-08T12:15:45.573-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.19:36548 conn77: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.574-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:44226 #78 (54 connections now open)
2020-05-08T12:15:45.575-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:44230 #79 (55 connections now open)
2020-05-08T12:15:45.575-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.18:44226 conn78: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.575-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36556 #80 (56 connections now open)
2020-05-08T12:15:45.575-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.18:44230 conn79: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.576-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:36558 #81 (57 connections now open)
2020-05-08T12:15:45.576-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.19:36556 conn80: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.576-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:44236 #82 (58 connections now open)
2020-05-08T12:15:45.577-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.19:36558 conn81: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.577-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.18:44236 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.597-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33532 #83 (59 connections now open)
2020-05-08T12:15:45.598-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.17:33532 conn83: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:45.639-0700 I  SHARDING [conn42] going to insert new entry for shard into config.shards: { _id: "rs_shard2", host: "rs_shard2/n7:27018,n8:27018,n9:27018", state: 1 }
2020-05-08T12:15:45.640-0700 I  SHARDING [conn42] about to log metadata event into changelog: { _id: "n1:27019-2020-05-08T12:15:45.640-0700-5eb5afe1a0224cfb413c73f1", server: "n1:27019", shard: "config", clientAddr: "192.168.122.11:39074", time: new Date(1588965345640), what: "addShard", ns: "", details: { name: "rs_shard2", host: "rs_shard2/n7:27018" } }
2020-05-08T12:15:45.683-0700 I  SHARDING [conn42] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c7406
2020-05-08T12:15:45.683-0700 I  SHARDING [conn42] Marking collection config.databases as collection version: <unsharded>
2020-05-08T12:15:45.688-0700 I  SHARDING [conn42] Registering new database { _id: "jepsendb", primary: "rs_shard1", partitioned: false, version: { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } } in sharding catalog
2020-05-08T12:15:45.689-0700 I  STORAGE  [conn42] createCollection: config.databases with generated UUID: ca3f968d-1e40-42a7-82a2-1fb918dba4dd and options: {}
2020-05-08T12:15:45.722-0700 I  INDEX    [conn42] index build: done building index _id_ on ns config.databases
2020-05-08T12:15:45.774-0700 I  SHARDING [conn42] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:45.788-0700 I  SHARDING [conn42] distributed lock with ts: 5eb5afe1a0224cfb413c7406' unlocked.
2020-05-08T12:15:45.789-0700 I  COMMAND  [conn42] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("18ff84d3-9f90-4e4a-ba7b-911c7de15f2d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965345, 12), signature: { hash: BinData(0, 33B8368DB4CEE2AAF0EBC5ED5D205D1DBB49097A), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:60764", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965345, 12), t: 1 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 6 } }, ReplicationStateTransition: { acquireCount: { w: 7 } }, Global: { acquireCount: { r: 1, w: 6 } }, Database: { acquireCount: { r: 1, w: 6 } }, Collection: { acquireCount: { r: 4, w: 5, W: 1 } }, Mutex: { acquireCount: { r: 12 } } } flowControl:{ acquireCount: 6, timeAcquiringMicros: 5 } storage:{} protocol:op_msg 117ms
2020-05-08T12:15:45.798-0700 I  SHARDING [conn42] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe1a0224cfb413c7466
2020-05-08T12:15:45.807-0700 I  SHARDING [conn42] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe1a0224cfb413c746d
2020-05-08T12:15:45.889-0700 I  SHARDING [conn42] distributed lock with ts: 5eb5afe1a0224cfb413c746d' unlocked.
2020-05-08T12:15:45.896-0700 I  SHARDING [conn42] distributed lock with ts: 5eb5afe1a0224cfb413c7466' unlocked.
2020-05-08T12:15:45.897-0700 I  COMMAND  [conn42] command admin.$cmd command: _configsvrCreateCollection { _configsvrCreateCollection: "jepsendb.jepsencoll", options: { capped: false, writeConcern: { w: "majority" }, lsid: { id: UUID("18ff84d3-9f90-4e4a-ba7b-911c7de15f2d") } }, writeConcern: { w: "majority" }, lsid: { id: UUID("18ff84d3-9f90-4e4a-ba7b-911c7de15f2d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965345, 18), signature: { hash: BinData(0, 33B8368DB4CEE2AAF0EBC5ED5D205D1DBB49097A), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:60764", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965345, 18), t: 1 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 1, w: 4 } }, Database: { acquireCount: { r: 1, w: 4 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { r: 9 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 104ms
2020-05-08T12:15:45.906-0700 I  SHARDING [conn42] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe1a0224cfb413c7491
2020-05-08T12:15:45.917-0700 I  SHARDING [conn42] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe1a0224cfb413c7498
2020-05-08T12:15:46.187-0700 I  STORAGE  [conn68] createCollection: config.collections with generated UUID: a3749b3b-8edc-4244-a80b-c03e81de0177 and options: {}
2020-05-08T12:15:46.242-0700 I  INDEX    [conn68] index build: done building index _id_ on ns config.collections
2020-05-08T12:15:46.303-0700 I  COMMAND  [conn68] command config.$cmd command: update { update: "collections", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "jepsendb.jepsencoll" }, u: { _id: "jepsendb.jepsencoll", lastmodEpoch: ObjectId('5eb5afe20a0e2b150583a3b5'), lastmod: new Date(4294967302), dropped: false, key: { _id: "hashed" }, unique: false, uuid: UUID("65f8ad74-7d16-4e9e-83ca-69436a42b0c7") }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, lsid: { id: UUID("18ff84d3-9f90-4e4a-ba7b-911c7de15f2d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965346, 12), signature: { hash: BinData(0, 5805D0AE1BACD3C6515FB39F0909446BA822C4C8), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:60764", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965346, 12), t: 1 } }, $db: "config" } numYields:0 reslen:650 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { w: 3 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 116ms
2020-05-08T12:15:46.524-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:46.527-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 1 ms
2020-05-08T12:15:46.538-0700 I  SHARDING [conn42] distributed lock with ts: 5eb5afe1a0224cfb413c7498' unlocked.
2020-05-08T12:15:46.560-0700 I  SHARDING [conn42] distributed lock with ts: 5eb5afe1a0224cfb413c7491' unlocked.
2020-05-08T12:15:46.560-0700 I  COMMAND  [conn42] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "jepsendb.jepsencoll", key: { _id: "hashed" }, unique: false, numInitialChunks: 7, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("18ff84d3-9f90-4e4a-ba7b-911c7de15f2d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965345, 23), signature: { hash: BinData(0, 33B8368DB4CEE2AAF0EBC5ED5D205D1DBB49097A), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:60764", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965345, 23), t: 1 } }, $db: "admin" } numYields:0 reslen:585 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 6 } }, Global: { acquireCount: { r: 2, w: 4 } }, Database: { acquireCount: { r: 2, w: 4 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { r: 10, W: 1 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 661ms
2020-05-08T12:15:46.696-0700 I  SHARDING [conn37] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c741b
2020-05-08T12:15:46.697-0700 I  SHARDING [conn37] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:46.706-0700 I  SHARDING [conn37] distributed lock with ts: 5eb5afe1a0224cfb413c741b' unlocked.
2020-05-08T12:15:46.706-0700 I  COMMAND  [conn37] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("70fd5fe5-d1dd-4ee7-a448-72506044d2bd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:49442", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 10), t: 1 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 7 } }, ReplicationStateTransition: { acquireCount: { w: 14 } }, Global: { acquireCount: { r: 9, w: 5 } }, Database: { acquireCount: { r: 7, w: 5 } }, Collection: { acquireCount: { r: 5, w: 5 } }, Mutex: { acquireCount: { r: 14 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 5, timeAcquiringMicros: 6 } storage:{} protocol:op_msg 1034ms
2020-05-08T12:15:46.718-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:33640 #86 (60 connections now open)
2020-05-08T12:15:46.718-0700 I  NETWORK  [conn86] received client metadata from 192.168.122.17:33640 conn86: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:46.719-0700 I  SHARDING [conn37] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe2a0224cfb413c7545
2020-05-08T12:15:46.729-0700 I  SHARDING [conn37] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe2a0224cfb413c754f
2020-05-08T12:15:46.741-0700 I  SHARDING [conn37] distributed lock with ts: 5eb5afe2a0224cfb413c754f' unlocked.
2020-05-08T12:15:46.752-0700 I  SHARDING [conn37] distributed lock with ts: 5eb5afe2a0224cfb413c7545' unlocked.
2020-05-08T12:15:46.766-0700 I  SHARDING [conn37] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe2a0224cfb413c7570
2020-05-08T12:15:46.775-0700 I  SHARDING [conn37] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe2a0224cfb413c7578
2020-05-08T12:15:46.779-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:46.781-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 1 ms
2020-05-08T12:15:46.790-0700 I  SHARDING [conn37] distributed lock with ts: 5eb5afe2a0224cfb413c7578' unlocked.
2020-05-08T12:15:46.797-0700 I  SHARDING [conn37] distributed lock with ts: 5eb5afe2a0224cfb413c7570' unlocked.
2020-05-08T12:15:47.211-0700 I  SHARDING [conn44] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c7414
2020-05-08T12:15:47.212-0700 I  SHARDING [conn44] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:47.221-0700 I  SHARDING [conn44] distributed lock with ts: 5eb5afe1a0224cfb413c7414' unlocked.
2020-05-08T12:15:47.221-0700 I  COMMAND  [conn44] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("fff7247f-b881-4a37-882a-fafa8a45a14e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54888", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 4), t: 1 } }, $db: "admin" } numYields:7 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 16 } }, ReplicationStateTransition: { acquireCount: { w: 26 } }, Global: { acquireCount: { r: 13, w: 13 } }, Database: { acquireCount: { r: 10, w: 13 } }, Collection: { acquireCount: { r: 7, w: 13 } }, Mutex: { acquireCount: { r: 18 } }, oplog: { acquireCount: { r: 3 } } } flowControl:{ acquireCount: 13, timeAcquiringMicros: 54 } storage:{} protocol:op_msg 1549ms
2020-05-08T12:15:47.223-0700 W  SHARDING [conn43] config server local time went backwards, from last seen: 2020-05-08T12:15:47.222-0700 to 2020-05-08T12:15:47.221-0700
2020-05-08T12:15:47.235-0700 I  SHARDING [conn44] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe3a0224cfb413c75ca
2020-05-08T12:15:47.248-0700 I  SHARDING [conn44] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe3a0224cfb413c75d2
2020-05-08T12:15:47.263-0700 I  SHARDING [conn44] distributed lock with ts: 5eb5afe3a0224cfb413c75d2' unlocked.
2020-05-08T12:15:47.273-0700 I  SHARDING [conn44] distributed lock with ts: 5eb5afe3a0224cfb413c75ca' unlocked.
2020-05-08T12:15:47.285-0700 I  SHARDING [conn44] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe3a0224cfb413c75f4
2020-05-08T12:15:47.294-0700 I  SHARDING [conn44] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe3a0224cfb413c75fc
2020-05-08T12:15:47.298-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:47.300-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 1 ms
2020-05-08T12:15:47.309-0700 I  SHARDING [conn44] distributed lock with ts: 5eb5afe3a0224cfb413c75fc' unlocked.
2020-05-08T12:15:47.317-0700 I  SHARDING [conn44] distributed lock with ts: 5eb5afe3a0224cfb413c75f4' unlocked.
2020-05-08T12:15:47.734-0700 I  SHARDING [conn47] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c741e
2020-05-08T12:15:47.735-0700 I  SHARDING [conn47] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:47.746-0700 I  SHARDING [conn47] distributed lock with ts: 5eb5afe1a0224cfb413c741e' unlocked.
2020-05-08T12:15:47.746-0700 I  COMMAND  [conn47] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("399b7779-e00b-41bc-9aef-1f16333454a4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:50386", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 10), t: 1 } }, $db: "admin" } numYields:18 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 29 } }, ReplicationStateTransition: { acquireCount: { w: 42 } }, Global: { acquireCount: { r: 17, w: 25 } }, Database: { acquireCount: { r: 13, w: 25 } }, Collection: { acquireCount: { r: 9, w: 25 } }, Mutex: { acquireCount: { r: 22 } }, oplog: { acquireCount: { r: 4 } } } flowControl:{ acquireCount: 25, timeAcquiringMicros: 27 } storage:{} protocol:op_msg 2074ms
2020-05-08T12:15:47.761-0700 I  SHARDING [conn47] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe3a0224cfb413c7649
2020-05-08T12:15:47.770-0700 I  SHARDING [conn47] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe3a0224cfb413c7651
2020-05-08T12:15:47.781-0700 I  SHARDING [conn47] distributed lock with ts: 5eb5afe3a0224cfb413c7651' unlocked.
2020-05-08T12:15:47.791-0700 I  SHARDING [conn47] distributed lock with ts: 5eb5afe3a0224cfb413c7649' unlocked.
2020-05-08T12:15:47.802-0700 I  SHARDING [conn47] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe3a0224cfb413c7672
2020-05-08T12:15:47.815-0700 I  SHARDING [conn47] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe3a0224cfb413c7679
2020-05-08T12:15:47.819-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:47.820-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 1 ms
2020-05-08T12:15:47.832-0700 I  SHARDING [conn47] distributed lock with ts: 5eb5afe3a0224cfb413c7679' unlocked.
2020-05-08T12:15:47.840-0700 I  SHARDING [conn47] distributed lock with ts: 5eb5afe3a0224cfb413c7672' unlocked.
2020-05-08T12:15:48.259-0700 I  SHARDING [conn46] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c7419
2020-05-08T12:15:48.259-0700 I  SHARDING [conn46] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:48.267-0700 I  SHARDING [conn46] distributed lock with ts: 5eb5afe1a0224cfb413c7419' unlocked.
2020-05-08T12:15:48.268-0700 I  COMMAND  [conn46] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("5dd6556a-a391-4aa3-a3a7-ac1307dbb51d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 4), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:55470", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 4), t: 1 } }, $db: "admin" } numYields:27 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 40 } }, ReplicationStateTransition: { acquireCount: { w: 56 } }, Global: { acquireCount: { r: 21, w: 35 } }, Database: { acquireCount: { r: 16, w: 35 } }, Collection: { acquireCount: { r: 11, w: 35 } }, Mutex: { acquireCount: { r: 26 } }, oplog: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 35, timeAcquiringMicros: 31 } storage:{} protocol:op_msg 2596ms
2020-05-08T12:15:48.282-0700 I  SHARDING [conn46] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe4a0224cfb413c76c6
2020-05-08T12:15:48.288-0700 I  SHARDING [conn46] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe4a0224cfb413c76cd
2020-05-08T12:15:48.298-0700 I  SHARDING [conn46] distributed lock with ts: 5eb5afe4a0224cfb413c76cd' unlocked.
2020-05-08T12:15:48.311-0700 I  SHARDING [conn46] distributed lock with ts: 5eb5afe4a0224cfb413c76c6' unlocked.
2020-05-08T12:15:48.323-0700 I  SHARDING [conn46] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe4a0224cfb413c76ed
2020-05-08T12:15:48.333-0700 I  SHARDING [conn46] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe4a0224cfb413c76f7
2020-05-08T12:15:48.337-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:48.338-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 1 ms
2020-05-08T12:15:48.348-0700 I  SHARDING [conn46] distributed lock with ts: 5eb5afe4a0224cfb413c76f7' unlocked.
2020-05-08T12:15:48.356-0700 I  SHARDING [conn46] distributed lock with ts: 5eb5afe4a0224cfb413c76ed' unlocked.
2020-05-08T12:15:48.782-0700 I  SHARDING [conn43] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c740e
2020-05-08T12:15:48.783-0700 I  SHARDING [conn43] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:48.788-0700 I  SHARDING [conn43] distributed lock with ts: 5eb5afe1a0224cfb413c740e' unlocked.
2020-05-08T12:15:48.788-0700 I  COMMAND  [conn43] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("8191e4f2-c2b9-4af1-9481-1737afdaf4ff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:54898", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 7), t: 1 } }, $db: "admin" } numYields:38 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 53 } }, ReplicationStateTransition: { acquireCount: { w: 72 } }, Global: { acquireCount: { r: 25, w: 47 } }, Database: { acquireCount: { r: 19, w: 47 } }, Collection: { acquireCount: { r: 13, w: 47 } }, Mutex: { acquireCount: { r: 30 } }, oplog: { acquireCount: { r: 6 } } } flowControl:{ acquireCount: 47, timeAcquiringMicros: 50 } storage:{} protocol:op_msg 3117ms
2020-05-08T12:15:48.802-0700 I  SHARDING [conn43] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe4a0224cfb413c773e
2020-05-08T12:15:48.807-0700 I  SHARDING [conn43] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe4a0224cfb413c7745
2020-05-08T12:15:48.816-0700 I  SHARDING [conn43] distributed lock with ts: 5eb5afe4a0224cfb413c7745' unlocked.
2020-05-08T12:15:48.824-0700 I  SHARDING [conn43] distributed lock with ts: 5eb5afe4a0224cfb413c773e' unlocked.
2020-05-08T12:15:48.832-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:47550 #87 (61 connections now open)
2020-05-08T12:15:48.833-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.16:47550 conn87: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:48.833-0700 I  SHARDING [conn43] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe4a0224cfb413c7765
2020-05-08T12:15:48.841-0700 I  SHARDING [conn43] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe4a0224cfb413c776f
2020-05-08T12:15:48.844-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:48.845-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 0 ms
2020-05-08T12:15:48.851-0700 I  SHARDING [conn43] distributed lock with ts: 5eb5afe4a0224cfb413c776f' unlocked.
2020-05-08T12:15:48.861-0700 I  SHARDING [conn43] distributed lock with ts: 5eb5afe4a0224cfb413c7765' unlocked.
2020-05-08T12:15:49.302-0700 I  SHARDING [conn48] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c740b
2020-05-08T12:15:49.303-0700 I  SHARDING [conn48] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:49.311-0700 I  SHARDING [conn48] distributed lock with ts: 5eb5afe1a0224cfb413c740b' unlocked.
2020-05-08T12:15:49.312-0700 I  COMMAND  [conn48] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("89738604-8f7f-41ea-978b-3824711623f9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:48058", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 10), t: 1 } }, $db: "admin" } numYields:48 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 65 } }, ReplicationStateTransition: { acquireCount: { w: 87 } }, Global: { acquireCount: { r: 29, w: 58 } }, Database: { acquireCount: { r: 22, w: 58 } }, Collection: { acquireCount: { r: 15, w: 58 } }, Mutex: { acquireCount: { r: 34 } }, oplog: { acquireCount: { r: 7 } } } flowControl:{ acquireCount: 58, timeAcquiringMicros: 62 } storage:{} protocol:op_msg 3640ms
2020-05-08T12:15:49.329-0700 I  SHARDING [conn48] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe5a0224cfb413c77b3
2020-05-08T12:15:49.339-0700 I  SHARDING [conn48] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe5a0224cfb413c77ba
2020-05-08T12:15:49.351-0700 I  SHARDING [conn48] distributed lock with ts: 5eb5afe5a0224cfb413c77ba' unlocked.
2020-05-08T12:15:49.361-0700 I  SHARDING [conn48] distributed lock with ts: 5eb5afe5a0224cfb413c77b3' unlocked.
2020-05-08T12:15:49.375-0700 I  SHARDING [conn48] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe5a0224cfb413c77db
2020-05-08T12:15:49.385-0700 I  SHARDING [conn48] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe5a0224cfb413c77e4
2020-05-08T12:15:49.389-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:49.390-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 1 ms
2020-05-08T12:15:49.399-0700 I  SHARDING [conn48] distributed lock with ts: 5eb5afe5a0224cfb413c77e4' unlocked.
2020-05-08T12:15:49.407-0700 I  SHARDING [conn48] distributed lock with ts: 5eb5afe5a0224cfb413c77db' unlocked.
2020-05-08T12:15:49.826-0700 I  SHARDING [conn24] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c740d
2020-05-08T12:15:49.827-0700 I  SHARDING [conn24] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:49.836-0700 I  SHARDING [conn24] distributed lock with ts: 5eb5afe1a0224cfb413c740d' unlocked.
2020-05-08T12:15:49.836-0700 I  COMMAND  [conn24] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("3ab9c542-a376-4786-8bbd-c8e0d5a6640f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:53454", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 10), t: 1 } }, $db: "admin" } numYields:59 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 78 } }, ReplicationStateTransition: { acquireCount: { w: 103 } }, Global: { acquireCount: { r: 33, w: 70 } }, Database: { acquireCount: { r: 25, w: 70 } }, Collection: { acquireCount: { r: 17, w: 70 } }, Mutex: { acquireCount: { r: 38 } }, oplog: { acquireCount: { r: 8 } } } flowControl:{ acquireCount: 70, timeAcquiringMicros: 90 } storage:{} protocol:op_msg 4164ms
2020-05-08T12:15:49.852-0700 I  SHARDING [conn24] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe5a0224cfb413c7822
2020-05-08T12:15:49.863-0700 I  SHARDING [conn24] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe5a0224cfb413c782a
2020-05-08T12:15:49.874-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:59158 #88 (62 connections now open)
2020-05-08T12:15:49.875-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.13:59158 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:49.876-0700 I  SHARDING [conn24] distributed lock with ts: 5eb5afe5a0224cfb413c782a' unlocked.
2020-05-08T12:15:49.888-0700 I  SHARDING [conn24] distributed lock with ts: 5eb5afe5a0224cfb413c7822' unlocked.
2020-05-08T12:15:49.897-0700 I  SHARDING [conn24] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe5a0224cfb413c784d
2020-05-08T12:15:49.905-0700 I  SHARDING [conn24] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe5a0224cfb413c7854
2020-05-08T12:15:49.908-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:49.909-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 0 ms
2020-05-08T12:15:49.916-0700 I  SHARDING [conn24] distributed lock with ts: 5eb5afe5a0224cfb413c7854' unlocked.
2020-05-08T12:15:49.923-0700 I  SHARDING [conn24] distributed lock with ts: 5eb5afe5a0224cfb413c784d' unlocked.
2020-05-08T12:15:50.349-0700 I  SHARDING [conn45] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb5afe1a0224cfb413c7413
2020-05-08T12:15:50.349-0700 I  SHARDING [conn45] Enabling sharding for database [jepsendb] in config db
2020-05-08T12:15:50.355-0700 I  SHARDING [conn45] distributed lock with ts: 5eb5afe1a0224cfb413c7413' unlocked.
2020-05-08T12:15:50.355-0700 I  COMMAND  [conn45] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("c41e3398-3d05-41a3-9df4-b19b6b8bb41a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965343, 10), signature: { hash: BinData(0, 530AAF1EDB3B7B291277D91AFB688E6AE96D43BA), keyId: 6824554174072487943 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n4:27017", client: "192.168.122.1:60532", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1588965343, 10), t: 1 } }, $db: "admin" } numYields:67 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 88 } }, ReplicationStateTransition: { acquireCount: { w: 116 } }, Global: { acquireCount: { r: 37, w: 79 } }, Database: { acquireCount: { r: 28, w: 79 } }, Collection: { acquireCount: { r: 19, w: 79 } }, Mutex: { acquireCount: { r: 42 } }, oplog: { acquireCount: { r: 9 } } } flowControl:{ acquireCount: 79, timeAcquiringMicros: 99 } storage:{} protocol:op_msg 4684ms
2020-05-08T12:15:50.368-0700 I  SHARDING [conn45] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb5afe6a0224cfb413c7890
2020-05-08T12:15:50.377-0700 I  SHARDING [conn45] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb5afe6a0224cfb413c7897
2020-05-08T12:15:50.387-0700 I  SHARDING [conn45] distributed lock with ts: 5eb5afe6a0224cfb413c7897' unlocked.
2020-05-08T12:15:50.393-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:46206 #89 (63 connections now open)
2020-05-08T12:15:50.394-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.14:46206 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:50.396-0700 I  SHARDING [conn45] distributed lock with ts: 5eb5afe6a0224cfb413c7890' unlocked.
2020-05-08T12:15:50.407-0700 I  SHARDING [conn45] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb5afe6a0224cfb413c78bb
2020-05-08T12:15:50.418-0700 I  SHARDING [conn45] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb5afe6a0224cfb413c78c2
2020-05-08T12:15:50.421-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("d83d36a8-6185-46a3-a2bf-8393b7a71805"), lastMod: 1 } took 0 ms
2020-05-08T12:15:50.423-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5afe20a0e2b150583a3b5 took 0 ms
2020-05-08T12:15:50.431-0700 I  SHARDING [conn45] distributed lock with ts: 5eb5afe6a0224cfb413c78c2' unlocked.
2020-05-08T12:15:50.437-0700 I  SHARDING [conn45] distributed lock with ts: 5eb5afe6a0224cfb413c78bb' unlocked.
2020-05-08T12:15:50.781-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43576 #90 (64 connections now open)
2020-05-08T12:15:50.781-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43580 #91 (65 connections now open)
2020-05-08T12:15:50.781-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.1:43576 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.782-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.1:43580 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:50.784-0700 I  NETWORK  [conn90] end connection 192.168.122.1:43576 (64 connections now open)
2020-05-08T12:15:50.784-0700 I  NETWORK  [conn91] end connection 192.168.122.1:43580 (63 connections now open)
2020-05-08T12:15:51.403-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43688 #92 (64 connections now open)
2020-05-08T12:15:51.404-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43694 #93 (65 connections now open)
2020-05-08T12:15:51.404-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.1:43688 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.404-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.1:43694 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:51.407-0700 I  NETWORK  [conn92] end connection 192.168.122.1:43688 (64 connections now open)
2020-05-08T12:15:51.408-0700 I  NETWORK  [conn93] end connection 192.168.122.1:43694 (63 connections now open)
2020-05-08T12:15:52.357-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:15:52.357-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:15:52.357-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-08T12:15:52.357-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-08T12:15:52.357-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:15:52.357-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:15:52.358-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:15:52.358-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-08T12:15:52.358-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:15:52.715-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:15:52.715-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:15:52.715-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:15:52.715-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:15:53.443-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:15:54.564-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:15:55.564-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:15:56.699-0700 I  ELECTION [replexec-0] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:15:56.705-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41842 #94 (64 connections now open)
2020-05-08T12:15:56.705-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.12:41842 conn94: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:56.705-0700 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:56.705-0700 I  ELECTION [conn94] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-05-08T12:15:56.708-0700 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:56.708-0700 I  ELECTION [conn94] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-08T12:15:56.833-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41894 #95 (65 connections now open)
2020-05-08T12:15:56.833-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.12:41894 conn95: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:56.853-0700 I  NETWORK  [conn40] end connection 192.168.122.12:40644 (64 connections now open)
2020-05-08T12:15:56.854-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42008 #96 (65 connections now open)
2020-05-08T12:15:56.854-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.12:42008 conn96: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:56.897-0700 I  NETWORK  [conn15] end connection 192.168.122.13:58334 (64 connections now open)
2020-05-08T12:15:57.812-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:15:58.862-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:15:59.073-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965350, 10), t: 1 } }
2020-05-08T12:15:59.073-0700 I  ELECTION [conn10] Sending vote response: { term: 4, voteGranted: false, reason: "candidate's term (1) is lower than mine (4)" }
2020-05-08T12:15:59.073-0700 I  NETWORK  [conn10] end connection 192.168.122.13:58244 (63 connections now open)
2020-05-08T12:15:59.329-0700 I  NETWORK  [conn9] end connection 192.168.122.12:40308 (62 connections now open)
2020-05-08T12:15:59.585-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:59734 #97 (63 connections now open)
2020-05-08T12:15:59.585-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:59712 #98 (64 connections now open)
2020-05-08T12:15:59.585-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.13:59734 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:59.586-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.13:59712 conn98: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:15:59.836-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44334 #99 (65 connections now open)
2020-05-08T12:15:59.836-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44340 #100 (66 connections now open)
2020-05-08T12:15:59.836-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.1:44334 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:59.837-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.1:44340 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:15:59.840-0700 I  NETWORK  [conn99] end connection 192.168.122.1:44334 (65 connections now open)
2020-05-08T12:15:59.840-0700 I  NETWORK  [conn100] end connection 192.168.122.1:44340 (64 connections now open)
2020-05-08T12:15:59.842-0700 I  REPL     [replexec-1] Member n2:27019 is now in state PRIMARY
2020-05-08T12:15:59.843-0700 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-05-08T12:16:00.886-0700
2020-05-08T12:15:59.843-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:00.362-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:16:00.362-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-08T12:16:00.365-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:16:00.370-0700 I  COMMAND  [conn42] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965357, 6), t: 4 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965357, 6), signature: { hash: BinData(0, 2C1FEE44F64D4EDEE505170B87F67AA344B069FF), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965357, 6), t: 4 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 1803ms
2020-05-08T12:16:00.663-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44414 #105 (65 connections now open)
2020-05-08T12:16:00.663-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44418 #106 (66 connections now open)
2020-05-08T12:16:00.664-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.1:44414 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:00.664-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.1:44418 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:00.667-0700 I  NETWORK  [conn105] end connection 192.168.122.1:44414 (65 connections now open)
2020-05-08T12:16:00.667-0700 I  NETWORK  [conn106] end connection 192.168.122.1:44418 (64 connections now open)
2020-05-08T12:16:00.886-0700 I  REPL     [replexec-5] Canceling priority takeover callback
2020-05-08T12:16:00.886-0700 I  ELECTION [replexec-5] Starting an election for a priority takeover
2020-05-08T12:16:00.886-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 4
2020-05-08T12:16:00.886-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 110 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965357, 6), t: 4 } }
2020-05-08T12:16:00.886-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 111 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965357, 6), t: 4 } }
2020-05-08T12:16:00.887-0700 I  ELECTION [replexec-4] VoteRequester(term 4 dry run) received a yes vote from n3:27019; response message: { term: 4, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1588965357, 6), $clusterTime: { clusterTime: Timestamp(1588965360, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965357, 6) }
2020-05-08T12:16:00.887-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 5
2020-05-08T12:16:00.887-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:00.887-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:00.890-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 112 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965357, 6), t: 4 } }
2020-05-08T12:16:00.891-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 113 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965357, 6), t: 4 } }
2020-05-08T12:16:00.895-0700 I  ELECTION [replexec-5] VoteRequester(term 5) received a yes vote from n3:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1588965357, 6), $clusterTime: { clusterTime: Timestamp(1588965360, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965357, 6) }
2020-05-08T12:16:00.895-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 5
2020-05-08T12:16:00.895-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-08T12:16:00.895-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n3:27019
2020-05-08T12:16:00.895-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-08T12:16:01.371-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965357, 6), t: 4 }; sync source index: 1; primary index: 1) is no longer valid
2020-05-08T12:16:01.373-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:16:01.555-0700 I  NETWORK  [conn95] end connection 192.168.122.12:41894 (63 connections now open)
2020-05-08T12:16:01.890-0700 I  REPL     [replexec-5] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:01.891-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965357, 6), t: 4 }. My Last Applied: { ts: Timestamp(1588965357, 6), t: 4 }
2020-05-08T12:16:01.891-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-08T12:16:01.891-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-08T12:16:01.891-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 5
2020-05-08T12:16:01.891-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:01.891-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:01.891-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:01.893-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:01.894-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:01.894-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:01.895-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:01.895-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:01.896-0700 I  REPL     [replexec-0] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:02.565-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:16:02.565-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:16:02.896-0700 I  REPL     [replexec-3] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:06.714-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44656 #109 (64 connections now open)
2020-05-08T12:16:06.715-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44660 #110 (65 connections now open)
2020-05-08T12:16:06.715-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.1:44656 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:06.715-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.1:44660 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:06.719-0700 I  NETWORK  [conn109] end connection 192.168.122.1:44656 (64 connections now open)
2020-05-08T12:16:06.719-0700 I  NETWORK  [conn110] end connection 192.168.122.1:44660 (63 connections now open)
2020-05-08T12:16:07.341-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:07.558-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:07.558-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-08T12:16:07.558-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-08T12:16:07.558-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:07.558-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:07.558-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 3, userOpsRunning: 0 }
2020-05-08T12:16:07.559-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-08T12:16:07.559-0700 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:16:07.559-0700 I  COMMAND  [conn43] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965365, 1), signature: { hash: BinData(0, 03DE14EC4ADE68F2191CD5F88A800546A5EDB6F5), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965361, 1), t: 5 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 179ms
2020-05-08T12:16:07.559-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:07.560-0700 I  COMMAND  [replSetDistLockPinger] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "ConfigServer" }, update: { $set: { ping: new Date(1588965367202) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:483 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 356ms
2020-05-08T12:16:07.560-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:07.897-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:07.897-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:16:08.665-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:08.892-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:09.691-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:10.392-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:10.392-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:10.824-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:11.426-0700 I  REPL     [replexec-3] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:11.426-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-08T12:16:12.563-0700
2020-05-08T12:16:11.561-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:11.562-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-08T12:16:11.566-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965367, 1), t: 5 }. source's GTE: { ts: Timestamp(1588965368, 1), t: 6 }
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-08T12:16:11.568-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 2, userOpsRunning: 62 }
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-08T12:16:11.568-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-08T12:16:11.568-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 98
2020-05-08T12:16:11.568-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 96
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 94
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 78
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-08T12:16:11.569-0700 I  COMMAND  [conn66] command config.$cmd command: find { find: "chunks", filter: { ns: "jepsendb.jepsencoll", lastmod: { $gte: Timestamp(1, 6) } }, sort: { lastmod: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965369, 16), t: 6 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965371, 8), signature: { hash: BinData(0, B603E1231135BE53F998376580FB5F2BE6FDDC3D), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965369, 16), t: 6 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965369, 16), t: 6 }, current relevant optime is { ts: Timestamp(1588965361, 1), t: 5 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:764 locks:{} protocol:op_msg 490ms
2020-05-08T12:16:11.569-0700 I  COMMAND  [conn68] command admin.$cmd command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(1604517341, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965369, 16), t: 6 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965370, 4), signature: { hash: BinData(0, EAE7C1D01EA42EC835187540DC90EC5FDD220A2E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965369, 16), t: 6 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965369, 16), t: 6 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:756 locks:{} protocol:op_msg 513ms
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 75
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 74
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 53
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-08T12:16:11.569-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-08T12:16:11.570-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 14
2020-05-08T12:16:11.570-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-08T12:16:11.570-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-08T12:16:11.570-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-08T12:16:11.575-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T12:16:11.590-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-08T12:16:11.590-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-08T12:16:11.590-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 81acf486-601b-4e2b-8ee1-bbf74a1edd96 to /var/lib/mongodb/rollback/config.lockpings/removed.2020-05-08T19-16-11.0.bson
2020-05-08T12:16:11.590-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-08T12:16:11.590-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-08T12:16:11.590-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-08T12:16:11.591-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-08T12:16:11.619-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44914 #114 (64 connections now open)
2020-05-08T12:16:11.619-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44920 #115 (65 connections now open)
2020-05-08T12:16:11.619-0700 I  NETWORK  [conn114] received client metadata from 192.168.122.1:44914 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:11.619-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.1:44920 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:11.622-0700 I  NETWORK  [conn114] end connection 192.168.122.1:44914 (64 connections now open)
2020-05-08T12:16:11.623-0700 I  NETWORK  [conn115] end connection 192.168.122.1:44920 (63 connections now open)
2020-05-08T12:16:11.673-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1588965361, 1) Initial Data Timestamp: Timestamp(1588965338, 1)
2020-05-08T12:16:11.674-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-08T12:16:11.686-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-08T12:16:11.686-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 181 records totaling to 40556 bytes
2020-05-08T12:16:11.686-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:16:11.687-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-08T12:16:11.690-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-08T12:16:11.691-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-08T12:16:11.707-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-08T12:16:11.707-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-08T12:16:11.707-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1588965361, 1)
2020-05-08T12:16:11.707-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 1 insert operations, 0 update operations and 0 delete operations.
2020-05-08T12:16:11.707-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1588965367, 1), t: 5 }
2020-05-08T12:16:11.708-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1588965367, 1) }
2020-05-08T12:16:11.708-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-08T12:16:11.710-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1588965361, 1) (top of oplog: { ts: Timestamp(1588965361, 1), t: 5 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-08T12:16:11.710-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1588965361, 1)
2020-05-08T12:16:11.710-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-08T12:16:11.710-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-08T12:16:11.568-0700
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-08T12:16:11.711-0700
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.lockpings
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1588965367, 1), t: 5 }
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1588965361, 1), t: 5 }
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-08T12:16:07.202-0700
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-08T12:16:07.202-0700
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1588965367, 1)
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1588965361, 1)
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 		update: 0
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 1
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 1
2020-05-08T12:16:11.711-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:16:11.711-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:11.927-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-08T12:16:12.997-0700
2020-05-08T12:16:12.002-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:12.005-0700 I  NETWORK  [conn96] end connection 192.168.122.12:42008 (62 connections now open)
2020-05-08T12:16:12.005-0700 I  NETWORK  [conn97] end connection 192.168.122.13:59734 (61 connections now open)
2020-05-08T12:16:12.065-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:60732 #116 (62 connections now open)
2020-05-08T12:16:12.065-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.13:60732 conn116: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:12.554-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44976 #117 (63 connections now open)
2020-05-08T12:16:12.555-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44982 #118 (64 connections now open)
2020-05-08T12:16:12.555-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.1:44976 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:12.555-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.1:44982 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:12.559-0700 I  NETWORK  [conn117] end connection 192.168.122.1:44976 (63 connections now open)
2020-05-08T12:16:12.559-0700 I  NETWORK  [conn118] end connection 192.168.122.1:44982 (62 connections now open)
2020-05-08T12:16:12.705-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:60670 #119 (63 connections now open)
2020-05-08T12:16:12.705-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.13:60670 conn119: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:12.997-0700 I  REPL     [replexec-0] Canceling priority takeover callback
2020-05-08T12:16:12.997-0700 I  ELECTION [replexec-0] Starting an election for a priority takeover
2020-05-08T12:16:12.997-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 6
2020-05-08T12:16:12.997-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 153 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965371, 16), t: 6 } }
2020-05-08T12:16:12.997-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 154 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965371, 16), t: 6 } }
2020-05-08T12:16:12.998-0700 I  ELECTION [replexec-3] VoteRequester(term 6 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965371, 16), t: 6 }, my last applied OpTime: { ts: Timestamp(1588965372, 24), t: 6 }"; response message: { term: 6, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965371, 16), t: 6 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000006') }, lastCommittedOpTime: Timestamp(1588965371, 16), $clusterTime: { clusterTime: Timestamp(1588965372, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965372, 24) }
2020-05-08T12:16:13.181-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45012 #120 (64 connections now open)
2020-05-08T12:16:13.182-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45020 #121 (65 connections now open)
2020-05-08T12:16:13.182-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:45012 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.182-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.1:45020 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.185-0700 I  NETWORK  [conn120] end connection 192.168.122.1:45012 (64 connections now open)
2020-05-08T12:16:13.185-0700 I  NETWORK  [conn121] end connection 192.168.122.1:45020 (63 connections now open)
2020-05-08T12:16:13.698-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45054 #122 (64 connections now open)
2020-05-08T12:16:13.699-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45060 #123 (65 connections now open)
2020-05-08T12:16:13.699-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:45054 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.699-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.1:45060 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:13.702-0700 I  NETWORK  [conn122] end connection 192.168.122.1:45054 (64 connections now open)
2020-05-08T12:16:13.702-0700 I  NETWORK  [conn123] end connection 192.168.122.1:45060 (63 connections now open)
2020-05-08T12:16:13.926-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-08T12:16:15.013-0700
2020-05-08T12:16:13.997-0700 I  ELECTION [replexec-4] VoteRequester(term 6 dry run) failed to receive response from n3:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:16:13.997-0700 I  ELECTION [replexec-4] not running for primary, we received insufficient votes
2020-05-08T12:16:13.997-0700 I  ELECTION [replexec-4] Lost dry run election due to internal error
2020-05-08T12:16:14.177-0700 I  ELECTION [conn94] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965361, 1), t: 5 } }
2020-05-08T12:16:14.177-0700 I  ELECTION [conn94] Sending vote response: { term: 6, voteGranted: false, reason: "candidate's term (5) is lower than mine (6)" }
2020-05-08T12:16:14.177-0700 I  NETWORK  [conn94] end connection 192.168.122.12:41842 (62 connections now open)
2020-05-08T12:16:14.177-0700 I  NETWORK  [conn98] end connection 192.168.122.13:59712 (61 connections now open)
2020-05-08T12:16:14.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45160 #124 (62 connections now open)
2020-05-08T12:16:14.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45164 #125 (63 connections now open)
2020-05-08T12:16:14.326-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.1:45160 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.326-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.1:45164 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:14.330-0700 I  NETWORK  [conn124] end connection 192.168.122.1:45160 (62 connections now open)
2020-05-08T12:16:14.330-0700 I  NETWORK  [conn125] end connection 192.168.122.1:45164 (61 connections now open)
2020-05-08T12:16:15.013-0700 I  REPL     [replexec-4] Canceling priority takeover callback
2020-05-08T12:16:15.013-0700 I  ELECTION [replexec-4] Starting an election for a priority takeover
2020-05-08T12:16:15.013-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 6
2020-05-08T12:16:15.013-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 172 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:15.013-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 173 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:15.013-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:16:15.016-0700 I  REPL     [replexec-2] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:15.016-0700 I  ELECTION [replexec-3] VoteRequester(term 6 dry run) received a yes vote from n3:27019; response message: { term: 6, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1588965373, 1), $clusterTime: { clusterTime: Timestamp(1588965373, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965373, 1) }
2020-05-08T12:16:15.016-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 7
2020-05-08T12:16:15.016-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:15.016-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:15.025-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 174 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:15.025-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 175 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965373, 1), t: 6 } }
2020-05-08T12:16:15.030-0700 I  ELECTION [replexec-1] VoteRequester(term 7) received a yes vote from n3:27019; response message: { term: 7, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1588965373, 1), $clusterTime: { clusterTime: Timestamp(1588965373, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965373, 1) }
2020-05-08T12:16:15.030-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 7
2020-05-08T12:16:15.030-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-08T12:16:15.030-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was n2:27019
2020-05-08T12:16:15.030-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-08T12:16:16.030-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:16.030-0700 I  REPL     [replexec-0] Catchup timed out after becoming primary.
2020-05-08T12:16:16.030-0700 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-05-08T12:16:16.030-0700 I  REPL     [replexec-0] Stopping replication producer
2020-05-08T12:16:16.030-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 7
2020-05-08T12:16:16.030-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:16:16.030-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:16.031-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:16.031-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:16.031-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:16.033-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:16.033-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:16.033-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:16.034-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:16.034-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:16.034-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:16.034-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:16.035-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:16.035-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:16.036-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-08T12:16:16.172-0700 I  REPL     [replexec-3] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:16.172-0700 I  REPL     [replexec-3] can't see a majority of the set, relinquishing primary
2020-05-08T12:16:16.172-0700 I  REPL     [replexec-3] Stepping down from primary in response to heartbeat
2020-05-08T12:16:16.172-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:16.172-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:16.173-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 4, userOpsRunning: 0 }
2020-05-08T12:16:16.173-0700 I  REPL     [replexec-3] transition to SECONDARY from PRIMARY
2020-05-08T12:16:16.174-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:16.174-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:16.535-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:17.032-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:17.533-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45240 #131 (62 connections now open)
2020-05-08T12:16:17.534-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45246 #132 (63 connections now open)
2020-05-08T12:16:17.534-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:45240 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:17.534-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.1:45246 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:17.538-0700 I  NETWORK  [conn131] end connection 192.168.122.1:45240 (62 connections now open)
2020-05-08T12:16:17.538-0700 I  NETWORK  [conn132] end connection 192.168.122.1:45246 (61 connections now open)
2020-05-08T12:16:17.730-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:32868 #133 (62 connections now open)
2020-05-08T12:16:17.731-0700 I  NETWORK  [conn133] received client metadata from 192.168.122.13:32868 conn133: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:18.031-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:18.031-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-08T12:16:19.122-0700
2020-05-08T12:16:18.116-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45278 #134 (63 connections now open)
2020-05-08T12:16:18.116-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45282 #135 (64 connections now open)
2020-05-08T12:16:18.117-0700 I  NETWORK  [conn134] received client metadata from 192.168.122.1:45278 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.117-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.1:45282 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:18.120-0700 I  NETWORK  [conn134] end connection 192.168.122.1:45278 (63 connections now open)
2020-05-08T12:16:18.120-0700 I  NETWORK  [conn135] end connection 192.168.122.1:45282 (62 connections now open)
2020-05-08T12:16:18.175-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:18.175-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-08T12:16:19.032-0700 I  REPL     [replexec-0] Canceling priority takeover callback
2020-05-08T12:16:19.032-0700 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:16:19.032-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 8
2020-05-08T12:16:19.032-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 200 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965376, 4), t: 7 } }
2020-05-08T12:16:19.032-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 201 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965376, 4), t: 7 } }
2020-05-08T12:16:19.033-0700 I  ELECTION [replexec-4] VoteRequester(term 8 dry run) received a yes vote from n3:27019; response message: { term: 8, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1588965373, 1), $clusterTime: { clusterTime: Timestamp(1588965377, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965376, 4) }
2020-05-08T12:16:19.033-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 9
2020-05-08T12:16:19.033-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:19.040-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 202 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965376, 4), t: 7 } }
2020-05-08T12:16:19.040-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 203 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965376, 4), t: 7 } }
2020-05-08T12:16:19.045-0700 I  ELECTION [replexec-1] VoteRequester(term 9) received a yes vote from n3:27019; response message: { term: 9, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1588965373, 1), $clusterTime: { clusterTime: Timestamp(1588965377, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965376, 4) }
2020-05-08T12:16:19.045-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 9
2020-05-08T12:16:19.045-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-08T12:16:19.045-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-08T12:16:19.045-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:19.045-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-08T12:16:19.531-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-08T12:16:19.531-0700 I  REPL     [replexec-1] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965376, 4), t: 7 }. My Last Applied: { ts: Timestamp(1588965376, 4), t: 7 }
2020-05-08T12:16:19.531-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-08T12:16:19.531-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-08T12:16:19.531-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 9
2020-05-08T12:16:19.531-0700 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: n2:27019
2020-05-08T12:16:19.531-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:19.532-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:19.532-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-08T12:16:19.533-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:19.533-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:19.534-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:19.534-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:19.534-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:19.535-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:19.538-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:16:19.538-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:16:24.470-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45520 #136 (63 connections now open)
2020-05-08T12:16:24.475-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45524 #137 (64 connections now open)
2020-05-08T12:16:24.475-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.1:45520 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.475-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.1:45524 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.478-0700 I  NETWORK  [conn136] end connection 192.168.122.1:45520 (63 connections now open)
2020-05-08T12:16:24.479-0700 I  NETWORK  [conn137] end connection 192.168.122.1:45524 (62 connections now open)
2020-05-08T12:16:24.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43418 #138 (63 connections now open)
2020-05-08T12:16:24.738-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.12:43418 conn138: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:24.898-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45546 #139 (64 connections now open)
2020-05-08T12:16:24.899-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45550 #140 (65 connections now open)
2020-05-08T12:16:24.899-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:45546 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.899-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.1:45550 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:24.903-0700 I  NETWORK  [conn139] end connection 192.168.122.1:45546 (64 connections now open)
2020-05-08T12:16:24.903-0700 I  NETWORK  [conn140] end connection 192.168.122.1:45550 (63 connections now open)
2020-05-08T12:16:25.189-0700 I  NETWORK  [conn34] end connection 192.168.122.12:40572 (62 connections now open)
2020-05-08T12:16:25.443-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:25.445-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41898 #142 (63 connections now open)
2020-05-08T12:16:25.445-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41900 #143 (64 connections now open)
2020-05-08T12:16:25.445-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.11:41898 conn142: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:25.446-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.11:41900 conn143: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:25.447-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41902 #144 (65 connections now open)
2020-05-08T12:16:25.447-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41904 #145 (66 connections now open)
2020-05-08T12:16:25.447-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.11:41902 conn144: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:25.448-0700 I  NETWORK  [conn145] received client metadata from 192.168.122.11:41904 conn145: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:27.532-0700 I  REPL     [replexec-6] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:27.656-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43608 #149 (67 connections now open)
2020-05-08T12:16:27.657-0700 I  NETWORK  [conn149] received client metadata from 192.168.122.12:43608 conn149: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:27.740-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43628 #150 (68 connections now open)
2020-05-08T12:16:27.741-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.12:43628 conn150: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:27.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43630 #151 (69 connections now open)
2020-05-08T12:16:27.744-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.12:43630 conn151: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:27.863-0700 I  NETWORK  [conn151] end connection 192.168.122.12:43630 (68 connections now open)
2020-05-08T12:16:29.862-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45794 #152 (69 connections now open)
2020-05-08T12:16:29.862-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45800 #153 (70 connections now open)
2020-05-08T12:16:29.862-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:45794 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:29.862-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:45800 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:29.865-0700 I  NETWORK  [conn152] end connection 192.168.122.1:45794 (69 connections now open)
2020-05-08T12:16:29.865-0700 I  NETWORK  [conn153] end connection 192.168.122.1:45800 (68 connections now open)
2020-05-08T12:16:30.173-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45804 #154 (69 connections now open)
2020-05-08T12:16:30.173-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45812 #155 (70 connections now open)
2020-05-08T12:16:30.173-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.1:45804 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.174-0700 I  NETWORK  [conn155] received client metadata from 192.168.122.1:45812 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.176-0700 I  NETWORK  [conn154] end connection 192.168.122.1:45804 (69 connections now open)
2020-05-08T12:16:30.176-0700 I  NETWORK  [conn155] end connection 192.168.122.1:45812 (68 connections now open)
2020-05-08T12:16:30.594-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45832 #156 (69 connections now open)
2020-05-08T12:16:30.594-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45838 #157 (70 connections now open)
2020-05-08T12:16:30.594-0700 I  NETWORK  [conn156] received client metadata from 192.168.122.1:45832 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.595-0700 I  NETWORK  [conn157] received client metadata from 192.168.122.1:45838 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:30.599-0700 I  NETWORK  [conn156] end connection 192.168.122.1:45832 (69 connections now open)
2020-05-08T12:16:30.599-0700 I  NETWORK  [conn157] end connection 192.168.122.1:45838 (68 connections now open)
2020-05-08T12:16:32.999-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46048 #158 (69 connections now open)
2020-05-08T12:16:33.000-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46052 #159 (70 connections now open)
2020-05-08T12:16:33.000-0700 I  NETWORK  [conn158] received client metadata from 192.168.122.1:46048 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:33.000-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.1:46052 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:33.003-0700 I  NETWORK  [conn158] end connection 192.168.122.1:46048 (69 connections now open)
2020-05-08T12:16:33.003-0700 I  NETWORK  [conn159] end connection 192.168.122.1:46052 (68 connections now open)
2020-05-08T12:16:33.938-0700 I  REPL     [replexec-6] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:33.938-0700 I  REPL     [replexec-6] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:33.938-0700 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-05-08T12:16:33.938-0700 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-05-08T12:16:33.938-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:33.938-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:33.938-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:33.938-0700 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-05-08T12:16:33.939-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:34.051-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:34.534-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:34.552-0700 I  REPL     [replexec-4] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:34.657-0700 I  ELECTION [conn149] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:34.657-0700 I  ELECTION [conn149] Sending vote response: { term: 10, voteGranted: false, reason: "candidate's term (9) is lower than mine (10)" }
2020-05-08T12:16:34.657-0700 I  NETWORK  [conn149] end connection 192.168.122.12:43608 (67 connections now open)
2020-05-08T12:16:34.696-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46124 #160 (68 connections now open)
2020-05-08T12:16:34.697-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46128 #161 (69 connections now open)
2020-05-08T12:16:34.697-0700 I  NETWORK  [conn160] received client metadata from 192.168.122.1:46124 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:34.697-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.1:46128 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:34.700-0700 I  NETWORK  [conn160] end connection 192.168.122.1:46124 (68 connections now open)
2020-05-08T12:16:34.700-0700 I  NETWORK  [conn161] end connection 192.168.122.1:46128 (67 connections now open)
2020-05-08T12:16:35.009-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:44012 #162 (68 connections now open)
2020-05-08T12:16:35.009-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.12:44012 conn162: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:35.010-0700 I  NETWORK  [conn14] end connection 192.168.122.12:40396 (67 connections now open)
2020-05-08T12:16:35.035-0700 I  REPL     [replexec-3] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:35.035-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-08T12:16:36.073-0700
2020-05-08T12:16:35.041-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:44014 #163 (68 connections now open)
2020-05-08T12:16:35.041-0700 I  NETWORK  [conn163] received client metadata from 192.168.122.12:44014 conn163: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:35.061-0700 I  ELECTION [conn119] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:35.061-0700 I  ELECTION [conn119] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-08T12:16:35.064-0700 I  REPL     [conn119] Canceling priority takeover callback
2020-05-08T12:16:35.064-0700 I  ELECTION [conn119] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965389, 3), t: 9 } }
2020-05-08T12:16:35.064-0700 I  ELECTION [conn119] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-08T12:16:35.553-0700 I  REPL     [replexec-1] Member n3:27019 is now in state PRIMARY
2020-05-08T12:16:35.553-0700 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-05-08T12:16:36.604-0700
2020-05-08T12:16:35.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46158 #164 (69 connections now open)
2020-05-08T12:16:35.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46166 #165 (70 connections now open)
2020-05-08T12:16:35.665-0700 I  NETWORK  [conn164] received client metadata from 192.168.122.1:46158 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:35.665-0700 I  NETWORK  [conn165] received client metadata from 192.168.122.1:46166 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:35.668-0700 I  NETWORK  [conn164] end connection 192.168.122.1:46158 (69 connections now open)
2020-05-08T12:16:35.669-0700 I  NETWORK  [conn165] end connection 192.168.122.1:46166 (68 connections now open)
2020-05-08T12:16:35.940-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:35.942-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:35.948-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1588965395, 4), t: 10 }, latest oplog optime of sync source: { ts: Timestamp(1588965395, 4), t: 10 } (sync source does not know the primary)
2020-05-08T12:16:35.948-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1588965395, 4), t: 10 }, its sync source index:-1
2020-05-08T12:16:35.948-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965395, 4), t: 10 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:16:35.948-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-08T12:16:35.949-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:16:35.950-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:35.951-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:36.604-0700 I  REPL     [replexec-3] Canceling priority takeover callback
2020-05-08T12:16:36.604-0700 I  ELECTION [replexec-3] Not starting an election for a priority takeover, since we are not electable due to: Not standing for election because member is not caught up enough to the most up-to-date member to call for priority takeover - must be within 2 seconds (mask 0x80)
2020-05-08T12:16:36.949-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:16:36.951-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:16:36.951-0700 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-05-08T12:16:38.042-0700
2020-05-08T12:16:36.952-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965395, 4), t: 10 }. source's GTE: { ts: Timestamp(1588965395, 4), t: 11 }
2020-05-08T12:16:36.952-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965389, 3), t: 9 }
2020-05-08T12:16:36.953-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:16:36.953-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n3:27019)
2020-05-08T12:16:36.953-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:16:36.953-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 69 }
2020-05-08T12:16:36.953-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-08T12:16:36.953-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 163
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 162
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 150
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 145
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 144
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 143
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 142
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 138
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 133
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 119
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 116
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 78
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 75
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 74
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-08T12:16:36.953-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 53
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-05-08T12:16:36.954-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-08T12:16:36.954-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-08T12:16:36.954-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-08T12:16:36.954-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-08T12:16:37.002-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1588965389, 3), t: 9 }
2020-05-08T12:16:37.004-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 3
2020-05-08T12:16:37.005-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-08T12:16:37.005-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid ed1a62fa-1d96-460b-b917-f8098f56b82b to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-08T19-16-37.1.bson
2020-05-08T12:16:37.005-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-08T12:16:37.005-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-08T12:16:37.005-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-08T12:16:37.006-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-08T12:16:37.011-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1588965389, 3) Initial Data Timestamp: Timestamp(1588965338, 1)
2020-05-08T12:16:37.012-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-08T12:16:37.023-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-08T12:16:37.023-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 221 records totaling to 48451 bytes
2020-05-08T12:16:37.023-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:16:37.023-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-08T12:16:37.027-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-08T12:16:37.027-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-08T12:16:37.044-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-08T12:16:37.044-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-08T12:16:37.044-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1588965389, 3)
2020-05-08T12:16:37.044-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 2 update operations and 0 delete operations.
2020-05-08T12:16:37.044-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1588965395, 1), t: 10 }
2020-05-08T12:16:37.044-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1588965395, 1) }
2020-05-08T12:16:37.044-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1588965389, 3) (top of oplog: { ts: Timestamp(1588965389, 3), t: 9 }, appliedThrough: { ts: Timestamp(1588965389, 3), t: 9 }, TruncateAfter: Timestamp(0, 0))
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1588965389, 3)
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-08T12:16:36.953-0700
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-08T12:16:37.047-0700
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n3:27019
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.mongos
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 3
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1588965395, 4), t: 10 }
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1588965389, 3), t: 9 }
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-08T12:16:35.569-0700
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-08T12:16:35.011-0700
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1588965395, 1)
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1588965389, 3)
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 		update: 2
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 3
2020-05-08T12:16:37.047-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n3:27019
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:16:37.047-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:16:37.049-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:16:37.203-0700 I  NETWORK  [shard-registry-reload] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:37.203-0700 I  NETWORK  [shard-registry-reload] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:37.205-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:16:37.205-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:37.467-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46294 #167 (69 connections now open)
2020-05-08T12:16:37.467-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46298 #168 (70 connections now open)
2020-05-08T12:16:37.468-0700 I  NETWORK  [conn167] received client metadata from 192.168.122.1:46294 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.468-0700 I  NETWORK  [conn168] received client metadata from 192.168.122.1:46298 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:37.471-0700 I  NETWORK  [conn167] end connection 192.168.122.1:46294 (69 connections now open)
2020-05-08T12:16:37.471-0700 I  NETWORK  [conn168] end connection 192.168.122.1:46298 (68 connections now open)
2020-05-08T12:16:38.952-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-08T12:16:40.087-0700
2020-05-08T12:16:39.023-0700 I  ELECTION [conn163] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965397, 5), t: 11 } }
2020-05-08T12:16:39.023-0700 I  ELECTION [conn163] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-08T12:16:39.030-0700 I  REPL     [conn163] Canceling priority takeover callback
2020-05-08T12:16:39.030-0700 I  ELECTION [conn163] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965397, 5), t: 11 } }
2020-05-08T12:16:39.030-0700 I  ELECTION [conn163] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-05-08T12:16:39.265-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n3:27019, my last fetched oplog optime: { ts: Timestamp(1588965397, 5), t: 11 }, latest oplog optime of sync source: { ts: Timestamp(1588965397, 5), t: 11 } (sync source does not know the primary)
2020-05-08T12:16:39.265-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n3:27019, OpTime { ts: Timestamp(1588965397, 5), t: 11 }, its sync source index:-1
2020-05-08T12:16:39.265-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965397, 5), t: 11 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:16:39.266-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-08T12:16:39.266-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:16:39.267-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:39.267-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-08T12:16:40.295-0700
2020-05-08T12:16:39.267-0700 I  REPL     [replexec-3] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:39.765-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:16:40.266-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-08T12:16:40.268-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-08T12:16:40.273-0700 I  COMMAND  [conn37] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965399, 5), t: 12 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965399, 5), signature: { hash: BinData(0, FA4D3AFD5793CA054CB0FB09FDE9207BEB6C7A05), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 229ms
2020-05-08T12:16:40.295-0700 I  REPL     [replexec-4] Canceling priority takeover callback
2020-05-08T12:16:40.295-0700 I  ELECTION [replexec-4] Starting an election for a priority takeover
2020-05-08T12:16:40.295-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 12
2020-05-08T12:16:40.295-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 310 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965399, 5), t: 12 } }
2020-05-08T12:16:40.295-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 311 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965399, 5), t: 12 } }
2020-05-08T12:16:40.296-0700 I  ELECTION [replexec-6] VoteRequester(term 12 dry run) received a yes vote from n2:27019; response message: { term: 12, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1588965399, 5), $clusterTime: { clusterTime: Timestamp(1588965399, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965399, 5) }
2020-05-08T12:16:40.296-0700 I  ELECTION [replexec-6] dry election run succeeded, running for election in term 13
2020-05-08T12:16:40.299-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 312 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965399, 5), t: 12 } }
2020-05-08T12:16:40.300-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 313 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965399, 5), t: 12 } }
2020-05-08T12:16:40.304-0700 I  ELECTION [replexec-4] VoteRequester(term 13) received a yes vote from n3:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1588965399, 5), $clusterTime: { clusterTime: Timestamp(1588965399, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965399, 5) }
2020-05-08T12:16:40.305-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 13
2020-05-08T12:16:40.305-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:16:40.305-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was n2:27019
2020-05-08T12:16:40.305-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:40.305-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:16:40.305-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:40.308-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:40.308-0700 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965399, 5), t: 12 }. My Last Applied: { ts: Timestamp(1588965399, 5), t: 12 }
2020-05-08T12:16:40.308-0700 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-05-08T12:16:40.308-0700 I  REPL     [replexec-4] Stopping replication producer
2020-05-08T12:16:40.308-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 13
2020-05-08T12:16:40.308-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:16:40.308-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:40.309-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:40.309-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:40.309-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:40.312-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:40.312-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:40.312-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:40.313-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:40.313-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:40.315-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:16:40.315-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:16:40.318-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:40.528-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46404 #171 (69 connections now open)
2020-05-08T12:16:40.529-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46410 #172 (70 connections now open)
2020-05-08T12:16:40.529-0700 I  NETWORK  [conn171] received client metadata from 192.168.122.1:46404 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:40.529-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.1:46410 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:40.531-0700 I  NETWORK  [conn171] end connection 192.168.122.1:46404 (69 connections now open)
2020-05-08T12:16:40.531-0700 I  NETWORK  [conn172] end connection 192.168.122.1:46410 (68 connections now open)
2020-05-08T12:16:40.777-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-08T12:16:40.818-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:16:41.307-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:44352 #173 (69 connections now open)
2020-05-08T12:16:41.307-0700 I  NETWORK  [conn173] received client metadata from 192.168.122.12:44352 conn173: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965400, 34), signature: { hash: BinData(0, 86148381B1EB0BAEF21514092F5830E2BEA81DE9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 388ms
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn145] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965400, 34), signature: { hash: BinData(0, 86148381B1EB0BAEF21514092F5830E2BEA81DE9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 195ms
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965400, 24), signature: { hash: BinData(0, 86148381B1EB0BAEF21514092F5830E2BEA81DE9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 410ms
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965400, 34), signature: { hash: BinData(0, 86148381B1EB0BAEF21514092F5830E2BEA81DE9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 134ms
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965400, 34), signature: { hash: BinData(0, 86148381B1EB0BAEF21514092F5830E2BEA81DE9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 222ms
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn24] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965400, 24), signature: { hash: BinData(0, 86148381B1EB0BAEF21514092F5830E2BEA81DE9), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 393ms
2020-05-08T12:16:41.313-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965401, 2), signature: { hash: BinData(0, 9F359F1F1561E034D8F7B53829925BB4BF56B12A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965399, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 131ms
2020-05-08T12:16:41.313-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:16:41.314-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:16:41.318-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:16:41.319-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-08T12:16:42.242-0700 I  NETWORK  [conn30] end connection 192.168.122.15:38584 (68 connections now open)
2020-05-08T12:16:44.278-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46682 #175 (69 connections now open)
2020-05-08T12:16:44.278-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46688 #176 (70 connections now open)
2020-05-08T12:16:44.278-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.1:46682 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:44.278-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.1:46688 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:44.282-0700 I  NETWORK  [conn175] end connection 192.168.122.1:46682 (69 connections now open)
2020-05-08T12:16:44.282-0700 I  NETWORK  [conn176] end connection 192.168.122.1:46688 (68 connections now open)
2020-05-08T12:16:45.067-0700 I  REPL     [replexec-6] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:45.067-0700 I  REPL     [replexec-6] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:45.067-0700 I  REPL     [replexec-6] can't see a majority of the set, relinquishing primary
2020-05-08T12:16:45.067-0700 I  REPL     [replexec-6] Stepping down from primary in response to heartbeat
2020-05-08T12:16:45.067-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:45.067-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:45.068-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:45.068-0700 I  REPL     [replexec-6] transition to SECONDARY from PRIMARY
2020-05-08T12:16:45.068-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:45.307-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:45.307-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:16:45.309-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:45.309-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:45.386-0700 I  NETWORK  [conn59] end connection 192.168.122.14:45818 (67 connections now open)
2020-05-08T12:16:45.386-0700 I  NETWORK  [conn64] end connection 192.168.122.15:38914 (66 connections now open)
2020-05-08T12:16:45.387-0700 I  NETWORK  [conn67] end connection 192.168.122.15:38920 (65 connections now open)
2020-05-08T12:16:45.387-0700 I  NETWORK  [conn65] end connection 192.168.122.16:47248 (64 connections now open)
2020-05-08T12:16:45.389-0700 I  NETWORK  [conn60] end connection 192.168.122.14:45826 (63 connections now open)
2020-05-08T12:16:45.574-0700 I  NETWORK  [conn75] end connection 192.168.122.17:33494 (62 connections now open)
2020-05-08T12:16:45.577-0700 I  NETWORK  [conn80] end connection 192.168.122.19:36556 (61 connections now open)
2020-05-08T12:16:45.578-0700 I  NETWORK  [conn82] end connection 192.168.122.18:44236 (60 connections now open)
2020-05-08T12:16:45.578-0700 I  NETWORK  [conn78] end connection 192.168.122.18:44226 (59 connections now open)
2020-05-08T12:16:45.583-0700 I  NETWORK  [conn74] end connection 192.168.122.17:33490 (58 connections now open)
2020-05-08T12:16:45.752-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34332 #177 (59 connections now open)
2020-05-08T12:16:45.752-0700 I  NETWORK  [conn177] received client metadata from 192.168.122.13:34332 conn177: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:45.753-0700 I  ELECTION [conn177] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.753-0700 I  ELECTION [conn177] Sending vote response: { term: 14, voteGranted: true, reason: "" }
2020-05-08T12:16:45.757-0700 I  NETWORK  [conn177] end connection 192.168.122.13:34332 (58 connections now open)
2020-05-08T12:16:45.793-0700 I  ELECTION [conn163] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.793-0700 I  ELECTION [conn163] Sending vote response: { term: 14, voteGranted: false, reason: "candidate's term (13) is lower than mine (14)" }
2020-05-08T12:16:45.793-0700 I  NETWORK  [conn163] end connection 192.168.122.12:44014 (57 connections now open)
2020-05-08T12:16:45.889-0700 I  ELECTION [conn119] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:45.889-0700 I  ELECTION [conn119] Sending vote response: { term: 14, voteGranted: false, reason: "candidate's term (13) is lower than mine (14)" }
2020-05-08T12:16:45.889-0700 I  NETWORK  [conn119] end connection 192.168.122.13:60670 (56 connections now open)
2020-05-08T12:16:45.902-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46734 #178 (57 connections now open)
2020-05-08T12:16:45.903-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46740 #179 (58 connections now open)
2020-05-08T12:16:45.903-0700 I  NETWORK  [conn178] received client metadata from 192.168.122.1:46734 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:45.903-0700 I  NETWORK  [conn179] received client metadata from 192.168.122.1:46740 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:45.907-0700 I  NETWORK  [conn178] end connection 192.168.122.1:46734 (57 connections now open)
2020-05-08T12:16:45.907-0700 I  NETWORK  [conn179] end connection 192.168.122.1:46740 (56 connections now open)
2020-05-08T12:16:46.158-0700 I  ELECTION [conn162] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965403, 8), t: 13 } }
2020-05-08T12:16:46.158-0700 I  ELECTION [conn162] Sending vote response: { term: 14, voteGranted: false, reason: "already voted for another candidate (n3:27019) this term (14)" }
2020-05-08T12:16:46.159-0700 I  NETWORK  [conn162] end connection 192.168.122.12:44012 (55 connections now open)
2020-05-08T12:16:46.177-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34310 #180 (56 connections now open)
2020-05-08T12:16:46.177-0700 I  NETWORK  [conn180] received client metadata from 192.168.122.13:34310 conn180: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:46.179-0700 I  NETWORK  [conn133] end connection 192.168.122.13:32868 (55 connections now open)
2020-05-08T12:16:46.338-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-08T12:16:46.339-0700 I  REPL     [replexec-3] Member n3:27019 is now in state PRIMARY
2020-05-08T12:16:46.339-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-08T12:16:47.456-0700
2020-05-08T12:16:46.561-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:44626 #183 (56 connections now open)
2020-05-08T12:16:46.561-0700 I  NETWORK  [conn183] received client metadata from 192.168.122.12:44626 conn183: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:46.720-0700 I  NETWORK  [conn86] end connection 192.168.122.17:33640 (55 connections now open)
2020-05-08T12:16:46.720-0700 I  NETWORK  [conn52] end connection 192.168.122.17:33260 (54 connections now open)
2020-05-08T12:16:46.731-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46808 #184 (55 connections now open)
2020-05-08T12:16:46.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46812 #185 (56 connections now open)
2020-05-08T12:16:46.732-0700 I  NETWORK  [conn184] received client metadata from 192.168.122.1:46808 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.732-0700 I  NETWORK  [conn185] received client metadata from 192.168.122.1:46812 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:46.735-0700 I  NETWORK  [conn184] end connection 192.168.122.1:46808 (55 connections now open)
2020-05-08T12:16:46.735-0700 I  NETWORK  [conn185] end connection 192.168.122.1:46812 (54 connections now open)
2020-05-08T12:16:47.069-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:16:47.283-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:16:47.456-0700 I  REPL     [replexec-4] Canceling priority takeover callback
2020-05-08T12:16:47.456-0700 I  ELECTION [replexec-4] Starting an election for a priority takeover
2020-05-08T12:16:47.456-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 14
2020-05-08T12:16:47.456-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 359 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965407, 1), t: 14 } }
2020-05-08T12:16:47.456-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 360 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965407, 1), t: 14 } }
2020-05-08T12:16:47.456-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:16:47.457-0700 I  ELECTION [replexec-3] VoteRequester(term 14 dry run) received a yes vote from n2:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1588965403, 8), $clusterTime: { clusterTime: Timestamp(1588965407, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965403, 8) }
2020-05-08T12:16:47.457-0700 I  ELECTION [replexec-6] dry election run succeeded, running for election in term 15
2020-05-08T12:16:47.460-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 362 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965407, 1), t: 14 } }
2020-05-08T12:16:47.460-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 363 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965407, 1), t: 14 } }
2020-05-08T12:16:47.463-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46856 #187 (55 connections now open)
2020-05-08T12:16:47.464-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46862 #188 (56 connections now open)
2020-05-08T12:16:47.464-0700 I  ELECTION [replexec-4] VoteRequester(term 15) received a yes vote from n2:27019; response message: { term: 15, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1588965403, 8), $clusterTime: { clusterTime: Timestamp(1588965407, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965403, 8) }
2020-05-08T12:16:47.464-0700 I  NETWORK  [conn187] received client metadata from 192.168.122.1:46856 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:47.464-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 15
2020-05-08T12:16:47.464-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:16:47.464-0700 I  NETWORK  [conn188] received client metadata from 192.168.122.1:46862 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:47.464-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:47.464-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was n3:27019
2020-05-08T12:16:47.464-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:16:47.465-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:47.467-0700 I  REPL     [replexec-4] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:47.467-0700 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965407, 1), t: 14 }. My Last Applied: { ts: Timestamp(1588965407, 1), t: 14 }
2020-05-08T12:16:47.467-0700 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-05-08T12:16:47.467-0700 I  REPL     [replexec-4] Stopping replication producer
2020-05-08T12:16:47.467-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 15
2020-05-08T12:16:47.467-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:16:47.467-0700 I  CONNPOOL [RS] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:16:47.468-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:47.468-0700 I  NETWORK  [conn187] end connection 192.168.122.1:46856 (55 connections now open)
2020-05-08T12:16:47.468-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:47.468-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:47.468-0700 I  NETWORK  [conn188] end connection 192.168.122.1:46862 (54 connections now open)
2020-05-08T12:16:47.470-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:47.470-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:47.471-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:47.471-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:47.471-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:47.760-0700 I  COMMAND  [conn44] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965405, 49), signature: { hash: BinData(0, 6EE48B0F525267D0F49F4711CADC69288848D8F0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965403, 8), t: 13 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 267ms
2020-05-08T12:16:47.760-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:16:47.760-0700 I  COMMAND  [conn145] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1588965407057), up: 63, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965407, 1), signature: { hash: BinData(0, 44F2904FF45A0449A2D359F3DA486CF736BDABB6), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965407, 1), t: 14 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 198ms
2020-05-08T12:16:47.760-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:16:47.760-0700 I  COMMAND  [conn88] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965407, 2), signature: { hash: BinData(0, 44F2904FF45A0449A2D359F3DA486CF736BDABB6), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965407, 1), t: 14 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 287ms
2020-05-08T12:16:47.791-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:16:47.815-0700 I  NETWORK  [conn53] end connection 192.168.122.18:43980 (53 connections now open)
2020-05-08T12:16:48.323-0700 I  NETWORK  [conn35] end connection 192.168.122.19:36226 (52 connections now open)
2020-05-08T12:16:48.834-0700 I  NETWORK  [conn26] end connection 192.168.122.16:46898 (51 connections now open)
2020-05-08T12:16:50.397-0700 I  NETWORK  [conn89] end connection 192.168.122.14:46206 (50 connections now open)
2020-05-08T12:16:51.110-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47058 #190 (51 connections now open)
2020-05-08T12:16:51.110-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47064 #191 (52 connections now open)
2020-05-08T12:16:51.110-0700 I  NETWORK  [conn190] received client metadata from 192.168.122.1:47058 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.111-0700 I  NETWORK  [conn191] received client metadata from 192.168.122.1:47064 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:51.114-0700 I  NETWORK  [conn190] end connection 192.168.122.1:47058 (51 connections now open)
2020-05-08T12:16:51.114-0700 I  NETWORK  [conn191] end connection 192.168.122.1:47064 (50 connections now open)
2020-05-08T12:16:51.791-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:51.791-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:51.791-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-08T12:16:51.791-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-08T12:16:51.791-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:51.791-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:51.791-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:51.792-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-08T12:16:51.792-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:52.467-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:52.467-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:52.468-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:52.468-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:16:52.897-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45008 #192 (51 connections now open)
2020-05-08T12:16:52.897-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45010 #193 (52 connections now open)
2020-05-08T12:16:52.897-0700 I  NETWORK  [conn192] received client metadata from 192.168.122.12:45008 conn192: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:52.898-0700 I  NETWORK  [conn193] received client metadata from 192.168.122.12:45010 conn193: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:16:52.920-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:52.957-0700 I  NETWORK  [conn150] end connection 192.168.122.12:43628 (51 connections now open)
2020-05-08T12:16:53.020-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47162 #194 (52 connections now open)
2020-05-08T12:16:53.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47166 #195 (53 connections now open)
2020-05-08T12:16:53.021-0700 I  NETWORK  [conn194] received client metadata from 192.168.122.1:47162 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.021-0700 I  NETWORK  [conn195] received client metadata from 192.168.122.1:47166 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.024-0700 I  NETWORK  [conn194] end connection 192.168.122.1:47162 (52 connections now open)
2020-05-08T12:16:53.024-0700 I  NETWORK  [conn195] end connection 192.168.122.1:47166 (51 connections now open)
2020-05-08T12:16:53.475-0700 I  REPL     [replexec-0] Member n2:27019 is now in state PRIMARY
2020-05-08T12:16:53.475-0700 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-05-08T12:16:54.525-0700
2020-05-08T12:16:53.475-0700 I  REPL     [replexec-3] Member n3:27019 is now in state SECONDARY
2020-05-08T12:16:53.649-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47192 #198 (52 connections now open)
2020-05-08T12:16:53.650-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47198 #199 (53 connections now open)
2020-05-08T12:16:53.650-0700 I  NETWORK  [conn198] received client metadata from 192.168.122.1:47192 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.650-0700 I  NETWORK  [conn199] received client metadata from 192.168.122.1:47198 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:53.653-0700 I  NETWORK  [conn198] end connection 192.168.122.1:47192 (52 connections now open)
2020-05-08T12:16:53.653-0700 I  NETWORK  [conn199] end connection 192.168.122.1:47198 (51 connections now open)
2020-05-08T12:16:53.794-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:16:53.795-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:16:53.796-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-08T12:16:54.484-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47236 #201 (52 connections now open)
2020-05-08T12:16:54.485-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47240 #202 (53 connections now open)
2020-05-08T12:16:54.485-0700 I  NETWORK  [conn201] received client metadata from 192.168.122.1:47236 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.485-0700 I  NETWORK  [conn202] received client metadata from 192.168.122.1:47240 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.488-0700 I  NETWORK  [conn201] end connection 192.168.122.1:47236 (52 connections now open)
2020-05-08T12:16:54.489-0700 I  NETWORK  [conn202] end connection 192.168.122.1:47240 (51 connections now open)
2020-05-08T12:16:54.525-0700 I  REPL     [replexec-4] Canceling priority takeover callback
2020-05-08T12:16:54.525-0700 I  ELECTION [replexec-4] Starting an election for a priority takeover
2020-05-08T12:16:54.525-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 16
2020-05-08T12:16:54.525-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 390 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:54.525-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 391 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:54.526-0700 I  ELECTION [replexec-3] VoteRequester(term 16 dry run) received a yes vote from n3:27019; response message: { term: 16, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000e') }, lastCommittedOpTime: Timestamp(1588965412, 1), $clusterTime: { clusterTime: Timestamp(1588965414, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965412, 1) }
2020-05-08T12:16:54.526-0700 I  ELECTION [replexec-6] dry election run succeeded, running for election in term 17
2020-05-08T12:16:54.526-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:54.526-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:16:54.529-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 392 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 17, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:54.529-0700 I  REPL     [replexec-6] Scheduling remote command request for vote request: RemoteCommand 393 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 17, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:16:54.533-0700 I  ELECTION [replexec-4] VoteRequester(term 17) received a yes vote from n3:27019; response message: { term: 17, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000e') }, lastCommittedOpTime: Timestamp(1588965412, 1), $clusterTime: { clusterTime: Timestamp(1588965414, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965412, 1) }
2020-05-08T12:16:54.533-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 17
2020-05-08T12:16:54.533-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:16:54.533-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was n3:27019
2020-05-08T12:16:54.533-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:16:54.803-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965412, 1), t: 16 }; sync source index: 1; primary index: -1) is no longer valid
2020-05-08T12:16:54.809-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:16:54.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47280 #203 (52 connections now open)
2020-05-08T12:16:54.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47284 #204 (53 connections now open)
2020-05-08T12:16:54.909-0700 I  NETWORK  [conn203] received client metadata from 192.168.122.1:47280 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.910-0700 I  NETWORK  [conn204] received client metadata from 192.168.122.1:47284 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:16:54.913-0700 I  NETWORK  [conn203] end connection 192.168.122.1:47280 (52 connections now open)
2020-05-08T12:16:54.913-0700 I  NETWORK  [conn204] end connection 192.168.122.1:47284 (51 connections now open)
2020-05-08T12:16:55.533-0700 I  REPL     [replexec-3] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-08T12:16:55.533-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965412, 1), t: 16 }. My Last Applied: { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:16:55.533-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-08T12:16:55.533-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-08T12:16:55.533-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 17
2020-05-08T12:16:55.534-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:55.534-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:55.534-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:55.536-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:16:55.536-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:16:55.537-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:16:55.537-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:16:55.537-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:16:55.889-0700 I  REPL     [replexec-0] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:16:55.889-0700 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-05-08T12:16:55.889-0700 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-05-08T12:16:55.889-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:16:55.889-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:16:55.889-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:16:55.890-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-08T12:16:55.890-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T12:16:55.890-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:16:57.011-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:57.534-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:16:57.534-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:16:58.066-0700 I  ELECTION [replexec-0] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:16:59.105-0700 I  ELECTION [replexec-6] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:00.189-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:01.254-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:02.372-0700 I  ELECTION [replexec-4] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:03.381-0700 I  ELECTION [replexec-0] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:03.585-0700 I  NETWORK  [conn192] end connection 192.168.122.12:45008 (50 connections now open)
2020-05-08T12:17:04.065-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45486 #205 (51 connections now open)
2020-05-08T12:17:04.065-0700 I  NETWORK  [conn205] received client metadata from 192.168.122.12:45486 conn205: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.097-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34994 #206 (52 connections now open)
2020-05-08T12:17:04.097-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34984 #207 (53 connections now open)
2020-05-08T12:17:04.097-0700 I  NETWORK  [conn206] received client metadata from 192.168.122.13:34994 conn206: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.097-0700 I  NETWORK  [conn207] received client metadata from 192.168.122.13:34984 conn207: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.098-0700 I  NETWORK  [conn207] end connection 192.168.122.13:34984 (52 connections now open)
2020-05-08T12:17:04.101-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45278 #208 (53 connections now open)
2020-05-08T12:17:04.101-0700 I  NETWORK  [conn208] received client metadata from 192.168.122.12:45278 conn208: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:04.391-0700 I  ELECTION [replexec-6] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:04.611-0700 I  REPL     [replexec-0] Member n3:27019 is now in state PRIMARY
2020-05-08T12:17:04.611-0700 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-05-08T12:17:05.644-0700
2020-05-08T12:17:04.894-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:04.896-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:04.898-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965415, 1), t: 17 }. source's GTE: { ts: Timestamp(1588965423, 2), t: 18 }
2020-05-08T12:17:04.898-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:17:04.898-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:17:04.898-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n3:27019)
2020-05-08T12:17:04.898-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:17:04.898-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 5, userOpsRunning: 49 }
2020-05-08T12:17:04.898-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-08T12:17:04.899-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 208
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 206
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 205
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 193
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 183
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 180
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 173
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 145
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 144
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 143
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 142
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 138
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 116
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-08T12:17:04.899-0700 I  COMMAND  [conn44] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965424, 57), t: 18 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 4ECFD216B39CDB4863389B7F011C915AB4422825), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(1588965412, 1), t: 16 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:766 locks:{} protocol:op_msg 133ms
2020-05-08T12:17:04.899-0700 I  COMMAND  [conn145] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965424, 57), t: 18 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 4ECFD216B39CDB4863389B7F011C915AB4422825), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(1588965412, 1), t: 16 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:766 locks:{} protocol:op_msg 133ms
2020-05-08T12:17:04.899-0700 I  COMMAND  [conn88] command config.$cmd command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965424, 57), t: 18 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 4ECFD216B39CDB4863389B7F011C915AB4422825), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:757 locks:{} protocol:op_msg 131ms
2020-05-08T12:17:04.899-0700 I  COMMAND  [conn87] command config.$cmd command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965424, 57), t: 18 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 4ECFD216B39CDB4863389B7F011C915AB4422825), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:757 locks:{} protocol:op_msg 131ms
2020-05-08T12:17:04.899-0700 I  COMMAND  [conn46] command config.$cmd command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1588965424, 57), t: 18 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965424, 57), signature: { hash: BinData(0, 4ECFD216B39CDB4863389B7F011C915AB4422825), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965424, 57), t: 18 } }, $db: "config" } numYields:0 ok:0 errMsg:"Error waiting for snapshot not less than { ts: Timestamp(1588965424, 57), t: 18 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:757 locks:{} protocol:op_msg 133ms
2020-05-08T12:17:04.899-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-05-08T12:17:04.900-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-08T12:17:04.900-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-08T12:17:04.900-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-08T12:17:04.900-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-08T12:17:04.905-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:17:04.912-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 4
2020-05-08T12:17:04.912-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-08T12:17:04.912-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-08T12:17:04.912-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-08T12:17:04.912-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-08T12:17:04.913-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-08T12:17:04.947-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1588965412, 1) Initial Data Timestamp: Timestamp(1588965338, 1)
2020-05-08T12:17:04.949-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-08T12:17:04.963-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-08T12:17:04.963-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 258 records totaling to 55489 bytes
2020-05-08T12:17:04.963-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:17:04.964-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-08T12:17:04.967-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-08T12:17:04.967-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-08T12:17:04.983-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-08T12:17:04.983-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-08T12:17:04.984-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1588965412, 1)
2020-05-08T12:17:04.984-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 0 update operations and 0 delete operations.
2020-05-08T12:17:04.984-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1588965415, 1), t: 17 }
2020-05-08T12:17:04.984-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1588965415, 1) }
2020-05-08T12:17:04.984-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1588965412, 1) (top of oplog: { ts: Timestamp(1588965412, 1), t: 16 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1588965412, 1)
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-08T12:17:04.898-0700
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-08T12:17:04.987-0700
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n3:27019
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: none; no files written
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 4
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1588965415, 1), t: 17 }
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1588965412, 1), t: 16 }
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-08T12:16:55.535-0700
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-08T12:16:55.535-0700
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1588965415, 1)
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1588965412, 1)
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: none
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 		update: 0
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 1
2020-05-08T12:17:04.987-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n3:27019
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:17:04.987-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:04.989-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:05.111-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-08T12:17:06.117-0700
2020-05-08T12:17:05.121-0700 I  NETWORK  [conn183] end connection 192.168.122.12:44626 (52 connections now open)
2020-05-08T12:17:05.410-0700 I  ELECTION [conn208] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 18, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:05.411-0700 I  ELECTION [conn208] Sending vote response: { term: 18, voteGranted: true, reason: "" }
2020-05-08T12:17:05.414-0700 I  REPL     [conn208] Canceling priority takeover callback
2020-05-08T12:17:05.414-0700 I  ELECTION [conn208] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:05.414-0700 I  ELECTION [conn208] Sending vote response: { term: 19, voteGranted: true, reason: "" }
2020-05-08T12:17:05.494-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n3:27019, my last fetched oplog optime: { ts: Timestamp(1588965424, 57), t: 18 }, latest oplog optime of sync source: { ts: Timestamp(1588965424, 57), t: 18 } (sync source does not know the primary)
2020-05-08T12:17:05.494-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n3:27019, OpTime { ts: Timestamp(1588965424, 57), t: 18 }, its sync source index:-1
2020-05-08T12:17:05.495-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965424, 57), t: 18 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:17:05.495-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-08T12:17:05.495-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:17:05.496-0700 I  REPL     [replexec-1] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:05.995-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:17:06.014-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47840 #211 (53 connections now open)
2020-05-08T12:17:06.014-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47846 #212 (54 connections now open)
2020-05-08T12:17:06.014-0700 I  NETWORK  [conn211] received client metadata from 192.168.122.1:47840 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.014-0700 I  NETWORK  [conn212] received client metadata from 192.168.122.1:47846 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.016-0700 I  NETWORK  [conn211] end connection 192.168.122.1:47840 (53 connections now open)
2020-05-08T12:17:06.016-0700 I  NETWORK  [conn212] end connection 192.168.122.1:47846 (52 connections now open)
2020-05-08T12:17:06.323-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47854 #213 (53 connections now open)
2020-05-08T12:17:06.324-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47862 #214 (54 connections now open)
2020-05-08T12:17:06.324-0700 I  NETWORK  [conn213] received client metadata from 192.168.122.1:47854 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.324-0700 I  NETWORK  [conn214] received client metadata from 192.168.122.1:47862 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:06.328-0700 I  NETWORK  [conn213] end connection 192.168.122.1:47854 (53 connections now open)
2020-05-08T12:17:06.328-0700 I  NETWORK  [conn214] end connection 192.168.122.1:47862 (52 connections now open)
2020-05-08T12:17:06.450-0700 I  ELECTION [conn206] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:06.450-0700 I  ELECTION [conn206] Sending vote response: { term: 19, voteGranted: true, reason: "" }
2020-05-08T12:17:06.455-0700 I  ELECTION [conn206] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 20, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965424, 57), t: 18 } }
2020-05-08T12:17:06.455-0700 I  ELECTION [conn206] Sending vote response: { term: 20, voteGranted: true, reason: "" }
2020-05-08T12:17:06.498-0700 I  REPL     [replexec-2] Member n3:27019 is now in state PRIMARY
2020-05-08T12:17:06.498-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-08T12:17:07.608-0700
2020-05-08T12:17:07.203-0700 I  NETWORK  [shard-registry-reload] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:07.203-0700 I  NETWORK  [shard-registry-reload] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:07.204-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:07.205-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:07.608-0700 I  REPL     [replexec-1] Canceling priority takeover callback
2020-05-08T12:17:07.608-0700 I  ELECTION [replexec-1] Not starting an election for a priority takeover, since we are not electable due to: Not standing for election because member is not caught up enough to the most up-to-date member to call for priority takeover - must be within 2 seconds (mask 0x80)
2020-05-08T12:17:07.999-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-08T12:17:09.029-0700
2020-05-08T12:17:08.496-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:08.498-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:09.029-0700 I  REPL     [replexec-1] Canceling priority takeover callback
2020-05-08T12:17:09.029-0700 I  ELECTION [replexec-1] Starting an election for a priority takeover
2020-05-08T12:17:09.029-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 20
2020-05-08T12:17:09.029-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 459 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 20, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:09.029-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 460 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 20, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:09.029-0700 I  ELECTION [replexec-0] VoteRequester(term 20 dry run) received a yes vote from n3:27019; response message: { term: 20, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1588965427, 1), $clusterTime: { clusterTime: Timestamp(1588965427, 48), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965427, 1) }
2020-05-08T12:17:09.030-0700 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 21
2020-05-08T12:17:09.032-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 461 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 21, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:09.032-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 462 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 21, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:09.036-0700 I  ELECTION [replexec-4] VoteRequester(term 21) received a yes vote from n3:27019; response message: { term: 21, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000014') }, lastCommittedOpTime: Timestamp(1588965427, 1), $clusterTime: { clusterTime: Timestamp(1588965427, 48), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965427, 1) }
2020-05-08T12:17:09.036-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 21
2020-05-08T12:17:09.036-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-08T12:17:09.036-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was n3:27019
2020-05-08T12:17:09.036-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-08T12:17:09.036-0700 I  REPL     [replexec-6] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:09.221-0700 I  ELECTION [conn180] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:17:09.221-0700 I  ELECTION [conn180] Sending vote response: { term: 21, voteGranted: false, reason: "candidate's term (17) is lower than mine (21)" }
2020-05-08T12:17:09.221-0700 I  NETWORK  [conn180] end connection 192.168.122.13:34310 (51 connections now open)
2020-05-08T12:17:09.506-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:17:09.506-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965427, 1), t: 20 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:17:10.036-0700 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-05-08T12:17:10.036-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-08T12:17:10.036-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-08T12:17:10.036-0700 I  REPL     [replexec-4] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:10.036-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:10.036-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-08T12:17:10.036-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 21
2020-05-08T12:17:10.036-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:10.036-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:10.036-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:10.036-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:10.037-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:17:10.037-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:10.037-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:10.173-0700 I  ELECTION [conn206] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:10.174-0700 I  ELECTION [conn206] Sending vote response: { term: 21, voteGranted: true, reason: "" }
2020-05-08T12:17:10.178-0700 I  ELECTION [conn206] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 22, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965427, 1), t: 20 } }
2020-05-08T12:17:10.178-0700 I  ELECTION [conn206] Sending vote response: { term: 22, voteGranted: true, reason: "" }
2020-05-08T12:17:10.753-0700 I  NETWORK  [conn208] end connection 192.168.122.12:45278 (50 connections now open)
2020-05-08T12:17:11.036-0700 I  REPL     [replexec-3] Member n3:27019 is now in state PRIMARY
2020-05-08T12:17:11.037-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-08T12:17:12.103-0700
2020-05-08T12:17:11.233-0700 I  NETWORK  [conn48] end connection 192.168.122.12:40660 (49 connections now open)
2020-05-08T12:17:11.421-0700 I  NETWORK  [conn205] end connection 192.168.122.12:45486 (48 connections now open)
2020-05-08T12:17:11.422-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45942 #215 (49 connections now open)
2020-05-08T12:17:11.423-0700 I  NETWORK  [conn215] received client metadata from 192.168.122.12:45942 conn215: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:11.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45878 #216 (50 connections now open)
2020-05-08T12:17:11.457-0700 I  NETWORK  [conn216] received client metadata from 192.168.122.12:45878 conn216: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:11.508-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:12.013-0700 I  NETWORK  [conn51] end connection 192.168.122.13:58618 (49 connections now open)
2020-05-08T12:17:12.066-0700 I  NETWORK  [conn116] end connection 192.168.122.13:60732 (48 connections now open)
2020-05-08T12:17:12.103-0700 I  REPL     [replexec-1] Canceling priority takeover callback
2020-05-08T12:17:12.103-0700 I  ELECTION [replexec-1] Not starting an election for a priority takeover, since we are not electable due to: Not standing for election because member is not caught up enough to the most up-to-date member to call for priority takeover - must be within 2 seconds (mask 0x80)
2020-05-08T12:17:12.903-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:45982 #217 (49 connections now open)
2020-05-08T12:17:13.087-0700 I  NETWORK  [conn217] received client metadata from 192.168.122.12:45982 conn217: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:13.538-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-08T12:17:14.607-0700
2020-05-08T12:17:14.533-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:14.607-0700 I  REPL     [replexec-0] Canceling priority takeover callback
2020-05-08T12:17:14.607-0700 I  ELECTION [replexec-0] Starting an election for a priority takeover
2020-05-08T12:17:14.607-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 22
2020-05-08T12:17:14.607-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 496 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:14.607-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 497 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 22, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:14.607-0700 I  ELECTION [replexec-4] VoteRequester(term 22 dry run) received a yes vote from n2:27019; response message: { term: 22, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000013') }, lastCommittedOpTime: Timestamp(1588965433, 8), $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965433, 8) }
2020-05-08T12:17:14.607-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 23
2020-05-08T12:17:14.615-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 498 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 23, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:14.616-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 499 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 23, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:14.620-0700 I  ELECTION [replexec-0] VoteRequester(term 23) received a yes vote from n2:27019; response message: { term: 23, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000013') }, lastCommittedOpTime: Timestamp(1588965433, 8), $clusterTime: { clusterTime: Timestamp(1588965433, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965433, 8) }
2020-05-08T12:17:14.622-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 23
2020-05-08T12:17:14.622-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-08T12:17:14.622-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was n3:27019
2020-05-08T12:17:14.622-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:14.622-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:14.622-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-08T12:17:14.623-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:14.623-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:14.623-0700 I  REPL     [replexec-0] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965433, 8), t: 22 }. My Last Applied: { ts: Timestamp(1588965433, 8), t: 22 }
2020-05-08T12:17:14.623-0700 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-05-08T12:17:14.623-0700 I  REPL     [replexec-0] Stopping replication producer
2020-05-08T12:17:14.624-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 23
2020-05-08T12:17:14.624-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-08T12:17:14.624-0700 I  CONNPOOL [RS] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:14.624-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:14.624-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:14.624-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-08T12:17:14.626-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:14.626-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:14.626-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:14.627-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:14.627-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:14.628-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:14.629-0700 W  QUERY    [conn173] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824554573504446466), stats: { stage: "COLLSCAN", nReturned: 12, executionTimeMillisEstimate: 0, works: 51, advanced: 12, needTime: 19, needYield: 0, saveState: 19, restoreState: 19, isEOF: 0, direction: "forward", docsExamined: 12 }
2020-05-08T12:17:15.098-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:17:15.395-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48182 #220 (50 connections now open)
2020-05-08T12:17:15.395-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48184 #221 (51 connections now open)
2020-05-08T12:17:15.395-0700 I  NETWORK  [conn220] received client metadata from 192.168.122.1:48182 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.396-0700 I  NETWORK  [conn221] received client metadata from 192.168.122.1:48184 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:15.399-0700 I  NETWORK  [conn220] end connection 192.168.122.1:48182 (50 connections now open)
2020-05-08T12:17:15.399-0700 I  NETWORK  [conn221] end connection 192.168.122.1:48184 (49 connections now open)
2020-05-08T12:17:15.420-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:49402 #222 (50 connections now open)
2020-05-08T12:17:15.421-0700 I  NETWORK  [conn222] received client metadata from 192.168.122.18:49402 conn222: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:15.629-0700 I  REPL     [replexec-1] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:15.847-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:17:15.848-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:17:15.849-0700 I  ELECTION [conn206] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965433, 8), t: 22 } }
2020-05-08T12:17:15.849-0700 I  ELECTION [conn206] Sending vote response: { term: 23, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965433, 8), t: 22 }, my last applied OpTime: { ts: Timestam..." }
2020-05-08T12:17:15.856-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1588965434769), up: 90, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1083ms
2020-05-08T12:17:15.856-0700 I  COMMAND  [conn88] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1588965434901), up: 91, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 951ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1588965434901), up: 91, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 950ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn145] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1588965434902), up: 91, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 950ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn143] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 159ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn39] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1588965434769), up: 91, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1083ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn44] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1588965434902), up: 91, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 950ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1588965434768), up: 90, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1084ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn87] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1588965434903), up: 91, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 950ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn222] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965435, 8), signature: { hash: BinData(0, 8B8BCE683CE45711B9BDB40225C9BC177229EF27), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 435ms
2020-05-08T12:17:15.857-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1588965434768), up: 90, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965434, 2), signature: { hash: BinData(0, 9978E23EF2CC7B15375A5F68176D455CDF1BF676), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1084ms
2020-05-08T12:17:16.624-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:17.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48258 #223 (51 connections now open)
2020-05-08T12:17:17.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48262 #224 (52 connections now open)
2020-05-08T12:17:17.915-0700 I  NETWORK  [conn223] received client metadata from 192.168.122.1:48258 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:17.916-0700 I  NETWORK  [conn224] received client metadata from 192.168.122.1:48262 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:17.919-0700 I  NETWORK  [conn223] end connection 192.168.122.1:48258 (51 connections now open)
2020-05-08T12:17:17.919-0700 I  NETWORK  [conn224] end connection 192.168.122.1:48262 (50 connections now open)
2020-05-08T12:17:18.819-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:41878 #225 (51 connections now open)
2020-05-08T12:17:18.819-0700 I  NETWORK  [conn225] received client metadata from 192.168.122.19:41878 conn225: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:18.860-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:18.860-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:18.860-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:18.860-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-08T12:17:18.860-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:18.860-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:18.860-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 8, userOpsRunning: 0 }
2020-05-08T12:17:18.861-0700 W  COMMAND  [conn83] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:18.862-0700 I  COMMAND  [conn83] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27018:1588965345:4642009900937274884" }, update: { $set: { ping: new Date(1588965438745) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965437, 200), signature: { hash: BinData(0, B36A751010940C5EB77B4D4930A9E36CD78C7A71), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 115ms
2020-05-08T12:17:18.862-0700 W  COMMAND  [conn79] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:18.862-0700 I  COMMAND  [conn79] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27018:1588965345:-3830833260225672011" }, update: { $set: { ping: new Date(1588965438747) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965437, 200), signature: { hash: BinData(0, B36A751010940C5EB77B4D4930A9E36CD78C7A71), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 114ms
2020-05-08T12:17:18.862-0700 W  COMMAND  [conn81] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:18.862-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-08T12:17:18.862-0700 I  COMMAND  [conn81] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27018:1588965345:-3626659247996741111" }, update: { $set: { ping: new Date(1588965438746) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965437, 200), signature: { hash: BinData(0, B36A751010940C5EB77B4D4930A9E36CD78C7A71), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965433, 8), t: 22 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 115ms
2020-05-08T12:17:18.863-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:19.624-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:19.624-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:19.624-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:19.624-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:19.714-0700 I  NETWORK  [conn45] end connection 192.168.122.14:45618 (50 connections now open)
2020-05-08T12:17:19.715-0700 I  NETWORK  [conn29] end connection 192.168.122.15:38582 (49 connections now open)
2020-05-08T12:17:19.715-0700 I  NETWORK  [conn49] end connection 192.168.122.19:36296 (48 connections now open)
2020-05-08T12:17:19.967-0700 I  ELECTION [replexec-7] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:21.052-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:21.972-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48448 #226 (49 connections now open)
2020-05-08T12:17:21.973-0700 I  NETWORK  [conn226] received client metadata from 192.168.122.1:48448 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:21.973-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48454 #227 (50 connections now open)
2020-05-08T12:17:21.973-0700 I  NETWORK  [conn227] received client metadata from 192.168.122.1:48454 conn227: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:21.977-0700 I  NETWORK  [conn226] end connection 192.168.122.1:48448 (49 connections now open)
2020-05-08T12:17:21.977-0700 I  NETWORK  [conn227] end connection 192.168.122.1:48454 (48 connections now open)
2020-05-08T12:17:22.017-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46274 #228 (49 connections now open)
2020-05-08T12:17:22.017-0700 I  NETWORK  [conn228] received client metadata from 192.168.122.12:46274 conn228: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:22.049-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46276 #229 (50 connections now open)
2020-05-08T12:17:22.049-0700 I  NETWORK  [conn229] received client metadata from 192.168.122.12:46276 conn229: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:22.145-0700 I  ELECTION [conn216] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 23, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:22.145-0700 I  ELECTION [conn216] Sending vote response: { term: 23, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965434, 11), t: 23 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:22.145-0700 I  NETWORK  [conn216] end connection 192.168.122.12:45878 (49 connections now open)
2020-05-08T12:17:22.175-0700 I  ELECTION [replexec-0] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:22.524-0700 I  ELECTION [conn229] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 25, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:22.524-0700 I  ELECTION [conn229] Sending vote response: { term: 25, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965434, 11), t: 23 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:22.529-0700 I  ELECTION [conn193] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965412, 1), t: 16 } }
2020-05-08T12:17:22.529-0700 I  ELECTION [conn193] Sending vote response: { term: 25, voteGranted: false, reason: "candidate's term (17) is lower than mine (25)" }
2020-05-08T12:17:22.529-0700 I  NETWORK  [conn138] end connection 192.168.122.12:43418 (48 connections now open)
2020-05-08T12:17:22.529-0700 I  NETWORK  [conn193] end connection 192.168.122.12:45010 (47 connections now open)
2020-05-08T12:17:23.124-0700 I  REPL     [replexec-7] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:23.429-0700 I  NETWORK  [conn217] end connection 192.168.122.12:45982 (46 connections now open)
2020-05-08T12:17:23.528-0700 I  ELECTION [conn229] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 25, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:23.528-0700 I  ELECTION [conn229] Sending vote response: { term: 25, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965434, 11), t: 23 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:23.627-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:23.627-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 25
2020-05-08T12:17:23.627-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 525 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 25, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965438, 3), t: 23 } }
2020-05-08T12:17:23.627-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 526 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 25, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965438, 3), t: 23 } }
2020-05-08T12:17:23.627-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:23.628-0700 I  ELECTION [replexec-2] VoteRequester(term 25 dry run) received a yes vote from n2:27019; response message: { term: 25, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965442, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965434, 11) }
2020-05-08T12:17:23.628-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 26
2020-05-08T12:17:23.631-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 527 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 26, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965438, 3), t: 23 } }
2020-05-08T12:17:23.631-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 528 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 26, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965438, 3), t: 23 } }
2020-05-08T12:17:23.635-0700 I  ELECTION [replexec-6] VoteRequester(term 26) received a yes vote from n2:27019; response message: { term: 26, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965442, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965434, 11) }
2020-05-08T12:17:23.636-0700 I  ELECTION [replexec-6] election succeeded, assuming primary role in term 26
2020-05-08T12:17:23.636-0700 I  REPL     [replexec-6] transition to PRIMARY from SECONDARY
2020-05-08T12:17:23.636-0700 I  REPL     [replexec-6] Resetting sync source to empty, which was :27017
2020-05-08T12:17:23.636-0700 I  REPL     [replexec-6] Entering primary catch-up mode.
2020-05-08T12:17:24.124-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965434, 11), t: 23 }. My Last Applied: { ts: Timestamp(1588965438, 3), t: 23 }
2020-05-08T12:17:24.124-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-08T12:17:24.124-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-08T12:17:24.124-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 26
2020-05-08T12:17:24.125-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:24.125-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:24.125-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:24.127-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:24.127-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:24.128-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:24.128-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:24.128-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:24.515-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44476 #231 (47 connections now open)
2020-05-08T12:17:24.515-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44478 #232 (48 connections now open)
2020-05-08T12:17:24.515-0700 I  NETWORK  [conn231] received client metadata from 192.168.122.15:44476 conn231: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:24.515-0700 I  NETWORK  [conn232] received client metadata from 192.168.122.15:44478 conn232: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:24.516-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:52812 #233 (49 connections now open)
2020-05-08T12:17:24.516-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:51412 #234 (50 connections now open)
2020-05-08T12:17:24.516-0700 I  NETWORK  [conn233] received client metadata from 192.168.122.16:52812 conn233: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:24.516-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:51414 #235 (51 connections now open)
2020-05-08T12:17:24.517-0700 I  NETWORK  [conn234] received client metadata from 192.168.122.14:51412 conn234: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:24.517-0700 I  NETWORK  [conn235] received client metadata from 192.168.122.14:51414 conn235: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:24.517-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:39026 #236 (52 connections now open)
2020-05-08T12:17:24.517-0700 I  NETWORK  [conn236] received client metadata from 192.168.122.17:39026 conn236: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:24.519-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:42070 #237 (53 connections now open)
2020-05-08T12:17:24.520-0700 I  NETWORK  [conn237] received client metadata from 192.168.122.19:42070 conn237: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:25.018-0700 I  REPL     [replexec-0] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:25.018-0700 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:25.018-0700 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-05-08T12:17:25.018-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:25.019-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:25.019-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 28, userOpsRunning: 0 }
2020-05-08T12:17:25.019-0700 W  COMMAND  [conn142] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.019-0700 I  COMMAND  [conn142] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 654ms
2020-05-08T12:17:25.019-0700 W  COMMAND  [conn66] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.019-0700 I  COMMAND  [conn66] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27018:1588965345:-465166209935970491" }, update: { $set: { ping: new Date(1588965439773) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965444, 1), signature: { hash: BinData(0, 8551F0F32DBD23A8C9F77A0833D44B1590B11CA4), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.019-0700 W  COMMAND  [conn44] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.019-0700 I  COMMAND  [conn44] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.019-0700 W  COMMAND  [conn235] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.020-0700 I  COMMAND  [conn235] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 502ms
2020-05-08T12:17:25.020-0700 W  COMMAND  [conn222] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.020-0700 I  COMMAND  [conn222] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 37), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 504ms
2020-05-08T12:17:25.020-0700 W  COMMAND  [conn79] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.020-0700 I  COMMAND  [conn79] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27018:1588965345:-3830833260225672011" }, update: { $set: { ping: new Date(1588965438747) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 502ms
2020-05-08T12:17:25.020-0700 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.020-0700 W  COMMAND  [conn46] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.020-0700 I  COMMAND  [conn43] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.020-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 37), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 502ms
2020-05-08T12:17:25.021-0700 W  COMMAND  [conn83] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.021-0700 I  COMMAND  [conn83] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27018:1588965345:4642009900937274884" }, update: { $set: { ping: new Date(1588965438745) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965444, 1), signature: { hash: BinData(0, 8551F0F32DBD23A8C9F77A0833D44B1590B11CA4), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 503ms
2020-05-08T12:17:25.021-0700 W  COMMAND  [conn47] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.021-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 37), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 506ms
2020-05-08T12:17:25.021-0700 W  COMMAND  [conn232] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.021-0700 I  COMMAND  [conn232] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.021-0700 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.021-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965442, 1), signature: { hash: BinData(0, 5B125569F099297752960086919EF72583C33123), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.021-0700 W  COMMAND  [conn68] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.021-0700 I  COMMAND  [conn68] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27018:1588965345:-5626666314136012223" }, update: { $set: { ping: new Date(1588965439786) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965442, 1), signature: { hash: BinData(0, 5B125569F099297752960086919EF72583C33123), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn50] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn36] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn50] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 407ms
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 506ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn237] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn236] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn237] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965441, 37), signature: { hash: BinData(0, ADECD09F1A722A4FE6CA2E4088FF12CBB91EB3B0), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 501ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn87] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn236] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965442, 1), signature: { hash: BinData(0, 5B125569F099297752960086919EF72583C33123), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 503ms
2020-05-08T12:17:25.022-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard1 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn87] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 3 } protocol:op_msg 507ms
2020-05-08T12:17:25.022-0700 I  CONNPOOL [ShardRegistry] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:25.022-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard2 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn63] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn231] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn38] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn143] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 408ms
2020-05-08T12:17:25.022-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn63] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27018:1588965345:-3184880103931982133" }, update: { $set: { ping: new Date(1588965439786) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965444, 1), signature: { hash: BinData(0, 8551F0F32DBD23A8C9F77A0833D44B1590B11CA4), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 508ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn234] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn231] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 506ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn39] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.023-0700 I  COMMAND  [conn39] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 408ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn233] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn144] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.023-0700 I  COMMAND  [conn233] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 505ms
2020-05-08T12:17:25.023-0700 I  COMMAND  [conn234] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 505ms
2020-05-08T12:17:25.023-0700 I  COMMAND  [conn144] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 658ms
2020-05-08T12:17:25.023-0700 W  SHARDING [Balancer] Failed to enforce tag ranges :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.023-0700 W  COMMAND  [conn145] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.023-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-08T12:17:25.022-0700 I  COMMAND  [conn143] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 658ms
2020-05-08T12:17:25.022-0700 W  COMMAND  [conn81] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-08T12:17:25.023-0700 I  COMMAND  [conn81] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27018:1588965345:-3626659247996741111" }, update: { $set: { ping: new Date(1588965438746) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 503ms
2020-05-08T12:17:25.023-0700 I  COMMAND  [conn145] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1588965341:7325128125104408104" }, update: { $set: { ping: new Date(1588965415457) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965443, 6), signature: { hash: BinData(0, 00F8062F337F02E7ACBA77B98087138DADEF3BF7), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 658ms
2020-05-08T12:17:25.023-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:17:25.023-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:25.023-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:25.117-0700 I  ELECTION [conn229] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965434, 11), t: 23 } }
2020-05-08T12:17:25.117-0700 I  ELECTION [conn229] Sending vote response: { term: 26, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965434, 11), t: 23 }, my last applied OpTime: { ts: Timesta..." }
2020-05-08T12:17:25.156-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48608 #239 (54 connections now open)
2020-05-08T12:17:25.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48612 #240 (55 connections now open)
2020-05-08T12:17:25.157-0700 I  NETWORK  [conn239] received client metadata from 192.168.122.1:48608 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.157-0700 I  NETWORK  [conn240] received client metadata from 192.168.122.1:48612 conn240: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.159-0700 I  NETWORK  [conn239] end connection 192.168.122.1:48608 (54 connections now open)
2020-05-08T12:17:25.159-0700 I  NETWORK  [conn240] end connection 192.168.122.1:48612 (53 connections now open)
2020-05-08T12:17:25.345-0700 I  NETWORK  [conn206] end connection 192.168.122.13:34994 (52 connections now open)
2020-05-08T12:17:25.456-0700 I  NETWORK  [conn42] end connection 192.168.122.11:39074 (51 connections now open)
2020-05-08T12:17:25.456-0700 I  NETWORK  [conn25] end connection 192.168.122.11:38954 (50 connections now open)
2020-05-08T12:17:25.578-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48674 #241 (51 connections now open)
2020-05-08T12:17:25.578-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48680 #242 (52 connections now open)
2020-05-08T12:17:25.578-0700 I  NETWORK  [conn241] received client metadata from 192.168.122.1:48674 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.578-0700 I  NETWORK  [conn242] received client metadata from 192.168.122.1:48680 conn242: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:25.581-0700 I  NETWORK  [conn241] end connection 192.168.122.1:48674 (51 connections now open)
2020-05-08T12:17:25.582-0700 I  NETWORK  [conn242] end connection 192.168.122.1:48680 (50 connections now open)
2020-05-08T12:17:25.845-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:26.148-0700 I  ELECTION [replexec-7] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:26.148-0700 I  ELECTION [replexec-7] conducting a dry run election to see if we could be elected. current term: 26
2020-05-08T12:17:26.148-0700 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 536 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965444, 5), t: 26 } }
2020-05-08T12:17:26.148-0700 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 537 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 26, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965444, 5), t: 26 } }
2020-05-08T12:17:26.149-0700 I  ELECTION [replexec-3] VoteRequester(term 26 dry run) received a no vote from n2:27019 with reason "candidate's term (26) is lower than mine (27)"; response message: { term: 27, voteGranted: false, reason: "candidate's term (26) is lower than mine (27)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965446, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965441, 26) }
2020-05-08T12:17:26.149-0700 I  ELECTION [replexec-3] not running for primary, we have been superseded already
2020-05-08T12:17:26.149-0700 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-05-08T12:17:26.299-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48692 #243 (51 connections now open)
2020-05-08T12:17:26.300-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48700 #244 (52 connections now open)
2020-05-08T12:17:26.300-0700 I  NETWORK  [conn243] received client metadata from 192.168.122.1:48692 conn243: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.300-0700 I  NETWORK  [conn244] received client metadata from 192.168.122.1:48700 conn244: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.304-0700 I  NETWORK  [conn243] end connection 192.168.122.1:48692 (51 connections now open)
2020-05-08T12:17:26.304-0700 I  NETWORK  [conn244] end connection 192.168.122.1:48700 (50 connections now open)
2020-05-08T12:17:26.659-0700 I  REPL     [replexec-0] Member n3:27019 is now in state PRIMARY
2020-05-08T12:17:26.659-0700 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-05-08T12:17:27.750-0700
2020-05-08T12:17:26.722-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48716 #246 (51 connections now open)
2020-05-08T12:17:26.722-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48724 #247 (52 connections now open)
2020-05-08T12:17:26.722-0700 I  NETWORK  [conn246] received client metadata from 192.168.122.1:48716 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.723-0700 I  NETWORK  [conn247] received client metadata from 192.168.122.1:48724 conn247: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:26.726-0700 I  NETWORK  [conn246] end connection 192.168.122.1:48716 (51 connections now open)
2020-05-08T12:17:26.726-0700 I  NETWORK  [conn247] end connection 192.168.122.1:48724 (50 connections now open)
2020-05-08T12:17:26.855-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46644 #248 (51 connections now open)
2020-05-08T12:17:26.856-0700 I  NETWORK  [conn248] received client metadata from 192.168.122.12:46644 conn248: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:26.858-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46646 #249 (52 connections now open)
2020-05-08T12:17:26.859-0700 I  NETWORK  [conn249] received client metadata from 192.168.122.12:46646 conn249: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:26.987-0700 I  NETWORK  [conn249] end connection 192.168.122.12:46646 (51 connections now open)
2020-05-08T12:17:27.750-0700 I  REPL     [replexec-3] Canceling priority takeover callback
2020-05-08T12:17:27.750-0700 I  ELECTION [replexec-3] Starting an election for a priority takeover
2020-05-08T12:17:27.750-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 27
2020-05-08T12:17:27.750-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 542 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965444, 5), t: 26 } }
2020-05-08T12:17:27.750-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 543 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 27, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965444, 5), t: 26 } }
2020-05-08T12:17:27.751-0700 I  ELECTION [replexec-2] VoteRequester(term 27 dry run) received a yes vote from n2:27019; response message: { term: 27, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965446, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965444, 5) }
2020-05-08T12:17:27.751-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 28
2020-05-08T12:17:27.755-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 544 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 28, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965444, 5), t: 26 } }
2020-05-08T12:17:27.755-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 545 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 28, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965444, 5), t: 26 } }
2020-05-08T12:17:27.755-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:27.764-0700 I  ELECTION [replexec-0] VoteRequester(term 28) received a yes vote from n2:27019; response message: { term: 28, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000018') }, lastCommittedOpTime: Timestamp(1588965434, 11), $clusterTime: { clusterTime: Timestamp(1588965446, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965444, 5) }
2020-05-08T12:17:27.764-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 28
2020-05-08T12:17:27.764-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-08T12:17:27.764-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-05-08T12:17:27.764-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-08T12:17:27.764-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-05-08T12:17:28.159-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-08T12:17:28.159-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965444, 5), t: 26 }. My Last Applied: { ts: Timestamp(1588965444, 5), t: 26 }
2020-05-08T12:17:28.159-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-08T12:17:28.159-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-08T12:17:28.159-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 28
2020-05-08T12:17:28.159-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:28.160-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:28.160-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:28.161-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:28.161-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:28.162-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:28.162-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:28.162-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:28.193-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:53056 #250 (52 connections now open)
2020-05-08T12:17:28.193-0700 I  NETWORK  [conn250] received client metadata from 192.168.122.16:53056 conn250: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.368-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46726 #251 (53 connections now open)
2020-05-08T12:17:28.368-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46728 #252 (54 connections now open)
2020-05-08T12:17:28.368-0700 I  NETWORK  [conn251] received client metadata from 192.168.122.12:46726 conn251: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.368-0700 I  NETWORK  [conn252] received client metadata from 192.168.122.12:46728 conn252: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.369-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46730 #253 (55 connections now open)
2020-05-08T12:17:28.369-0700 I  NETWORK  [conn253] received client metadata from 192.168.122.12:46730 conn253: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.522-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:45164 #254 (56 connections now open)
2020-05-08T12:17:28.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:45166 #255 (57 connections now open)
2020-05-08T12:17:28.523-0700 I  NETWORK  [conn254] received client metadata from 192.168.122.11:45164 conn254: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:50034 #256 (58 connections now open)
2020-05-08T12:17:28.523-0700 I  NETWORK  [conn255] received client metadata from 192.168.122.11:45166 conn255: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.523-0700 I  NETWORK  [conn256] received client metadata from 192.168.122.18:50034 conn256: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.524-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:45170 #257 (59 connections now open)
2020-05-08T12:17:28.524-0700 I  NETWORK  [conn257] received client metadata from 192.168.122.11:45170 conn257: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.525-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:42362 #258 (60 connections now open)
2020-05-08T12:17:28.525-0700 I  NETWORK  [conn258] received client metadata from 192.168.122.19:42362 conn258: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.710-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36452 #259 (61 connections now open)
2020-05-08T12:17:28.710-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36454 #260 (62 connections now open)
2020-05-08T12:17:28.710-0700 I  NETWORK  [conn259] received client metadata from 192.168.122.13:36452 conn259: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:28.711-0700 I  NETWORK  [conn260] received client metadata from 192.168.122.13:36454 conn260: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:29.006-0700 I  COMMAND  [conn43] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 814ms
2020-05-08T12:17:29.006-0700 I  COMMAND  [conn50] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 638ms
2020-05-08T12:17:29.006-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 639ms
2020-05-08T12:17:29.006-0700 I  COMMAND  [conn251] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 637ms
2020-05-08T12:17:29.006-0700 I  COMMAND  [conn142] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1588965341:7325128125104408104" }, update: { $set: { ping: new Date(1588965415457) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 485ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1588965445860), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 2), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 484ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn231] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 483ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn254] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 483ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn237] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 482ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn256] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 2), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 482ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn255] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 483ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1588965445859), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 4), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 445ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn259] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 296ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn258] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1588965445859), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 481ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn233] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1588965445860), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 815ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn39] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 640ms
2020-05-08T12:17:29.007-0700 I  COMMAND  [conn252] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 638ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn253] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1588965445860), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 638ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn232] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1588965445860), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 484ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn235] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 486ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn234] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 486ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn222] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 2), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 485ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn24] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1588965445859), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 298ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn236] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 4), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 446ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn250] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 814ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn87] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 816ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn143] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 487ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 10), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 483ms
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn145] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 486ms
2020-05-08T12:17:29.008-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1588965445860), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 487ms
2020-05-08T12:17:29.009-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:17:29.008-0700 I  COMMAND  [conn44] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 485ms
2020-05-08T12:17:29.009-0700 I  COMMAND  [conn260] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965447, 8), signature: { hash: BinData(0, 69A5783D8478E77CF4623B2786E4E6D570CE3412), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 296ms
2020-05-08T12:17:29.009-0700 I  COMMAND  [conn257] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 482ms
2020-05-08T12:17:29.009-0700 I  COMMAND  [conn144] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1588965445859), up: 102, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965448, 6), signature: { hash: BinData(0, 757BE20189694B764CE2F7BC81A0D7963927BD0E), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965434, 11), t: 23 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 487ms
2020-05-08T12:17:30.159-0700 I  REPL     [replexec-4] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:32.482-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49026 #262 (63 connections now open)
2020-05-08T12:17:32.482-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49034 #263 (64 connections now open)
2020-05-08T12:17:32.482-0700 I  NETWORK  [conn262] received client metadata from 192.168.122.1:49026 conn262: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:32.483-0700 I  NETWORK  [conn263] received client metadata from 192.168.122.1:49034 conn263: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:32.486-0700 I  NETWORK  [conn262] end connection 192.168.122.1:49026 (63 connections now open)
2020-05-08T12:17:32.486-0700 I  NETWORK  [conn263] end connection 192.168.122.1:49034 (62 connections now open)
2020-05-08T12:17:33.190-0700 I  REPL     [replexec-4] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:33.190-0700 I  REPL     [replexec-4] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-08T12:17:33.190-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-08T12:17:33.190-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-08T12:17:33.190-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:33.190-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:33.190-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:33.191-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-08T12:17:33.191-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard1 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:33.191-0700 I  SHARDING [Balancer] Unable to obtain shard version for rs_shard2 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:33.191-0700 I  CONNPOOL [ShardRegistry] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:33.192-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-08T12:17:33.192-0700 W  SHARDING [Balancer] Failed to enforce tag ranges :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:33.192-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-08T12:17:33.192-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T12:17:33.192-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-08T12:17:34.277-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:34.365-0700 I  REPL     [replexec-1] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:34.408-0700 I  NETWORK  [conn248] end connection 192.168.122.12:46644 (61 connections now open)
2020-05-08T12:17:34.593-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-08T12:17:34.593-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-08T12:17:35.661-0700
2020-05-08T12:17:34.597-0700 I  ELECTION [conn228] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 28, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965448, 18), t: 28 } }
2020-05-08T12:17:34.597-0700 I  ELECTION [conn228] Sending vote response: { term: 29, voteGranted: false, reason: "candidate's term (28) is lower than mine (29)" }
2020-05-08T12:17:34.597-0700 I  NETWORK  [conn228] end connection 192.168.122.12:46274 (60 connections now open)
2020-05-08T12:17:34.625-0700 I  NETWORK  [conn229] end connection 192.168.122.12:46276 (59 connections now open)
2020-05-08T12:17:34.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49124 #265 (60 connections now open)
2020-05-08T12:17:34.733-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49130 #266 (61 connections now open)
2020-05-08T12:17:34.733-0700 I  NETWORK  [conn265] received client metadata from 192.168.122.1:49124 conn265: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:34.733-0700 I  NETWORK  [conn266] received client metadata from 192.168.122.1:49130 conn266: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:34.734-0700 I  NETWORK  [conn265] end connection 192.168.122.1:49124 (60 connections now open)
2020-05-08T12:17:34.734-0700 I  NETWORK  [conn266] end connection 192.168.122.1:49130 (59 connections now open)
2020-05-08T12:17:35.073-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36012 #268 (60 connections now open)
2020-05-08T12:17:35.073-0700 I  NETWORK  [conn268] received client metadata from 192.168.122.13:36012 conn268: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:35.192-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:35.194-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:35.195-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-08T12:17:35.628-0700 I  ELECTION [conn268] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 29, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:35.628-0700 I  ELECTION [conn268] Sending vote response: { term: 29, voteGranted: true, reason: "" }
2020-05-08T12:17:35.633-0700 I  REPL     [conn268] Canceling priority takeover callback
2020-05-08T12:17:35.633-0700 I  ELECTION [conn268] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:35.633-0700 I  ELECTION [conn268] Sending vote response: { term: 30, voteGranted: true, reason: "" }
2020-05-08T12:17:35.909-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49266 #270 (61 connections now open)
2020-05-08T12:17:35.910-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49270 #271 (62 connections now open)
2020-05-08T12:17:35.910-0700 I  NETWORK  [conn270] received client metadata from 192.168.122.1:49266 conn270: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.910-0700 I  NETWORK  [conn271] received client metadata from 192.168.122.1:49270 conn271: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:35.913-0700 I  NETWORK  [conn270] end connection 192.168.122.1:49266 (61 connections now open)
2020-05-08T12:17:35.913-0700 I  NETWORK  [conn271] end connection 192.168.122.1:49270 (60 connections now open)
2020-05-08T12:17:36.093-0700 I  REPL     [replexec-6] Member n2:27019 is now in state RS_DOWN - Request 559 timed out, deadline was 2020-05-08T12:17:36.093-0700, op was RemoteCommand 559 -- target:[n2:27019] db:admin expDate:2020-05-08T12:17:36.093-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 29 }
2020-05-08T12:17:36.093-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:36.093-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:36.827-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:36.827-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 30
2020-05-08T12:17:36.827-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 572 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:36.827-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 573 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:37.204-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T12:17:37.827-0700 I  ELECTION [replexec-1] VoteRequester(term 30 dry run) failed to receive response from n3:27019: NetworkInterfaceExceededTimeLimit: Request 573 timed out, deadline was 2020-05-08T12:17:37.827-0700, op was RemoteCommand 573 -- target:[n3:27019] db:admin expDate:2020-05-08T12:17:37.827-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:37.827-0700 I  ELECTION [replexec-1] VoteRequester(term 30 dry run) failed to receive response from n2:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:17:37.827-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:37.827-0700 I  ELECTION [replexec-1] not running for primary, we received insufficient votes
2020-05-08T12:17:37.827-0700 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-05-08T12:17:37.841-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:37.841-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 30
2020-05-08T12:17:37.841-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 578 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:37.841-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 579 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965453, 11), t: 29 } }
2020-05-08T12:17:37.841-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:38.093-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:38.366-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - Request 577 timed out, deadline was 2020-05-08T12:17:38.366-0700, op was RemoteCommand 577 -- target:[n3:27019] db:admin expDate:2020-05-08T12:17:38.366-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 30 }
2020-05-08T12:17:38.366-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:38.841-0700 I  ELECTION [replexec-0] VoteRequester(term 30 dry run) failed to receive response from n3:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:17:38.841-0700 I  ELECTION [replexec-6] VoteRequester(term 30 dry run) failed to receive response from n2:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:17:38.841-0700 I  ELECTION [replexec-6] not running for primary, we received insufficient votes
2020-05-08T12:17:38.841-0700 I  ELECTION [replexec-6] Lost dry run election due to internal error
2020-05-08T12:17:38.963-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:39.556-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n3:27019, my last fetched oplog optime: { ts: Timestamp(1588965456, 1), t: 30 }, latest oplog optime of sync source: { ts: Timestamp(1588965456, 1), t: 30 } (sync source does not know the primary)
2020-05-08T12:17:39.556-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n3:27019, OpTime { ts: Timestamp(1588965456, 1), t: 30 }, its sync source index:-1
2020-05-08T12:17:39.556-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965456, 1), t: 30 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:17:39.556-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-08T12:17:39.556-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:17:39.559-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:17:39.807-0700 I  NETWORK  [conn215] end connection 192.168.122.12:45942 (59 connections now open)
2020-05-08T12:17:39.808-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:47360 #272 (60 connections now open)
2020-05-08T12:17:39.809-0700 I  NETWORK  [conn272] received client metadata from 192.168.122.12:47360 conn272: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:39.946-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49452 #273 (61 connections now open)
2020-05-08T12:17:39.946-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49460 #274 (62 connections now open)
2020-05-08T12:17:39.946-0700 I  NETWORK  [conn273] received client metadata from 192.168.122.1:49452 conn273: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:39.946-0700 I  NETWORK  [conn274] received client metadata from 192.168.122.1:49460 conn274: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:39.949-0700 I  NETWORK  [conn273] end connection 192.168.122.1:49452 (61 connections now open)
2020-05-08T12:17:39.950-0700 I  NETWORK  [conn274] end connection 192.168.122.1:49460 (60 connections now open)
2020-05-08T12:17:40.193-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46956 #275 (61 connections now open)
2020-05-08T12:17:40.193-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:46954 #276 (62 connections now open)
2020-05-08T12:17:40.193-0700 I  NETWORK  [conn275] received client metadata from 192.168.122.12:46956 conn275: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:40.193-0700 I  NETWORK  [conn276] received client metadata from 192.168.122.12:46954 conn276: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:40.511-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:47472 #277 (63 connections now open)
2020-05-08T12:17:40.512-0700 I  NETWORK  [conn277] received client metadata from 192.168.122.12:47472 conn277: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:40.689-0700 I  ELECTION [replexec-0] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:40.690-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37178 #278 (64 connections now open)
2020-05-08T12:17:40.690-0700 I  NETWORK  [conn278] received client metadata from 192.168.122.13:37178 conn278: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:40.962-0700 I  ELECTION [conn278] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 30, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:40.963-0700 I  ELECTION [conn278] Sending vote response: { term: 30, voteGranted: true, reason: "" }
2020-05-08T12:17:40.967-0700 I  ELECTION [conn278] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 31, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:40.967-0700 I  ELECTION [conn278] Sending vote response: { term: 31, voteGranted: true, reason: "" }
2020-05-08T12:17:40.993-0700 I  NETWORK  [conn268] end connection 192.168.122.13:36012 (63 connections now open)
2020-05-08T12:17:41.057-0700 I  REPL     [replexec-2] Member n3:27019 is now in state PRIMARY
2020-05-08T12:17:41.057-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-08T12:17:42.090-0700
2020-05-08T12:17:41.122-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:41.141-0700 I  NETWORK  [conn22] end connection 192.168.122.13:58440 (62 connections now open)
2020-05-08T12:17:41.141-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37192 #281 (63 connections now open)
2020-05-08T12:17:41.142-0700 I  NETWORK  [conn281] received client metadata from 192.168.122.13:37192 conn281: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:42.050-0700 I  ELECTION [conn275] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 31, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:42.050-0700 I  ELECTION [conn275] Sending vote response: { term: 31, voteGranted: true, reason: "" }
2020-05-08T12:17:42.056-0700 I  REPL     [conn275] Canceling priority takeover callback
2020-05-08T12:17:42.056-0700 I  ELECTION [conn275] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965456, 1), t: 30 } }
2020-05-08T12:17:42.056-0700 I  ELECTION [conn275] Sending vote response: { term: 32, voteGranted: true, reason: "" }
2020-05-08T12:17:42.124-0700 I  REPL     [replexec-2] Member n2:27019 is now in state PRIMARY
2020-05-08T12:17:42.124-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-08T12:17:43.146-0700
2020-05-08T12:17:42.551-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49616 #282 (64 connections now open)
2020-05-08T12:17:42.551-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49624 #283 (65 connections now open)
2020-05-08T12:17:42.551-0700 I  NETWORK  [conn282] received client metadata from 192.168.122.1:49616 conn282: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:42.552-0700 I  NETWORK  [conn283] received client metadata from 192.168.122.1:49624 conn283: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:42.555-0700 I  NETWORK  [conn282] end connection 192.168.122.1:49616 (64 connections now open)
2020-05-08T12:17:42.555-0700 I  NETWORK  [conn283] end connection 192.168.122.1:49624 (63 connections now open)
2020-05-08T12:17:42.557-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:42.558-0700 I  REPL     [replexec-6] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:42.559-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:43.146-0700 I  REPL     [replexec-0] Canceling priority takeover callback
2020-05-08T12:17:43.146-0700 I  ELECTION [replexec-0] Starting an election for a priority takeover
2020-05-08T12:17:43.146-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 32
2020-05-08T12:17:43.146-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 603 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:43.146-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 604 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:43.147-0700 I  ELECTION [replexec-6] VoteRequester(term 32 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timestamp(1588965463, 17), t: 32 }"; response message: { term: 32, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000020') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965463, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965463, 17) }
2020-05-08T12:17:44.146-0700 I  ELECTION [replexec-3] VoteRequester(term 32 dry run) failed to receive response from n3:27019: NetworkInterfaceExceededTimeLimit: Request 604 timed out, deadline was 2020-05-08T12:17:44.146-0700, op was RemoteCommand 604 -- target:[n3:27019] db:admin expDate:2020-05-08T12:17:44.146-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:44.146-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:44.146-0700 I  ELECTION [replexec-3] not running for primary, we received insufficient votes
2020-05-08T12:17:44.146-0700 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-05-08T12:17:44.146-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:44.217-0700 I  ELECTION [replexec-7] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:44.217-0700 I  ELECTION [replexec-7] conducting a dry run election to see if we could be elected. current term: 32
2020-05-08T12:17:44.217-0700 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 605 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:44.217-0700 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 606 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:44.218-0700 I  ELECTION [replexec-0] VoteRequester(term 32 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timestamp(1588965463, 18), t: 32 }"; response message: { term: 32, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000020') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965463, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965463, 18) }
2020-05-08T12:17:44.625-0700 I  REPL     [replexec-7] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:44.684-0700 I  ELECTION [conn275] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 32, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:44.684-0700 I  ELECTION [conn275] Sending vote response: { term: 32, voteGranted: true, reason: "" }
2020-05-08T12:17:44.689-0700 I  ELECTION [conn275] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 33, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:44.689-0700 I  ELECTION [conn275] Sending vote response: { term: 33, voteGranted: true, reason: "" }
2020-05-08T12:17:45.128-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:45.158-0700 I  ELECTION [replexec-0] VoteRequester(term 32 dry run) received a no vote from n3:27019 with reason "candidate's term (32) is lower than mine (33)"; response message: { term: 33, voteGranted: false, reason: "candidate's term (32) is lower than mine (33)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001f') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965464, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965463, 18) }
2020-05-08T12:17:45.158-0700 I  ELECTION [replexec-0] not running for primary, we have been superseded already during dry run. original term: 32, current term: 33
2020-05-08T12:17:45.158-0700 I  ELECTION [replexec-0] Lost dry run election due to internal error
2020-05-08T12:17:45.276-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49810 #286 (64 connections now open)
2020-05-08T12:17:45.276-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49812 #287 (65 connections now open)
2020-05-08T12:17:45.276-0700 I  NETWORK  [conn286] received client metadata from 192.168.122.1:49810 conn286: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.277-0700 I  NETWORK  [conn287] received client metadata from 192.168.122.1:49812 conn287: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:45.280-0700 I  NETWORK  [conn286] end connection 192.168.122.1:49810 (64 connections now open)
2020-05-08T12:17:45.280-0700 I  NETWORK  [conn287] end connection 192.168.122.1:49812 (63 connections now open)
2020-05-08T12:17:45.797-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:45.797-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 33
2020-05-08T12:17:45.797-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 614 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:45.797-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 615 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:45.798-0700 I  ELECTION [replexec-7] VoteRequester(term 33 dry run) received a no vote from n3:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timestamp(1588965463, 18), t: 32 }"; response message: { term: 33, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000001f') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965465, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965463, 18) }
2020-05-08T12:17:46.145-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37262 #289 (64 connections now open)
2020-05-08T12:17:46.145-0700 I  NETWORK  [conn289] received client metadata from 192.168.122.13:37262 conn289: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:46.249-0700 I  ELECTION [conn289] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:46.249-0700 I  ELECTION [conn289] Sending vote response: { term: 33, voteGranted: true, reason: "" }
2020-05-08T12:17:46.253-0700 I  ELECTION [conn289] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 34, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965463, 18), t: 32 } }
2020-05-08T12:17:46.253-0700 I  ELECTION [conn289] Sending vote response: { term: 34, voteGranted: true, reason: "" }
2020-05-08T12:17:46.305-0700 I  NETWORK  [conn278] end connection 192.168.122.13:37178 (63 connections now open)
2020-05-08T12:17:46.402-0700 I  REPL     [replication-1] Restarting oplog query due to error: QueryPlanKilled: error in fetcher batch callback :: caused by :: Database epoch changed due to a database-level event such as 'restartCatalog'.. Last fetched optime: { ts: Timestamp(1588965461, 59), t: 31 }. Restarts remaining: 1
2020-05-08T12:17:46.402-0700 I  REPL     [replication-1] Scheduled new oplog query Fetcher source: n3:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1588965461, 59) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 34, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 617 -- target:n3:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1588965461, 59) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 34, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-08T12:17:46.403-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: Upstream node rolled back after choosing it as a sync source. Choosing new sync source.
2020-05-08T12:17:46.403-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-08T12:17:46.403-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:46.404-0700 I  REPL     [rsBackgroundSync] Chose same sync source candidate as last time, n3:27019. Sleeping for 1 second to avoid immediately choosing a new sync source for the same reason as last time.
2020-05-08T12:17:46.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49862 #290 (64 connections now open)
2020-05-08T12:17:46.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49870 #291 (65 connections now open)
2020-05-08T12:17:46.590-0700 I  NETWORK  [conn290] received client metadata from 192.168.122.1:49862 conn290: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:46.590-0700 I  NETWORK  [conn291] received client metadata from 192.168.122.1:49870 conn291: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-08T12:17:46.594-0700 I  NETWORK  [conn290] end connection 192.168.122.1:49862 (64 connections now open)
2020-05-08T12:17:46.595-0700 I  NETWORK  [conn291] end connection 192.168.122.1:49870 (63 connections now open)
2020-05-08T12:17:46.797-0700 I  ELECTION [replexec-0] VoteRequester(term 33 dry run) failed to receive response from n2:27019: NetworkInterfaceExceededTimeLimit: Request 614 timed out, deadline was 2020-05-08T12:17:46.797-0700, op was RemoteCommand 614 -- target:[n2:27019] db:admin expDate:2020-05-08T12:17:46.797-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 33, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:46.797-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:46.797-0700 I  ELECTION [replexec-0] not running for primary, we have been superseded already during dry run. original term: 33, current term: 34
2020-05-08T12:17:46.797-0700 I  ELECTION [replexec-0] Lost dry run election due to internal error
2020-05-08T12:17:47.292-0700 I  ELECTION [replexec-7] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:47.292-0700 I  ELECTION [replexec-7] conducting a dry run election to see if we could be elected. current term: 34
2020-05-08T12:17:47.292-0700 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 624 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:47.292-0700 I  REPL     [replexec-7] Scheduling remote command request for vote request: RemoteCommand 625 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:47.292-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-08T12:17:47.625-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:47.625-0700 I  REPL     [replexec-6] Member n2:27019 is now in state RS_DOWN - Request 621 timed out, deadline was 2020-05-08T12:17:47.625-0700, op was RemoteCommand 621 -- target:[n2:27019] db:admin expDate:2020-05-08T12:17:47.625-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 34 }
2020-05-08T12:17:48.159-0700 I  REPL     [replexec-1] Member n3:27019 is now in state RS_DOWN - Request 623 timed out, deadline was 2020-05-08T12:17:48.159-0700, op was RemoteCommand 623 -- target:[n3:27019] db:admin expDate:2020-05-08T12:17:48.159-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 34 }
2020-05-08T12:17:48.159-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T12:17:48.292-0700 I  ELECTION [replexec-4] VoteRequester(term 34 dry run) failed to receive response from n3:27019: NetworkInterfaceExceededTimeLimit: Request 625 timed out, deadline was 2020-05-08T12:17:48.292-0700, op was RemoteCommand 625 -- target:[n3:27019] db:admin expDate:2020-05-08T12:17:48.292-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:48.292-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T12:17:48.292-0700 I  ELECTION [replexec-0] VoteRequester(term 34 dry run) failed to receive response from n2:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-08T12:17:48.292-0700 I  ELECTION [replexec-0] not running for primary, we received insufficient votes
2020-05-08T12:17:48.292-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:48.292-0700 I  ELECTION [replexec-0] Lost dry run election due to internal error
2020-05-08T12:17:48.399-0700 I  ELECTION [replexec-7] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:49.533-0700 I  ELECTION [replexec-6] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-08T12:17:50.338-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-08T12:17:50.658-0700 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:50.658-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 34
2020-05-08T12:17:50.658-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 629 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:50.658-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 630 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965461, 59), t: 31 } }
2020-05-08T12:17:50.658-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-08T12:17:50.659-0700 I  ELECTION [replexec-7] VoteRequester(term 34 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timestamp(1588965464, 2), t: 33 }"; response message: { term: 34, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000021') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965466, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965464, 2) }
2020-05-08T12:17:50.661-0700 I  REPL     [replexec-6] Member n3:27019 is now in state SECONDARY
2020-05-08T12:17:50.661-0700 I  ELECTION [replexec-1] VoteRequester(term 34 dry run) received a no vote from n3:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timestamp(1588965466, 2), t: 34 }"; response message: { term: 34, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1588965461, 59), t: 31 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000022') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965470, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965466, 2) }
2020-05-08T12:17:50.661-0700 I  ELECTION [replexec-1] not running for primary, we received insufficient votes
2020-05-08T12:17:50.661-0700 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-05-08T12:17:50.754-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1588965461, 59), t: 31 }. source's GTE: { ts: Timestamp(1588965463, 1), t: 32 }
2020-05-08T12:17:50.754-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1588965453, 11), t: 29 }
2020-05-08T12:17:50.754-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-08T12:17:50.754-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n3:27019)
2020-05-08T12:17:50.754-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-08T12:17:50.754-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 64 }
2020-05-08T12:17:50.754-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 289
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 281
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 277
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 276
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 275
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 272
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 260
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 259
2020-05-08T12:17:50.754-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 258
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 257
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 256
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 255
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 254
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 253
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 252
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 251
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 250
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 237
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 236
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 235
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 234
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 233
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 232
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 231
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 225
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 222
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 173
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 145
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 144
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 143
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 142
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-08T12:17:50.755-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-08T12:17:50.755-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-08T12:17:50.756-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-08T12:17:50.756-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-08T12:17:50.763-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:50.766-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 5
2020-05-08T12:17:50.766-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-08T12:17:50.766-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid ed1a62fa-1d96-460b-b917-f8098f56b82b to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-08T19-17-50.2.bson
2020-05-08T12:17:50.767-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-08T12:17:50.767-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-08T12:17:50.767-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-08T12:17:50.767-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-08T12:17:50.807-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1588965453, 11) Initial Data Timestamp: Timestamp(1588965338, 1)
2020-05-08T12:17:50.808-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-08T12:17:50.821-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-08T12:17:50.821-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 317 records totaling to 66738 bytes
2020-05-08T12:17:50.821-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-08T12:17:50.821-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-08T12:17:50.825-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-08T12:17:50.825-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-08T12:17:50.842-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-08T12:17:50.842-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-08T12:17:50.842-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1588965453, 11)
2020-05-08T12:17:50.842-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 9 update operations and 0 delete operations.
2020-05-08T12:17:50.842-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1588965461, 1), t: 31 }
2020-05-08T12:17:50.843-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1588965461, 1) }
2020-05-08T12:17:50.843-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-08T12:17:50.847-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1588965453, 11) (top of oplog: { ts: Timestamp(1588965456, 1), t: 30 }, appliedThrough: { ts: Timestamp(1588965453, 11), t: 29 }, TruncateAfter: Timestamp(0, 0))
2020-05-08T12:17:50.847-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1588965453, 11)
2020-05-08T12:17:50.847-0700 I  REPL     [rsBackgroundSync] Replaying stored operations from Timestamp(1588965453, 11) (inclusive) to Timestamp(1588965456, 1) (inclusive).
2020-05-08T12:17:50.849-0700 I  REPL     [rsBackgroundSync] Applied 1 operations in 1 batches. Last operation applied with optime: { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-08T12:17:50.849-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-08T12:17:50.754-0700
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-08T12:17:50.849-0700
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n3:27019
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.mongos
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 5
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1588965461, 59), t: 31 }
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1588965456, 1), t: 30 }
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-08T12:17:41.616-0700
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-08T12:17:41.140-0700
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-08T12:17:50.849-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1588965461, 1)
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1588965453, 11)
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 		update: 9
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 10
2020-05-08T12:17:50.850-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-08T12:17:50.850-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-08T12:17:50.850-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n3:27019
2020-05-08T12:17:50.850-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-08T12:17:50.850-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-08T12:17:50.850-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-08T12:17:50.850-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-08T12:17:50.851-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-08T12:17:51.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:47920 #295 (64 connections now open)
2020-05-08T12:17:51.327-0700 I  NETWORK  [conn295] received client metadata from 192.168.122.12:47920 conn295: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.354-0700 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n3:27019, my last fetched oplog optime: { ts: Timestamp(1588965466, 2), t: 34 }, latest oplog optime of sync source: { ts: Timestamp(1588965466, 2), t: 34 } (sync source does not know the primary)
2020-05-08T12:17:51.354-0700 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n3:27019, OpTime { ts: Timestamp(1588965466, 2), t: 34 }, its sync source index:-1
2020-05-08T12:17:51.354-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1588965466, 2), t: 34 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-08T12:17:51.354-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-08T12:17:51.354-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-08T12:17:51.521-0700 I  NETWORK  [conn276] end connection 192.168.122.12:46954 (63 connections now open)
2020-05-08T12:17:51.585-0700 I  NETWORK  [conn289] end connection 192.168.122.13:37262 (62 connections now open)
2020-05-08T12:17:51.701-0700 I  NETWORK  [conn272] end connection 192.168.122.12:47360 (61 connections now open)
2020-05-08T12:17:51.701-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:47924 #297 (62 connections now open)
2020-05-08T12:17:51.701-0700 I  NETWORK  [conn297] received client metadata from 192.168.122.12:47924 conn297: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.910-0700 I  NETWORK  [conn281] end connection 192.168.122.13:37192 (61 connections now open)
2020-05-08T12:17:51.911-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37634 #298 (62 connections now open)
2020-05-08T12:17:51.911-0700 I  NETWORK  [conn298] received client metadata from 192.168.122.13:37634 conn298: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:51.961-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-08T12:17:51.961-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 34
2020-05-08T12:17:51.961-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 641 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965466, 2), t: 34 } }
2020-05-08T12:17:51.961-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 642 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 34, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965466, 2), t: 34 } }
2020-05-08T12:17:51.962-0700 I  ELECTION [replexec-3] VoteRequester(term 34 dry run) received a yes vote from n2:27019; response message: { term: 34, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000021') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965470, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965466, 2) }
2020-05-08T12:17:51.962-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 35
2020-05-08T12:17:51.965-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 643 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 35, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965466, 2), t: 34 } }
2020-05-08T12:17:51.965-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 644 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 35, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1588965466, 2), t: 34 } }
2020-05-08T12:17:51.968-0700 I  ELECTION [replexec-1] VoteRequester(term 35) received a yes vote from n2:27019; response message: { term: 35, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000021') }, lastCommittedOpTime: Timestamp(1588965453, 11), $clusterTime: { clusterTime: Timestamp(1588965470, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1588965466, 2) }
2020-05-08T12:17:51.968-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 35
2020-05-08T12:17:51.968-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-08T12:17:51.968-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-08T12:17:51.968-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-08T12:17:51.969-0700 I  REPL     [replexec-8] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1588965466, 2), t: 34 }. My Last Applied: { ts: Timestamp(1588965466, 2), t: 34 }
2020-05-08T12:17:51.969-0700 I  REPL     [replexec-8] Exited primary catch-up mode.
2020-05-08T12:17:51.969-0700 I  REPL     [replexec-8] Stopping replication producer
2020-05-08T12:17:51.970-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 35
2020-05-08T12:17:51.970-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-08T12:17:51.970-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-08T12:17:51.970-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-08T12:17:51.972-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-08T12:17:51.972-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-08T12:17:51.972-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-08T12:17:52.225-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:47850 #299 (63 connections now open)
2020-05-08T12:17:52.225-0700 I  NETWORK  [conn299] received client metadata from 192.168.122.12:47850 conn299: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:52.289-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37554 #300 (64 connections now open)
2020-05-08T12:17:52.289-0700 I  NETWORK  [conn300] received client metadata from 192.168.122.13:37554 conn300: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:53.337-0700 I  COMMAND  [conn253] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 47), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1136ms
2020-05-08T12:17:53.337-0700 I  COMMAND  [conn251] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 47), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1136ms
2020-05-08T12:17:53.337-0700 I  COMMAND  [conn252] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 47), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1136ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn39] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n2:27017:1588965341:-7408192429411933944" }, update: { $set: { ping: new Date(1588965463098) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 47), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:628 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1137ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn256] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 23), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 932ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 94), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 930ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn232] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 10), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 930ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn144] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965468, 5), signature: { hash: BinData(0, 863890BE952A3FC25C97D02873A41FA4D6E6AC33), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 928ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn145] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965468, 5), signature: { hash: BinData(0, 863890BE952A3FC25C97D02873A41FA4D6E6AC33), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 928ms
2020-05-08T12:17:53.338-0700 I  COMMAND  [conn24] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 95), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 928ms
2020-05-08T12:17:53.339-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn250] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965467, 22), signature: { hash: BinData(0, B2C0B39B13884B26BEDF41C2EF5B6E84028E06DF), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 934ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn222] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 23), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 933ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn87] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965467, 22), signature: { hash: BinData(0, B2C0B39B13884B26BEDF41C2EF5B6E84028E06DF), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 934ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn235] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 94), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 932ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn258] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 94), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 931ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn44] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 10), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 931ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn231] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 10), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 931ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn260] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 95), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 929ms
2020-05-08T12:17:53.339-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn257] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965468, 5), signature: { hash: BinData(0, 863890BE952A3FC25C97D02873A41FA4D6E6AC33), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 929ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn234] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 94), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 933ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 94), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 933ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn88] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965472, 95), signature: { hash: BinData(0, F1ACD2AD932B092821B542E9B8962920CC1EAEFB), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 929ms
2020-05-08T12:17:53.339-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1588965470, 23), signature: { hash: BinData(0, EBFEF07E0E997520BB9B6894B61BC5F02F70A79A), keyId: 6824554174072487943 } }, $configServerState: { opTime: { ts: Timestamp(1588965453, 11), t: 29 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 934ms
2020-05-08T12:17:53.339-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-08T12:17:53.340-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-08T12:17:53.340-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-08T12:17:53.340-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:53.341-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:53.342-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-08T12:17:53.412-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37666 #301 (65 connections now open)
2020-05-08T12:17:53.413-0700 I  NETWORK  [conn301] received client metadata from 192.168.122.13:37666 conn301: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-08T12:17:53.505-0700 I  NETWORK  [conn275] end connection 192.168.122.12:46956 (64 connections now open)
2020-05-08T12:17:53.765-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-08T12:17:53.842-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:54.342-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:54.842-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:55.341-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:55.841-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:56.341-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T12:17:56.842-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
