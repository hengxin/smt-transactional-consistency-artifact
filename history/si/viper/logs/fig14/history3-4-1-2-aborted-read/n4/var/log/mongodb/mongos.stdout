2020-05-09 06:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T06:37:13.083-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.085-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.086-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:13.086-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n4:27017:1589031433:6195452691469558094 (sleeping for 30000ms)
2020-05-09T06:37:13.086-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:13.086-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T06:37:13.088-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.089-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.615-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T06:37:14.256-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T06:37:15.619-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T06:37:15.620-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T06:37:15.623-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("73ae5ac4-2bfc-4c63-a15b-c9714f5e5697"), lastMod: 0 } took 0 ms
2020-05-09T06:37:15.624-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.624-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.657-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35934 #9 (1 connection now open)
2020-05-09T06:37:15.658-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.1:35934 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.662-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:35942 #10 (2 connections now open)
2020-05-09T06:37:15.662-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:35942 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.830-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36088 #11 (3 connections now open)
2020-05-09T06:37:17.830-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:36088 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.831-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36096 #12 (4 connections now open)
2020-05-09T06:37:17.831-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:36096 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:18.876-0700 I  COMMAND  [conn11] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("48029aeb-51e8-4e2d-8faa-93c2c51a89fb") } } numYields:0 reslen:163 protocol:op_msg 1037ms
2020-05-09T06:37:18.879-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T06:37:18.881-0700 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:18.882-0700 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:18.882-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:18.882-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:18.882-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:18.882-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:18.882-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:18.882-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:18.885-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:18.885-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:18.886-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:18.886-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:18.975-0700 I  NETWORK  [conn11] end connection 192.168.122.1:36088 (3 connections now open)
2020-05-09T06:37:18.975-0700 I  NETWORK  [conn12] end connection 192.168.122.1:36096 (2 connections now open)
2020-05-09T06:37:22.624-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36296 #19 (3 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:36296 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.627-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36316 #20 (4 connections now open)
2020-05-09T06:37:22.627-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:36316 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.637-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36334 #21 (5 connections now open)
2020-05-09T06:37:22.637-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:36334 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36344 #22 (6 connections now open)
2020-05-09T06:37:22.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36350 #23 (7 connections now open)
2020-05-09T06:37:22.639-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:36344 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.639-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:36350 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.640-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:36366 #24 (8 connections now open)
2020-05-09T06:37:22.640-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:36366 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.668-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 2 ms
2020-05-09T06:37:22.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T06:37:22.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T06:37:23.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T06:37:23.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:23.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:23.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:24.127-0700 I  NETWORK  [conn19] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:24.129-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.629-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.128-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.128-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.129-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T06:37:25.130-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.132-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:25.132-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:25.132-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T06:37:25.154-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031443, 95) } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 95) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2027664, timeActiveMicros:2034253, timeInactiveMicros:410, 2034ms
2020-05-09T06:37:25.154-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 95) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2027719, timeActiveMicros:2035191, timeInactiveMicros:549, 2035ms
2020-05-09T06:37:25.154-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 113) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1990307, timeActiveMicros:1993240, timeInactiveMicros:401, 1993ms
2020-05-09T06:37:25.155-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 16, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2027ms
2020-05-09T06:37:25.155-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 18, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2027ms
2020-05-09T06:37:25.155-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 18, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1990ms
2020-05-09T06:37:25.602-0700 I  NETWORK  [conn22] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:25.602-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.602-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.603-0700 I  NETWORK  [conn21] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:25.604-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 28) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:393306, timeInactiveMicros:0, 393ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 19, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 393ms
2020-05-09T06:37:25.605-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 418ms
2020-05-09T06:37:25.605-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 21, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 387ms
2020-05-09T06:37:25.606-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 15) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:553, timeActiveMicros:418647, timeInactiveMicros:585, 419ms
2020-05-09T06:37:25.607-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 31) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:907, timeActiveMicros:388116, timeInactiveMicros:849, 388ms
2020-05-09T06:37:25.865-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 87) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:233355, timeActiveMicros:243366, timeInactiveMicros:548, 243ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 20, autocommit: false } numYields:0 reslen:214 protocol:op_msg 233ms
2020-05-09T06:37:25.866-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 25, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 94) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:221258, timeActiveMicros:230353, timeInactiveMicros:417, 230ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 105), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 25, autocommit: false } numYields:0 reslen:214 protocol:op_msg 221ms
2020-05-09T06:37:25.866-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:233757, timeActiveMicros:241838, timeInactiveMicros:560, 242ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 22, autocommit: false } numYields:0 reslen:214 protocol:op_msg 233ms
2020-05-09T06:37:26.070-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:26.070-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:26.372-0700 I  SHARDING [conn19] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T06:37:26.373-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 25, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 159) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:435364, timeActiveMicros:442811, timeInactiveMicros:559, 443ms
2020-05-09T06:37:26.373-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 161), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 25, autocommit: false } numYields:0 reslen:214 protocol:op_msg 435ms
2020-05-09T06:37:26.373-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 25, autocommit: false } numYields:0 reslen:321 protocol:op_msg 414ms
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 30, autocommit: false } numYields:0 reslen:321 protocol:op_msg 414ms
2020-05-09T06:37:26.570-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.570-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.571-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:26.892-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 34, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 75) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:428244, timeActiveMicros:448500, timeInactiveMicros:384, 448ms
2020-05-09T06:37:26.892-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 42, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 153) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:264711, timeActiveMicros:266865, timeInactiveMicros:545, 267ms
2020-05-09T06:37:26.892-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 86), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 34, autocommit: false } numYields:0 reslen:214 protocol:op_msg 428ms
2020-05-09T06:37:26.892-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 154), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 42, autocommit: false } numYields:0 reslen:214 protocol:op_msg 264ms
2020-05-09T06:37:26.893-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 114), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 31, autocommit: false } numYields:0 reslen:321 protocol:op_msg 383ms
2020-05-09T06:37:29.042-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:30.720-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.043-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.543-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.543-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.544-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:31.544-0700 I  SHARDING [conn19] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:31.544-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 76, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3476ms
2020-05-09T06:37:31.544-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.545-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:31.545-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:31.582-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 69, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 632) } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 632) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3585322, timeActiveMicros:3619450, timeInactiveMicros:335, 3619ms
2020-05-09T06:37:31.582-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 66, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 28) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3413647, timeActiveMicros:3419374, timeInactiveMicros:340, 3419ms
2020-05-09T06:37:31.582-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 638), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 69, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3585ms
2020-05-09T06:37:31.583-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 66, autocommit: false } numYields:0 reslen:428 protocol:op_msg 3414ms
2020-05-09T06:37:31.610-0700 I  NETWORK  [conn21] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.611-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.611-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.729-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:32.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:33.663-0700 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:33.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.796-0700 I  NETWORK  [conn19] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:33.796-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:34.164-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.165-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.166-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:34.167-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.167-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.731-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.011-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:36.577-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:36.577-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:36.577-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:36.645-0700 I  NETWORK  [conn24] end connection 192.168.122.1:36366 (7 connections now open)
2020-05-09T06:37:36.646-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37476 #53 (8 connections now open)
2020-05-09T06:37:36.647-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37478 #54 (9 connections now open)
2020-05-09T06:37:36.647-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:37476 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:36.647-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:37478 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:36.690-0700 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:36.691-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:36.838-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 106), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("67e1c44e-87c9-472f-b2ca-688921da9170") }, txnNumber: 69, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5013ms
2020-05-09T06:37:36.839-0700 I  NETWORK  [conn22] end connection 192.168.122.1:36344 (8 connections now open)
2020-05-09T06:37:37.019-0700 I  NETWORK  [conn23] end connection 192.168.122.1:36350 (7 connections now open)
2020-05-09T06:37:37.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37484 #55 (8 connections now open)
2020-05-09T06:37:37.021-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37486 #56 (9 connections now open)
2020-05-09T06:37:37.021-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:37484 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:37.022-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.1:37486 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:37.023-0700 I  -        [conn21] operation was interrupted because a client disconnected
2020-05-09T06:37:37.024-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005513, timeInactiveMicros:0, 5005ms
2020-05-09T06:37:37.024-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 84 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031452, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc965491-8da5-4df4-a501-4549cb6b7fa8") }, txnNumber: 77, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-09T06:37:37.024-0700 I  NETWORK  [conn21] end connection 192.168.122.1:36334 (8 connections now open)
2020-05-09T06:37:37.026-0700 I  NETWORK  [conn55] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:37.027-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:37.027-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:37.028-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.077-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.130-0700 I  NETWORK  [conn20] end connection 192.168.122.1:36316 (7 connections now open)
2020-05-09T06:37:37.131-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37488 #57 (8 connections now open)
2020-05-09T06:37:37.132-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:37490 #58 (9 connections now open)
2020-05-09T06:37:37.132-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.1:37488 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:37.132-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.1:37490 conn58: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:37.135-0700 I  -        [conn19] operation was interrupted because a client disconnected
2020-05-09T06:37:37.135-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 85, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 18) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005632, timeInactiveMicros:0, 5005ms
2020-05-09T06:37:37.135-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 78 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031452, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672eed04-980e-4ad6-ab28-85a2c29946a0") }, txnNumber: 85, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-09T06:37:37.135-0700 I  NETWORK  [conn19] end connection 192.168.122.1:36296 (8 connections now open)
2020-05-09T06:37:37.577-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:37.578-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:37.578-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:37.724-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.725-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.742-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 185), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 219ms
2020-05-09T06:37:38.077-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:38.333-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031457, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 569ms
2020-05-09T06:37:38.334-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 15) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1684757, timeInactiveMicros:0, 1684ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn53] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031456, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1684ms
2020-05-09T06:37:38.335-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 185) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1200232, timeInactiveMicros:0, 1200ms
2020-05-09T06:37:38.335-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031456, 185), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1200ms
2020-05-09T06:37:38.350-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031457, 20) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:16099, timeActiveMicros:585561, timeInactiveMicros:1304, 586ms
2020-05-09T06:37:38.533-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-09T06:37:38.577-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.078-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.577-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.840-0700 I  NETWORK  [conn53] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:40.048-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.077-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:40.077-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:40.078-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:40.340-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:41.696-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:41.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.341-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.341-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.342-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.342-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 474), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 23, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3464ms
2020-05-09T06:37:42.343-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:42.343-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:42.549-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 435) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3725210, timeActiveMicros:3734406, timeInactiveMicros:271, 3734ms
2020-05-09T06:37:42.549-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 491) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3639903, timeActiveMicros:3648493, timeInactiveMicros:376, 3648ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn57] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 492), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 21, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3640ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn53] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 437), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 19, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3725ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031462, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 23, autocommit: false } numYields:0 reslen:397 protocol:op_msg 204ms
2020-05-09T06:37:42.553-0700 I  NETWORK  [conn53] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.610-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.634-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.954-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:42.955-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.053-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.053-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.456-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:43.456-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:43.456-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:43.484-0700 I  NETWORK  [conn55] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.486-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.487-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.553-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.909-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.909-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.911-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.955-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.053-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.258-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.455-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.553-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:44.554-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:44.554-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:44.555-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.589-0700 I  NETWORK  [conn53] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:44.590-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.956-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:45.053-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.456-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:45.553-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.622-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6b20412268df81b113504 to 5eb6b206ee2d3ee1870078ea; invalidating user cache
2020-05-09T06:37:45.956-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.053-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.456-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.553-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.955-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.053-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:47.053-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:47.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 70), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 24, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4446ms
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 27, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4422ms
2020-05-09T06:37:47.056-0700 I  COMMAND  [conn53] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 121 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 4503ms
2020-05-09T06:37:47.056-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:47.056-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 70) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:572, timeActiveMicros:4447133, timeInactiveMicros:389, 4447ms
2020-05-09T06:37:47.057-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 27, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:774, timeActiveMicros:4423153, timeInactiveMicros:502, 4423ms
2020-05-09T06:37:47.057-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:821, timeActiveMicros:4504613, timeInactiveMicros:849, 4505ms
2020-05-09T06:37:47.059-0700 I  NETWORK  [conn53] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:47.060-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.060-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.061-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.135-0700 I  NETWORK  [conn55] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:47.135-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:47.455-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.560-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.561-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.562-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.562-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 35, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 35) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:427919, timeInactiveMicros:0, 427ms
2020-05-09T06:37:47.562-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 35, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 428ms
2020-05-09T06:37:47.729-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.814-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 19) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:731054, timeActiveMicros:738374, timeInactiveMicros:246, 738ms
2020-05-09T06:37:47.814-0700 I  COMMAND  [conn53] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 23, autocommit: false } numYields:0 reslen:214 protocol:op_msg 731ms
2020-05-09T06:37:47.814-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 31, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 29) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:694317, timeActiveMicros:700129, timeInactiveMicros:239, 700ms
2020-05-09T06:37:47.814-0700 I  COMMAND  [conn57] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 31, autocommit: false } numYields:0 reslen:214 protocol:op_msg 694ms
2020-05-09T06:37:47.955-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:48.144-0700 I  NETWORK  [conn53] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:48.455-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.456-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.456-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:48.457-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 6), t: 15 }
2020-05-09T06:37:49.144-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.145-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.146-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 37) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1322703, timeInactiveMicros:0, 1322ms
2020-05-09T06:37:49.146-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 35, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1582ms
2020-05-09T06:37:49.146-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 32, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1322ms
2020-05-09T06:37:49.146-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 37) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1323338, timeInactiveMicros:0, 1323ms
2020-05-09T06:37:49.146-0700 I  COMMAND  [conn53] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 24, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1323ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 35, autocommit: false } numYields:0 reslen:397 protocol:op_msg 122ms
2020-05-09T06:37:49.271-0700 I  COMMAND  [conn53] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 24, autocommit: false } numYields:0 reslen:397 protocol:op_msg 122ms
2020-05-09T06:37:49.271-0700 I  COMMAND  [conn57] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 32, autocommit: false } numYields:0 reslen:397 protocol:op_msg 122ms
2020-05-09T06:37:49.495-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 38, autocommit: false } numYields:0 reslen:321 protocol:op_msg 112ms
2020-05-09T06:37:49.495-0700 I  COMMAND  [conn57] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 35, autocommit: false } numYields:0 reslen:321 protocol:op_msg 112ms
2020-05-09T06:37:49.495-0700 I  COMMAND  [conn53] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 27, autocommit: false } numYields:0 reslen:321 protocol:op_msg 113ms
2020-05-09T06:37:49.679-0700 I  NETWORK  [conn55] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.680-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.680-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.681-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.681-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.681-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.867-0700 I  NETWORK  [conn53] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:49.868-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.180-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.180-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.181-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 33, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 197) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:447156, timeInactiveMicros:0, 447ms
2020-05-09T06:37:50.181-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 188), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 44, autocommit: false } numYields:0 reslen:515 protocol:op_msg 499ms
2020-05-09T06:37:50.181-0700 I  COMMAND  [conn53] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 33, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 447ms
2020-05-09T06:37:50.216-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T06:37:50.991-0700 I  NETWORK  [conn55] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:50.992-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.243-0700 I  NETWORK  [conn57] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:51.244-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:51.492-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.744-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:51.744-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:51.753-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 45, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 213) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:1935990, timeActiveMicros:1937089, timeInactiveMicros:275, 1937ms
2020-05-09T06:37:51.754-0700 I  COMMAND  [conn57] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 213), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("399b3cf8-d2a7-4e96-b858-9f7a5107f051") }, txnNumber: 45, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1937ms
2020-05-09T06:37:51.810-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.810-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.812-0700 I  COMMAND  [conn53] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 33, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1629ms
2020-05-09T06:37:51.812-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 44, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1629ms
2020-05-09T06:37:52.703-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:56.942-0700 I  -        [conn55] operation was interrupted because a client disconnected
2020-05-09T06:37:56.943-0700 I  CONNPOOL [conn55] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-09T06:37:56.943-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 48, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031471, 16) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006652, timeInactiveMicros:0, 5006ms
2020-05-09T06:37:56.944-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 130 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031471, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc15eaf6-84ec-4039-9433-1aa08cf9895c") }, txnNumber: 48, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-09T06:37:56.944-0700 I  NETWORK  [conn55] end connection 192.168.122.1:37484 (7 connections now open)
2020-05-09T06:37:56.948-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38074 #69 (8 connections now open)
2020-05-09T06:37:56.948-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:38074 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:56.949-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T06:37:56.952-0700 I  NETWORK  [conn69] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:56.955-0700 I  -        [conn53] operation was interrupted because a client disconnected
2020-05-09T06:37:56.956-0700 I  CONNPOOL [conn53] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-09T06:37:56.956-0700 I  TXN      [conn53] transaction parameters:{ lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 37, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031471, 18) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004711, timeInactiveMicros:0, 5004ms
2020-05-09T06:37:56.957-0700 I  COMMAND  [conn53] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 130 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031471, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2144f60e-96d7-42af-b31b-1172ec53df09") }, txnNumber: 37, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-09T06:37:56.957-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38078 #71 (9 connections now open)
2020-05-09T06:37:56.957-0700 I  NETWORK  [conn53] end connection 192.168.122.1:37476 (8 connections now open)
2020-05-09T06:37:56.957-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.1:38078 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:56.974-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38080 #72 (9 connections now open)
2020-05-09T06:37:56.974-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.1:38080 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.244-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n5:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1457 timed out, deadline was 2020-05-09T06:37:57.244-0700, op was RemoteCommand 1457 -- target:[n5:27018] db:admin expDate:2020-05-09T06:37:57.244-0700 cmd:{ isMaster: 1 }
2020-05-09T06:37:57.244-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n6:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1458 timed out, deadline was 2020-05-09T06:37:57.244-0700, op was RemoteCommand 1458 -- target:[n6:27018] db:admin expDate:2020-05-09T06:37:57.244-0700 cmd:{ isMaster: 1 }
2020-05-09T06:37:57.244-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n5:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:57.244-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:57.244-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:57.244-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:57.456-0700 I  NETWORK  [conn58] end connection 192.168.122.1:37490 (8 connections now open)
2020-05-09T06:37:57.456-0700 I  NETWORK  [conn54] end connection 192.168.122.1:37478 (7 connections now open)
2020-05-09T06:37:57.458-0700 I  NETWORK  [conn56] end connection 192.168.122.1:37486 (6 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38124 #73 (7 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:38128 #74 (8 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.1:38124 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.1:38128 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.467-0700 I  NETWORK  [conn74] end connection 192.168.122.1:38128 (7 connections now open)
2020-05-09T06:37:57.468-0700 I  NETWORK  [conn73] end connection 192.168.122.1:38124 (6 connections now open)
2020-05-09T06:38:02.453-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:38:07.953-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
