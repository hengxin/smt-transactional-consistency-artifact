2020-05-09 08:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T08:37:13.078-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T08:37:13.083-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.083-0500 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T08:37:13.083-0500 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T08:37:13.083-0500 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T08:37:13.083-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.084-0500 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] modules: none
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] build environment:
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T08:37:13.085-0500 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.085-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T08:37:13.085-0500 I  SHARDING [thread1] creating distributed lock ping thread for process n9:27017:1589031433:1765043958672717246 (sleeping for 30000ms)
2020-05-09T08:37:13.085-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T08:37:13.085-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T08:37:13.087-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.087-0500 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.614-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T08:37:13.617-0500 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-09T08:37:14.256-0500 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T08:37:14.618-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:14.621-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:14.625-0500 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T08:37:14.626-0500 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T08:37:14.630-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("5493ac81-4428-4d97-a812-1804e7d414c4"), lastMod: 0 } took 0 ms
2020-05-09T08:37:14.630-0500 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T08:37:14.630-0500 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T08:37:14.630-0500 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T08:37:14.631-0500 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:14.631-0500 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:15.158-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37634 #10 (1 connection now open)
2020-05-09T08:37:15.159-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37638 #11 (2 connections now open)
2020-05-09T08:37:15.159-0500 I  NETWORK  [conn10] received client metadata from 192.168.122.1:37634 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:15.159-0500 I  NETWORK  [conn11] received client metadata from 192.168.122.1:37638 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.834-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37818 #12 (3 connections now open)
2020-05-09T08:37:17.834-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37822 #13 (4 connections now open)
2020-05-09T08:37:17.834-0500 I  NETWORK  [conn12] received client metadata from 192.168.122.1:37818 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.834-0500 I  NETWORK  [conn13] received client metadata from 192.168.122.1:37822 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:21.459-0500 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a2590085-a8df-4e70-afe0-7a207781839a") } } numYields:0 reslen:163 protocol:op_msg 3618ms
2020-05-09T08:37:21.462-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T08:37:21.465-0500 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:21.465-0500 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:21.466-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T08:37:21.466-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T08:37:21.466-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T08:37:21.466-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T08:37:21.466-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T08:37:21.466-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T08:37:21.469-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:21.469-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:21.470-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:21.470-0500 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:21.552-0500 I  NETWORK  [conn12] end connection 192.168.122.1:37818 (3 connections now open)
2020-05-09T08:37:21.552-0500 I  NETWORK  [conn13] end connection 192.168.122.1:37822 (2 connections now open)
2020-05-09T08:37:22.636-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38038 #20 (3 connections now open)
2020-05-09T08:37:22.637-0500 I  NETWORK  [conn20] received client metadata from 192.168.122.1:38038 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.637-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38044 #21 (4 connections now open)
2020-05-09T08:37:22.637-0500 I  NETWORK  [conn21] received client metadata from 192.168.122.1:38044 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.644-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38084 #22 (5 connections now open)
2020-05-09T08:37:22.644-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38086 #23 (6 connections now open)
2020-05-09T08:37:22.644-0500 I  NETWORK  [conn22] received client metadata from 192.168.122.1:38084 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.645-0500 I  NETWORK  [conn23] received client metadata from 192.168.122.1:38086 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.650-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38094 #24 (7 connections now open)
2020-05-09T08:37:22.650-0500 I  NETWORK  [conn24] received client metadata from 192.168.122.1:38094 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.650-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38098 #25 (8 connections now open)
2020-05-09T08:37:22.651-0500 I  NETWORK  [conn25] received client metadata from 192.168.122.1:38098 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.668-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 2 ms
2020-05-09T08:37:22.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T08:37:22.689-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:23.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:23.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:23.689-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T08:37:23.689-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:24.160-0500 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:24.161-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.336-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.339-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.662-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.713-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:24.714-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.714-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.953-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T08:37:25.161-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.162-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.163-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 88), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1") }, txnNumber: 17, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2046ms
2020-05-09T08:37:25.163-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 83), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 20, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2049ms
2020-05-09T08:37:25.563-0500 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:25.564-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:25.603-0500 I  NETWORK  [conn24] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T08:37:25.604-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.604-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.605-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 110) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2454537, timeInactiveMicros:0, 2454ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031443, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 19, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 26e61263-8a31-4535-b936-4073d5e2bff4:19 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:627 protocol:op_msg 2454ms
2020-05-09T08:37:25.605-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 18, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 10) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 15) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:411185, timeInactiveMicros:0, 411ms
2020-05-09T08:37:25.605-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 10) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 15) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:411118, timeInactiveMicros:0, 411ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1") }, txnNumber: 18, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 411ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 21, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 411ms
2020-05-09T08:37:25.865-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 81) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:246227, timeActiveMicros:247256, timeInactiveMicros:442, 247ms
2020-05-09T08:37:25.865-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 21, autocommit: false } numYields:0 reslen:214 protocol:op_msg 246ms
2020-05-09T08:37:26.055-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 21, autocommit: false } numYields:0 reslen:397 protocol:op_msg 374ms
2020-05-09T08:37:26.373-0500 I  SHARDING [conn20] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T08:37:26.373-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 30, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 1) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:366144, timeActiveMicros:368756, timeInactiveMicros:406, 369ms
2020-05-09T08:37:26.373-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 30, autocommit: false } numYields:0 reslen:214 protocol:op_msg 366ms
2020-05-09T08:37:26.373-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:294128, timeActiveMicros:295096, timeInactiveMicros:366, 295ms
2020-05-09T08:37:26.373-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 23, autocommit: false } numYields:0 reslen:214 protocol:op_msg 294ms
2020-05-09T08:37:26.893-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 37, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 97) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:407751, timeActiveMicros:414446, timeInactiveMicros:689, 415ms
2020-05-09T08:37:26.893-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 30, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 121) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:370093, timeActiveMicros:374524, timeInactiveMicros:484, 375ms
2020-05-09T08:37:26.893-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 121), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 30, autocommit: false } numYields:0 reslen:214 protocol:op_msg 370ms
2020-05-09T08:37:26.893-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 37, autocommit: false } numYields:0 reslen:214 protocol:op_msg 407ms
2020-05-09T08:37:27.274-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1") }, txnNumber: 18, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1593ms
2020-05-09T08:37:27.494-0500 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T08:37:29.041-0500 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:29.041-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:29.043-0500 I  NETWORK  [conn24] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:29.043-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:29.541-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.041-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:30.041-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:30.041-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T08:37:30.042-0500 I  SHARDING [conn20] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T08:37:30.042-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 644), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 69, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2045ms
2020-05-09T08:37:30.042-0500 I  NETWORK  [Sharding-Fixed-2] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:30.043-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:30.044-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:30.146-0500 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:30.147-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.148-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 24) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:1997043, timeActiveMicros:2006020, timeInactiveMicros:570, 2006ms
2020-05-09T08:37:30.149-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.211-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T08:37:30.542-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:31.041-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:31.541-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.541-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.542-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:31.543-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1") }, txnNumber: 36, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3391ms
2020-05-09T08:37:31.544-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031450, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 69, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1499ms
2020-05-09T08:37:31.575-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 64, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 632) } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 632) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3578552, timeActiveMicros:3612882, timeInactiveMicros:394, 3613ms
2020-05-09T08:37:31.575-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 638), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 64, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3578ms
2020-05-09T08:37:31.578-0500 I  NETWORK  [conn24] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.579-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.579-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.632-0500 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T08:37:31.828-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 67, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 86) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:109569, timeActiveMicros:130074, timeInactiveMicros:398, 130ms
2020-05-09T08:37:31.829-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 93), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 67, autocommit: false } numYields:0 reslen:214 protocol:op_msg 109ms
2020-05-09T08:37:31.830-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 80), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1") }, txnNumber: 38, autocommit: false } numYields:0 reslen:321 protocol:op_msg 151ms
2020-05-09T08:37:32.829-0500 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:32.832-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:32.833-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.142-0500 I  NETWORK  [conn23] end connection 192.168.122.1:38086 (7 connections now open)
2020-05-09T08:37:33.144-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39024 #51 (8 connections now open)
2020-05-09T08:37:33.144-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39026 #52 (9 connections now open)
2020-05-09T08:37:33.144-0500 I  NETWORK  [conn51] received client metadata from 192.168.122.1:39024 conn51: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:33.145-0500 I  NETWORK  [conn52] received client metadata from 192.168.122.1:39026 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:33.148-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.330-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.830-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:34.330-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:34.330-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:34.331-0500 I  NETWORK  [Sharding-Fixed-2] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:34.331-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 120), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e02dc4e-a1ae-4143-85a9-8ac33de38ae1") }, txnNumber: 39, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2483ms
2020-05-09T08:37:34.331-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:34.331-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:34.331-0500 I  NETWORK  [conn22] end connection 192.168.122.1:38084 (8 connections now open)
2020-05-09T08:37:34.731-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T08:37:35.011-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 139) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3082753, timeActiveMicros:3114767, timeInactiveMicros:639, 3115ms
2020-05-09T08:37:35.014-0500 I  NETWORK  [conn51] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:35.015-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 18) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2881469, timeActiveMicros:2908359, timeInactiveMicros:645, 2909ms
2020-05-09T08:37:35.016-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:35.016-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:35.515-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.515-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.516-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:35.516-0500 I  NETWORK  [Sharding-Fixed-2] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.517-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 140), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 70, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3588ms
2020-05-09T08:37:35.517-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:35.517-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:35.518-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 80, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3384ms
2020-05-09T08:37:35.519-0500 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 30) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2371898, timeInactiveMicros:0, 2371ms
2020-05-09T08:37:35.519-0500 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031452, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2372ms
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 80, autocommit: false } numYields:0 reslen:214 protocol:op_msg 276ms
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 70, autocommit: false } numYields:0 reslen:214 protocol:op_msg 277ms
2020-05-09T08:37:35.799-0500 I  COMMAND  [conn51] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 277ms
2020-05-09T08:37:35.823-0500 I  NETWORK  [conn20] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.824-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:35.824-0500 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:36.689-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.690-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:36.691-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.691-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.173-0500 I  NETWORK  [conn24] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.176-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:37.177-0500 I  NETWORK  [conn51] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.177-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:37.178-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:37.190-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.190-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.191-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:37.674-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.675-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.676-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 96, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1447ms
2020-05-09T08:37:37.721-0500 I  NETWORK  [Uptime-reporter] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.724-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.222-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.332-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 85, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 160) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2076553, timeActiveMicros:2084308, timeInactiveMicros:374, 2084ms
2020-05-09T08:37:38.333-0500 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 111) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2141672, timeActiveMicros:2149734, timeInactiveMicros:418, 2150ms
2020-05-09T08:37:38.333-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 166), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 85, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2077ms
2020-05-09T08:37:38.334-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 96, autocommit: false } numYields:0 reslen:397 protocol:op_msg 654ms
2020-05-09T08:37:38.334-0500 I  COMMAND  [conn51] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 116), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 13, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2142ms
2020-05-09T08:37:38.722-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.222-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.722-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.839-0500 I  NETWORK  [conn24] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:39.840-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:39.841-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:39.841-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.222-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.222-0500 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.223-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T08:37:40.340-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.840-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.841-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.842-0500 I  COMMAND  [conn51] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 449), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 28, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2000ms
2020-05-09T08:37:41.535-0500 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:41.537-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:41.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.037-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.536-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.537-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.538-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:42.538-0500 I  COMMAND  [conn51] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 28, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1694ms
2020-05-09T08:37:42.539-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.539-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.549-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 109, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 491) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3640351, timeActiveMicros:3648674, timeInactiveMicros:503, 3649ms
2020-05-09T08:37:42.549-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 130, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 512) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3565263, timeActiveMicros:3569567, timeInactiveMicros:450, 3570ms
2020-05-09T08:37:42.549-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 493), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 109, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3640ms
2020-05-09T08:37:42.549-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 513), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 130, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3565ms
2020-05-09T08:37:42.955-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:42.955-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.024-0500 I  NETWORK  [conn51] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:43.025-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.025-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.026-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.027-0500 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 62) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:424057, timeInactiveMicros:0, 424ms
2020-05-09T08:37:43.027-0500 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 32, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 424ms
2020-05-09T08:37:43.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.123-0500 I  NETWORK  [conn24] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:43.486-0500 I  NETWORK  [conn24] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.540-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.540-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:43.908-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.908-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.910-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.258-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.629-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6b20412268df81b113504 to 5eb6b206ee2d3ee1870078ea; invalidating user cache
2020-05-09T08:37:45.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.816-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.816-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.817-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.818-0500 I  COMMAND  [conn51] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031462, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 32, autocommit: false } numYields:0 reslen:515 protocol:op_msg 3777ms
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 118, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4205ms
2020-05-09T08:37:46.896-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 118, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 103) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:574, timeActiveMicros:4206462, timeInactiveMicros:630, 4207ms
2020-05-09T08:37:47.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.540-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.553-0500 I  NETWORK  [conn21] end connection 192.168.122.1:38044 (7 connections now open)
2020-05-09T08:37:47.554-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39530 #62 (8 connections now open)
2020-05-09T08:37:47.555-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39532 #63 (9 connections now open)
2020-05-09T08:37:47.555-0500 I  NETWORK  [conn62] received client metadata from 192.168.122.1:39530 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.555-0500 I  NETWORK  [conn63] received client metadata from 192.168.122.1:39532 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.557-0500 I  -        [conn20] operation was interrupted because a client disconnected
2020-05-09T08:37:47.557-0500 I  CONNPOOL [conn20] Ending connection to host n7:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-09T08:37:47.558-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 131, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 4) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006576, timeInactiveMicros:0, 5006ms
2020-05-09T08:37:47.558-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 121 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4") }, txnNumber: 131, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-09T08:37:47.559-0500 I  NETWORK  [conn20] end connection 192.168.122.1:38038 (8 connections now open)
2020-05-09T08:37:47.603-0500 I  NETWORK  [conn52] end connection 192.168.122.1:39026 (7 connections now open)
2020-05-09T08:37:47.604-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39546 #64 (8 connections now open)
2020-05-09T08:37:47.605-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39548 #65 (9 connections now open)
2020-05-09T08:37:47.605-0500 I  NETWORK  [conn64] received client metadata from 192.168.122.1:39546 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.605-0500 I  NETWORK  [conn65] received client metadata from 192.168.122.1:39548 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.746-0500 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 33, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:850069, timeInactiveMicros:0, 850ms
2020-05-09T08:37:47.746-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 119, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:847600, timeInactiveMicros:0, 847ms
2020-05-09T08:37:47.746-0500 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039") }, txnNumber: 33, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 850ms
2020-05-09T08:37:47.746-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 119, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 847ms
2020-05-09T08:37:47.746-0500 I  NETWORK  [conn51] end connection 192.168.122.1:39024 (8 connections now open)
2020-05-09T08:37:48.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:48.142-0500 I  NETWORK  [conn64] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:48.143-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.144-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.147-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.540-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.540-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:48.552-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 14), t: 15 }
2020-05-09T08:37:48.642-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:49.142-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.142-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.143-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:49.144-0500 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 11) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1585566, timeInactiveMicros:0, 1585ms
2020-05-09T08:37:49.144-0500 I  COMMAND  [conn62] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1585ms
2020-05-09T08:37:49.144-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 121, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 45) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1309371, timeInactiveMicros:0, 1309ms
2020-05-09T08:37:49.144-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 121, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1309ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 121, autocommit: false } numYields:0 reslen:399 protocol:op_msg 123ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn64] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 128 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1664ms
2020-05-09T08:37:49.271-0500 I  COMMAND  [conn62] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 124ms
2020-05-09T08:37:49.272-0500 I  TXN      [conn64] transaction parameters:{ lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 11) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1132, timeActiveMicros:1665297, timeInactiveMicros:584, 1665ms
2020-05-09T08:37:49.274-0500 I  NETWORK  [conn64] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:49.275-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:49.275-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:49.275-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:49.276-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:49.276-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:49.495-0500 I  COMMAND  [conn62] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a") }, txnNumber: 4, autocommit: false } numYields:0 reslen:320 protocol:op_msg 112ms
2020-05-09T08:37:49.734-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:50.187-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:50.216-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T08:37:50.287-0500 I  NETWORK  [conn24] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:50.288-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.288-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.289-0500 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 197) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:555114, timeInactiveMicros:0, 555ms
2020-05-09T08:37:50.289-0500 I  COMMAND  [conn62] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a") }, txnNumber: 10, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 555ms
2020-05-09T08:37:50.289-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 123, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 53) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:957706, timeInactiveMicros:0, 957ms
2020-05-09T08:37:50.290-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 123, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 957ms
2020-05-09T08:37:50.991-0500 I  NETWORK  [conn64] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:50.991-0500 I  NETWORK  [conn62] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:52.448-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:52.448-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:52.450-0500 I  COMMAND  [conn62] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a") }, txnNumber: 10, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2158ms
2020-05-09T08:37:52.450-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 123, autocommit: false } numYields:0 reslen:517 protocol:op_msg 2158ms
2020-05-09T08:37:52.450-0500 I  COMMAND  [conn64] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 3176ms
2020-05-09T08:37:52.453-0500 I  TXN      [conn64] transaction parameters:{ lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 25) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1263, timeActiveMicros:3177873, timeInactiveMicros:1178, 3179ms
2020-05-09T08:37:52.456-0500 I  NETWORK  [conn64] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:52.457-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:52.458-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:52.504-0500 I  NETWORK  [conn62] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:52.505-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:52.819-0500 I  NETWORK  [conn64] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:52.821-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:52.957-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:53.005-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:53.005-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:53.457-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:53.457-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:53.459-0500 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 998ms
2020-05-09T08:37:53.513-0500 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 11, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031472, 26) } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 26) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1027912, timeActiveMicros:1029214, timeInactiveMicros:455, 1029ms
2020-05-09T08:37:53.513-0500 I  COMMAND  [conn62] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b031e4d5-c890-4f2c-a929-a4cd6530408a") }, txnNumber: 11, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1028ms
2020-05-09T08:37:53.513-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 124, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031472, 26) } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 26) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1028063, timeActiveMicros:1029533, timeInactiveMicros:467, 1030ms
2020-05-09T08:37:53.513-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea") }, txnNumber: 124, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1028ms
2020-05-09T08:37:53.961-0500 I  NETWORK  [conn64] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:53.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:54.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:54.961-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:55.461-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:55.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:56.462-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:56.961-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:57.455-0500 I  NETWORK  [conn65] end connection 192.168.122.1:39548 (7 connections now open)
2020-05-09T08:37:57.456-0500 I  NETWORK  [conn62] end connection 192.168.122.1:39530 (6 connections now open)
2020-05-09T08:37:57.457-0500 I  NETWORK  [conn24] end connection 192.168.122.1:38094 (5 connections now open)
2020-05-09T08:37:57.457-0500 I  NETWORK  [conn63] end connection 192.168.122.1:39532 (4 connections now open)
2020-05-09T08:37:57.458-0500 I  NETWORK  [conn25] end connection 192.168.122.1:38098 (3 connections now open)
2020-05-09T08:37:57.461-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:57.465-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39838 #69 (4 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn69] received client metadata from 192.168.122.1:39838 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn69] end connection 192.168.122.1:39838 (3 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:39846 #70 (4 connections now open)
2020-05-09T08:37:57.467-0500 I  NETWORK  [conn70] end connection 192.168.122.1:39846 (3 connections now open)
2020-05-09T08:37:57.961-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:58.461-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:58.961-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:59.461-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:59.962-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:38:00.461-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:38:00.462-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:38:00.463-0500 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031473, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 7002ms
2020-05-09T08:38:00.463-0500 I  NETWORK  [conn64] end connection 192.168.122.1:39546 (2 connections now open)
