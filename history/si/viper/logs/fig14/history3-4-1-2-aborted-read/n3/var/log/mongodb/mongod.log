2020-05-09T06:37:05.705-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:05.727-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=4230 port=27019 dbpath=/var/lib/mongodb 64-bit host=n3
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] modules: none
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] build environment:
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-09T06:37:05.728-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-09T06:37:05.728-0700 I  STORAGE  [initandlisten] 
2020-05-09T06:37:05.728-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-09T06:37:05.728-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-09T06:37:05.728-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-09T06:37:06.487-0700 I  STORAGE  [initandlisten] WiredTiger message [1589031426:487316][4230:0x7f1294f79140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-09T06:37:06.542-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-09T06:37:06.590-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-09T06:37:06.634-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.634-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:06.634-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:06.634-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-09T06:37:06.636-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.638-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-09T06:37:06.638-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-09T06:37:06.638-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-09T06:37:06.638-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-09T06:37:06.639-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 471dd721-1d49-485e-905e-9a778a453db2 and options: { capped: true, size: 10485760 }
2020-05-09T06:37:06.687-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-09T06:37:06.687-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-09T06:37:06.688-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-09T06:37:06.693-0700 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-05-09T06:37:06.693-0700 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-05-09T06:37:06.694-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 3002596c-3939-4cd0-95ab-cc62df012ea3 and options: {}
2020-05-09T06:37:06.738-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-09T06:37:06.738-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: f4bbcf2f-ec61-4b81-88a6-0f75253a1048 and options: {}
2020-05-09T06:37:06.798-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-09T06:37:06.799-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-09T06:37:06.799-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 044df754-9d01-43d6-afc1-b781c71060c0 and options: {}
2020-05-09T06:37:06.852-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-09T06:37:06.852-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-09T06:37:06.852-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-09T06:37:06.852-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-09T06:37:06.853-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 49fd80ff-b96c-47ea-b109-2e8c61f7b6c5 and options: {}
2020-05-09T06:37:06.905-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-09T06:37:06.905-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-09T06:37:06.906-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-09T06:37:06.906-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-09T06:37:06.907-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("a41a454e-043b-44b5-857e-9caac83a5007"), lastMod: 0 } took 0 ms
2020-05-09T06:37:06.908-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-05-09T06:37:06.908-0700 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-05-09T06:37:06.908-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:06.908-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-05-09T06:37:06.908-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-05-09T06:37:06.908-0700 I  NETWORK  [listener] waiting for connections on port 27019
2020-05-09T06:37:07.001-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-09T06:37:07.904-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41046 #1 (1 connection now open)
2020-05-09T06:37:07.906-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41056 #2 (2 connections now open)
2020-05-09T06:37:07.909-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:41056 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.910-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:41046 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.953-0700 I  NETWORK  [conn1] end connection 192.168.122.1:41046 (1 connection now open)
2020-05-09T06:37:07.954-0700 I  NETWORK  [conn2] end connection 192.168.122.1:41056 (0 connections now open)
2020-05-09T06:37:08.042-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:32900 #3 (1 connection now open)
2020-05-09T06:37:08.042-0700 I  NETWORK  [conn3] end connection 192.168.122.11:32900 (0 connections now open)
2020-05-09T06:37:08.043-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:32904 #4 (1 connection now open)
2020-05-09T06:37:08.043-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.11:32904 conn4: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:08.044-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T06:37:08.589-0700 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: 059ae069-60be-4134-b9f0-521f15e7bd47 and options: {}
2020-05-09T06:37:08.590-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:48774 #8 (2 connections now open)
2020-05-09T06:37:08.591-0700 I  NETWORK  [conn8] end connection 192.168.122.12:48774 (1 connection now open)
2020-05-09T06:37:08.705-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2020-05-09T06:37:08.706-0700 I  REPL     [replexec-0] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n1:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n2:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n3:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb6b20312268df81b1134ff') } }
2020-05-09T06:37:08.706-0700 I  REPL     [replexec-0] This node is n3:27019 in the config
2020-05-09T06:37:08.706-0700 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2020-05-09T06:37:08.706-0700 I  REPL     [replexec-0] Starting replication storage threads
2020-05-09T06:37:08.707-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:08.707-0700 I  REPL     [replexec-3] Member n1:27019 is now in state SECONDARY
2020-05-09T06:37:08.710-0700 I  REPL     [replexec-2] Member n2:27019 is now in state STARTUP
2020-05-09T06:37:08.710-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:48786 #10 (2 connections now open)
2020-05-09T06:37:08.711-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.12:48786 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:08.722-0700 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: 86ec4c24-0686-4c06-8d65-a4d5d1a88fce and options: { temp: true }
2020-05-09T06:37:08.840-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-09T06:37:08.840-0700 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2020-05-09T06:37:08.841-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (86ec4c24-0686-4c06-8d65-a4d5d1a88fce).
2020-05-09T06:37:08.867-0700 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: 4236e060-56d1-4158-9df6-70480959e512 and options: { temp: true }
2020-05-09T06:37:08.979-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-09T06:37:08.979-0700 I  REPL     [replication-0] sync source candidate: n1:27019
2020-05-09T06:37:08.980-0700 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2020-05-09T06:37:08.980-0700 I  REPL     [replication-0] ******
2020-05-09T06:37:08.980-0700 I  REPL     [replication-0] creating replication oplog of size: 36624MB...
2020-05-09T06:37:08.980-0700 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: 5a60f172-2d46-4232-952d-bd4b90358316 and options: { capped: true, size: 38403864780.0, autoIndexId: false }
2020-05-09T06:37:09.056-0700 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2020-05-09T06:37:09.057-0700 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-09T06:37:09.057-0700 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:09.057-0700 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:09.211-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP2
2020-05-09T06:37:09.426-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.427-0700 I  ELECTION [conn4] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2020-05-09T06:37:09.444-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.444-0700 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-09T06:37:09.585-0700 I  REPL     [replication-0] ******
2020-05-09T06:37:09.586-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2020-05-09T06:37:09.586-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2020-05-09T06:37:09.586-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T06:37:09.590-0700 I  COMMAND  [conn4] command local.replset.election command: replSetRequestVotes { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 }, $clusterTime: { clusterTime: Timestamp(1589031428, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "admin" } numYields:0 reslen:293 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 1, w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 141496 } }, Database: { acquireCount: { r: 1, w: 1 } }, Collection: { acquireCount: { r: 1, w: 1 } }, Mutex: { acquireCount: { r: 3 } } } storage:{} protocol:op_msg 146ms
2020-05-09T06:37:10.394-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41202 #13 (3 connections now open)
2020-05-09T06:37:10.394-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41210 #14 (4 connections now open)
2020-05-09T06:37:10.394-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:41202 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:10.395-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:41210 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:10.506-0700 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:admin.system.version
2020-05-09T06:37:10.508-0700 I  STORAGE  [repl-writer-worker-15] createCollection: admin.system.version with provided UUID: e21ec07c-5ee8-4e45-81d9-11c669b2e1d8 and options: { uuid: UUID("e21ec07c-5ee8-4e45-81d9-11c669b2e1d8") }
2020-05-09T06:37:10.508-0700 I  SHARDING [replication-1] Marking collection local.temp_oplog_buffer as collection version: <unsharded>
2020-05-09T06:37:10.545-0700 I  INDEX    [repl-writer-worker-15] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2020-05-09T06:37:10.545-0700 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.548-0700 I  COMMAND  [repl-writer-worker-0] setting featureCompatibilityVersion to 4.2
2020-05-09T06:37:10.548-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 14
2020-05-09T06:37:10.548-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 13
2020-05-09T06:37:10.548-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 10
2020-05-09T06:37:10.548-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 4
2020-05-09T06:37:10.548-0700 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.version finished cloning with status: OK
2020-05-09T06:37:10.550-0700 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.556-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.version
2020-05-09T06:37:10.560-0700 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.version
2020-05-09T06:37:10.562-0700 I  STORAGE  [repl-writer-worker-1] createCollection: config.version with provided UUID: 0cf7f778-40b9-464c-b668-4ef14ed770ce and options: { uuid: UUID("0cf7f778-40b9-464c-b668-4ef14ed770ce") }
2020-05-09T06:37:10.642-0700 I  INDEX    [repl-writer-worker-1] index build: starting on config.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.version" } using method: Hybrid
2020-05-09T06:37:10.642-0700 I  INDEX    [repl-writer-worker-1] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.644-0700 I  SHARDING [repl-writer-worker-2] Marking collection config.version as collection version: <unsharded>
2020-05-09T06:37:10.645-0700 I  INITSYNC [replication-0] CollectionCloner ns:config.version finished cloning with status: OK
2020-05-09T06:37:10.646-0700 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.651-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns config.version
2020-05-09T06:37:10.655-0700 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:config.chunks
2020-05-09T06:37:10.657-0700 I  STORAGE  [repl-writer-worker-3] createCollection: config.chunks with provided UUID: 30857f98-8618-4345-9ef9-9dfb8d9fe020 and options: { uuid: UUID("30857f98-8618-4345-9ef9-9dfb8d9fe020") }
2020-05-09T06:37:10.755-0700 I  INDEX    [repl-writer-worker-3] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:10.755-0700 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 66 megabytes of RAM
2020-05-09T06:37:10.822-0700 I  INDEX    [repl-writer-worker-3] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:10.822-0700 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 66 megabytes of RAM
2020-05-09T06:37:10.889-0700 I  INDEX    [repl-writer-worker-3] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:10.889-0700 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 66 megabytes of RAM
2020-05-09T06:37:10.963-0700 I  INDEX    [repl-writer-worker-3] index build: starting on config.chunks properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:10.963-0700 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.966-0700 I  INITSYNC [replication-1] CollectionCloner ns:config.chunks finished cloning with status: OK
2020-05-09T06:37:10.968-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.976-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.986-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.994-0700 I  INDEX    [replication-1] index build: done building index ns_1_min_1 on ns config.chunks
2020-05-09T06:37:10.995-0700 I  INDEX    [replication-1] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-05-09T06:37:10.995-0700 I  INDEX    [replication-1] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-05-09T06:37:10.996-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.003-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns config.chunks
2020-05-09T06:37:11.040-0700 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.shards
2020-05-09T06:37:11.042-0700 I  STORAGE  [repl-writer-worker-4] createCollection: config.shards with provided UUID: 8f635616-875a-4131-bf1c-0238dbecde2e and options: { uuid: UUID("8f635616-875a-4131-bf1c-0238dbecde2e") }
2020-05-09T06:37:11.126-0700 I  INDEX    [repl-writer-worker-4] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-05-09T06:37:11.126-0700 I  INDEX    [repl-writer-worker-4] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.187-0700 I  INDEX    [repl-writer-worker-4] index build: starting on config.shards properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.shards" } using method: Hybrid
2020-05-09T06:37:11.187-0700 I  INDEX    [repl-writer-worker-4] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.190-0700 I  INITSYNC [replication-0] CollectionCloner ns:config.shards finished cloning with status: OK
2020-05-09T06:37:11.192-0700 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.200-0700 I  INDEX    [replication-0] index build: done building index host_1 on ns config.shards
2020-05-09T06:37:11.202-0700 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.211-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns config.shards
2020-05-09T06:37:11.235-0700 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:config.migrations
2020-05-09T06:37:11.237-0700 I  STORAGE  [repl-writer-worker-5] createCollection: config.migrations with provided UUID: 90ef7ec6-d003-4d50-920d-7b1bb037da02 and options: { uuid: UUID("90ef7ec6-d003-4d50-920d-7b1bb037da02") }
2020-05-09T06:37:11.323-0700 I  INDEX    [repl-writer-worker-5] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-05-09T06:37:11.323-0700 I  INDEX    [repl-writer-worker-5] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.381-0700 I  INDEX    [repl-writer-worker-5] index build: starting on config.migrations properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.migrations" } using method: Hybrid
2020-05-09T06:37:11.381-0700 I  INDEX    [repl-writer-worker-5] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.384-0700 I  INITSYNC [replication-1] CollectionCloner ns:config.migrations finished cloning with status: OK
2020-05-09T06:37:11.386-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.397-0700 I  INDEX    [replication-1] index build: done building index ns_1_min_1 on ns config.migrations
2020-05-09T06:37:11.399-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.405-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns config.migrations
2020-05-09T06:37:11.429-0700 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.lockpings
2020-05-09T06:37:11.431-0700 I  STORAGE  [repl-writer-worker-6] createCollection: config.lockpings with provided UUID: d60b2eae-0875-45e7-945d-da2c28b42ddc and options: { uuid: UUID("d60b2eae-0875-45e7-945d-da2c28b42ddc") }
2020-05-09T06:37:11.494-0700 I  INDEX    [repl-writer-worker-6] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-05-09T06:37:11.494-0700 I  INDEX    [repl-writer-worker-6] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.568-0700 I  INDEX    [repl-writer-worker-6] index build: starting on config.lockpings properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.lockpings" } using method: Hybrid
2020-05-09T06:37:11.568-0700 I  INDEX    [repl-writer-worker-6] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.571-0700 I  INITSYNC [replication-1] CollectionCloner ns:config.lockpings finished cloning with status: OK
2020-05-09T06:37:11.573-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.582-0700 I  INDEX    [replication-1] index build: done building index ping_1 on ns config.lockpings
2020-05-09T06:37:11.584-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.590-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns config.lockpings
2020-05-09T06:37:11.597-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031430, 19), t: 1 } }
2020-05-09T06:37:11.598-0700 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-09T06:37:11.603-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031430, 19), t: 1 } }
2020-05-09T06:37:11.603-0700 I  ELECTION [conn4] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-05-09T06:37:11.614-0700 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.tags
2020-05-09T06:37:11.616-0700 I  STORAGE  [repl-writer-worker-7] createCollection: config.tags with provided UUID: db4258f9-f664-4812-beb7-a5326a0f15d9 and options: { uuid: UUID("db4258f9-f664-4812-beb7-a5326a0f15d9") }
2020-05-09T06:37:11.617-0700 I  REPL     [replication-1] Restarting oplog query due to error: CappedPositionLost: error in fetcher batch callback :: caused by :: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824838028461080578). Last fetched optime: { ts: Timestamp(1589031431, 2), t: 2 }. Restarts remaining: 10
2020-05-09T06:37:11.617-0700 I  REPL     [replication-1] Scheduled new oplog query Fetcher source: n1:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031431, 2) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 2, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 40 -- target:n1:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031431, 2) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 2, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-09T06:37:11.707-0700 I  INDEX    [repl-writer-worker-7] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-05-09T06:37:11.707-0700 I  INDEX    [repl-writer-worker-7] build may temporarily use up to 100 megabytes of RAM
2020-05-09T06:37:11.763-0700 I  INDEX    [repl-writer-worker-7] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-05-09T06:37:11.763-0700 I  INDEX    [repl-writer-worker-7] build may temporarily use up to 100 megabytes of RAM
2020-05-09T06:37:11.835-0700 I  INDEX    [repl-writer-worker-7] index build: starting on config.tags properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.tags" } using method: Hybrid
2020-05-09T06:37:11.835-0700 I  INDEX    [repl-writer-worker-7] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:11.838-0700 I  INITSYNC [replication-1] CollectionCloner ns:config.tags finished cloning with status: OK
2020-05-09T06:37:11.840-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.846-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.852-0700 I  INDEX    [replication-1] index build: done building index ns_1_min_1 on ns config.tags
2020-05-09T06:37:11.852-0700 I  INDEX    [replication-1] index build: done building index ns_1_tag_1 on ns config.tags
2020-05-09T06:37:11.854-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:11.858-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns config.tags
2020-05-09T06:37:11.882-0700 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.locks
2020-05-09T06:37:11.884-0700 I  STORAGE  [repl-writer-worker-8] createCollection: config.locks with provided UUID: dd3d40c6-a31d-4660-9497-ae3227412d13 and options: { uuid: UUID("dd3d40c6-a31d-4660-9497-ae3227412d13") }
2020-05-09T06:37:11.957-0700 I  INDEX    [repl-writer-worker-8] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-05-09T06:37:11.957-0700 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 100 megabytes of RAM
2020-05-09T06:37:12.001-0700 I  INDEX    [repl-writer-worker-8] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-05-09T06:37:12.001-0700 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 100 megabytes of RAM
2020-05-09T06:37:12.068-0700 I  INDEX    [repl-writer-worker-8] index build: starting on config.locks properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.locks" } using method: Hybrid
2020-05-09T06:37:12.068-0700 I  INDEX    [repl-writer-worker-8] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:12.071-0700 I  INITSYNC [replication-0] CollectionCloner ns:config.locks finished cloning with status: OK
2020-05-09T06:37:12.072-0700 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:12.080-0700 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:12.086-0700 I  INDEX    [replication-0] index build: done building index ts_1 on ns config.locks
2020-05-09T06:37:12.086-0700 I  INDEX    [replication-0] index build: done building index state_1_process_1 on ns config.locks
2020-05-09T06:37:12.088-0700 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:12.096-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns config.locks
2020-05-09T06:37:12.119-0700 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:config.transactions
2020-05-09T06:37:12.121-0700 I  STORAGE  [repl-writer-worker-9] createCollection: config.transactions with provided UUID: f1fdd767-8664-404a-85c0-c058b1f9a6e5 and options: { uuid: UUID("f1fdd767-8664-404a-85c0-c058b1f9a6e5") }
2020-05-09T06:37:12.200-0700 I  INDEX    [repl-writer-worker-9] index build: starting on config.transactions properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.transactions" } using method: Hybrid
2020-05-09T06:37:12.200-0700 I  INDEX    [repl-writer-worker-9] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:12.203-0700 I  INITSYNC [replication-1] CollectionCloner ns:config.transactions finished cloning with status: OK
2020-05-09T06:37:12.205-0700 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:12.212-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns config.transactions
2020-05-09T06:37:12.222-0700 I  INITSYNC [replication-1] Finished cloning data: OK. Beginning oplog replay.
2020-05-09T06:37:12.223-0700 I  INITSYNC [replication-0] Writing to the oplog and applying operations until { : Timestamp(1589031431, 2) } before initial sync can complete. (started fetching at { : Timestamp(1589031428, 1) } and applying at { : Timestamp(1589031428, 1) })
2020-05-09T06:37:12.224-0700 I  SHARDING [replication-0] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-09T06:37:12.259-0700 I  INITSYNC [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T06:37:12.259-0700 I  INITSYNC [replication-1] Initial sync attempt finishing up.
2020-05-09T06:37:12.259-0700 I  INITSYNC [replication-1] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1589031428840), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 32, initialSyncOplogStart: Timestamp(1589031428, 1), initialSyncOplogEnd: Timestamp(1589031431, 2), databases: { databasesCloned: 2, admin: { collections: 1, clonedCollections: 1, start: new Date(1589031430505), end: new Date(1589031430559), elapsedMillis: 54, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1589031430506), end: new Date(1589031430559), elapsedMillis: 53, receivedBatches: 1 } }, config: { collections: 8, clonedCollections: 8, start: new Date(1589031430559), end: new Date(1589031432223), elapsedMillis: 1664, config.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1589031430560), end: new Date(1589031430655), elapsedMillis: 95, receivedBatches: 1 }, config.chunks: { documentsToCopy: 0, documentsCopied: 0, indexes: 4, fetchedBatches: 0, start: new Date(1589031430655), end: new Date(1589031431041), elapsedMillis: 386, receivedBatches: 0 }, config.shards: { documentsToCopy: 0, documentsCopied: 0, indexes: 2, fetchedBatches: 0, start: new Date(1589031431040), end: new Date(1589031431235), elapsedMillis: 195, receivedBatches: 0 }, config.migrations: { documentsToCopy: 0, documentsCopied: 0, indexes: 2, fetchedBatches: 0, start: new Date(1589031431235), end: new Date(1589031431429), elapsedMillis: 194, receivedBatches: 0 }, config.lockpings: { documentsToCopy: 0, documentsCopied: 0, indexes: 2, fetchedBatches: 0, start: new Date(1589031431429), end: new Date(1589031431614), elapsedMillis: 185, receivedBatches: 0 }, config.tags: { documentsToCopy: 0, documentsCopied: 0, indexes: 3, fetchedBatches: 0, start: new Date(1589031431614), end: new Date(1589031431882), elapsedMillis: 268, receivedBatches: 0 }, config.locks: { documentsToCopy: 0, documentsCopied: 0, indexes: 3, fetchedBatches: 0, start: new Date(1589031431882), end: new Date(1589031432120), elapsedMillis: 238, receivedBatches: 0 }, config.transactions: { documentsToCopy: 0, documentsCopied: 0, indexes: 1, fetchedBatches: 0, start: new Date(1589031432119), end: new Date(1589031432223), elapsedMillis: 104, receivedBatches: 0 } } } }
2020-05-09T06:37:12.259-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:12.260-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (4236e060-56d1-4158-9df6-70480959e512).
2020-05-09T06:37:12.268-0700 I  SHARDING [replication-0] Marking collection config.transactions as collection version: <unsharded>
2020-05-09T06:37:12.268-0700 I  INITSYNC [replication-0] initial sync done; took 3s.
2020-05-09T06:37:12.268-0700 I  REPL     [replication-0] transition to RECOVERING from STARTUP2
2020-05-09T06:37:12.268-0700 I  REPL     [replication-0] Starting replication fetcher thread
2020-05-09T06:37:12.268-0700 I  REPL     [replication-0] Starting replication applier thread
2020-05-09T06:37:12.268-0700 I  REPL     [replication-0] Starting replication reporter thread
2020-05-09T06:37:12.268-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-09T06:37:12.268-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:12.269-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-09T06:37:12.269-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-09T06:37:12.269-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-09T06:37:12.270-0700 I  REPL     [replexec-0] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:12.425-0700 I  NETWORK  [conn13] end connection 192.168.122.1:41202 (3 connections now open)
2020-05-09T06:37:12.425-0700 I  NETWORK  [conn14] end connection 192.168.122.1:41210 (2 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:34512 #24 (3 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:56734 #25 (4 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:48922 #26 (5 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.18:34512 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.17:56734 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.12:48922 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:56968 #27 (6 connections now open)
2020-05-09T06:37:13.086-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.15:56968 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:50530 #28 (7 connections now open)
2020-05-09T06:37:13.086-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.19:50530 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:42620 #29 (8 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.16:42620 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.107-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:51300 #30 (9 connections now open)
2020-05-09T06:37:13.107-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:33114 #31 (10 connections now open)
2020-05-09T06:37:13.107-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.14:51300 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.107-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:44880 #32 (11 connections now open)
2020-05-09T06:37:13.108-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.11:33114 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.108-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.13:44880 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.771-0700 I  STORAGE  [replexec-1] Triggering the first stable checkpoint. Initial Data: Timestamp(1589031431, 2) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1589031431, 2)
2020-05-09T06:37:13.816-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:56904 #33 (12 connections now open)
2020-05-09T06:37:13.817-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:49088 #34 (13 connections now open)
2020-05-09T06:37:13.817-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.17:56904 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.817-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:44952 #35 (14 connections now open)
2020-05-09T06:37:13.817-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.12:49088 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.817-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:57132 #36 (15 connections now open)
2020-05-09T06:37:13.818-0700 I  SHARDING [conn33] Marking collection admin.system.keys as collection version: <unsharded>
2020-05-09T06:37:13.818-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.13:44952 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.818-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:51440 #37 (16 connections now open)
2020-05-09T06:37:13.818-0700 I  NETWORK  [conn36] received client metadata from 192.168.122.15:57132 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.818-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.14:51440 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:14.138-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:42776 #38 (17 connections now open)
2020-05-09T06:37:14.138-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.16:42776 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:14.269-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T06:37:14.271-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T06:37:14.271-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T06:37:14.275-0700 I  SHARDING [repl-writer-worker-9] Marking collection config.lockpings as collection version: <unsharded>
2020-05-09T06:37:14.281-0700 I  STORAGE  [repl-writer-worker-1] createCollection: admin.system.keys with provided UUID: 16eb3e02-0d20-421e-ab05-71522f18c333 and options: { uuid: UUID("16eb3e02-0d20-421e-ab05-71522f18c333") }
2020-05-09T06:37:14.319-0700 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns admin.system.keys
2020-05-09T06:37:14.319-0700 I  STORAGE  [monitoring-keys-for-HMAC] tried reading at last-applied time: Timestamp(1589031433, 9) on ns: admin.system.keys, but future catalog changes are pending at time Timestamp(1589031433, 10). Trying again without reading at last-applied time.
2020-05-09T06:37:14.619-0700 I  SHARDING [conn34] Marking collection config.settings as collection version: <unsharded>
2020-05-09T06:37:14.620-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:50706 #40 (18 connections now open)
2020-05-09T06:37:14.620-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.19:50706 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:14.624-0700 I  SHARDING [conn33] Marking collection config.collections as collection version: <unsharded>
2020-05-09T06:37:14.657-0700 I  STORAGE  [repl-writer-worker-6] createCollection: config.mongos with provided UUID: dfc556fb-2d21-4f15-beaf-e1ef4ad5320d and options: { uuid: UUID("dfc556fb-2d21-4f15-beaf-e1ef4ad5320d") }
2020-05-09T06:37:14.699-0700 I  INDEX    [repl-writer-worker-6] index build: done building index _id_ on ns config.mongos
2020-05-09T06:37:14.701-0700 I  SHARDING [repl-writer-worker-13] Marking collection config.mongos as collection version: <unsharded>
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:34750 #41 (19 connections now open)
2020-05-09T06:37:15.624-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.18:34750 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:15.689-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:51530 #42 (20 connections now open)
2020-05-09T06:37:15.689-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.14:51530 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.727-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:57240 #43 (21 connections now open)
2020-05-09T06:37:16.728-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.15:57240 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.806-0700 I  SHARDING [repl-writer-worker-13] Marking collection config.shards as collection version: <unsharded>
2020-05-09T06:37:16.815-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:42892 #44 (22 connections now open)
2020-05-09T06:37:16.815-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.16:42892 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.816-0700 I  NETWORK  [conn44] end connection 192.168.122.16:42892 (21 connections now open)
2020-05-09T06:37:16.888-0700 I  STORAGE  [repl-writer-worker-15] createCollection: config.changelog with provided UUID: 4e48f34c-cc2b-4d34-8cb7-66507755a530 and options: { uuid: UUID("4e48f34c-cc2b-4d34-8cb7-66507755a530"), capped: true, size: 209715200 }
2020-05-09T06:37:16.936-0700 I  INDEX    [repl-writer-worker-15] index build: done building index _id_ on ns config.changelog
2020-05-09T06:37:16.945-0700 I  SHARDING [repl-writer-worker-0] Marking collection config.changelog as collection version: <unsharded>
2020-05-09T06:37:16.969-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:57062 #45 (22 connections now open)
2020-05-09T06:37:16.969-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.17:57062 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.315-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:42942 #46 (23 connections now open)
2020-05-09T06:37:17.316-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.16:42942 conn46: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:50866 #47 (24 connections now open)
2020-05-09T06:37:17.744-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.19:50866 conn47: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.750-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:57100 #48 (25 connections now open)
2020-05-09T06:37:17.751-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.17:57100 conn48: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.823-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:34896 #49 (26 connections now open)
2020-05-09T06:37:17.824-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.18:34896 conn49: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.824-0700 I  NETWORK  [conn49] end connection 192.168.122.18:34896 (25 connections now open)
2020-05-09T06:37:17.844-0700 I  SHARDING [repl-writer-worker-13] Marking collection config.locks as collection version: <unsharded>
2020-05-09T06:37:17.900-0700 I  STORAGE  [repl-writer-worker-15] createCollection: config.databases with provided UUID: c96b7667-3321-4fd3-9bfe-d1bbd40ed124 and options: { uuid: UUID("c96b7667-3321-4fd3-9bfe-d1bbd40ed124") }
2020-05-09T06:37:17.940-0700 I  INDEX    [repl-writer-worker-15] index build: done building index _id_ on ns config.databases
2020-05-09T06:37:17.942-0700 I  SHARDING [repl-writer-worker-12] Marking collection config.databases as collection version: <unsharded>
2020-05-09T06:37:18.120-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:51702 #50 (26 connections now open)
2020-05-09T06:37:18.121-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.14:51702 conn50: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.122-0700 I  SHARDING [conn50] Marking collection config.chunks as collection version: <unsharded>
2020-05-09T06:37:18.211-0700 I  SHARDING [conn50] Marking collection config.tags as collection version: <unsharded>
2020-05-09T06:37:18.323-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:34976 #51 (27 connections now open)
2020-05-09T06:37:18.324-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.18:34976 conn51: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.447-0700 I  STORAGE  [repl-writer-worker-13] createCollection: config.collections with provided UUID: 1baeabe0-91e8-48d8-84aa-25d3730e1b7b and options: { uuid: UUID("1baeabe0-91e8-48d8-84aa-25d3730e1b7b") }
2020-05-09T06:37:18.493-0700 I  INDEX    [repl-writer-worker-13] index build: done building index _id_ on ns config.collections
2020-05-09T06:37:22.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41868 #52 (28 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41890 #53 (29 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:41868 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:41890 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.644-0700 I  NETWORK  [conn52] end connection 192.168.122.1:41868 (28 connections now open)
2020-05-09T06:37:22.644-0700 I  NETWORK  [conn53] end connection 192.168.122.1:41890 (27 connections now open)
2020-05-09T06:37:23.617-0700 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:23.617-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 2
2020-05-09T06:37:23.617-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 544 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031442, 16), t: 2 } }
2020-05-09T06:37:23.617-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 545 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031442, 16), t: 2 } }
2020-05-09T06:37:23.618-0700 I  ELECTION [replexec-2] VoteRequester(term 2 dry run) received a yes vote from n2:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589031442, 16), $clusterTime: { clusterTime: Timestamp(1589031442, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031442, 16) }
2020-05-09T06:37:23.618-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 3
2020-05-09T06:37:23.618-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:23.618-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T06:37:23.623-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 546 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031442, 16), t: 2 } }
2020-05-09T06:37:23.623-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 547 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031442, 16), t: 2 } }
2020-05-09T06:37:23.626-0700 I  ELECTION [replexec-1] VoteRequester(term 3) received a yes vote from n2:27019; response message: { term: 3, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589031442, 16), $clusterTime: { clusterTime: Timestamp(1589031442, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031442, 16) }
2020-05-09T06:37:23.626-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 3
2020-05-09T06:37:23.626-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T06:37:23.626-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was n1:27019
2020-05-09T06:37:23.626-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T06:37:23.939-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1589031442, 16), t: 2 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T06:37:24.350-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42320 #54 (28 connections now open)
2020-05-09T06:37:24.350-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:42320 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.351-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42326 #55 (29 connections now open)
2020-05-09T06:37:24.351-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:42326 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.353-0700 I  NETWORK  [conn54] end connection 192.168.122.1:42320 (28 connections now open)
2020-05-09T06:37:24.353-0700 I  NETWORK  [conn55] end connection 192.168.122.1:42326 (27 connections now open)
2020-05-09T06:37:24.435-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T06:37:24.626-0700 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-05-09T06:37:24.626-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T06:37:24.626-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T06:37:24.626-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 3
2020-05-09T06:37:24.627-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:24.627-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:24.627-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:24.627-0700 I  REPL     [replexec-2] Member n1:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T06:37:24.630-0700 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-05-09T06:37:24.631-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:24.631-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-05-09T06:37:24.631-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:24.632-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:24.632-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:24.632-0700 I  NETWORK  [PeriodicShardedIndexConsistencyChecker] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:24.633-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:24.633-0700 I  NETWORK  [PeriodicShardedIndexConsistencyChecker] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:24.633-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:24.633-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:24.633-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:24.633-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:24.633-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:24.633-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:24.635-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:24.637-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:24.638-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.642-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.644-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-05-09T06:37:24.939-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:50008 #71 (28 connections now open)
2020-05-09T06:37:24.939-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.12:50008 conn71: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:24.943-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:50010 #72 (29 connections now open)
2020-05-09T06:37:24.943-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.12:50010 conn72: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:24.952-0700 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-05-09T06:37:24.952-0700 I  COMMAND  [conn33] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1589031444714), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031443, 129), signature: { hash: BinData(0, 7FF5D65FF66897ED40C3B694ABA67EEB3DBB5C37), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031442, 16), t: 2 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 235ms
2020-05-09T06:37:24.952-0700 I  COMMAND  [conn35] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1589031444711), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031443, 129), signature: { hash: BinData(0, 7FF5D65FF66897ED40C3B694ABA67EEB3DBB5C37), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031442, 16), t: 2 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 237ms
2020-05-09T06:37:24.952-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1589031444752), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031443, 129), signature: { hash: BinData(0, 7FF5D65FF66897ED40C3B694ABA67EEB3DBB5C37), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031442, 16), t: 2 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 195ms
2020-05-09T06:37:24.952-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:24.953-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031444, 2), signature: { hash: BinData(0, E76227B2633CD96DE6748BBF0188365F67977AB9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031442, 16), t: 2 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 112ms
2020-05-09T06:37:24.953-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:24.952-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1589031444711), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031443, 129), signature: { hash: BinData(0, 7FF5D65FF66897ED40C3B694ABA67EEB3DBB5C37), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031442, 16), t: 2 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 237ms
2020-05-09T06:37:24.953-0700 I  COMMAND  [conn40] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1589031444711), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031443, 129), signature: { hash: BinData(0, 7FF5D65FF66897ED40C3B694ABA67EEB3DBB5C37), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031442, 16), t: 2 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 237ms
2020-05-09T06:37:24.983-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42378 #73 (30 connections now open)
2020-05-09T06:37:24.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42384 #74 (31 connections now open)
2020-05-09T06:37:24.984-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.1:42384 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.985-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.1:42378 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.989-0700 I  NETWORK  [conn73] end connection 192.168.122.1:42378 (30 connections now open)
2020-05-09T06:37:24.989-0700 I  NETWORK  [conn74] end connection 192.168.122.1:42384 (29 connections now open)
2020-05-09T06:37:25.136-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.345-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34236 #76 (30 connections now open)
2020-05-09T06:37:25.345-0700 I  NETWORK  [conn76] received client metadata from 192.168.122.11:34236 conn76: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:25.505-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42446 #77 (31 connections now open)
2020-05-09T06:37:25.506-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42454 #78 (32 connections now open)
2020-05-09T06:37:25.506-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.1:42446 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:25.506-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:42454 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:25.511-0700 I  NETWORK  [conn77] end connection 192.168.122.1:42446 (31 connections now open)
2020-05-09T06:37:25.511-0700 I  NETWORK  [conn78] end connection 192.168.122.1:42454 (30 connections now open)
2020-05-09T06:37:25.565-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51692 #79 (31 connections now open)
2020-05-09T06:37:25.565-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.19:51692 conn79: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:25.636-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:26.064-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:35742 #80 (32 connections now open)
2020-05-09T06:37:26.065-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.18:35742 conn80: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.065-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031445, 97), t: 3 } }
2020-05-09T06:37:26.065-0700 I  ELECTION [conn10] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-05-09T06:37:26.068-0700 I  REPL     [conn10] stepping down from primary, because a new term has begun: 4
2020-05-09T06:37:26.069-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:26.069-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:26.069-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 4, userOpsRunning: 2 }
2020-05-09T06:37:26.069-0700 W  COMMAND  [conn41] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:26.069-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-09T06:37:26.069-0700 W  COMMAND  [conn36] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:26.069-0700 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:26.069-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1589031445637), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031445, 58), signature: { hash: BinData(0, F651DB24D25DE253543A0732BAF31D1482E5AB8B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 430ms
2020-05-09T06:37:26.069-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1589031445640), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031445, 94), signature: { hash: BinData(0, F651DB24D25DE253543A0732BAF31D1482E5AB8B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 427ms
2020-05-09T06:37:26.069-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1589031445640), up: 10, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, F651DB24D25DE253543A0732BAF31D1482E5AB8B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 427ms
2020-05-09T06:37:26.069-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:26.070-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031445, 97), t: 3 } }
2020-05-09T06:37:26.070-0700 I  ELECTION [conn10] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-09T06:37:26.464-0700 I  REPL     [replexec-2] Member n2:27019 is now in state PRIMARY
2020-05-09T06:37:26.556-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42554 #81 (33 connections now open)
2020-05-09T06:37:26.556-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42556 #82 (34 connections now open)
2020-05-09T06:37:26.556-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.1:42554 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:26.556-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.1:42556 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:26.559-0700 I  NETWORK  [conn81] end connection 192.168.122.1:42554 (33 connections now open)
2020-05-09T06:37:26.559-0700 I  NETWORK  [conn82] end connection 192.168.122.1:42556 (32 connections now open)
2020-05-09T06:37:26.560-0700 I  NETWORK  [conn71] end connection 192.168.122.12:50008 (31 connections now open)
2020-05-09T06:37:26.628-0700 I  REPL     [replexec-4] Member n1:27019 is now in state SECONDARY
2020-05-09T06:37:26.659-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34284 #83 (32 connections now open)
2020-05-09T06:37:26.660-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.11:34284 conn83: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:27.070-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T06:37:27.071-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T06:37:27.532-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:27.532-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 4
2020-05-09T06:37:27.532-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 597 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.532-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 598 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.532-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:27.533-0700 I  ELECTION [replexec-1] VoteRequester(term 4 dry run) received a yes vote from n1:27019; response message: { term: 4, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000002') }, lastCommittedOpTime: Timestamp(1589031446, 87), $clusterTime: { clusterTime: Timestamp(1589031446, 141), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031446, 87) }
2020-05-09T06:37:27.533-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 5
2020-05-09T06:37:27.533-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.533-0700 I  ELECTION [conn4] Sending vote response: { term: 5, voteGranted: false, reason: "candidate's term (4) is lower than mine (5)" }
2020-05-09T06:37:27.546-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 599 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.546-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 600 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.558-0700 I  ELECTION [replexec-2] VoteRequester(term 5) received a yes vote from n1:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000002') }, lastCommittedOpTime: Timestamp(1589031446, 87), $clusterTime: { clusterTime: Timestamp(1589031446, 141), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031446, 87) }
2020-05-09T06:37:27.558-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 5
2020-05-09T06:37:27.558-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:27.558-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was n1:27019
2020-05-09T06:37:27.558-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-05-09T06:37:27.558-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:37:27.575-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1589031446, 87), t: 4 }; sync source index: 1; primary index: -1) is no longer valid
2020-05-09T06:37:27.579-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T06:37:27.964-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T06:37:27.964-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031446, 87), t: 4 }. My Last Applied: { ts: Timestamp(1589031446, 87), t: 4 }
2020-05-09T06:37:27.964-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-09T06:37:27.964-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-09T06:37:27.964-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 5
2020-05-09T06:37:27.965-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:27.965-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:27.965-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:27.967-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:27.967-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:27.967-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:27.967-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:27.967-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:27.968-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T06:37:29.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34454 #87 (33 connections now open)
2020-05-09T06:37:29.143-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.11:34454 conn87: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:29.146-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34456 #88 (34 connections now open)
2020-05-09T06:37:29.147-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.11:34456 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:29.153-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:29.153-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:29.195-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 2), t: 5 } }
2020-05-09T06:37:29.195-0700 I  ELECTION [conn4] Sending vote response: { term: 5, voteGranted: true, reason: "" }
2020-05-09T06:37:29.198-0700 I  REPL     [conn4] stepping down from primary, because a new term has begun: 6
2020-05-09T06:37:29.199-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:29.199-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:29.199-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T06:37:29.199-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-09T06:37:29.200-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:29.200-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 2), t: 5 } }
2020-05-09T06:37:29.200-0700 I  ELECTION [conn4] Sending vote response: { term: 6, voteGranted: true, reason: "" }
2020-05-09T06:37:29.205-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34458 #89 (35 connections now open)
2020-05-09T06:37:29.206-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.11:34458 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:29.208-0700 I  NETWORK  [conn4] end connection 192.168.122.11:32904 (34 connections now open)
2020-05-09T06:37:29.487-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:50302 #90 (35 connections now open)
2020-05-09T06:37:29.487-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.12:50302 conn90: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:29.560-0700 I  REPL     [replexec-0] Member n1:27019 is now in state PRIMARY
2020-05-09T06:37:29.654-0700 I  NETWORK  [conn88] end connection 192.168.122.11:34456 (34 connections now open)
2020-05-09T06:37:29.811-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:43984 #91 (35 connections now open)
2020-05-09T06:37:29.811-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.16:43984 conn91: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:29.964-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:30.201-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T06:37:30.203-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T06:37:31.410-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:58422 #92 (36 connections now open)
2020-05-09T06:37:31.411-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.15:58422 conn92: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.448-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:35992 #93 (37 connections now open)
2020-05-09T06:37:31.449-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.18:35992 conn93: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.921-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42862 #94 (38 connections now open)
2020-05-09T06:37:31.921-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:42864 #95 (39 connections now open)
2020-05-09T06:37:31.921-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.1:42862 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:31.922-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.1:42864 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:31.925-0700 I  NETWORK  [conn94] end connection 192.168.122.1:42862 (38 connections now open)
2020-05-09T06:37:31.925-0700 I  NETWORK  [conn95] end connection 192.168.122.1:42864 (37 connections now open)
2020-05-09T06:37:32.638-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:32.638-0700 I  ELECTION [conn10] Sending vote response: { term: 6, voteGranted: true, reason: "" }
2020-05-09T06:37:32.650-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:32.650-0700 I  ELECTION [conn10] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-05-09T06:37:33.560-0700 I  REPL     [replexec-0] Member n1:27019 is now in state RS_DOWN - Request 631 timed out, deadline was 2020-05-09T06:37:33.560-0700, op was RemoteCommand 631 -- target:[n1:27019] db:admin expDate:2020-05-09T06:37:33.560-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 6 }
2020-05-09T06:37:33.560-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:33.696-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:33.696-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 7
2020-05-09T06:37:33.696-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 632 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:33.696-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 633 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:33.697-0700 I  ELECTION [replexec-5] VoteRequester(term 7 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031449, 2), t: 6 }, my last applied OpTime: { ts: Timestamp(1589031453, 1), t: 7 }"; response message: { term: 7, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031449, 2), t: 6 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1589031449, 2), $clusterTime: { clusterTime: Timestamp(1589031453, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031453, 1) }
2020-05-09T06:37:33.697-0700 I  ELECTION [replexec-3] VoteRequester(term 7 dry run) received a yes vote from n1:27019; response message: { term: 7, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000006') }, lastCommittedOpTime: Timestamp(1589031449, 2), $clusterTime: { clusterTime: Timestamp(1589031452, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031449, 2) }
2020-05-09T06:37:33.697-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 8
2020-05-09T06:37:33.703-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 634 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:33.704-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 635 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:33.705-0700 I  ELECTION [replexec-4] VoteRequester(term 8) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031449, 2), t: 6 }, my last applied OpTime: { ts: Timestamp(1589031453, 1), t: 7 }"; response message: { term: 8, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031449, 2), t: 6 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1589031449, 2), $clusterTime: { clusterTime: Timestamp(1589031453, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031453, 1) }
2020-05-09T06:37:33.708-0700 I  ELECTION [replexec-5] VoteRequester(term 8) received a yes vote from n1:27019; response message: { term: 8, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000006') }, lastCommittedOpTime: Timestamp(1589031449, 2), $clusterTime: { clusterTime: Timestamp(1589031453, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031449, 2) }
2020-05-09T06:37:33.708-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 8
2020-05-09T06:37:33.708-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-09T06:37:33.708-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n1:27019
2020-05-09T06:37:33.709-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-09T06:37:33.709-0700 I  REPL     [replexec-1] Member n1:27019 is now in state SECONDARY
2020-05-09T06:37:33.710-0700 I  REPL     [replexec-5] Heartbeats updated catchup target optime to { ts: Timestamp(1589031453, 1), t: 7 }
2020-05-09T06:37:33.710-0700 I  REPL     [replexec-5] Latest known optime per replica set member:
2020-05-09T06:37:33.710-0700 I  REPL     [replexec-5] Member ID: MemberId(0), latest known optime: { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:33.710-0700 I  REPL     [replexec-5] Member ID: MemberId(1), latest known optime: { ts: Timestamp(1589031453, 1), t: 7 }
2020-05-09T06:37:33.710-0700 I  REPL     [replexec-5] Member ID: MemberId(2), latest known optime: unknown
2020-05-09T06:37:33.888-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1589031449, 2), t: 6 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T06:37:33.888-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T06:37:33.889-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-09T06:37:33.891-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T06:37:33.894-0700 I  REPL     [rsSync-0] Caught up to the latest known optime successfully after becoming primary. Target optime: { ts: Timestamp(1589031453, 1), t: 7 }. My Last Applied: { ts: Timestamp(1589031453, 1), t: 7 }
2020-05-09T06:37:33.894-0700 I  REPL     [rsSync-0] Exited primary catch-up mode.
2020-05-09T06:37:33.894-0700 I  REPL     [rsSync-0] Stopping replication producer
2020-05-09T06:37:33.894-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 8
2020-05-09T06:37:33.894-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:33.894-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:33.894-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:33.895-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T06:37:33.895-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:33.895-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:33.895-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:33.896-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:33.896-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:34.330-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:50568 #97 (38 connections now open)
2020-05-09T06:37:34.330-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.12:50568 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:34.387-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T06:37:34.722-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34728 #98 (39 connections now open)
2020-05-09T06:37:34.723-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.11:34728 conn98: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:34.730-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:34.730-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031453, 3), signature: { hash: BinData(0, AEB951AEA99F36B35DA7AFDA11EA3E0937BB292B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 744ms
2020-05-09T06:37:34.730-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:34.730-0700 I  COMMAND  [conn40] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031454, 8), signature: { hash: BinData(0, 6DBDEBBEC7466C7107462CB7FB75DDEEDC39C2F9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 398ms
2020-05-09T06:37:34.730-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, AEB951AEA99F36B35DA7AFDA11EA3E0937BB292B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 563ms
2020-05-09T06:37:34.730-0700 I  COMMAND  [conn97] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031453, 3), signature: { hash: BinData(0, AEB951AEA99F36B35DA7AFDA11EA3E0937BB292B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 399ms
2020-05-09T06:37:34.730-0700 I  COMMAND  [conn35] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031454, 3), signature: { hash: BinData(0, 6DBDEBBEC7466C7107462CB7FB75DDEEDC39C2F9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 399ms
2020-05-09T06:37:34.731-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, AEB951AEA99F36B35DA7AFDA11EA3E0937BB292B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 627ms
2020-05-09T06:37:34.731-0700 I  COMMAND  [conn33] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, AEB951AEA99F36B35DA7AFDA11EA3E0937BB292B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 398ms
2020-05-09T06:37:34.731-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031454, 5), signature: { hash: BinData(0, 6DBDEBBEC7466C7107462CB7FB75DDEEDC39C2F9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 400ms
2020-05-09T06:37:34.731-0700 I  COMMAND  [conn83] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, AEB951AEA99F36B35DA7AFDA11EA3E0937BB292B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 396ms
2020-05-09T06:37:35.123-0700 I  ELECTION [conn89] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:35.123-0700 I  ELECTION [conn89] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-05-09T06:37:35.133-0700 I  REPL     [conn89] stepping down from primary, because a new term has begun: 9
2020-05-09T06:37:35.134-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:35.134-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:35.134-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-05-09T06:37:35.134-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T06:37:35.135-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:35.135-0700 I  ELECTION [conn89] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:35.135-0700 I  ELECTION [conn89] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-09T06:37:35.135-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:35.140-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34734 #99 (40 connections now open)
2020-05-09T06:37:35.140-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.11:34734 conn99: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.143-0700 I  NETWORK  [conn89] end connection 192.168.122.11:34458 (39 connections now open)
2020-05-09T06:37:35.231-0700 I  NETWORK  [conn98] end connection 192.168.122.11:34728 (38 connections now open)
2020-05-09T06:37:35.637-0700 I  REPL     [replexec-1] Member n1:27019 is now in state PRIMARY
2020-05-09T06:37:35.855-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43018 #100 (39 connections now open)
2020-05-09T06:37:35.856-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43024 #101 (40 connections now open)
2020-05-09T06:37:35.856-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.1:43018 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:35.856-0700 I  NETWORK  [conn101] received client metadata from 192.168.122.1:43024 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:35.859-0700 I  NETWORK  [conn100] end connection 192.168.122.1:43018 (39 connections now open)
2020-05-09T06:37:35.859-0700 I  NETWORK  [conn101] end connection 192.168.122.1:43024 (38 connections now open)
2020-05-09T06:37:36.137-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T06:37:36.711-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:36.712-0700 I  ELECTION [conn10] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-09T06:37:36.716-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 10, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:36.716-0700 I  ELECTION [conn10] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-09T06:37:37.137-0700 I  REPL     [replexec-5] Member n1:27019 is now in state RS_DOWN - Request 653 timed out, deadline was 2020-05-09T06:37:37.137-0700, op was RemoteCommand 653 -- target:[n1:27019] db:admin expDate:2020-05-09T06:37:37.137-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 9 }
2020-05-09T06:37:37.137-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:37.137-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T06:37:37.717-0700 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:37.717-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 10
2020-05-09T06:37:37.717-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 656 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:37.717-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 657 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:37.718-0700 I  ELECTION [replexec-3] VoteRequester(term 10 dry run) received a no vote from n2:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031453, 3), t: 8 }, my last applied OpTime: { ts: Timestamp(1589031457, 18), t: 10 }"; response message: { term: 10, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031453, 3), t: 8 }, my last applied OpTime: { ts: Timestamp...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1589031453, 3), $clusterTime: { clusterTime: Timestamp(1589031457, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031457, 18) }
2020-05-09T06:37:38.717-0700 I  ELECTION [replexec-4] VoteRequester(term 10 dry run) failed to receive response from n1:27019: NetworkInterfaceExceededTimeLimit: Couldn't get a connection within the time limit
2020-05-09T06:37:38.717-0700 I  ELECTION [replexec-4] not running for primary, we received insufficient votes
2020-05-09T06:37:38.717-0700 I  ELECTION [replexec-4] Lost dry run election due to internal error
2020-05-09T06:37:38.776-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031457, 18), t: 10 } }
2020-05-09T06:37:38.776-0700 I  ELECTION [conn10] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-09T06:37:38.782-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031457, 18), t: 10 } }
2020-05-09T06:37:38.782-0700 I  ELECTION [conn10] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-09T06:37:39.167-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:34914 #102 (39 connections now open)
2020-05-09T06:37:39.168-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.11:34914 conn102: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:39.553-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T06:37:39.708-0700 I  REPL     [replication-0] Restarting oplog query due to error: InterruptedDueToReplStateChange: error in fetcher batch callback :: caused by :: operation was interrupted. Last fetched optime: { ts: Timestamp(1589031456, 185), t: 9 }. Restarts remaining: 1
2020-05-09T06:37:39.709-0700 I  REPL     [replication-0] Scheduled new oplog query Fetcher source: n1:27019 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031456, 185) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 11, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 666 -- target:n1:27019 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031456, 185) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 11, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-09T06:37:39.822-0700 I  REPL     [replication-1] Error returned from oplog query (no more query restarts left): NotMasterOrSecondary: error in fetcher batch callback :: caused by :: Oplog collection reads are not allowed while in the rollback or startup state.
2020-05-09T06:37:39.823-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: NotMasterOrSecondary: error in fetcher batch callback :: caused by :: Oplog collection reads are not allowed while in the rollback or startup state.
2020-05-09T06:37:39.823-0700 I  REPL     [rsBackgroundSync] Clearing sync source n1:27019 to choose a new one.
2020-05-09T06:37:39.823-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T06:37:39.826-0700 I  REPL     [rsBackgroundSync] Changed sync source from n1:27019 to n2:27019
2020-05-09T06:37:39.826-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source changed from n1:27019 to n2:27019
2020-05-09T06:37:39.826-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-09T06:37:39.828-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589031456, 185), t: 9 }. source's GTE: { ts: Timestamp(1589031457, 1), t: 10 }
2020-05-09T06:37:39.828-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:39.828-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T06:37:39.828-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-09T06:37:39.828-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T06:37:39.828-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 40 }
2020-05-09T06:37:39.828-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 102
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 99
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 93
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 92
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 91
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-09T06:37:39.828-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-09T06:37:39.829-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 10
2020-05-09T06:37:39.829-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T06:37:39.829-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T06:37:39.829-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T06:37:39.835-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:39.837-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-09T06:37:39.838-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T06:37:39.838-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid dfc556fb-2d21-4f15-beaf-e1ef4ad5320d to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-09T13-37-39.0.bson
2020-05-09T06:37:39.838-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T06:37:39.839-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T06:37:39.839-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T06:37:39.839-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T06:37:39.913-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589031453, 3) Initial Data Timestamp: Timestamp(1589031431, 2)
2020-05-09T06:37:39.914-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T06:37:39.927-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T06:37:39.927-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 193 records totaling to 42505 bytes
2020-05-09T06:37:39.927-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:39.927-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:39.931-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T06:37:39.931-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T06:37:39.948-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T06:37:39.948-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T06:37:39.948-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589031453, 3)
2020-05-09T06:37:39.948-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 8 update operations and 0 delete operations.
2020-05-09T06:37:39.948-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589031455, 2), t: 9 }
2020-05-09T06:37:39.948-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589031455, 2) }
2020-05-09T06:37:39.948-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T06:37:39.951-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589031453, 3) (top of oplog: { ts: Timestamp(1589031453, 3), t: 8 }, appliedThrough: { ts: Timestamp(1589031453, 3), t: 8 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T06:37:39.951-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589031453, 3)
2020-05-09T06:37:39.951-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-09T06:37:39.951-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-09T06:37:39.951-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T06:37:39.951-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T06:37:39.951-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T06:37:39.828-0700
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T06:37:39.952-0700
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.mongos
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589031456, 185), t: 9 }
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T06:37:36.578-0700
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T06:37:35.144-0700
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 1 second(s)
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589031455, 2)
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589031453, 3)
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 		update: 8
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 9
2020-05-09T06:37:39.952-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T06:37:39.952-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T06:37:39.952-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-09T06:37:39.952-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T06:37:39.952-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T06:37:39.952-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T06:37:39.952-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T06:37:39.954-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T06:37:40.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43170 #105 (40 connections now open)
2020-05-09T06:37:40.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43178 #106 (41 connections now open)
2020-05-09T06:37:40.078-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.1:43170 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:40.078-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.1:43178 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:40.082-0700 I  NETWORK  [conn105] end connection 192.168.122.1:43170 (40 connections now open)
2020-05-09T06:37:40.082-0700 I  NETWORK  [conn106] end connection 192.168.122.1:43178 (39 connections now open)
2020-05-09T06:37:40.480-0700 I  NETWORK  [conn99] end connection 192.168.122.11:34734 (38 connections now open)
2020-05-09T06:37:41.138-0700 I  REPL     [replexec-0] Member n2:27019 is now in state RS_DOWN - Request 685 timed out, deadline was 2020-05-09T06:37:41.138-0700, op was RemoteCommand 685 -- target:[n2:27019] db:admin expDate:2020-05-09T06:37:41.138-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n3:27019", fromId: 2, term: 11 }
2020-05-09T06:37:41.138-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:41.141-0700 I  ELECTION [conn102] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:41.141-0700 I  ELECTION [conn102] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-09T06:37:41.146-0700 I  ELECTION [conn102] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:41.146-0700 I  ELECTION [conn102] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-05-09T06:37:41.151-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35002 #108 (39 connections now open)
2020-05-09T06:37:41.151-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.11:35002 conn108: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:41.151-0700 I  NETWORK  [conn102] end connection 192.168.122.11:34914 (38 connections now open)
2020-05-09T06:37:41.307-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43222 #109 (39 connections now open)
2020-05-09T06:37:41.307-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43226 #110 (40 connections now open)
2020-05-09T06:37:41.308-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.1:43222 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.308-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.1:43226 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.311-0700 I  NETWORK  [conn109] end connection 192.168.122.1:43222 (39 connections now open)
2020-05-09T06:37:41.311-0700 I  NETWORK  [conn110] end connection 192.168.122.1:43226 (38 connections now open)
2020-05-09T06:37:41.876-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1589031460, 1), t: 11 }, latest oplog optime of sync source: { ts: Timestamp(1589031460, 1), t: 11 } (sync source does not know the primary)
2020-05-09T06:37:41.876-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1589031460, 1), t: 11 }, its sync source index:-1
2020-05-09T06:37:41.876-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1589031460, 1), t: 11 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-09T06:37:41.876-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-09T06:37:41.876-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:41.877-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:41.877-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-09T06:37:41.964-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43250 #111 (39 connections now open)
2020-05-09T06:37:41.965-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43252 #112 (40 connections now open)
2020-05-09T06:37:41.965-0700 I  NETWORK  [conn111] received client metadata from 192.168.122.1:43250 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.965-0700 I  NETWORK  [conn112] received client metadata from 192.168.122.1:43252 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.969-0700 I  NETWORK  [conn111] end connection 192.168.122.1:43250 (39 connections now open)
2020-05-09T06:37:41.969-0700 I  NETWORK  [conn112] end connection 192.168.122.1:43252 (38 connections now open)
2020-05-09T06:37:42.376-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-09T06:37:42.877-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T06:37:42.899-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:42.899-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 12
2020-05-09T06:37:42.899-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 696 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:42.899-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T06:37:42.899-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 697 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:42.900-0700 I  ELECTION [replexec-0] VoteRequester(term 12 dry run) received a yes vote from n2:27019; response message: { term: 12, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031461, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:42.900-0700 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 13
2020-05-09T06:37:42.903-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 698 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:42.903-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 699 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:42.905-0700 I  ELECTION [replexec-1] VoteRequester(term 13) received a yes vote from n2:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031461, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:42.905-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 13
2020-05-09T06:37:42.905-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T06:37:42.905-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-09T06:37:42.905-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T06:37:42.905-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-05-09T06:37:43.377-0700 I  REPL     [replexec-5] Member n1:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T06:37:43.377-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031460, 1), t: 11 }. My Last Applied: { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:43.377-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-09T06:37:43.377-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-09T06:37:43.377-0700 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: n1:27019
2020-05-09T06:37:43.377-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:43.377-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 13
2020-05-09T06:37:43.378-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:43.378-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:43.378-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:43.380-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:43.380-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:43.381-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:43.382-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:43.382-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:43.382-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:43.382-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.383-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:43.384-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53272 #113 (39 connections now open)
2020-05-09T06:37:43.458-0700 I  NETWORK  [conn113] received client metadata from 192.168.122.14:53272 conn113: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:43.539-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:58972 #114 (40 connections now open)
2020-05-09T06:37:43.540-0700 I  NETWORK  [conn114] received client metadata from 192.168.122.15:58972 conn114: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:43.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:44612 #115 (41 connections now open)
2020-05-09T06:37:43.541-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.16:44612 conn115: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:43.541-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:52534 #116 (42 connections now open)
2020-05-09T06:37:43.542-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:58756 #117 (43 connections now open)
2020-05-09T06:37:43.542-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.19:52534 conn116: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:43.542-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.17:58756 conn117: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:43.616-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:58758 #118 (44 connections now open)
2020-05-09T06:37:43.617-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.17:58758 conn118: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:43.884-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:43.906-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:43.906-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:43.906-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-09T06:37:43.906-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:43.906-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:43.907-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 12, userOpsRunning: 0 }
2020-05-09T06:37:43.907-0700 W  COMMAND  [conn40] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.907-0700 I  COMMAND  [conn40] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 4), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 366ms
2020-05-09T06:37:43.907-0700 W  COMMAND  [conn38] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.907-0700 I  COMMAND  [conn38] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 4), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 367ms
2020-05-09T06:37:43.907-0700 W  COMMAND  [conn115] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.908-0700 I  COMMAND  [conn115] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 4), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 365ms
2020-05-09T06:37:43.908-0700 W  COMMAND  [conn114] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.908-0700 I  COMMAND  [conn114] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 4), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 367ms
2020-05-09T06:37:43.908-0700 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.908-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 87), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 451ms
2020-05-09T06:37:43.908-0700 W  COMMAND  [conn116] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.908-0700 I  COMMAND  [conn116] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 4), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 365ms
2020-05-09T06:37:43.909-0700 W  COMMAND  [conn41] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.909-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 3), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 370ms
2020-05-09T06:37:43.909-0700 W  COMMAND  [conn80] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.909-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T06:37:43.909-0700 I  COMMAND  [conn80] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 3), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 370ms
2020-05-09T06:37:43.909-0700 W  COMMAND  [conn33] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.909-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:43.909-0700 I  COMMAND  [conn33] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 103), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 368ms
2020-05-09T06:37:43.909-0700 W  COMMAND  [conn113] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.910-0700 I  COMMAND  [conn113] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 87), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 450ms
2020-05-09T06:37:43.910-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-09T06:37:43.910-0700 W  COMMAND  [conn36] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.910-0700 W  COMMAND  [conn117] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:43.910-0700 I  COMMAND  [conn36] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031463, 4), signature: { hash: BinData(0, 1287BA6DF539D5ED18A56AAF17BED06C9DFDF5DD), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 371ms
2020-05-09T06:37:43.910-0700 I  COMMAND  [conn117] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 103), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 367ms
2020-05-09T06:37:43.937-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:43.937-0700 I  ELECTION [conn10] Sending vote response: { term: 13, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:44.907-0700 I  REPL     [replexec-0] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:44.942-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:44.942-0700 I  ELECTION [conn10] Sending vote response: { term: 13, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:45.033-0700 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:45.033-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 13
2020-05-09T06:37:45.033-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 718 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:45.033-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 719 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:45.033-0700 I  ELECTION [replexec-4] VoteRequester(term 13 dry run) received a yes vote from n2:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:45.034-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 14
2020-05-09T06:37:45.036-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 720 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:45.036-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 721 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:45.039-0700 I  ELECTION [replexec-5] VoteRequester(term 14) received a yes vote from n2:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:45.039-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 14
2020-05-09T06:37:45.039-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-09T06:37:45.040-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was :27017
2020-05-09T06:37:45.040-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-09T06:37:46.040-0700 I  REPL     [replexec-1] Catchup timed out after becoming primary.
2020-05-09T06:37:46.040-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-09T06:37:46.040-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-09T06:37:46.040-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:46.040-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:46.040-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T06:37:46.040-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 14
2020-05-09T06:37:46.040-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:46.040-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:46.040-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:46.040-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:46.041-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-09T06:37:46.041-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:46.041-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:46.158-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:46.158-0700 I  ELECTION [conn10] Sending vote response: { term: 14, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:46.496-0700 I  NETWORK  [conn108] end connection 192.168.122.11:35002 (43 connections now open)
2020-05-09T06:37:46.874-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43374 #119 (44 connections now open)
2020-05-09T06:37:46.875-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43378 #120 (45 connections now open)
2020-05-09T06:37:46.875-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.1:43374 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:46.875-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:43378 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:46.877-0700 I  NETWORK  [conn119] end connection 192.168.122.1:43374 (44 connections now open)
2020-05-09T06:37:46.877-0700 I  NETWORK  [conn120] end connection 192.168.122.1:43378 (43 connections now open)
2020-05-09T06:37:47.040-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:47.167-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:47.167-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 14
2020-05-09T06:37:47.167-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 725 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:47.167-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 726 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:47.167-0700 I  ELECTION [replexec-2] VoteRequester(term 14 dry run) received a yes vote from n2:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:47.168-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 15
2020-05-09T06:37:47.170-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 727 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:47.170-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 728 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 15, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 1), t: 13 } }
2020-05-09T06:37:47.173-0700 I  ELECTION [replexec-1] VoteRequester(term 15) received a yes vote from n2:27019; response message: { term: 15, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:47.173-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 15
2020-05-09T06:37:47.173-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-09T06:37:47.174-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-05-09T06:37:47.174-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-09T06:37:47.199-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35106 #121 (44 connections now open)
2020-05-09T06:37:47.199-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.11:35106 conn121: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:47.954-0700 I  NETWORK  [conn31] end connection 192.168.122.11:33114 (43 connections now open)
2020-05-09T06:37:47.954-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35264 #122 (44 connections now open)
2020-05-09T06:37:47.955-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.11:35264 conn122: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:47.960-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35266 #123 (45 connections now open)
2020-05-09T06:37:47.961-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.11:35266 conn123: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.031-0700 I  NETWORK  [conn123] end connection 192.168.122.11:35266 (44 connections now open)
2020-05-09T06:37:48.033-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35268 #124 (45 connections now open)
2020-05-09T06:37:48.034-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.11:35268 conn124: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.174-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T06:37:48.174-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:37:48.174-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:37:48.174-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 15
2020-05-09T06:37:48.174-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:48.174-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:48.174-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T06:37:48.177-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:48.177-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:48.177-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:48.178-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:48.178-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:48.179-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.183-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:48.183-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:48.184-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:48.184-0700 I  ELECTION [conn10] Sending vote response: { term: 15, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:48.456-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35274 #125 (46 connections now open)
2020-05-09T06:37:48.456-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35276 #126 (47 connections now open)
2020-05-09T06:37:48.456-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.11:35274 conn125: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.456-0700 I  NETWORK  [conn126] received client metadata from 192.168.122.11:35276 conn126: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53466 #127 (48 connections now open)
2020-05-09T06:37:48.457-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35280 #128 (49 connections now open)
2020-05-09T06:37:48.458-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.14:53466 conn127: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.458-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35282 #129 (50 connections now open)
2020-05-09T06:37:48.458-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.11:35280 conn128: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.458-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53472 #130 (51 connections now open)
2020-05-09T06:37:48.458-0700 I  NETWORK  [conn129] received client metadata from 192.168.122.11:35282 conn129: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.459-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.14:53472 conn130: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.459-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53474 #131 (52 connections now open)
2020-05-09T06:37:48.459-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35288 #132 (53 connections now open)
2020-05-09T06:37:48.460-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.14:53474 conn131: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.460-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.11:35288 conn132: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.460-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53478 #133 (54 connections now open)
2020-05-09T06:37:48.460-0700 I  NETWORK  [conn133] received client metadata from 192.168.122.14:53478 conn133: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.467-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:46996 #134 (55 connections now open)
2020-05-09T06:37:48.467-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:46998 #135 (56 connections now open)
2020-05-09T06:37:48.468-0700 I  NETWORK  [conn134] received client metadata from 192.168.122.13:46996 conn134: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.468-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.13:46998 conn135: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.469-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:47000 #136 (57 connections now open)
2020-05-09T06:37:48.469-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:47002 #137 (58 connections now open)
2020-05-09T06:37:48.469-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.13:47000 conn136: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.470-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.13:47002 conn137: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.531-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:51142 #138 (59 connections now open)
2020-05-09T06:37:48.531-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:51144 #139 (60 connections now open)
2020-05-09T06:37:48.531-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.12:51142 conn138: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.532-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.12:51144 conn139: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.539-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:59186 #140 (61 connections now open)
2020-05-09T06:37:48.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:36748 #141 (62 connections now open)
2020-05-09T06:37:48.540-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.15:59186 conn140: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:36750 #142 (63 connections now open)
2020-05-09T06:37:48.540-0700 I  NETWORK  [conn141] received client metadata from 192.168.122.18:36748 conn141: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:59192 #143 (64 connections now open)
2020-05-09T06:37:48.540-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.18:36750 conn142: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.541-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:44832 #144 (65 connections now open)
2020-05-09T06:37:48.541-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.15:59192 conn143: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.541-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.16:44832 conn144: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.541-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:52754 #145 (66 connections now open)
2020-05-09T06:37:48.542-0700 I  NETWORK  [conn145] received client metadata from 192.168.122.19:52754 conn145: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:48.679-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:49.179-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.179-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:49.205-0700 I  ELECTION [conn121] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031468, 18), t: 15 } }
2020-05-09T06:37:49.205-0700 I  ELECTION [conn121] Sending vote response: { term: 15, voteGranted: true, reason: "" }
2020-05-09T06:37:49.208-0700 I  REPL     [conn121] stepping down from primary, because a new term has begun: 16
2020-05-09T06:37:49.208-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:49.208-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:49.208-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T06:37:49.208-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-09T06:37:49.209-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:49.209-0700 I  ELECTION [conn121] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031468, 18), t: 15 } }
2020-05-09T06:37:49.209-0700 I  ELECTION [conn121] Sending vote response: { term: 16, voteGranted: true, reason: "" }
2020-05-09T06:37:49.213-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:35336 #147 (67 connections now open)
2020-05-09T06:37:49.214-0700 I  NETWORK  [conn147] received client metadata from 192.168.122.11:35336 conn147: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:49.216-0700 I  NETWORK  [conn121] end connection 192.168.122.11:35106 (66 connections now open)
2020-05-09T06:37:49.563-0700 I  NETWORK  [conn124] end connection 192.168.122.11:35268 (65 connections now open)
2020-05-09T06:37:50.174-0700 I  REPL     [replexec-2] Member n1:27019 is now in state PRIMARY
2020-05-09T06:37:50.209-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T06:37:50.210-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T06:37:50.211-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T06:37:50.222-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:50.222-0700 I  ELECTION [conn10] Sending vote response: { term: 16, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:51.578-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:51.578-0700 I  ELECTION [conn10] Sending vote response: { term: 16, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:51.924-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43618 #151 (66 connections now open)
2020-05-09T06:37:51.924-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:43624 #152 (67 connections now open)
2020-05-09T06:37:51.924-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.1:43618 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:51.924-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:43624 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:51.927-0700 I  NETWORK  [conn151] end connection 192.168.122.1:43618 (66 connections now open)
2020-05-09T06:37:51.927-0700 I  NETWORK  [conn152] end connection 192.168.122.1:43624 (65 connections now open)
