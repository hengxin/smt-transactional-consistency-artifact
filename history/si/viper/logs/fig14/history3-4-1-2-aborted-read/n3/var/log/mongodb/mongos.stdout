2020-05-09 06:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T06:37:13.102-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:13.104-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.104-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:13.104-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:13.104-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T06:37:13.104-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.104-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T06:37:13.104-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T06:37:13.106-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.106-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:13.106-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n3:27017:1589031433:-6125704359618895521 (sleeping for 30000ms)
2020-05-09T06:37:13.106-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T06:37:13.106-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:13.108-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.108-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.615-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T06:37:13.617-0700 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-09T06:37:14.255-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T06:37:14.620-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T06:37:14.621-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T06:37:14.624-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("a51a077f-a0a1-4213-980b-cde57e484340"), lastMod: 0 } took 0 ms
2020-05-09T06:37:14.624-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T06:37:14.624-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:14.624-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T06:37:14.625-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:14.625-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.156-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51842 #9 (1 connection now open)
2020-05-09T06:37:15.157-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.1:51842 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.158-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51858 #10 (2 connections now open)
2020-05-09T06:37:15.159-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:51858 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.833-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52036 #11 (3 connections now open)
2020-05-09T06:37:17.833-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52038 #12 (4 connections now open)
2020-05-09T06:37:17.834-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:52036 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.834-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:52038 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:19.392-0700 I  COMMAND  [conn11] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("afd8c811-66cf-4b46-b3f8-dc64d6880149") } } numYields:0 reslen:163 protocol:op_msg 1553ms
2020-05-09T06:37:19.396-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T06:37:19.399-0700 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:19.399-0700 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:19.399-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:19.399-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:19.399-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:19.399-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:19.399-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:19.400-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:19.403-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:19.403-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:19.404-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:19.404-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:19.485-0700 I  NETWORK  [conn11] end connection 192.168.122.1:52036 (3 connections now open)
2020-05-09T06:37:19.485-0700 I  NETWORK  [conn12] end connection 192.168.122.1:52038 (2 connections now open)
2020-05-09T06:37:22.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52212 #19 (3 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52238 #20 (4 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:52212 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:52238 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52286 #21 (5 connections now open)
2020-05-09T06:37:22.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52290 #22 (6 connections now open)
2020-05-09T06:37:22.640-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:52286 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.640-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52294 #23 (7 connections now open)
2020-05-09T06:37:22.640-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:52290 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.640-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52298 #24 (8 connections now open)
2020-05-09T06:37:22.640-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:52294 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.640-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:52298 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.668-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 2 ms
2020-05-09T06:37:22.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T06:37:22.708-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T06:37:23.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T06:37:23.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:23.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:23.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:24.129-0700 I  NETWORK  [conn19] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:24.130-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.131-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.630-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.713-0700 I  NETWORK  [Sharding-Fixed-3] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:24.714-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:24.714-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:24.953-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T06:37:25.130-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.130-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.130-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T06:37:25.131-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 114), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 24, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1974ms
2020-05-09T06:37:25.153-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 101) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2015678, timeActiveMicros:2019020, timeInactiveMicros:368, 2019ms
2020-05-09T06:37:25.153-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031443, 80) } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 82) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2037255, timeActiveMicros:2041538, timeInactiveMicros:565, 2042ms
2020-05-09T06:37:25.153-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 21, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2015ms
2020-05-09T06:37:25.154-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 88), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2037ms
2020-05-09T06:37:25.563-0700 I  NETWORK  [conn21] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.563-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.602-0700 I  NETWORK  [conn23] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:25.603-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.603-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.604-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 25, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:425303, timeInactiveMicros:0, 425ms
2020-05-09T06:37:25.604-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:423337, timeInactiveMicros:0, 423ms
2020-05-09T06:37:25.604-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 12) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:416792, timeInactiveMicros:0, 416ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 25, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 50b1baf5-fb9a-45a2-b398-accae9f2cb94:25 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 425ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 25 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 15, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 9fc3081a-6409-4831-aab2-837ae47b5f57:15 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:627 protocol:op_msg 423ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 23, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 416ms
2020-05-09T06:37:25.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:25.865-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 81) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:246337, timeActiveMicros:247450, timeInactiveMicros:428, 247ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 17, autocommit: false } numYields:0 reslen:214 protocol:op_msg 246ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 24, autocommit: false } numYields:0 reslen:321 protocol:op_msg 232ms
2020-05-09T06:37:25.867-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 26, autocommit: false } numYields:0 reslen:321 protocol:op_msg 232ms
2020-05-09T06:37:26.373-0700 I  SHARDING [conn23] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T06:37:26.373-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 27, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 159) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:435402, timeActiveMicros:443015, timeInactiveMicros:543, 443ms
2020-05-09T06:37:26.373-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 161), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 27, autocommit: false } numYields:0 reslen:214 protocol:op_msg 435ms
2020-05-09T06:37:26.373-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 25, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 178) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:399043, timeActiveMicros:401390, timeInactiveMicros:420, 401ms
2020-05-09T06:37:26.373-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 178), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 25, autocommit: false } numYields:0 reslen:214 protocol:op_msg 399ms
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 161), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 31, autocommit: false } numYields:0 reslen:321 protocol:op_msg 435ms
2020-05-09T06:37:26.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:26.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:26.884-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 30, autocommit: false } numYields:0 reslen:321 protocol:op_msg 447ms
2020-05-09T06:37:26.892-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 88), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 30, autocommit: false } numYields:0 reslen:321 protocol:op_msg 420ms
2020-05-09T06:37:26.892-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 104) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:392352, timeActiveMicros:403355, timeInactiveMicros:425, 403ms
2020-05-09T06:37:26.892-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 38, autocommit: false } numYields:0 reslen:214 protocol:op_msg 392ms
2020-05-09T06:37:27.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:28.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:28.707-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:29.042-0700 I  NETWORK  [conn23] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:29.043-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:29.542-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.042-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:30.042-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:30.043-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T06:37:30.043-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:30.043-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 645), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 61, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2044ms
2020-05-09T06:37:30.043-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 75, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1950ms
2020-05-09T06:37:30.043-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:30.043-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 64, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2008ms
2020-05-09T06:37:30.044-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:30.148-0700 I  NETWORK  [conn19] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:30.149-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.211-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:30.542-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.042-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.542-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.542-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.543-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031450, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 64, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1498ms
2020-05-09T06:37:31.543-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031450, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 61, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1499ms
2020-05-09T06:37:31.544-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031450, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 75, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1498ms
2020-05-09T06:37:31.576-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:31.694-0700 I  NETWORK  [conn21] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.695-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.695-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.725-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:31.829-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 66, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 58) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 58) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:197276, timeActiveMicros:209703, timeInactiveMicros:817, 210ms
2020-05-09T06:37:31.829-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 58), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 66, autocommit: false } numYields:0 reslen:214 protocol:op_msg 197ms
2020-05-09T06:37:31.829-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 59), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 63, autocommit: false } numYields:0 reslen:321 protocol:op_msg 196ms
2020-05-09T06:37:32.829-0700 I  NETWORK  [conn23] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:32.832-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:32.834-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.330-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.830-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:34.329-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.329-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.330-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:34.330-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 120), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 64, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2483ms
2020-05-09T06:37:34.330-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.330-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.731-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.014-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 84, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 162) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3014481, timeActiveMicros:3037141, timeInactiveMicros:668, 3037ms
2020-05-09T06:37:35.015-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.015-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 9) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2962216, timeActiveMicros:2970833, timeInactiveMicros:633, 2971ms
2020-05-09T06:37:35.015-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:35.515-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.516-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.517-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.517-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 167), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 84, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3517ms
2020-05-09T06:37:35.517-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 70, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3464ms
2020-05-09T06:37:35.518-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031454, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 64, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1185ms
2020-05-09T06:37:35.518-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.518-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.521-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 70, autocommit: false } numYields:0 reslen:214 protocol:op_msg 276ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 84, autocommit: false } numYields:0 reslen:214 protocol:op_msg 276ms
2020-05-09T06:37:35.804-0700 I  NETWORK  [conn23] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.805-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.805-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.808-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 65, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031455, 2) } }, globalReadTimestamp:{ ts: Timestamp(1589031455, 2) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:287056, timeInactiveMicros:0, 287ms
2020-05-09T06:37:35.808-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 65, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031455, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 9fc3081a-6409-4831-aab2-837ae47b5f57:65 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 287ms
2020-05-09T06:37:37.174-0700 I  NETWORK  [conn19] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:37.178-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:37.675-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.676-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:38.332-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 78, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 131) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2122768, timeActiveMicros:2128121, timeInactiveMicros:423, 2128ms
2020-05-09T06:37:38.333-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 91, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 142) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2104449, timeActiveMicros:2114276, timeInactiveMicros:565, 2114ms
2020-05-09T06:37:38.333-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031456, 90) } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 93) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2157305, timeActiveMicros:2167120, timeInactiveMicros:424, 2167ms
2020-05-09T06:37:38.333-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 135), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 78, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2123ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 91, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2105ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 102), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 75, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2158ms
2020-05-09T06:37:39.360-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.360-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:39.361-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.812-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:39.812-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:39.812-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:39.812-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:39.835-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031459, 6), t: 11 }
2020-05-09T06:37:39.836-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: NotMasterOrSecondary: node is not in primary or recovering state
2020-05-09T06:37:39.838-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:39.840-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:39.842-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.032-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:40.338-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.838-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.838-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.840-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 92, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2014ms
2020-05-09T06:37:41.252-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:41.253-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:41.253-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:41.537-0700 I  NETWORK  [conn21] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:41.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:41.538-0700 I  NETWORK  [conn19] Marking host n6:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:41.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.538-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.538-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.540-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 92, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1698ms
2020-05-09T06:37:42.549-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 114, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031459, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3522000, timeActiveMicros:3526448, timeInactiveMicros:542, 3526ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031459, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 114, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3522ms
2020-05-09T06:37:42.549-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 108, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031458, 449) } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 449) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3708062, timeActiveMicros:3717252, timeInactiveMicros:305, 3717ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 449), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 108, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3708ms
2020-05-09T06:37:42.625-0700 I  NETWORK  [conn21] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.626-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.633-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.644-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.126-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.127-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.485-0700 I  NETWORK  [conn19] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.486-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.488-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.626-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.126-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.623-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-09T06:37:44.626-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.126-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.626-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.126-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.464-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:46.465-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.626-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:46.626-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:46.627-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.895-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 124 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 97, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4261ms
2020-05-09T06:37:46.895-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 119, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4251ms
2020-05-09T06:37:46.895-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 112, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4270ms
2020-05-09T06:37:46.895-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:46.896-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 112, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:805, timeActiveMicros:4270977, timeInactiveMicros:419, 4271ms
2020-05-09T06:37:46.897-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 119, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 92) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1290, timeActiveMicros:4252305, timeInactiveMicros:646, 4252ms
2020-05-09T06:37:46.897-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 97, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1659, timeActiveMicros:4263573, timeInactiveMicros:666, 4264ms
2020-05-09T06:37:46.898-0700 I  NETWORK  [conn23] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:46.899-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:46.899-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:46.900-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.965-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.399-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.399-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.400-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.465-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.584-0700 I  NETWORK  [Sharding-Fixed-6] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:47.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.813-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 127, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 37) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:819565, timeActiveMicros:823383, timeInactiveMicros:568, 823ms
2020-05-09T06:37:47.814-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 127, autocommit: false } numYields:0 reslen:214 protocol:op_msg 819ms
2020-05-09T06:37:47.815-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 113, autocommit: false } numYields:0 reslen:322 protocol:op_msg 912ms
2020-05-09T06:37:47.815-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 98, autocommit: false } numYields:0 reslen:321 protocol:op_msg 912ms
2020-05-09T06:37:47.965-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:48.144-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:48.145-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.147-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.465-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.466-0700 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.466-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:48.481-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 10), t: 15 }
2020-05-09T06:37:48.645-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:49.145-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.145-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.147-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 128, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 39) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1323472, timeInactiveMicros:0, 1323ms
2020-05-09T06:37:49.147-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 128, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1323ms
2020-05-09T06:37:49.148-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 102, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 53) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1274371, timeInactiveMicros:0, 1274ms
2020-05-09T06:37:49.148-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 102, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1274ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 102, autocommit: false } numYields:0 reslen:398 protocol:op_msg 120ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 131 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 50), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 116, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1420ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 128, autocommit: false } numYields:0 reslen:399 protocol:op_msg 121ms
2020-05-09T06:37:49.272-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 116, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 50) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1106, timeActiveMicros:1421743, timeInactiveMicros:784, 1422ms
2020-05-09T06:37:49.332-0700 I  NETWORK  [conn21] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.333-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.333-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.334-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.335-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.335-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.494-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 131, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 74) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:113281, timeActiveMicros:119923, timeInactiveMicros:314, 120ms
2020-05-09T06:37:49.494-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 131, autocommit: false } numYields:0 reslen:214 protocol:op_msg 113ms
2020-05-09T06:37:49.495-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 105, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 74) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:114161, timeActiveMicros:121041, timeInactiveMicros:317, 121ms
2020-05-09T06:37:49.495-0700 I  COMMAND  [conn19] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 105, autocommit: false } numYields:0 reslen:214 protocol:op_msg 114ms
2020-05-09T06:37:49.635-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:49.867-0700 I  NETWORK  [conn19] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:49.867-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:49.868-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.216-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T06:37:50.367-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.367-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.368-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 110, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 188) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:679448, timeInactiveMicros:0, 679ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 54), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 118, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1032ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 110, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 679ms
2020-05-09T06:37:50.820-0700 I  NETWORK  [conn23] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:50.821-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:50.990-0700 I  NETWORK  [conn19] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:50.991-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.992-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.321-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:51.491-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.820-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:51.820-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:51.991-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.992-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.993-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94") }, txnNumber: 118, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1623ms
2020-05-09T06:37:51.993-0700 I  COMMAND  [conn19] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57") }, txnNumber: 110, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1624ms
2020-05-09T06:37:52.819-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 144, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 214) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2985832, timeActiveMicros:3000002, timeInactiveMicros:390, 3000ms
2020-05-09T06:37:52.820-0700 I  NETWORK  [conn23] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:52.821-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:53.320-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.320-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.322-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 215), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 144, autocommit: false } numYields:0 reslen:497 protocol:op_msg 3488ms
2020-05-09T06:37:53.961-0700 I  NETWORK  [conn23] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:53.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:54.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:54.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:55.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:55.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:56.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:56.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.044-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54024 #66 (9 connections now open)
2020-05-09T06:37:57.045-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.1:54024 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.056-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54026 #67 (10 connections now open)
2020-05-09T06:37:57.056-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.1:54026 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.455-0700 I  NETWORK  [conn20] end connection 192.168.122.1:52238 (9 connections now open)
2020-05-09T06:37:57.456-0700 I  NETWORK  [conn22] end connection 192.168.122.1:52290 (8 connections now open)
2020-05-09T06:37:57.459-0700 I  NETWORK  [conn24] end connection 192.168.122.1:52298 (7 connections now open)
2020-05-09T06:37:57.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54050 #68 (8 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:54050 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn68] end connection 192.168.122.1:54050 (7 connections now open)
2020-05-09T06:37:57.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:58.335-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031473, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60") }, txnNumber: 144, autocommit: false } numYields:0 reslen:497 protocol:op_msg 5012ms
2020-05-09T06:37:58.419-0700 I  NETWORK  [conn23] end connection 192.168.122.1:52294 (6 connections now open)
2020-05-09T06:37:58.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:58.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:59.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:59.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:38:00.461-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:38:00.461-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
