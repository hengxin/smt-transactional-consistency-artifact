2020-05-09T06:37:05.722-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:05.738-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=4695 port=27018 dbpath=/var/lib/mongodb 64-bit host=n5
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] modules: none
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] build environment:
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-09T06:37:05.738-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_shard1" }, sharding: { clusterRole: "shardsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-09T06:37:05.739-0700 I  STORAGE  [initandlisten] 
2020-05-09T06:37:05.739-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-09T06:37:05.739-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-09T06:37:05.739-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-09T06:37:06.500-0700 I  STORAGE  [initandlisten] WiredTiger message [1589031426:500795][4695:0x7f9033af4140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-09T06:37:06.547-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-09T06:37:06.600-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-09T06:37:06.640-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.640-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:06.640-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:06.640-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-09T06:37:06.642-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.643-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-09T06:37:06.644-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-09T06:37:06.644-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-09T06:37:06.644-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-09T06:37:06.644-0700 W  SHARDING [initandlisten] Started with --shardsvr, but no shardIdentity document was found on disk in admin.system.version. This most likely means this server has not yet been added to a sharded cluster.
2020-05-09T06:37:06.645-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: fe18e5a9-4034-4f3e-95a0-5376dda41acc and options: { capped: true, size: 10485760 }
2020-05-09T06:37:06.693-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-09T06:37:06.693-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-09T06:37:06.694-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-09T06:37:06.699-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 6d2cfcc6-fb1d-4178-87a8-16216c3a4014 and options: {}
2020-05-09T06:37:06.743-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-09T06:37:06.744-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: a6a1e872-b470-47a0-b2de-54dd4cb4bf22 and options: {}
2020-05-09T06:37:06.803-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-09T06:37:06.804-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-09T06:37:06.804-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 0f53cf6b-f4b7-4d20-8af2-7a481cb7e255 and options: {}
2020-05-09T06:37:06.866-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-09T06:37:06.866-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-09T06:37:06.866-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-09T06:37:06.866-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-09T06:37:06.867-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 938722f6-2872-4e12-9b6b-b1a6db9580b4 and options: {}
2020-05-09T06:37:06.917-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-09T06:37:06.917-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-09T06:37:06.917-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-09T06:37:06.917-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-09T06:37:06.918-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: sharding state is not yet initialized
2020-05-09T06:37:06.918-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: sharding state is not yet initialized
2020-05-09T06:37:06.919-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27018.sock
2020-05-09T06:37:06.919-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:06.919-0700 I  NETWORK  [listener] waiting for connections on port 27018
2020-05-09T06:37:07.001-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-09T06:37:07.904-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50202 #1 (1 connection now open)
2020-05-09T06:37:07.904-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50210 #2 (2 connections now open)
2020-05-09T06:37:07.906-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:50202 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.909-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:50210 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.954-0700 I  NETWORK  [conn1] end connection 192.168.122.1:50202 (1 connection now open)
2020-05-09T06:37:07.954-0700 I  NETWORK  [conn2] end connection 192.168.122.1:50210 (0 connections now open)
2020-05-09T06:37:08.000-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:54086 #3 (1 connection now open)
2020-05-09T06:37:08.001-0700 I  NETWORK  [conn3] end connection 192.168.122.14:54086 (0 connections now open)
2020-05-09T06:37:08.003-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:54096 #4 (1 connection now open)
2020-05-09T06:37:08.003-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.14:54096 conn4: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:08.004-0700 I  CONNPOOL [Replication] Connecting to n4:27018
2020-05-09T06:37:08.547-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57058 #7 (2 connections now open)
2020-05-09T06:37:08.548-0700 I  NETWORK  [conn7] end connection 192.168.122.16:57058 (1 connection now open)
2020-05-09T06:37:08.548-0700 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: e8421814-1d94-43af-9b6d-4ab7d4b1a5a3 and options: {}
2020-05-09T06:37:08.653-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2020-05-09T06:37:08.655-0700 I  REPL     [replexec-0] New replica set config in use: { _id: "rs_shard1", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n4:27018", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n5:27018", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n6:27018", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb6b2030f8124bc6bb7e60b') } }
2020-05-09T06:37:08.655-0700 I  REPL     [replexec-0] This node is n5:27018 in the config
2020-05-09T06:37:08.655-0700 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2020-05-09T06:37:08.656-0700 I  CONNPOOL [Replication] Connecting to n6:27018
2020-05-09T06:37:08.656-0700 I  REPL     [replexec-0] Starting replication storage threads
2020-05-09T06:37:08.656-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57074 #9 (2 connections now open)
2020-05-09T06:37:08.656-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.16:57074 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:08.656-0700 I  REPL     [replexec-2] Member n4:27018 is now in state SECONDARY
2020-05-09T06:37:08.658-0700 I  REPL     [replexec-3] Member n6:27018 is now in state STARTUP2
2020-05-09T06:37:08.670-0700 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: ee976b35-8deb-47fc-ad0d-5c63dbcb0815 and options: { temp: true }
2020-05-09T06:37:08.797-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-09T06:37:08.798-0700 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2020-05-09T06:37:08.798-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (ee976b35-8deb-47fc-ad0d-5c63dbcb0815).
2020-05-09T06:37:08.819-0700 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: 57c1b8cd-1d06-4fab-a17c-05d09f1ca65a and options: { temp: true }
2020-05-09T06:37:08.943-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-09T06:37:08.944-0700 I  REPL     [replication-0] sync source candidate: n4:27018
2020-05-09T06:37:08.944-0700 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2020-05-09T06:37:08.944-0700 I  REPL     [replication-0] ******
2020-05-09T06:37:08.944-0700 I  REPL     [replication-0] creating replication oplog of size: 36624MB...
2020-05-09T06:37:08.944-0700 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: e64289d6-332c-4fa0-ba80-85591f5d0d9c and options: { capped: true, size: 38403865600.0, autoIndexId: false }
2020-05-09T06:37:09.003-0700 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2020-05-09T06:37:09.004-0700 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-09T06:37:09.004-0700 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:09.004-0700 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:09.380-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.380-0700 I  ELECTION [conn4] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2020-05-09T06:37:09.399-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.399-0700 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-09T06:37:09.497-0700 I  REPL     [replication-0] ******
2020-05-09T06:37:09.498-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2020-05-09T06:37:09.498-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2020-05-09T06:37:09.498-0700 I  CONNPOOL [RS] Connecting to n4:27018
2020-05-09T06:37:09.507-0700 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:admin.system.version
2020-05-09T06:37:09.507-0700 I  SHARDING [replication-1] Marking collection local.temp_oplog_buffer as collection version: <unsharded>
2020-05-09T06:37:09.508-0700 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: 72fcdfab-6b6e-4c6e-9234-dd889cc441e2 and options: { uuid: UUID("72fcdfab-6b6e-4c6e-9234-dd889cc441e2") }
2020-05-09T06:37:09.524-0700 I  COMMAND  [conn4] command local.replset.election command: replSetRequestVotes { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 }, $db: "admin" } numYields:0 reslen:204 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 1, w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 97582 } }, Database: { acquireCount: { r: 1, w: 1 } }, Collection: { acquireCount: { r: 1, w: 1 } }, Mutex: { acquireCount: { r: 3 } } } storage:{} protocol:op_msg 124ms
2020-05-09T06:37:09.626-0700 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2020-05-09T06:37:09.626-0700 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:09.635-0700 I  COMMAND  [repl-writer-worker-15] setting featureCompatibilityVersion to 4.0
2020-05-09T06:37:09.635-0700 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.version finished cloning with status: OK
2020-05-09T06:37:09.636-0700 I  REPL     [replication-1] Restarting oplog query due to error: CappedPositionLost: error in fetcher batch callback :: caused by :: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824838019871145987). Last fetched optime: { ts: Timestamp(1589031429, 3), t: 1 }. Restarts remaining: 10
2020-05-09T06:37:09.637-0700 I  REPL     [replication-1] Scheduled new oplog query Fetcher source: n4:27018 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031429, 3) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 1, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 19 -- target:n4:27018 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031429, 3) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 1, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-09T06:37:09.637-0700 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-05-09T06:37:09.645-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.version
2020-05-09T06:37:09.647-0700 I  INITSYNC [replication-0] Finished cloning data: OK. Beginning oplog replay.
2020-05-09T06:37:09.648-0700 I  INITSYNC [replication-1] Writing to the oplog and applying operations until { : Timestamp(1589031429, 3) } before initial sync can complete. (started fetching at { : Timestamp(1589031428, 1) } and applying at { : Timestamp(1589031428, 1) })
2020-05-09T06:37:09.648-0700 I  SHARDING [replication-1] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-09T06:37:09.651-0700 I  STORAGE  [repl-writer-worker-4] createCollection: config.transactions with provided UUID: bbb4c996-e4e1-4518-b143-7fc1e9533a3d and options: { uuid: UUID("bbb4c996-e4e1-4518-b143-7fc1e9533a3d") }
2020-05-09T06:37:09.703-0700 I  INDEX    [repl-writer-worker-4] index build: done building index _id_ on ns config.transactions
2020-05-09T06:37:09.705-0700 I  INITSYNC [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(1589031429, 3), t: 1 }
2020-05-09T06:37:09.705-0700 I  INITSYNC [replication-1] Initial sync attempt finishing up.
2020-05-09T06:37:09.705-0700 I  INITSYNC [replication-1] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1589031428797), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 3, initialSyncOplogStart: Timestamp(1589031428, 1), initialSyncOplogEnd: Timestamp(1589031429, 3), databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1589031429506), end: new Date(1589031429647), elapsedMillis: 141, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1589031429507), end: new Date(1589031429647), elapsedMillis: 140, receivedBatches: 1 } } } }
2020-05-09T06:37:09.705-0700 I  CONNPOOL [RS] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:09.706-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (57c1b8cd-1d06-4fab-a17c-05d09f1ca65a).
2020-05-09T06:37:09.712-0700 I  SHARDING [replication-0] Marking collection config.transactions as collection version: <unsharded>
2020-05-09T06:37:09.713-0700 I  INITSYNC [replication-0] initial sync done; took 0s.
2020-05-09T06:37:09.713-0700 I  REPL     [replication-0] transition to RECOVERING from STARTUP2
2020-05-09T06:37:09.713-0700 I  REPL     [replication-0] Starting replication fetcher thread
2020-05-09T06:37:09.713-0700 I  REPL     [replication-0] Starting replication applier thread
2020-05-09T06:37:09.713-0700 I  REPL     [replication-0] Starting replication reporter thread
2020-05-09T06:37:09.714-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-09T06:37:09.714-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:09.715-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-09T06:37:09.715-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-09T06:37:09.715-0700 I  REPL     [replexec-3] Member n4:27018 is now in state PRIMARY
2020-05-09T06:37:10.216-0700 I  REPL     [replexec-0] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:10.394-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50358 #14 (3 connections now open)
2020-05-09T06:37:10.395-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:50358 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:10.395-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50376 #15 (4 connections now open)
2020-05-09T06:37:10.395-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.1:50376 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:12.431-0700 I  NETWORK  [conn14] end connection 192.168.122.1:50358 (3 connections now open)
2020-05-09T06:37:12.431-0700 I  NETWORK  [conn15] end connection 192.168.122.1:50376 (2 connections now open)
2020-05-09T06:37:15.683-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:38856 #16 (3 connections now open)
2020-05-09T06:37:15.684-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.11:38856 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.717-0700 I  REPL     [rsBackgroundSync] sync source candidate: n4:27018
2020-05-09T06:37:16.719-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n4:27018
2020-05-09T06:37:16.720-0700 I  CONNPOOL [RS] Connecting to n4:27018
2020-05-09T06:37:16.721-0700 I  STORAGE  [replication-1] Triggering the first stable checkpoint. Initial Data: Timestamp(1589031429, 3) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1589031429, 3)
2020-05-09T06:37:16.724-0700 I  SHARDING [repl-writer-worker-8] initializing sharding state with: { shardName: "rs_shard1", clusterId: ObjectId('5eb6b20612268df81b11352f'), configsvrConnectionString: "rs_config/n1:27019,n2:27019,n3:27019" }
2020-05-09T06:37:16.725-0700 I  NETWORK  [repl-writer-worker-8] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:16.725-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T06:37:16.725-0700 I  SHARDING [thread10] creating distributed lock ping thread for process n5:27018:1589031436:8583194282863132541 (sleeping for 30000ms)
2020-05-09T06:37:16.726-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:16.726-0700 I  SHARDING [repl-writer-worker-8] Finished initializing sharding components for secondary node.
2020-05-09T06:37:16.726-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:16.729-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:16.729-0700 I  SHARDING [Sharding-Fixed-0] Updating config server with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:16.732-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031435, 5), t: 2 }
2020-05-09T06:37:16.745-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T06:37:16.761-0700 I  COMMAND  [repl-writer-worker-10] setting featureCompatibilityVersion to upgrading to 4.2
2020-05-09T06:37:16.761-0700 I  NETWORK  [repl-writer-worker-10] Skip closing connection for connection # 16
2020-05-09T06:37:16.761-0700 I  NETWORK  [repl-writer-worker-10] Skip closing connection for connection # 9
2020-05-09T06:37:16.761-0700 I  NETWORK  [repl-writer-worker-10] Skip closing connection for connection # 4
2020-05-09T06:37:16.792-0700 I  COMMAND  [repl-writer-worker-0] setting featureCompatibilityVersion to 4.2
2020-05-09T06:37:16.792-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 16
2020-05-09T06:37:16.792-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 9
2020-05-09T06:37:16.792-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 4
2020-05-09T06:37:16.820-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57516 #24 (4 connections now open)
2020-05-09T06:37:16.820-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.16:57516 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.954-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:38910 #25 (5 connections now open)
2020-05-09T06:37:16.954-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.11:38910 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.027-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51544 #26 (6 connections now open)
2020-05-09T06:37:17.027-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.17:51544 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.751-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:33460 #27 (7 connections now open)
2020-05-09T06:37:17.751-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.19:33460 conn27: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.969-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57640 #28 (8 connections now open)
2020-05-09T06:37:17.970-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.16:57640 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.022-0700 I  STORAGE  [repl-writer-worker-1] createCollection: jepsendb.jepsencoll with provided UUID: 369a08af-19c6-4a50-a50a-0622ffd47ed1 and options: { uuid: UUID("369a08af-19c6-4a50-a50a-0622ffd47ed1") }
2020-05-09T06:37:18.071-0700 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns jepsendb.jepsencoll
2020-05-09T06:37:18.208-0700 I  INDEX    [repl-writer-worker-6] index build: starting on jepsendb.jepsencoll properties: { v: 2, key: { _id: "hashed" }, name: "_id_hashed", ns: "jepsendb.jepsencoll" } using method: Hybrid
2020-05-09T06:37:18.208-0700 I  INDEX    [repl-writer-worker-6] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:18.208-0700 I  STORAGE  [repl-writer-worker-6] Index build initialized: b1f31228-1b20-4f80-ab75-15a07943d428: jepsendb.jepsencoll (369a08af-19c6-4a50-a50a-0622ffd47ed1 ): indexes: 1
2020-05-09T06:37:18.209-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:18.210-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:18.216-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index _id_hashed on ns jepsendb.jepsencoll
2020-05-09T06:37:18.217-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:54730 #29 (9 connections now open)
2020-05-09T06:37:18.218-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.14:54730 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.226-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: b1f31228-1b20-4f80-ab75-15a07943d428: jepsendb.jepsencoll ( 369a08af-19c6-4a50-a50a-0622ffd47ed1 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T06:37:18.372-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:53226 #30 (10 connections now open)
2020-05-09T06:37:18.372-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.18:53226 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.573-0700 I  STORAGE  [repl-writer-worker-8] createCollection: config.cache.databases with provided UUID: ac00475a-64d1-4809-8de5-3f2d60514834 and options: { uuid: UUID("ac00475a-64d1-4809-8de5-3f2d60514834") }
2020-05-09T06:37:18.622-0700 I  INDEX    [repl-writer-worker-8] index build: done building index _id_ on ns config.cache.databases
2020-05-09T06:37:18.624-0700 I  STORAGE  [repl-writer-worker-10] createCollection: config.cache.collections with provided UUID: a7cd83b9-ae39-4cbe-a69d-2882fc80c5e3 and options: { uuid: UUID("a7cd83b9-ae39-4cbe-a69d-2882fc80c5e3") }
2020-05-09T06:37:18.710-0700 I  INDEX    [repl-writer-worker-10] index build: done building index _id_ on ns config.cache.collections
2020-05-09T06:37:18.715-0700 I  STORAGE  [repl-writer-worker-0] createCollection: config.cache.chunks.jepsendb.jepsencoll with provided UUID: 1ff6706c-10b9-4f4c-8ffd-d41947c657da and options: { uuid: UUID("1ff6706c-10b9-4f4c-8ffd-d41947c657da") }
2020-05-09T06:37:18.773-0700 I  INDEX    [repl-writer-worker-0] index build: done building index _id_ on ns config.cache.chunks.jepsendb.jepsencoll
2020-05-09T06:37:18.816-0700 I  INDEX    [repl-writer-worker-4] index build: starting on config.cache.chunks.jepsendb.jepsencoll properties: { v: 2, key: { lastmod: 1 }, name: "lastmod_1", ns: "config.cache.chunks.jepsendb.jepsencoll" } using method: Hybrid
2020-05-09T06:37:18.816-0700 I  INDEX    [repl-writer-worker-4] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:18.816-0700 I  STORAGE  [repl-writer-worker-4] Index build initialized: 90ce856f-16b7-4a62-9fd1-97eb731b5cfc: config.cache.chunks.jepsendb.jepsencoll (1ff6706c-10b9-4f4c-8ffd-d41947c657da ): indexes: 1
2020-05-09T06:37:18.817-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:18.818-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:18.824-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: drain applied 5 side writes (inserted: 5, deleted: 0) for 'lastmod_1' in 2 ms
2020-05-09T06:37:18.824-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: drain applied 2 side writes (inserted: 2, deleted: 0) for 'lastmod_1' in 0 ms
2020-05-09T06:37:18.824-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index lastmod_1 on ns config.cache.chunks.jepsendb.jepsencoll
2020-05-09T06:37:18.829-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 90ce856f-16b7-4a62-9fd1-97eb731b5cfc: config.cache.chunks.jepsendb.jepsencoll ( 1ff6706c-10b9-4f4c-8ffd-d41947c657da ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T06:37:18.883-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:54776 #31 (11 connections now open)
2020-05-09T06:37:18.884-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.14:54776 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:19.401-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:42698 #32 (12 connections now open)
2020-05-09T06:37:19.402-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.13:42698 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:19.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:33068 #33 (13 connections now open)
2020-05-09T06:37:19.915-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.15:33068 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:20.435-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42584 #34 (14 connections now open)
2020-05-09T06:37:20.436-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.12:42584 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:20.944-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:53302 #35 (15 connections now open)
2020-05-09T06:37:20.945-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.18:53302 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:21.468-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:33648 #36 (16 connections now open)
2020-05-09T06:37:21.468-0700 I  NETWORK  [conn36] received client metadata from 192.168.122.19:33648 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:21.991-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:51772 #37 (17 connections now open)
2020-05-09T06:37:21.992-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.17:51772 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.315-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51352 #38 (18 connections now open)
2020-05-09T06:37:23.315-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51354 #39 (19 connections now open)
2020-05-09T06:37:23.315-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.1:51352 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:23.315-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.1:51354 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:23.321-0700 I  NETWORK  [conn38] end connection 192.168.122.1:51352 (18 connections now open)
2020-05-09T06:37:23.321-0700 I  NETWORK  [conn39] end connection 192.168.122.1:51354 (17 connections now open)
2020-05-09T06:37:23.669-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:52132 #40 (18 connections now open)
2020-05-09T06:37:23.670-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.17:52132 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.676-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42992 #41 (19 connections now open)
2020-05-09T06:37:23.676-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.12:42992 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.679-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:33498 #42 (20 connections now open)
2020-05-09T06:37:23.679-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58164 #43 (21 connections now open)
2020-05-09T06:37:23.680-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.15:33498 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.680-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.16:58164 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.683-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:53714 #44 (22 connections now open)
2020-05-09T06:37:23.684-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.18:53714 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.688-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34062 #45 (23 connections now open)
2020-05-09T06:37:23.688-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.19:34062 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.703-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:55284 #46 (24 connections now open)
2020-05-09T06:37:23.704-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.14:55284 conn46: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.708-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43198 #47 (25 connections now open)
2020-05-09T06:37:23.708-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.13:43198 conn47: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:23.727-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39612 #48 (26 connections now open)
2020-05-09T06:37:23.728-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.11:39612 conn48: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:24.033-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51468 #49 (27 connections now open)
2020-05-09T06:37:24.034-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.1:51468 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.034-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51478 #50 (28 connections now open)
2020-05-09T06:37:24.034-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.1:51478 conn50: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.039-0700 I  NETWORK  [conn49] end connection 192.168.122.1:51468 (27 connections now open)
2020-05-09T06:37:24.039-0700 I  NETWORK  [conn50] end connection 192.168.122.1:51478 (26 connections now open)
2020-05-09T06:37:24.635-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43242 #51 (27 connections now open)
2020-05-09T06:37:24.635-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.13:43242 conn51: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:24.640-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43256 #52 (28 connections now open)
2020-05-09T06:37:24.641-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.13:43256 conn52: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:25.931-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51660 #53 (29 connections now open)
2020-05-09T06:37:25.932-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51664 #54 (30 connections now open)
2020-05-09T06:37:25.932-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:51660 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:25.932-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:51664 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:25.935-0700 I  NETWORK  [conn53] end connection 192.168.122.1:51660 (29 connections now open)
2020-05-09T06:37:25.935-0700 I  NETWORK  [conn54] end connection 192.168.122.1:51664 (28 connections now open)
2020-05-09T06:37:26.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43282 #55 (29 connections now open)
2020-05-09T06:37:26.078-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.12:43282 conn55: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.080-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43294 #56 (30 connections now open)
2020-05-09T06:37:26.080-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.12:43294 conn56: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.448-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51700 #57 (31 connections now open)
2020-05-09T06:37:26.448-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51704 #58 (32 connections now open)
2020-05-09T06:37:26.448-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.1:51700 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:26.448-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.1:51704 conn58: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:26.450-0700 I  NETWORK  [conn57] end connection 192.168.122.1:51700 (31 connections now open)
2020-05-09T06:37:26.450-0700 I  NETWORK  [conn58] end connection 192.168.122.1:51704 (30 connections now open)
2020-05-09T06:37:26.670-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:52492 #59 (31 connections now open)
2020-05-09T06:37:26.670-0700 I  NETWORK  [conn59] received client metadata from 192.168.122.17:52492 conn59: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.680-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:33840 #60 (32 connections now open)
2020-05-09T06:37:26.680-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58506 #61 (33 connections now open)
2020-05-09T06:37:26.680-0700 I  NETWORK  [conn60] received client metadata from 192.168.122.15:33840 conn60: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.680-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58510 #62 (34 connections now open)
2020-05-09T06:37:26.681-0700 I  NETWORK  [conn61] received client metadata from 192.168.122.16:58506 conn61: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.681-0700 I  NETWORK  [conn62] received client metadata from 192.168.122.16:58510 conn62: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.708-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43496 #63 (35 connections now open)
2020-05-09T06:37:26.708-0700 I  NETWORK  [conn63] received client metadata from 192.168.122.13:43496 conn63: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:26.728-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:39910 #64 (36 connections now open)
2020-05-09T06:37:26.729-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.11:39910 conn64: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:28.022-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51796 #65 (37 connections now open)
2020-05-09T06:37:28.022-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51802 #66 (38 connections now open)
2020-05-09T06:37:28.022-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.1:51796 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:28.023-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.1:51802 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:28.025-0700 I  NETWORK  [conn65] end connection 192.168.122.1:51796 (37 connections now open)
2020-05-09T06:37:28.025-0700 I  NETWORK  [conn66] end connection 192.168.122.1:51802 (36 connections now open)
2020-05-09T06:37:28.708-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43562 #67 (37 connections now open)
2020-05-09T06:37:28.709-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.13:43562 conn67: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:29.123-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 1, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 652), t: 1 } }
2020-05-09T06:37:29.123-0700 I  ELECTION [conn9] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-09T06:37:29.136-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 652), t: 1 } }
2020-05-09T06:37:29.136-0700 I  ELECTION [conn9] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-05-09T06:37:29.726-0700 I  REPL     [replexec-3] Member n4:27018 is now in state RS_DOWN - Request 904 timed out, deadline was 2020-05-09T06:37:29.726-0700, op was RemoteCommand 904 -- target:[n4:27018] db:admin expDate:2020-05-09T06:37:29.726-0700 cmd:{ replSetHeartbeat: "rs_shard1", configVersion: 1, hbv: 1, from: "n5:27018", fromId: 1, term: 1 }
2020-05-09T06:37:29.726-0700 I  CONNPOOL [Replication] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:29.726-0700 I  CONNPOOL [Replication] Connecting to n4:27018
2020-05-09T06:37:30.199-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:30.199-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 2
2020-05-09T06:37:30.199-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 905 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 652), t: 1 } }
2020-05-09T06:37:30.199-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 906 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 652), t: 1 } }
2020-05-09T06:37:30.200-0700 I  ELECTION [replexec-0] VoteRequester(term 2 dry run) received a no vote from n6:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timestamp(1589031450, 15), t: 2 }"; response message: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000002') }, lastCommittedOpTime: Timestamp(1589031447, 638), $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $clusterTime: { clusterTime: Timestamp(1589031450, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031450, 15) }
2020-05-09T06:37:30.219-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51864 #68 (38 connections now open)
2020-05-09T06:37:30.219-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:51864 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:30.219-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51866 #69 (39 connections now open)
2020-05-09T06:37:30.220-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:51866 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:30.224-0700 I  NETWORK  [conn68] end connection 192.168.122.1:51864 (38 connections now open)
2020-05-09T06:37:30.224-0700 I  NETWORK  [conn69] end connection 192.168.122.1:51866 (37 connections now open)
2020-05-09T06:37:30.753-0700 I  ELECTION [replexec-3] VoteRequester(term 2 dry run) received a no vote from n4:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timestamp(1589031448, 29), t: 1 }"; response message: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000001') }, lastCommittedOpTime: Timestamp(1589031447, 638), $configServerState: { opTime: { ts: Timestamp(1589031446, 87), t: 4 } }, $clusterTime: { clusterTime: Timestamp(1589031450, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031448, 29) }
2020-05-09T06:37:30.753-0700 I  ELECTION [replexec-3] not running for primary, we received insufficient votes
2020-05-09T06:37:30.753-0700 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-05-09T06:37:31.259-0700 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:31.259-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 2
2020-05-09T06:37:31.259-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 908 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 652), t: 1 } }
2020-05-09T06:37:31.259-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 909 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 652), t: 1 } }
2020-05-09T06:37:31.260-0700 I  ELECTION [replexec-4] VoteRequester(term 2 dry run) received a no vote from n4:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timestamp(1589031450, 15), t: 2 }"; response message: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000001') }, lastCommittedOpTime: Timestamp(1589031447, 638), $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $clusterTime: { clusterTime: Timestamp(1589031450, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031450, 15) }
2020-05-09T06:37:31.260-0700 I  ELECTION [replexec-4] VoteRequester(term 2 dry run) received a no vote from n6:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timestamp(1589031450, 15), t: 2 }"; response message: { term: 2, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031447, 652), t: 1 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000002') }, lastCommittedOpTime: Timestamp(1589031447, 638), $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $clusterTime: { clusterTime: Timestamp(1589031450, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031450, 15) }
2020-05-09T06:37:31.260-0700 I  ELECTION [replexec-4] not running for primary, we received insufficient votes
2020-05-09T06:37:31.260-0700 I  ELECTION [replexec-4] Lost dry run election due to internal error
2020-05-09T06:37:31.283-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031450, 15), t: 2 } }
2020-05-09T06:37:31.283-0700 I  ELECTION [conn9] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-05-09T06:37:31.283-0700 I  NETWORK  [conn9] end connection 192.168.122.16:57074 (36 connections now open)
2020-05-09T06:37:31.284-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58662 #71 (37 connections now open)
2020-05-09T06:37:31.285-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.16:58662 conn71: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.287-0700 I  ELECTION [conn71] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 3, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031450, 15), t: 2 } }
2020-05-09T06:37:31.287-0700 I  ELECTION [conn71] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-05-09T06:37:31.293-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58664 #72 (38 connections now open)
2020-05-09T06:37:31.294-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.16:58664 conn72: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.297-0700 I  NETWORK  [conn71] end connection 192.168.122.16:58662 (37 connections now open)
2020-05-09T06:37:31.395-0700 I  REPL     [replication-0] Restarting oplog query due to error: QueryPlanKilled: error in fetcher batch callback :: caused by :: Database epoch changed due to a database-level event such as 'restartCatalog'.. Last fetched optime: { ts: Timestamp(1589031448, 6), t: 1 }. Restarts remaining: 1
2020-05-09T06:37:31.395-0700 I  REPL     [replication-0] Scheduled new oplog query Fetcher source: n4:27018 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031448, 6) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 3, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 5500ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 912 -- target:n4:27018 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031448, 6) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 3, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
2020-05-09T06:37:31.396-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: Upstream node rolled back after choosing it as a sync source. Choosing new sync source.
2020-05-09T06:37:31.396-0700 I  REPL     [rsBackgroundSync] Clearing sync source n4:27018 to choose a new one.
2020-05-09T06:37:31.396-0700 I  REPL     [rsBackgroundSync] sync source candidate: n6:27018
2020-05-09T06:37:31.396-0700 I  CONNPOOL [RS] Connecting to n6:27018
2020-05-09T06:37:31.407-0700 I  REPL     [rsBackgroundSync] Changed sync source from n4:27018 to n6:27018
2020-05-09T06:37:31.407-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n4:27018: InvalidSyncSource: Sync source changed from n4:27018 to n6:27018
2020-05-09T06:37:31.408-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589031448, 6), t: 1 }. source's GTE: { ts: Timestamp(1589031449, 2), t: 2 }
2020-05-09T06:37:31.408-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589031447, 638), t: 1 }
2020-05-09T06:37:31.408-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T06:37:31.408-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n6:27018)
2020-05-09T06:37:31.408-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T06:37:31.408-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 38 }
2020-05-09T06:37:31.408-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T06:37:31.408-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T06:37:31.408-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-09T06:37:31.408-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-09T06:37:31.408-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-09T06:37:31.408-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-09T06:37:31.408-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 56
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 55
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 16
2020-05-09T06:37:31.409-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 4
2020-05-09T06:37:31.409-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T06:37:31.409-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T06:37:31.409-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T06:37:31.409-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:31.412-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031436, 1), t: 2 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:31.422-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589031447, 652), t: 1 }
2020-05-09T06:37:31.424-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-09T06:37:31.424-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T06:37:31.424-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T06:37:31.424-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T06:37:31.424-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T06:37:31.425-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T06:37:31.533-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589031447, 638) Initial Data Timestamp: Timestamp(1589031429, 3)
2020-05-09T06:37:31.534-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T06:37:31.544-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T06:37:31.544-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 1020 records totaling to 214703 bytes
2020-05-09T06:37:31.544-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:31.545-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:31.549-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T06:37:31.549-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T06:37:31.561-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T06:37:31.562-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T06:37:31.562-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589031447, 638)
2020-05-09T06:37:31.562-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 0 update operations and 0 delete operations.
2020-05-09T06:37:31.562-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589031448, 1), t: 1 }
2020-05-09T06:37:31.562-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589031448, 1) }
2020-05-09T06:37:31.562-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T06:37:31.574-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589031447, 638) (top of oplog: { ts: Timestamp(1589031447, 652), t: 1 }, appliedThrough: { ts: Timestamp(1589031447, 638), t: 1 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T06:37:31.574-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589031447, 638)
2020-05-09T06:37:31.574-0700 I  REPL     [rsBackgroundSync] Replaying stored operations from Timestamp(1589031447, 638) (inclusive) to Timestamp(1589031447, 652) (inclusive).
2020-05-09T06:37:31.577-0700 I  REPL     [rsBackgroundSync] Applied 14 operations in 1 batches. Last operation applied with optime: { ts: Timestamp(1589031447, 652), t: 1 }
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T06:37:31.578-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T06:37:31.408-0700
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T06:37:31.578-0700
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n6:27018
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: none; no files written
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589031448, 6), t: 1 }
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589031447, 652), t: 1 }
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T06:37:28.030-0700
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T06:37:28.005-0700
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589031448, 1)
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589031447, 638)
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: none
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 		update: 0
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 4
2020-05-09T06:37:31.578-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T06:37:31.578-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T06:37:31.579-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n6:27018
2020-05-09T06:37:31.579-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T06:37:31.579-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T06:37:31.579-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T06:37:31.579-0700 I  REPL     [rsBackgroundSync] sync source candidate: n6:27018
2020-05-09T06:37:31.606-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n6:27018
2020-05-09T06:37:31.676-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43590 #77 (38 connections now open)
2020-05-09T06:37:31.677-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43592 #78 (39 connections now open)
2020-05-09T06:37:31.677-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.12:43590 conn77: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.677-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.12:43592 conn78: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.684-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:54298 #79 (40 connections now open)
2020-05-09T06:37:31.684-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:54300 #80 (41 connections now open)
2020-05-09T06:37:31.684-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.18:54298 conn79: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.684-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.18:54300 conn80: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:31.726-0700 I  REPL     [replexec-4] Member n4:27018 is now in state SECONDARY
2020-05-09T06:37:31.810-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51994 #81 (42 connections now open)
2020-05-09T06:37:31.811-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52000 #82 (43 connections now open)
2020-05-09T06:37:31.811-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.1:51994 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:31.811-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.1:52000 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:31.814-0700 I  NETWORK  [conn81] end connection 192.168.122.1:51994 (42 connections now open)
2020-05-09T06:37:31.814-0700 I  NETWORK  [conn82] end connection 192.168.122.1:52000 (41 connections now open)
2020-05-09T06:37:32.680-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34146 #83 (42 connections now open)
2020-05-09T06:37:32.681-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.15:34146 conn83: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:32.704-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:55888 #84 (43 connections now open)
2020-05-09T06:37:32.704-0700 I  NETWORK  [conn84] received client metadata from 192.168.122.14:55888 conn84: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:32.892-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 3, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031451, 104), t: 3 } }
2020-05-09T06:37:32.892-0700 I  ELECTION [conn4] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-05-09T06:37:32.895-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:32.895-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 3
2020-05-09T06:37:32.895-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 978 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031451, 104), t: 3 } }
2020-05-09T06:37:32.895-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 979 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031451, 104), t: 3 } }
2020-05-09T06:37:32.895-0700 I  CONNPOOL [Replication] Connecting to n6:27018
2020-05-09T06:37:32.896-0700 I  ELECTION [replexec-2] VoteRequester(term 3 dry run) received a no vote from n4:27018 with reason "candidate's term (3) is lower than mine (4)"; response message: { term: 4, voteGranted: false, reason: "candidate's term (3) is lower than mine (4)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000001') }, lastCommittedOpTime: Timestamp(1589031451, 100), $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $clusterTime: { clusterTime: Timestamp(1589031451, 107), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031451, 104) }
2020-05-09T06:37:32.896-0700 I  ELECTION [replexec-2] not running for primary, we have been superseded already
2020-05-09T06:37:32.896-0700 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-05-09T06:37:32.898-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031451, 104), t: 3 } }
2020-05-09T06:37:32.898-0700 I  ELECTION [conn4] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-09T06:37:33.727-0700 I  REPL     [replexec-0] Member n4:27018 is now in state PRIMARY
2020-05-09T06:37:33.727-0700 I  ELECTION [replexec-0] Scheduling catchup takeover at 2020-05-09T06:37:36.727-0700
2020-05-09T06:37:34.009-0700 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n6:27018, my last fetched oplog optime: { ts: Timestamp(1589031452, 30), t: 3 }, latest oplog optime of sync source: { ts: Timestamp(1589031452, 30), t: 3 } (n4:27018 is)
2020-05-09T06:37:34.009-0700 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n6:27018, OpTime { ts: Timestamp(1589031452, 30), t: 3 }, its sync source index:-1
2020-05-09T06:37:34.010-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n6:27018 (config version: 1; last applied optime: { ts: Timestamp(1589031452, 30), t: 3 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T06:37:34.010-0700 I  REPL     [rsBackgroundSync] Clearing sync source n6:27018 to choose a new one.
2020-05-09T06:37:34.010-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:34.011-0700 I  REPL     [replexec-4] Canceling catchup takeover callback
2020-05-09T06:37:34.020-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n6:27018: InvalidSyncSource: Sync source was cleared. Was n6:27018
2020-05-09T06:37:34.192-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52088 #86 (44 connections now open)
2020-05-09T06:37:34.192-0700 I  NETWORK  [conn86] received client metadata from 192.168.122.1:52088 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:34.192-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52094 #87 (45 connections now open)
2020-05-09T06:37:34.193-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.1:52094 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:34.196-0700 I  NETWORK  [conn86] end connection 192.168.122.1:52088 (44 connections now open)
2020-05-09T06:37:34.196-0700 I  NETWORK  [conn87] end connection 192.168.122.1:52094 (43 connections now open)
2020-05-09T06:37:35.010-0700 I  REPL     [rsBackgroundSync] sync source candidate: n4:27018
2020-05-09T06:37:35.079-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:35.079-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 4
2020-05-09T06:37:35.079-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 994 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031452, 30), t: 3 } }
2020-05-09T06:37:35.079-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 995 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031452, 30), t: 3 } }
2020-05-09T06:37:35.079-0700 I  CONNPOOL [Replication] Connecting to n4:27018
2020-05-09T06:37:35.080-0700 I  ELECTION [replexec-1] VoteRequester(term 4 dry run) received a yes vote from n6:27018; response message: { term: 4, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1589031451, 100), $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031452, 30) }
2020-05-09T06:37:35.080-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 5
2020-05-09T06:37:35.087-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 996 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031452, 30), t: 3 } }
2020-05-09T06:37:35.087-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 997 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031452, 30), t: 3 } }
2020-05-09T06:37:35.088-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031452, 30), t: 3 } }
2020-05-09T06:37:35.088-0700 I  ELECTION [conn72] Sending vote response: { term: 5, voteGranted: false, reason: "candidate's term (4) is lower than mine (5)" }
2020-05-09T06:37:35.092-0700 I  ELECTION [replexec-0] VoteRequester(term 5) received a yes vote from n6:27018; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1589031451, 100), $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031452, 30) }
2020-05-09T06:37:35.092-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 5
2020-05-09T06:37:35.092-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-09T06:37:35.092-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-05-09T06:37:35.092-0700 I  CONNPOOL [Replication] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-05-09T06:37:35.092-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-09T06:37:35.511-0700 I  REPL     [replexec-2] Member n4:27018 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T06:37:35.511-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031452, 30), t: 3 }. My Last Applied: { ts: Timestamp(1589031452, 30), t: 3 }
2020-05-09T06:37:35.511-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:37:35.511-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:37:35.511-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 5
2020-05-09T06:37:35.511-0700 I  REPL     [rsBackgroundSync] failed to find sync source, received error CallbackCanceled: sync source resolver shut down while probing candidate: n4:27018
2020-05-09T06:37:35.511-0700 I  CONNPOOL [RS] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:35.512-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:35.512-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:35.512-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:35.514-0700 I  SHARDING [rsSync-0] The ChunkSplitter has started and will accept autosplit tasks.
2020-05-09T06:37:35.514-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:35.515-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.515-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:35.517-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34756 #89 (44 connections now open)
2020-05-09T06:37:35.517-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34758 #90 (45 connections now open)
2020-05-09T06:37:35.517-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.19:34756 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.518-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43722 #91 (46 connections now open)
2020-05-09T06:37:35.518-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.19:34758 conn90: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.518-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:52874 #92 (47 connections now open)
2020-05-09T06:37:35.518-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.12:43722 conn91: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.519-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40272 #93 (48 connections now open)
2020-05-09T06:37:35.519-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.17:52874 conn92: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.519-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43728 #94 (49 connections now open)
2020-05-09T06:37:35.519-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.11:40272 conn93: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.520-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.12:43728 conn94: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.522-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34768 #95 (50 connections now open)
2020-05-09T06:37:35.522-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:54436 #96 (51 connections now open)
2020-05-09T06:37:35.522-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.19:34768 conn95: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.522-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43872 #97 (52 connections now open)
2020-05-09T06:37:35.522-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.18:54436 conn96: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.522-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:52886 #98 (53 connections now open)
2020-05-09T06:37:35.522-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.13:43872 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.522-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:54442 #99 (54 connections now open)
2020-05-09T06:37:35.522-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.17:52886 conn98: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43878 #100 (55 connections now open)
2020-05-09T06:37:35.523-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.18:54442 conn99: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34780 #101 (56 connections now open)
2020-05-09T06:37:35.523-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.13:43878 conn100: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:52894 #102 (57 connections now open)
2020-05-09T06:37:35.523-0700 I  NETWORK  [conn101] received client metadata from 192.168.122.19:34780 conn101: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40292 #103 (58 connections now open)
2020-05-09T06:37:35.523-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.17:52894 conn102: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.523-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:52898 #104 (59 connections now open)
2020-05-09T06:37:35.523-0700 I  NETWORK  [conn103] received client metadata from 192.168.122.11:40292 conn103: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.523-0700 I  NETWORK  [conn104] received client metadata from 192.168.122.17:52898 conn104: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.547-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40296 #105 (60 connections now open)
2020-05-09T06:37:35.548-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.11:40296 conn105: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.637-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40298 #106 (61 connections now open)
2020-05-09T06:37:35.638-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.11:40298 conn106: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.778-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58916 #107 (62 connections now open)
2020-05-09T06:37:35.778-0700 I  NETWORK  [conn107] received client metadata from 192.168.122.16:58916 conn107: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.782-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58918 #108 (63 connections now open)
2020-05-09T06:37:35.782-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.16:58918 conn108: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.797-0700 I  COMMAND  [conn97] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 70, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52294", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 274ms
2020-05-09T06:37:35.797-0700 I  COMMAND  [conn99] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 79, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36228", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 273ms
2020-05-09T06:37:35.797-0700 I  COMMAND  [conn104] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 85, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35484", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 273ms
2020-05-09T06:37:35.797-0700 I  COMMAND  [conn100] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 84, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52286", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 273ms
2020-05-09T06:37:35.797-0700 I  COMMAND  [conn101] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 80, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:38038", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 273ms
2020-05-09T06:37:35.797-0700 I  COMMAND  [conn105] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 69, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59290", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 249ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn96] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 75, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36314", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 275ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn95] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 70, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:38094", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 275ms
2020-05-09T06:37:35.798-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn91] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 3, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:45602", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 3 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:546 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 275ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn98] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 74, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35540", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 274ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn102] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 81, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35518", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 274ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn103] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 89, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59320", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 274ms
2020-05-09T06:37:35.798-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn106] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 66, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59222", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:344 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } } } protocol:op_msg 159ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn78] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 1, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:45596", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:546 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 275ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 1, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:39024", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:546 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 276ms
2020-05-09T06:37:35.799-0700 I  TXN      [conn44] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031455, 2) } }, readTimestamp:Timestamp(1589031455, 2), terminationCause:aborted timeActiveMicros:473 timeInactiveMicros:276551 numYields:0 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } storage:{} wasPrepared:0, 277ms
2020-05-09T06:37:35.799-0700 I  TXN      [conn94] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031455, 2) } }, readTimestamp:Timestamp(1589031455, 2), terminationCause:aborted timeActiveMicros:490 timeInactiveMicros:276269 numYields:0 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } storage:{ data: { bytesRead: 1 } } wasPrepared:0, 276ms
2020-05-09T06:37:35.799-0700 I  TXN      [conn63] transaction parameters:{ lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 65, autocommit: false, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031455, 2) } }, readTimestamp:Timestamp(1589031455, 2), terminationCause:aborted timeActiveMicros:530 timeInactiveMicros:276551 numYields:0 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } storage:{} wasPrepared:0, 277ms
2020-05-09T06:37:35.801-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T06:37:35.802-0700 I  NETWORK  [conn45] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.803-0700 I  NETWORK  [conn45] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.803-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:35.803-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:35.803-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:35.803-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:35.803-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:35.804-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34258 #110 (64 connections now open)
2020-05-09T06:37:35.805-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.15:34258 conn110: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.806-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.806-0700 I  SHARDING [Sharding-Fixed-1] Updating config server with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.807-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34270 #117 (65 connections now open)
2020-05-09T06:37:35.807-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.807-0700 I  SHARDING [Sharding-Fixed-1] Updating config server with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.807-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 4 ms
2020-05-09T06:37:35.807-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.15:34270 conn117: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.807-0700 I  SHARDING [conn94] Marking collection jepsendb.jepsencoll as collection version: 1|6||5eb6b20e0f8124bc6bb7e6e0, shard version: 1|6||5eb6b20e0f8124bc6bb7e6e0
2020-05-09T06:37:35.807-0700 I  COMMAND  [conn94] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 85 }, u: { $push: { value: 4 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031455522), clusterTime: Timestamp(1589031455, 2) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031455, 2) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:44634", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:650 locks:{ ReplicationStateTransition: { acquireCount: { w: 8 } }, Global: { acquireCount: { r: 5, w: 2 } }, Database: { acquireCount: { r: 4, w: 2 } }, Collection: { acquireCount: { r: 2, w: 2 } }, Mutex: { acquireCount: { r: 7, W: 1 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 2 } storage:{ data: { bytesRead: 1 } } protocol:op_msg 285ms
2020-05-09T06:37:35.807-0700 I  COMMAND  [conn44] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 80 }, u: { $push: { value: 6 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031455521), clusterTime: Timestamp(1589031455, 2) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031455, 2) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36262", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:650 locks:{ ReplicationStateTransition: { acquireCount: { w: 8 } }, Global: { acquireCount: { r: 5, w: 2 } }, Database: { acquireCount: { r: 4, w: 2 } }, Collection: { acquireCount: { r: 2, w: 2 } }, Mutex: { acquireCount: { r: 7, W: 1 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 40 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 285ms
2020-05-09T06:37:35.807-0700 I  COMMAND  [conn63] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 80 }, u: { $push: { value: 1 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031455521), clusterTime: Timestamp(1589031455, 2) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 65, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031455, 2) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52212", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:650 locks:{ ReplicationStateTransition: { acquireCount: { w: 8 } }, Global: { acquireCount: { r: 5, w: 2 } }, Database: { acquireCount: { r: 4, w: 2 } }, Collection: { acquireCount: { r: 2, w: 2 } }, Mutex: { acquireCount: { r: 7, W: 1 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 35 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 285ms
2020-05-09T06:37:35.821-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43778 #118 (66 connections now open)
2020-05-09T06:37:35.821-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:34818 #119 (67 connections now open)
2020-05-09T06:37:35.821-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.12:43778 conn118: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.822-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:43782 #120 (68 connections now open)
2020-05-09T06:37:35.822-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.19:34818 conn119: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.822-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.12:43782 conn120: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.830-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58942 #121 (69 connections now open)
2020-05-09T06:37:35.831-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58944 #122 (70 connections now open)
2020-05-09T06:37:35.831-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.16:58942 conn121: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.831-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.16:58944 conn122: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.876-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34294 #123 (71 connections now open)
2020-05-09T06:37:35.877-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.15:34294 conn123: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.999-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34298 #124 (72 connections now open)
2020-05-09T06:37:35.999-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.15:34298 conn124: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:36.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34302 #125 (73 connections now open)
2020-05-09T06:37:36.092-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.15:34302 conn125: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:36.153-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52208 #128 (74 connections now open)
2020-05-09T06:37:36.153-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52210 #129 (75 connections now open)
2020-05-09T06:37:36.153-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.1:52208 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:36.154-0700 I  NETWORK  [conn129] received client metadata from 192.168.122.1:52210 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:36.156-0700 I  NETWORK  [conn129] end connection 192.168.122.1:52210 (74 connections now open)
2020-05-09T06:37:36.156-0700 I  NETWORK  [conn128] end connection 192.168.122.1:52208 (73 connections now open)
2020-05-09T06:37:36.184-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34318 #130 (74 connections now open)
2020-05-09T06:37:36.184-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:34320 #132 (75 connections now open)
2020-05-09T06:37:36.184-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.15:34318 conn130: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:36.184-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.15:34320 conn132: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:36.229-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:43966 #134 (76 connections now open)
2020-05-09T06:37:36.230-0700 I  NETWORK  [conn134] received client metadata from 192.168.122.13:43966 conn134: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:37.171-0700 I  REPL     [replexec-0] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:37.171-0700 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:37.171-0700 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-05-09T06:37:37.171-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:37.172-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:37.172-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 21, userOpsRunning: 0 }
2020-05-09T06:37:37.172-0700 W  COMMAND  [conn120] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.173-0700 I  COMMAND  [conn120] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 22, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 181), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:45596", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 872ms
2020-05-09T06:37:37.173-0700 W  COMMAND  [conn101] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.173-0700 I  COMMAND  [conn101] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 85, lsid: { id: UUID("6c6b4874-e98d-41cb-b89b-b9d8d73111ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 166), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:38094", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 916ms
2020-05-09T06:37:37.173-0700 W  COMMAND  [conn125] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.173-0700 I  COMMAND  [conn125] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 89, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 169), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54894", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 913ms
2020-05-09T06:37:37.173-0700 W  COMMAND  [conn79] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.173-0700 I  COMMAND  [conn79] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 94, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 127), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36228", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 94 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 975ms
2020-05-09T06:37:37.173-0700 W  COMMAND  [conn97] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.174-0700 I  COMMAND  [conn97] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 78, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 135), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52294", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 963ms
2020-05-09T06:37:37.174-0700 W  COMMAND  [conn100] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.174-0700 I  COMMAND  [conn100] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 75, lsid: { id: UUID("9fc3081a-6409-4831-aab2-837ae47b5f57"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 102), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52212", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 997ms
2020-05-09T06:37:37.175-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-09T06:37:37.175-0700 W  COMMAND  [conn102] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.175-0700 I  SHARDING [replexec-0] The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any autosplit tasks that have already started will be allowed to finish.
2020-05-09T06:37:37.175-0700 W  COMMAND  [conn123] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.175-0700 I  COMMAND  [conn102] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 93, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 155), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35540", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 929ms
2020-05-09T06:37:37.175-0700 W  COMMAND  [conn93] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.175-0700 I  COMMAND  [conn123] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 111, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 182), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54892", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 873ms
2020-05-09T06:37:37.175-0700 I  COMMAND  [conn93] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 107, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 170), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59320", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 107 has been aborted." errName:NoSuchTransaction errCode:251 reslen:590 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 914ms
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn48] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn118] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn92] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn118] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 19, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 173), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:45602", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 904ms
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn48] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 80, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 166), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59290", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 80 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 918ms
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn59] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn119] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn59] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 101, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 153), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35484", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 101 has been aborted." errName:NoSuchTransaction errCode:251 reslen:590 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 937ms
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn94] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn119] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 13, lsid: { id: UUID("24b9874a-7d96-41fc-8004-52eb11172039"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 116), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:39024", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 984ms
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn96] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn134] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn99] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn134] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 91, lsid: { id: UUID("50b1baf5-fb9a-45a2-b398-accae9f2cb94"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52286", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 945ms
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn99] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 88, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 146), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36262", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 951ms
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn92] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 96, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 170), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35518", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 96 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 914ms
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn64] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn94] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 92, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 172), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:44634", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 92 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 911ms
2020-05-09T06:37:37.176-0700 I  COMMAND  [conn96] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 91, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36314", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 reslen:462 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 2 } }, Collection: { acquireCount: { w: 2 } }, Mutex: { acquireCount: { r: 8 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 947ms
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn42] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.176-0700 W  COMMAND  [conn89] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:37.177-0700 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 80, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 136), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59222", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 80 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 964ms
2020-05-09T06:37:37.177-0700 I  COMMAND  [conn42] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 87, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 120), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54912", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 87 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 980ms
2020-05-09T06:37:37.177-0700 I  COMMAND  [conn89] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 96, lsid: { id: UUID("26e61263-8a31-4535-b936-4073d5e2bff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:38038", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Transaction 96 has been aborted." errName:NoSuchTransaction errCode:251 reslen:589 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 947ms
2020-05-09T06:37:37.508-0700 I  REPL     [replexec-1] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:37.512-0700 I  REPL     [replexec-2] Member n4:27018 is now in state PRIMARY
2020-05-09T06:37:37.924-0700 I  NETWORK  [conn4] end connection 192.168.122.14:54096 (75 connections now open)
2020-05-09T06:37:37.983-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.983-0700 I  SHARDING [Sharding-Fixed-10] Updating config server with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:38.178-0700 I  REPL     [rsBackgroundSync] sync source candidate: n4:27018
2020-05-09T06:37:38.180-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n4:27018
2020-05-09T06:37:38.180-0700 I  CONNPOOL [RS] Connecting to n4:27018
2020-05-09T06:37:38.182-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589031456, 183), t: 5 }. source's GTE: { ts: Timestamp(1589031457, 5), t: 6 }
2020-05-09T06:37:38.182-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589031456, 90), t: 5 }
2020-05-09T06:37:38.182-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T06:37:38.182-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n4:27018)
2020-05-09T06:37:38.182-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T06:37:38.182-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 1, userOpsRunning: 75 }
2020-05-09T06:37:38.182-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 134
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 132
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 130
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 125
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 124
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 123
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 122
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 121
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 120
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 119
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 118
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 117
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 110
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 108
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 107
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 105
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 104
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 103
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 102
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 101
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 100
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 99
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 98
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 96
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 95
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 94
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 93
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 92
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 91
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 84
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 78
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 56
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 55
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 27
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-09T06:37:38.182-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 16
2020-05-09T06:37:38.182-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T06:37:38.182-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T06:37:38.182-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T06:37:38.195-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589031456, 94), t: 5 }
2020-05-09T06:37:38.198-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 3
2020-05-09T06:37:38.198-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T06:37:38.198-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection jepsendb.jepsencoll with uuid 369a08af-19c6-4a50-a50a-0622ffd47ed1 to /var/lib/mongodb/rollback/jepsendb.jepsencoll/removed.2020-05-09T13-37-38.0.bson
2020-05-09T06:37:38.199-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T06:37:38.200-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T06:37:38.200-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T06:37:38.200-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T06:37:38.200-0700 W  QUERY    [conn108] GetMore command executor error: FAILURE, status: InterruptedDueToReplStateChange: operation was interrupted, stats: { stage: "COLLSCAN", nReturned: 227, executionTimeMillisEstimate: 2, works: 721, advanced: 227, needTime: 247, needYield: 0, saveState: 247, restoreState: 246, isEOF: 0, direction: "forward", docsExamined: 227 }
2020-05-09T06:37:38.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56094 #137 (76 connections now open)
2020-05-09T06:37:38.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56092 #138 (77 connections now open)
2020-05-09T06:37:38.208-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.14:56094 conn137: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:38.208-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.14:56092 conn138: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:38.294-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589031456, 90) Initial Data Timestamp: Timestamp(1589031429, 3)
2020-05-09T06:37:38.295-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T06:37:38.299-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T06:37:38.299-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 1347 records totaling to 284506 bytes
2020-05-09T06:37:38.299-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:38.300-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:38.303-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T06:37:38.303-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T06:37:38.311-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T06:37:38.311-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T06:37:38.311-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589031456, 90)
2020-05-09T06:37:38.311-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 4 insert operations, 8 update operations and 0 delete operations.
2020-05-09T06:37:38.311-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589031456, 103), t: 5 }
2020-05-09T06:37:38.311-0700 I  COMMAND  [conn108] command local.oplog.rs command: find { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031456, 183) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 6, readConcern: { afterClusterTime: Timestamp(0, 1) }, $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1589031457, 27), signature: { hash: BinData(0, 2975B3F78A5A661CB5F367E1AE4DE4098772F974), keyId: 6824838024166113299 } }, $db: "local" } numYields:0 ok:0 errMsg:"Oplog collection reads are not allowed while in the rollback or startup state." errName:NotMasterOrSecondary errCode:13436 reslen:868 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 3 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 109962 } }, Database: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 110ms
2020-05-09T06:37:38.312-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589031456, 103) }
2020-05-09T06:37:38.312-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T06:37:38.315-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589031456, 90) (top of oplog: { ts: Timestamp(1589031456, 94), t: 5 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T06:37:38.315-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589031456, 90)
2020-05-09T06:37:38.315-0700 I  REPL     [rsBackgroundSync] Replaying stored operations from Timestamp(1589031456, 90) (inclusive) to Timestamp(1589031456, 94) (inclusive).
2020-05-09T06:37:38.318-0700 I  REPL     [rsBackgroundSync] Applied 1 operations in 1 batches. Last operation applied with optime: { ts: Timestamp(1589031456, 94), t: 5 }
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T06:37:38.320-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T06:37:38.182-0700
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T06:37:38.320-0700
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n4:27018
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/jepsendb.jepsencoll
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 3
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589031456, 183), t: 5 }
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589031456, 94), t: 5 }
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T06:37:36.302-0700
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T06:37:36.176-0700
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589031456, 103)
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589031456, 90)
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: 
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 		08a6ed21-9bf1-4197-9826-7e70d71c6e60
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 		24b9874a-7d96-41fc-8004-52eb11172039
2020-05-09T06:37:38.320-0700 I  ROLLBACK [rsBackgroundSync] 		29dac40d-f8cc-40d2-8750-948aba1d1c87
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		50b1baf5-fb9a-45a2-b398-accae9f2cb94
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		5466143c-6e64-4c36-a7b9-0c13071e589b
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		57bdd1a3-c100-49b5-8b97-747191521968
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		6c6b4874-e98d-41cb-b89b-b9d8d73111ea
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		7e55ea3e-f5d2-4bcf-935b-4a14245efc81
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		9fc3081a-6409-4831-aab2-837ae47b5f57
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		a3f8e68d-5ad2-4a5f-a69f-48811aa1549a
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		a83d102d-69a3-4d89-8bdb-48f20a51e81b
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		b8678949-c9e9-4b4d-9995-da5acd5a4fc9
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		jepsendb.jepsencoll
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 4
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		update: 8
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 62
2020-05-09T06:37:38.321-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T06:37:38.321-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T06:37:38.321-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n4:27018
2020-05-09T06:37:38.321-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T06:37:38.321-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T06:37:38.321-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T06:37:38.321-0700 I  REPL     [rsBackgroundSync] sync source candidate: n4:27018
2020-05-09T06:37:38.323-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n4:27018
2020-05-09T06:37:38.826-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52302 #139 (78 connections now open)
2020-05-09T06:37:38.826-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:52302 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:38.826-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52306 #140 (79 connections now open)
2020-05-09T06:37:38.827-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.1:52306 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:38.828-0700 I  NETWORK  [conn139] end connection 192.168.122.1:52302 (78 connections now open)
2020-05-09T06:37:38.829-0700 I  NETWORK  [conn140] end connection 192.168.122.1:52306 (77 connections now open)
2020-05-09T06:37:39.951-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 6, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031458, 449), t: 6 } }
2020-05-09T06:37:39.951-0700 I  ELECTION [conn72] Sending vote response: { term: 6, voteGranted: true, reason: "" }
2020-05-09T06:37:39.955-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031458, 449), t: 6 } }
2020-05-09T06:37:39.955-0700 I  ELECTION [conn72] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-05-09T06:37:40.509-0700 I  REPL     [replexec-1] Member n6:27018 is now in state PRIMARY
2020-05-09T06:37:40.509-0700 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-05-09T06:37:42.651-0700
2020-05-09T06:37:40.513-0700 I  REPL     [replexec-0] Member n4:27018 is now in state SECONDARY
2020-05-09T06:37:40.785-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52366 #141 (78 connections now open)
2020-05-09T06:37:40.785-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52368 #142 (79 connections now open)
2020-05-09T06:37:40.785-0700 I  NETWORK  [conn141] received client metadata from 192.168.122.1:52366 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:40.785-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.1:52368 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:40.790-0700 I  NETWORK  [conn141] end connection 192.168.122.1:52366 (78 connections now open)
2020-05-09T06:37:40.790-0700 I  NETWORK  [conn142] end connection 192.168.122.1:52368 (77 connections now open)
2020-05-09T06:37:42.204-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n4:27018, my last fetched oplog optime: { ts: Timestamp(1589031460, 13), t: 7 }, latest oplog optime of sync source: { ts: Timestamp(1589031460, 13), t: 7 } (sync source does not know the primary)
2020-05-09T06:37:42.204-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n4:27018, OpTime { ts: Timestamp(1589031460, 13), t: 7 }, its sync source index:-1
2020-05-09T06:37:42.205-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n4:27018 (config version: 1; last applied optime: { ts: Timestamp(1589031460, 13), t: 7 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-09T06:37:42.205-0700 I  REPL     [rsBackgroundSync] Clearing sync source n4:27018 to choose a new one.
2020-05-09T06:37:42.205-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:42.206-0700 I  REPL     [replexec-5] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:42.208-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n4:27018: InvalidSyncSource: Sync source was cleared. Was n4:27018
2020-05-09T06:37:42.222-0700 I  ELECTION [conn138] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:42.222-0700 I  ELECTION [conn138] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-05-09T06:37:42.229-0700 I  REPL     [conn138] Canceling priority takeover callback
2020-05-09T06:37:42.229-0700 I  ELECTION [conn138] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:42.229-0700 I  ELECTION [conn138] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-05-09T06:37:42.707-0700 I  REPL     [replexec-5] Member n4:27018 is now in state PRIMARY
2020-05-09T06:37:42.889-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52422 #143 (78 connections now open)
2020-05-09T06:37:42.889-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52424 #144 (79 connections now open)
2020-05-09T06:37:42.889-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.1:52422 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:42.889-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.1:52424 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:42.893-0700 I  NETWORK  [conn143] end connection 192.168.122.1:52422 (78 connections now open)
2020-05-09T06:37:42.894-0700 I  NETWORK  [conn144] end connection 192.168.122.1:52424 (77 connections now open)
2020-05-09T06:37:43.206-0700 I  REPL     [rsBackgroundSync] sync source candidate: n4:27018
2020-05-09T06:37:43.774-0700 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:43.774-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 8
2020-05-09T06:37:43.774-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1309 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:43.774-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1310 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:43.775-0700 I  ELECTION [replexec-3] VoteRequester(term 8 dry run) received a no vote from n6:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 13), t: 7 }, my last applied OpTime: { ts: Timestamp(1589031462, 103), t: 8 }"; response message: { term: 8, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 13), t: 7 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1589031462, 103), $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $clusterTime: { clusterTime: Timestamp(1589031462, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031462, 103) }
2020-05-09T06:37:43.821-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 8, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031462, 103), t: 8 } }
2020-05-09T06:37:43.821-0700 I  ELECTION [conn72] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-05-09T06:37:43.826-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 9, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031462, 103), t: 8 } }
2020-05-09T06:37:43.826-0700 I  ELECTION [conn72] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-09T06:37:44.207-0700 I  REPL     [replexec-2] Member n4:27018 is now in state RS_DOWN - Request 1308 timed out, deadline was 2020-05-09T06:37:44.207-0700, op was RemoteCommand 1308 -- target:[n4:27018] db:admin expDate:2020-05-09T06:37:44.207-0700 cmd:{ replSetHeartbeat: "rs_shard1", configVersion: 1, hbv: 1, from: "n5:27018", fromId: 1, term: 8 }
2020-05-09T06:37:44.207-0700 I  CONNPOOL [Replication] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:44.774-0700 I  ELECTION [replexec-1] VoteRequester(term 8 dry run) failed to receive response from n4:27018: NetworkInterfaceExceededTimeLimit: Request 1309 timed out, deadline was 2020-05-09T06:37:44.774-0700, op was RemoteCommand 1309 -- target:[n4:27018] db:admin expDate:2020-05-09T06:37:44.774-0700 cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:44.774-0700 I  CONNPOOL [Replication] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:44.774-0700 I  ELECTION [replexec-1] not running for primary, we have been superseded already during dry run. original term: 8, current term: 9
2020-05-09T06:37:44.774-0700 I  ELECTION [replexec-1] Lost dry run election due to internal error
2020-05-09T06:37:44.774-0700 I  CONNPOOL [Replication] Connecting to n4:27018
2020-05-09T06:37:44.865-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:44.865-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 9
2020-05-09T06:37:44.865-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1311 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:44.865-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1312 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 13), t: 7 } }
2020-05-09T06:37:44.866-0700 I  ELECTION [replexec-2] VoteRequester(term 9 dry run) received a no vote from n6:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 13), t: 7 }, my last applied OpTime: { ts: Timestamp(1589031463, 2), t: 9 }"; response message: { term: 9, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 13), t: 7 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1589031462, 103), $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $clusterTime: { clusterTime: Timestamp(1589031464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031463, 2) }
2020-05-09T06:37:44.928-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n4:27018
2020-05-09T06:37:44.935-0700 I  REPL     [replication-0] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n4:27018, my last fetched oplog optime: { ts: Timestamp(1589031462, 103), t: 8 }, latest oplog optime of sync source: { ts: Timestamp(1589031462, 103), t: 8 } (sync source does not know the primary)
2020-05-09T06:37:44.935-0700 I  REPL     [replication-0] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n4:27018, OpTime { ts: Timestamp(1589031462, 103), t: 8 }, its sync source index:-1
2020-05-09T06:37:44.935-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n4:27018 (config version: 1; last applied optime: { ts: Timestamp(1589031462, 103), t: 8 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-09T06:37:44.935-0700 I  REPL     [rsBackgroundSync] Clearing sync source n4:27018 to choose a new one.
2020-05-09T06:37:44.935-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:44.937-0700 I  ELECTION [replexec-2] VoteRequester(term 9 dry run) received a no vote from n4:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 13), t: 7 }, my last applied OpTime: { ts: Timestamp(1589031462, 103), t: 8 }"; response message: { term: 9, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 13), t: 7 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000008') }, lastCommittedOpTime: Timestamp(1589031462, 103), $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $clusterTime: { clusterTime: Timestamp(1589031464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031462, 103) }
2020-05-09T06:37:44.937-0700 I  ELECTION [replexec-2] not running for primary, we received insufficient votes
2020-05-09T06:37:44.937-0700 I  ELECTION [replexec-2] Lost dry run election due to internal error
2020-05-09T06:37:44.938-0700 I  REPL     [replexec-1] Member n4:27018 is now in state SECONDARY
2020-05-09T06:37:44.943-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n4:27018: InvalidSyncSource: Sync source was cleared. Was n4:27018
2020-05-09T06:37:45.020-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52494 #146 (78 connections now open)
2020-05-09T06:37:45.020-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52498 #147 (79 connections now open)
2020-05-09T06:37:45.020-0700 I  NETWORK  [conn146] received client metadata from 192.168.122.1:52494 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:45.021-0700 I  NETWORK  [conn147] received client metadata from 192.168.122.1:52498 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:45.024-0700 I  NETWORK  [conn146] end connection 192.168.122.1:52494 (78 connections now open)
2020-05-09T06:37:45.026-0700 I  NETWORK  [conn147] end connection 192.168.122.1:52498 (77 connections now open)
2020-05-09T06:37:45.868-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:45.868-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 9
2020-05-09T06:37:45.868-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1331 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031462, 103), t: 8 } }
2020-05-09T06:37:45.868-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1332 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031462, 103), t: 8 } }
2020-05-09T06:37:45.869-0700 I  ELECTION [replexec-1] VoteRequester(term 9 dry run) received a no vote from n4:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031462, 103), t: 8 }, my last applied OpTime: { ts: Timestamp(1589031463, 2), t: 9 }"; response message: { term: 9, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031462, 103), t: 8 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000008') }, lastCommittedOpTime: Timestamp(1589031462, 103), $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $clusterTime: { clusterTime: Timestamp(1589031464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031463, 2) }
2020-05-09T06:37:45.869-0700 I  ELECTION [replexec-3] VoteRequester(term 9 dry run) received a no vote from n6:27018 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031462, 103), t: 8 }, my last applied OpTime: { ts: Timestamp(1589031463, 2), t: 9 }"; response message: { term: 9, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031462, 103), t: 8 }, my last applied OpTime: { ts: Timesta...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1589031462, 103), $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $clusterTime: { clusterTime: Timestamp(1589031464, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031463, 2) }
2020-05-09T06:37:45.869-0700 I  ELECTION [replexec-3] not running for primary, we received insufficient votes
2020-05-09T06:37:45.869-0700 I  ELECTION [replexec-3] Lost dry run election due to internal error
2020-05-09T06:37:45.898-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 9, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 2), t: 9 } }
2020-05-09T06:37:45.898-0700 I  ELECTION [conn72] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-09T06:37:45.903-0700 I  ELECTION [conn72] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031463, 2), t: 9 } }
2020-05-09T06:37:45.903-0700 I  ELECTION [conn72] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-09T06:37:45.908-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:59272 #149 (78 connections now open)
2020-05-09T06:37:45.908-0700 I  NETWORK  [conn72] end connection 192.168.122.16:58664 (77 connections now open)
2020-05-09T06:37:45.908-0700 I  NETWORK  [conn149] received client metadata from 192.168.122.16:59272 conn149: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:45.936-0700 I  REPL     [rsBackgroundSync] sync source candidate: n6:27018
2020-05-09T06:37:45.937-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n6:27018
2020-05-09T06:37:45.937-0700 I  REPL     [replexec-1] Member n6:27018 is now in state PRIMARY
2020-05-09T06:37:45.938-0700 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-05-09T06:37:47.985-0700
2020-05-09T06:37:46.733-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:46.746-0700 I  NETWORK  [Sharding-Fixed-7] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:46.747-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.132-0700 I  ELECTION [conn138] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 10, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031467, 32), t: 10 } }
2020-05-09T06:37:47.132-0700 I  ELECTION [conn138] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-09T06:37:47.135-0700 I  REPL     [conn138] Canceling priority takeover callback
2020-05-09T06:37:47.135-0700 I  ELECTION [conn138] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031467, 33), t: 10 } }
2020-05-09T06:37:47.135-0700 I  ELECTION [conn138] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-09T06:37:47.137-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n6:27018, my last fetched oplog optime: { ts: Timestamp(1589031467, 35), t: 10 }, latest oplog optime of sync source: { ts: Timestamp(1589031467, 35), t: 10 } (sync source does not know the primary)
2020-05-09T06:37:47.139-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n6:27018, OpTime { ts: Timestamp(1589031467, 35), t: 10 }, its sync source index:-1
2020-05-09T06:37:47.139-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n6:27018 (config version: 1; last applied optime: { ts: Timestamp(1589031467, 35), t: 10 }; sync source index: -1; primary index: -1) is no longer valid
2020-05-09T06:37:47.139-0700 I  REPL     [rsBackgroundSync] Clearing sync source n6:27018 to choose a new one.
2020-05-09T06:37:47.139-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T06:37:47.140-0700 I  REPL     [replexec-0] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:47.140-0700 I  REPL     [replexec-2] Member n4:27018 is now in state PRIMARY
2020-05-09T06:37:47.247-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.579-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52578 #150 (78 connections now open)
2020-05-09T06:37:47.579-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52582 #151 (79 connections now open)
2020-05-09T06:37:47.579-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.1:52578 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.580-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.1:52582 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.583-0700 I  NETWORK  [conn150] end connection 192.168.122.1:52578 (78 connections now open)
2020-05-09T06:37:47.583-0700 I  NETWORK  [conn151] end connection 192.168.122.1:52582 (77 connections now open)
2020-05-09T06:37:47.639-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n6:27018: InvalidSyncSource: Sync source was cleared. Was n6:27018
2020-05-09T06:37:47.747-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:48.147-0700 I  ELECTION [conn149] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031467, 35), t: 10 } }
2020-05-09T06:37:48.147-0700 I  ELECTION [conn149] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-09T06:37:48.151-0700 I  ELECTION [conn149] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 12, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031467, 35), t: 10 } }
2020-05-09T06:37:48.151-0700 I  ELECTION [conn149] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-05-09T06:37:48.247-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.247-0700 I  SHARDING [Sharding-Fixed-1] Updating config server with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.258-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 3), t: 15 }
2020-05-09T06:37:48.640-0700 I  REPL     [replexec-1] Member n4:27018 is now in state RS_DOWN - Request 1458 timed out, deadline was 2020-05-09T06:37:48.640-0700, op was RemoteCommand 1458 -- target:[n4:27018] db:admin expDate:2020-05-09T06:37:48.640-0700 cmd:{ replSetHeartbeat: "rs_shard1", configVersion: 1, hbv: 1, from: "n5:27018", fromId: 1, term: 11 }
2020-05-09T06:37:48.640-0700 I  CONNPOOL [Replication] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:48.641-0700 I  REPL     [replexec-5] Member n6:27018 is now in state PRIMARY
2020-05-09T06:37:48.641-0700 I  ELECTION [replexec-5] Scheduling priority takeover at 2020-05-09T06:37:50.704-0700
2020-05-09T06:37:49.141-0700 I  REPL     [replexec-1] Member n4:27018 is now in state SECONDARY
2020-05-09T06:37:49.809-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52724 #152 (78 connections now open)
2020-05-09T06:37:49.809-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52732 #153 (79 connections now open)
2020-05-09T06:37:49.809-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:52724 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:49.810-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:52732 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:49.811-0700 I  NETWORK  [conn152] end connection 192.168.122.1:52724 (78 connections now open)
2020-05-09T06:37:49.812-0700 I  NETWORK  [conn153] end connection 192.168.122.1:52732 (77 connections now open)
2020-05-09T06:37:50.140-0700 I  REPL     [rsBackgroundSync] sync source candidate: n4:27018
2020-05-09T06:37:50.142-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n4:27018
2020-05-09T06:37:50.648-0700 I  ELECTION [conn138] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 213), t: 12 } }
2020-05-09T06:37:50.649-0700 I  ELECTION [conn138] Sending vote response: { term: 12, voteGranted: true, reason: "" }
2020-05-09T06:37:50.651-0700 I  REPL     [replication-0] Canceling priority takeover callback
2020-05-09T06:37:50.654-0700 I  ELECTION [conn138] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 213), t: 12 } }
2020-05-09T06:37:50.654-0700 I  ELECTION [conn138] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-05-09T06:37:51.142-0700 I  REPL     [replexec-5] Member n6:27018 is now in state RS_DOWN - Request 1478 timed out, deadline was 2020-05-09T06:37:51.142-0700, op was RemoteCommand 1478 -- target:[n6:27018] db:admin expDate:2020-05-09T06:37:51.142-0700 cmd:{ replSetHeartbeat: "rs_shard1", configVersion: 1, hbv: 1, from: "n5:27018", fromId: 1, term: 12 }
2020-05-09T06:37:51.142-0700 I  CONNPOOL [Replication] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:51.814-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52770 #154 (78 connections now open)
2020-05-09T06:37:51.814-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:52774 #155 (79 connections now open)
2020-05-09T06:37:51.814-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.1:52770 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:51.814-0700 I  NETWORK  [conn155] received client metadata from 192.168.122.1:52774 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:51.817-0700 I  NETWORK  [conn154] end connection 192.168.122.1:52770 (78 connections now open)
2020-05-09T06:37:51.818-0700 I  NETWORK  [conn155] end connection 192.168.122.1:52774 (77 connections now open)
2020-05-09T06:37:51.839-0700 I  NETWORK  [conn149] end connection 192.168.122.16:59272 (76 connections now open)
2020-05-09T06:37:52.159-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:59528 #156 (77 connections now open)
2020-05-09T06:37:52.160-0700 I  NETWORK  [conn156] received client metadata from 192.168.122.16:59528 conn156: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:52.864-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 13, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:37:52.865-0700 I  ELECTION [conn156] Sending vote response: { term: 13, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:37:52.948-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:52.948-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 13
2020-05-09T06:37:52.948-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1532 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031471, 7), t: 13 } }
2020-05-09T06:37:52.948-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1533 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031471, 7), t: 13 } }
2020-05-09T06:37:52.948-0700 I  CONNPOOL [Replication] Connecting to n4:27018
2020-05-09T06:37:52.949-0700 I  ELECTION [replexec-3] VoteRequester(term 13 dry run) received a yes vote from n6:27018; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031472, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:52.949-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 14
2020-05-09T06:37:52.952-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1534 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031471, 7), t: 13 } }
2020-05-09T06:37:52.952-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1535 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031471, 7), t: 13 } }
2020-05-09T06:37:52.958-0700 I  ELECTION [replexec-2] VoteRequester(term 14) received a yes vote from n6:27018; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031472, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:52.958-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 14
2020-05-09T06:37:52.958-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:52.958-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was n4:27018
2020-05-09T06:37:52.958-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:37:52.958-0700 I  CONNPOOL [Replication] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 2 connections to that host remain open
2020-05-09T06:37:52.959-0700 I  REPL     [replexec-5] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:53.141-0700 I  REPL     [replexec-2] Member n4:27018 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T06:37:53.141-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031469, 216), t: 12 }. My Last Applied: { ts: Timestamp(1589031471, 7), t: 13 }
2020-05-09T06:37:53.141-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:37:53.141-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:37:53.141-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 14
2020-05-09T06:37:53.141-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T06:37:53.141-0700 I  CONNPOOL [RS] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:53.141-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:53.142-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:53.142-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:53.143-0700 I  SHARDING [rsSync-0] The ChunkSplitter has started and will accept autosplit tasks.
2020-05-09T06:37:53.143-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:53.143-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:53.321-0700 I  SHARDING [conn63] Received request from 192.168.122.13:43496 indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 3), t: 15 }, now { ts: Timestamp(1589031470, 6), t: 16 }
2020-05-09T06:37:53.959-0700 I  REPL     [replexec-1] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:53.959-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:53.959-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-09T06:37:53.959-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:53.959-0700 W  COMMAND  [conn94] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn94] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 137, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031473, 1), signature: { hash: BinData(0, E10D9FDD731CE9FA2E87D8B99AB360494AB5B6EC), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:44634", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 137 does not match any in-progress transactions. The active transaction number is 135" errName:NoSuchTransaction errCode:251 reslen:667 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 636ms
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn83] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn64] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn42] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn134] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn61] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn89] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn62] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn83] command jepsendb.$cmd command: find { find: "jepsencoll", filter: { _id: 134 }, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031471, 24) }, limit: 1, runtimeConstants: { localNow: new Date(1589031471996), clusterTime: Timestamp(1589031471, 24) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], txnNumber: 128, startTransaction: true, coordinator: true, autocommit: false, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, C7A86767DF6D1DFB70D642EDF217D31A940B6ACE), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54894", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:458 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 461ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn62] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 142 }, u: { $push: { value: 3 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031472106), clusterTime: Timestamp(1589031472, 23) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 140, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031472, 23) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031472, 24), signature: { hash: BinData(0, C7A86767DF6D1DFB70D642EDF217D31A940B6ACE), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:52208", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:478 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 461ms
2020-05-09T06:37:53.960-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 10, userOpsRunning: 0 }
2020-05-09T06:37:53.960-0700 W  COMMAND  [conn60] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn42] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 139 }, u: { $push: { value: 6 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031472038), clusterTime: Timestamp(1589031472, 12) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031472, 12) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, C7A86767DF6D1DFB70D642EDF217D31A940B6ACE), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:56434", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:478 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 462ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn60] command jepsendb.$cmd command: find { find: "jepsencoll", filter: { _id: 139 }, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031472, 21) }, limit: 1, runtimeConstants: { localNow: new Date(1589031472091), clusterTime: Timestamp(1589031472, 21) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], txnNumber: 147, startTransaction: true, coordinator: true, autocommit: false, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, C7A86767DF6D1DFB70D642EDF217D31A940B6ACE), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54892", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:478 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 462ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn134] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, coordinator: true, autocommit: false, txnNumber: 144, lsid: { id: UUID("08a6ed21-9bf1-4197-9826-7e70d71c6e60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031473, 1), signature: { hash: BinData(0, E10D9FDD731CE9FA2E87D8B99AB360494AB5B6EC), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52294", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 144 does not match any in-progress transactions. The active transaction number is 142" errName:NoSuchTransaction errCode:251 reslen:616 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 3 } protocol:op_msg 636ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn61] command jepsendb.$cmd command: find { find: "jepsencoll", filter: { _id: 84 }, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031472, 23) }, limit: 1, runtimeConstants: { localNow: new Date(1589031472106), clusterTime: Timestamp(1589031472, 23) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], txnNumber: 7, startTransaction: true, coordinator: true, autocommit: false, lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031472, 24), signature: { hash: BinData(0, C7A86767DF6D1DFB70D642EDF217D31A940B6ACE), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:53736", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:478 locks:{ ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 1 } }, Database: { acquireCount: { r: 2, w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 4 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 461ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn89] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 3, lsid: { id: UUID("a70f7f56-11c8-44cd-a3f7-4d3434d48e98"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031473, 4), signature: { hash: BinData(0, E10D9FDD731CE9FA2E87D8B99AB360494AB5B6EC), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:39546", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 3 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:664 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 498ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 5, lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031473, 1), signature: { hash: BinData(0, E10D9FDD731CE9FA2E87D8B99AB360494AB5B6EC), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:60804", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 5 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:664 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 636ms
2020-05-09T06:37:53.960-0700 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority", wtimeout: 0 }, coordinator: true, autocommit: false, txnNumber: 17, lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $clusterTime: { clusterTime: Timestamp(1589031473, 5), signature: { hash: BinData(0, E10D9FDD731CE9FA2E87D8B99AB360494AB5B6EC), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:53724", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Given transaction number 17 does not match any in-progress transactions. The active transaction number is 14" errName:NoSuchTransaction errCode:251 reslen:665 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, oplog: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 458ms
2020-05-09T06:37:53.960-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-09T06:37:53.960-0700 I  SHARDING [replexec-1] The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any autosplit tasks that have already started will be allowed to finish.
2020-05-09T06:37:53.961-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-09T06:37:54.094-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 14, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:37:54.094-0700 I  ELECTION [conn156] Sending vote response: { term: 14, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:37:54.960-0700 I  REPL     [replexec-0] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:54.961-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:54.961-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 14
2020-05-09T06:37:54.961-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1540 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:54.961-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1541 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:54.961-0700 I  ELECTION [replexec-4] VoteRequester(term 14 dry run) received a yes vote from n6:27018; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031473, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:54.961-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 15
2020-05-09T06:37:54.972-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1542 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:54.972-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1543 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:54.977-0700 I  ELECTION [replexec-2] VoteRequester(term 15) received a yes vote from n6:27018; response message: { term: 15, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031473, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:54.978-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 15
2020-05-09T06:37:54.978-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:54.978-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-09T06:37:54.978-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:37:55.978-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T06:37:55.978-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:37:55.978-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:37:55.978-0700 I  REPL     [replexec-5] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:55.978-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:55.978-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T06:37:55.978-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 15
2020-05-09T06:37:55.978-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:55.978-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:55.978-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:55.979-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:55.979-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-09T06:37:55.979-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:55.979-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:56.012-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 15, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:37:56.012-0700 I  ELECTION [conn156] Sending vote response: { term: 15, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:37:56.978-0700 I  REPL     [replexec-3] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:57.089-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 15, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:37:57.089-0700 I  ELECTION [conn156] Sending vote response: { term: 15, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:37:57.092-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:57.092-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 15
2020-05-09T06:37:57.092-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1548 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:57.092-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1549 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:57.093-0700 I  ELECTION [replexec-0] VoteRequester(term 15 dry run) received a yes vote from n6:27018; response message: { term: 15, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031474, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:57.093-0700 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 16
2020-05-09T06:37:57.105-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1550 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:57.105-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1551 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:57.110-0700 I  ELECTION [replexec-2] VoteRequester(term 16) received a yes vote from n6:27018; response message: { term: 16, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031474, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:57.110-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 16
2020-05-09T06:37:57.110-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:57.110-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-09T06:37:57.110-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-4] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-09T06:37:58.110-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 16
2020-05-09T06:37:58.110-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:58.110-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:58.110-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:58.110-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:58.110-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-09T06:37:58.110-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:58.110-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:58.154-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 16, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:37:58.154-0700 I  ELECTION [conn156] Sending vote response: { term: 16, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:37:59.110-0700 I  REPL     [replexec-5] Member n6:27018 is now in state SECONDARY
2020-05-09T06:37:59.184-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:59.184-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 16
2020-05-09T06:37:59.184-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1556 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:59.184-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1557 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:59.184-0700 I  ELECTION [replexec-1] VoteRequester(term 16 dry run) received a yes vote from n6:27018; response message: { term: 16, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031477, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:59.184-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 17
2020-05-09T06:37:59.193-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1558 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:59.193-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1559 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031473, 6), t: 14 } }
2020-05-09T06:37:59.197-0700 I  ELECTION [replexec-2] VoteRequester(term 17) received a yes vote from n6:27018; response message: { term: 17, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031477, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:37:59.197-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 17
2020-05-09T06:37:59.198-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:59.198-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-09T06:37:59.198-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:38:00.198-0700 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-05-09T06:38:00.198-0700 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-05-09T06:38:00.198-0700 I  REPL     [replexec-4] Stopping replication producer
2020-05-09T06:38:00.198-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 17
2020-05-09T06:38:00.198-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 17
2020-05-09T06:38:00.198-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:00.198-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:00.198-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:00.200-0700 I  SHARDING [rsSync-0] The ChunkSplitter has started and will accept autosplit tasks.
2020-05-09T06:38:00.200-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:38:00.200-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:38:01.161-0700 I  REPL     [replexec-1] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:38:01.161-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-09T06:38:01.161-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-09T06:38:01.161-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:01.161-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:01.161-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T06:38:01.162-0700 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:38:01.162-0700 W  COMMAND  [conn60] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:38:01.162-0700 I  COMMAND  [conn43] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 142 }, u: { $push: { value: 3 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031477109), clusterTime: Timestamp(1589031473, 6) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 141, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031480, 7) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031480, 7), signature: { hash: BinData(0, F8DAFE6D753CDAF689D5652050C0A541C385E651), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:53966", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031480, 1), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:478 locks:{ ReplicationStateTransition: { acquireCount: { w: 4 } }, Global: { acquireCount: { r: 3 } }, Database: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 662ms
2020-05-09T06:38:01.162-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-09T06:38:01.162-0700 I  COMMAND  [conn60] command jepsendb.$cmd command: update { update: "jepsencoll", bypassDocumentValidation: false, ordered: true, stmtIds: [ 0 ], updates: [ { q: { _id: 139 }, u: { $push: { value: 6 } }, multi: false, upsert: true } ], runtimeConstants: { localNow: new Date(1589031477043), clusterTime: Timestamp(1589031473, 6) }, shardVersion: [ Timestamp(1, 6), ObjectId('5eb6b20e0f8124bc6bb7e6e0') ], allowImplicitCollectionCreation: false, lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, readConcern: { level: "snapshot", atClusterTime: Timestamp(1589031480, 6) }, startTransaction: true, coordinator: true, autocommit: false, $clusterTime: { clusterTime: Timestamp(1589031480, 6), signature: { hash: BinData(0, F8DAFE6D753CDAF689D5652050C0A541C385E651), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:56680", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031480, 1), t: 16 } }, $db: "jepsendb" } numYields:0 ok:0 errMsg:"operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:478 locks:{ ReplicationStateTransition: { acquireCount: { w: 4 } }, Global: { acquireCount: { r: 3 } }, Database: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 662ms
2020-05-09T06:38:01.162-0700 I  SHARDING [replexec-1] The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any autosplit tasks that have already started will be allowed to finish.
2020-05-09T06:38:01.162-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-09T06:38:01.174-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:01.174-0700 I  ELECTION [conn156] Sending vote response: { term: 17, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:38:01.198-0700 I  REPL     [replexec-4] Member n6:27018 is now in state SECONDARY
2020-05-09T06:38:02.232-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 17, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:02.232-0700 I  ELECTION [conn156] Sending vote response: { term: 17, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:38:02.261-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:38:02.261-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 17
2020-05-09T06:38:02.261-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1567 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031480, 7), t: 17 } }
2020-05-09T06:38:02.261-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1568 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 17, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031480, 7), t: 17 } }
2020-05-09T06:38:02.261-0700 I  ELECTION [replexec-2] VoteRequester(term 17 dry run) received a yes vote from n6:27018; response message: { term: 17, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031480, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:02.261-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 18
2020-05-09T06:38:02.269-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1569 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 18, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031480, 7), t: 17 } }
2020-05-09T06:38:02.269-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1570 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 18, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031480, 7), t: 17 } }
2020-05-09T06:38:02.274-0700 I  ELECTION [replexec-4] VoteRequester(term 18) received a yes vote from n6:27018; response message: { term: 18, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031480, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:02.274-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 18
2020-05-09T06:38:02.274-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-09T06:38:02.274-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-05-09T06:38:02.274-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-09T06:38:03.198-0700 I  REPL     [replexec-4] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031469, 216), t: 12 }. My Last Applied: { ts: Timestamp(1589031480, 7), t: 17 }
2020-05-09T06:38:03.198-0700 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-05-09T06:38:03.198-0700 I  REPL     [replexec-4] Stopping replication producer
2020-05-09T06:38:03.198-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 18
2020-05-09T06:38:03.198-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:03.198-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:03.199-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:03.200-0700 I  SHARDING [rsSync-0] The ChunkSplitter has started and will accept autosplit tasks.
2020-05-09T06:38:03.200-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:38:03.201-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:38:03.274-0700 I  REPL     [replexec-0] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:38:03.274-0700 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-05-09T06:38:03.274-0700 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-05-09T06:38:03.274-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:03.274-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:03.274-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:03.274-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-09T06:38:03.274-0700 I  SHARDING [replexec-0] The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any autosplit tasks that have already started will be allowed to finish.
2020-05-09T06:38:03.274-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-09T06:38:03.306-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 18, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:03.306-0700 I  ELECTION [conn156] Sending vote response: { term: 18, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:38:04.274-0700 I  REPL     [replexec-1] Member n6:27018 is now in state SECONDARY
2020-05-09T06:38:04.280-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:38:04.280-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 18
2020-05-09T06:38:04.280-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1575 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 18, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031483, 1), t: 18 } }
2020-05-09T06:38:04.280-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1576 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 18, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031483, 1), t: 18 } }
2020-05-09T06:38:04.280-0700 I  ELECTION [replexec-4] VoteRequester(term 18 dry run) received a yes vote from n6:27018; response message: { term: 18, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031483, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:04.280-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 19
2020-05-09T06:38:04.288-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1577 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031483, 1), t: 18 } }
2020-05-09T06:38:04.288-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 1578 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031483, 1), t: 18 } }
2020-05-09T06:38:04.293-0700 I  ELECTION [replexec-2] VoteRequester(term 19) received a yes vote from n6:27018; response message: { term: 19, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031483, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:04.293-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 19
2020-05-09T06:38:04.293-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:38:04.293-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-09T06:38:04.293-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:38:05.293-0700 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-05-09T06:38:05.293-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T06:38:05.293-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T06:38:05.293-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 19
2020-05-09T06:38:05.293-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:05.293-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:05.293-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:05.294-0700 I  REPL     [replexec-5] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:38:05.294-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T06:38:05.294-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T06:38:05.294-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:05.294-0700 I  SHARDING [rsSync-0] The ChunkSplitter has started and will accept autosplit tasks.
2020-05-09T06:38:05.294-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:38:05.294-0700 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-05-09T06:38:05.294-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:05.294-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:05.295-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-09T06:38:05.295-0700 I  SHARDING [replexec-4] The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any autosplit tasks that have already started will be allowed to finish.
2020-05-09T06:38:05.301-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-09T06:38:05.406-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 19, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:05.406-0700 I  ELECTION [conn156] Sending vote response: { term: 19, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:38:06.294-0700 I  REPL     [replexec-1] Member n6:27018 is now in state SECONDARY
2020-05-09T06:38:06.317-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:38:06.317-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 19
2020-05-09T06:38:06.317-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1589 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:06.317-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1590 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 19, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:06.317-0700 I  ELECTION [replexec-5] VoteRequester(term 19 dry run) received a yes vote from n6:27018; response message: { term: 19, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031485, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:06.317-0700 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 20
2020-05-09T06:38:06.320-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1591 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:06.320-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1592 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:06.325-0700 I  ELECTION [replexec-4] VoteRequester(term 20) received a yes vote from n6:27018; response message: { term: 20, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031485, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:06.326-0700 I  ELECTION [replexec-4] election succeeded, assuming primary role in term 20
2020-05-09T06:38:06.326-0700 I  REPL     [replexec-4] transition to PRIMARY from SECONDARY
2020-05-09T06:38:06.326-0700 I  REPL     [replexec-4] Resetting sync source to empty, which was :27017
2020-05-09T06:38:06.326-0700 I  REPL     [replexec-4] Entering primary catch-up mode.
2020-05-09T06:38:07.326-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T06:38:07.326-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:38:07.326-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:38:07.326-0700 I  REPL     [replexec-1] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:38:07.326-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-09T06:38:07.326-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-09T06:38:07.326-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 20
2020-05-09T06:38:07.326-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:07.326-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:07.326-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:07.326-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:07.327-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-09T06:38:07.327-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:07.327-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:07.327-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 20, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:07.327-0700 I  ELECTION [conn156] Sending vote response: { term: 20, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:38:08.327-0700 I  REPL     [replexec-2] Member n6:27018 is now in state SECONDARY
2020-05-09T06:38:08.336-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 20, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:08.337-0700 I  ELECTION [conn156] Sending vote response: { term: 20, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T06:38:08.451-0700 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:38:08.451-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 20
2020-05-09T06:38:08.451-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1597 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:08.451-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 1598 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 20, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:08.452-0700 I  ELECTION [replexec-3] VoteRequester(term 20 dry run) received a yes vote from n6:27018; response message: { term: 20, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031486, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:08.452-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 21
2020-05-09T06:38:08.459-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1599 -- target:n4:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 21, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:08.459-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 1600 -- target:n6:27018 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_shard1", dryRun: false, term: 21, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031485, 1), t: 19 } }
2020-05-09T06:38:08.464-0700 I  ELECTION [replexec-4] VoteRequester(term 21) received a yes vote from n6:27018; response message: { term: 21, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589031469, 213), $configServerState: { opTime: { ts: Timestamp(1589031470, 6), t: 16 } }, $clusterTime: { clusterTime: Timestamp(1589031486, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031469, 216) }
2020-05-09T06:38:08.464-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 21
2020-05-09T06:38:08.464-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T06:38:08.464-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-09T06:38:08.465-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T06:38:09.465-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T06:38:09.465-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:38:09.465-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:38:09.465-0700 I  REPL     [replexec-4] Member n6:27018 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:38:09.465-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-09T06:38:09.465-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-09T06:38:09.465-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 21
2020-05-09T06:38:09.465-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:09.465-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:38:09.465-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:09.466-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:09.466-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-09T06:38:09.466-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:38:09.466-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:38:09.483-0700 I  ELECTION [conn156] Received vote request: { replSetRequestVotes: 1, setName: "rs_shard1", dryRun: true, term: 21, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031469, 216), t: 12 } }
2020-05-09T06:38:09.483-0700 I  ELECTION [conn156] Sending vote response: { term: 21, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031469, 216), t: 12 }, my last applied OpTime: { ts: Timest..." }
