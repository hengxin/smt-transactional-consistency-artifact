2020-05-09 06:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T06:37:13.080-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:13.083-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.083-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:13.083-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:13.083-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T06:37:13.083-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.083-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T06:37:13.084-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.084-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T06:37:13.084-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n5:27017:1589031433:2030226727092958320 (sleeping for 30000ms)
2020-05-09T06:37:13.084-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:13.084-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:13.086-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.086-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.615-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T06:37:14.255-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T06:37:15.619-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T06:37:15.620-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T06:37:15.623-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("457fbd53-ee22-4018-8b04-62d0d13e6650"), lastMod: 0 } took 0 ms
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T06:37:15.624-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.624-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.660-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54528 #10 (1 connection now open)
2020-05-09T06:37:15.661-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:54528 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.668-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54540 #11 (2 connections now open)
2020-05-09T06:37:15.669-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:54540 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.833-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54692 #12 (3 connections now open)
2020-05-09T06:37:17.833-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:54692 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.834-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54700 #13 (4 connections now open)
2020-05-09T06:37:17.834-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:54700 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:19.906-0700 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9d1991f1-eb74-4a93-879f-ddd6ef3d9b59") } } numYields:0 reslen:163 protocol:op_msg 2063ms
2020-05-09T06:37:19.909-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T06:37:19.912-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:19.912-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:19.913-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:19.913-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:19.913-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:19.913-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:19.913-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:19.913-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:19.916-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:19.917-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:19.917-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:19.917-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:19.995-0700 I  NETWORK  [conn12] end connection 192.168.122.1:54692 (3 connections now open)
2020-05-09T06:37:19.995-0700 I  NETWORK  [conn13] end connection 192.168.122.1:54700 (2 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54892 #20 (3 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54894 #21 (4 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:54892 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:54894 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.627-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54910 #22 (5 connections now open)
2020-05-09T06:37:22.627-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54912 #23 (6 connections now open)
2020-05-09T06:37:22.627-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:54910 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.627-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:54912 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.628-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54914 #24 (7 connections now open)
2020-05-09T06:37:22.628-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:54914 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.629-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:54918 #25 (8 connections now open)
2020-05-09T06:37:22.629-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.1:54918 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.668-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 2 ms
2020-05-09T06:37:22.679-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T06:37:22.688-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T06:37:23.679-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:23.679-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:23.688-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:23.688-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T06:37:24.130-0700 I  NETWORK  [conn21] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:24.131-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.131-0700 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:24.131-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.630-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.130-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.131-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.131-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T06:37:25.132-0700 I  SHARDING [conn23] Received reply from shard n9:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T06:37:25.132-0700 I  NETWORK  [Sharding-Fixed-3] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.132-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 18, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2004ms
2020-05-09T06:37:25.132-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 19, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1967ms
2020-05-09T06:37:25.133-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:25.133-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:25.154-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 121) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1979009, timeActiveMicros:1984527, timeInactiveMicros:424, 1984ms
2020-05-09T06:37:25.154-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 121), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 22, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1979ms
2020-05-09T06:37:25.562-0700 I  NETWORK  [conn21] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.563-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.602-0700 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:25.603-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.603-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.603-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 47) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:340443, timeInactiveMicros:0, 340ms
2020-05-09T06:37:25.604-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:425441, timeInactiveMicros:0, 425ms
2020-05-09T06:37:25.604-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:425314, timeInactiveMicros:0, 425ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 47), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 28, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 340ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 19, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 02074a1e-8413-46aa-a745-5311c6ac3cf3:19 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 425ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a83d102d-69a3-4d89-8bdb-48f20a51e81b:20 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 425ms
2020-05-09T06:37:25.866-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 81) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 81) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:234160, timeActiveMicros:247116, timeInactiveMicros:613, 247ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 20, autocommit: false } numYields:0 reslen:214 protocol:op_msg 234ms
2020-05-09T06:37:25.867-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 21, autocommit: false } numYields:0 reslen:321 protocol:op_msg 232ms
2020-05-09T06:37:25.867-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 29, autocommit: false } numYields:0 reslen:321 protocol:op_msg 233ms
2020-05-09T06:37:26.070-0700 I  NETWORK  [Uptime-reporter] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:26.070-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:26.373-0700 I  SHARDING [conn23] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 161), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 25, autocommit: false } numYields:0 reslen:321 protocol:op_msg 435ms
2020-05-09T06:37:26.379-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 33 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 164), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 25, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 436ms
2020-05-09T06:37:26.383-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 25, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 164) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:655, timeActiveMicros:436737, timeInactiveMicros:2565, 439ms
2020-05-09T06:37:26.414-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 31 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 35, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 424ms
2020-05-09T06:37:26.415-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 35, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 187) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:574, timeActiveMicros:424826, timeInactiveMicros:710, 425ms
2020-05-09T06:37:26.571-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.571-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.679-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:26.679-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:26.690-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 97) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:212527, timeInactiveMicros:0, 212ms
2020-05-09T06:37:26.690-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031446, 97), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 29, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 212ms
2020-05-09T06:37:26.714-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 39, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 110) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:218358, timeInactiveMicros:0, 218ms
2020-05-09T06:37:26.714-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031446, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 39, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 218ms
2020-05-09T06:37:26.883-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 56) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:446886, timeActiveMicros:453190, timeInactiveMicros:414, 453ms
2020-05-09T06:37:26.883-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 28, autocommit: false } numYields:0 reslen:214 protocol:op_msg 447ms
2020-05-09T06:37:26.893-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 157), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 39, autocommit: false } numYields:0 reslen:321 protocol:op_msg 178ms
2020-05-09T06:37:26.893-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 29, autocommit: false } numYields:0 reslen:321 protocol:op_msg 201ms
2020-05-09T06:37:27.001-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-09T06:37:27.147-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T06:37:30.720-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:30.721-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.783-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:30.784-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.221-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.392-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.392-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.393-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:31.394-0700 I  SHARDING [conn23] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T06:37:31.394-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 61, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 10) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3357577, timeInactiveMicros:0, 3357ms
2020-05-09T06:37:31.394-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:31.394-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031448, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 61, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 3357ms
2020-05-09T06:37:31.394-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.395-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 645), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 74, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3396ms
2020-05-09T06:37:31.395-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:31.395-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:31.413-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 64, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 649) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3378727, timeActiveMicros:3412966, timeInactiveMicros:405, 3413ms
2020-05-09T06:37:31.414-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 64, autocommit: false } numYields:0 reslen:428 protocol:op_msg 3379ms
2020-05-09T06:37:31.531-0700 I  NETWORK  [conn23] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.532-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.532-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.580-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:31.828-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 72, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 85) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:123999, timeActiveMicros:136066, timeInactiveMicros:469, 136ms
2020-05-09T06:37:31.828-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 72, autocommit: false } numYields:0 reslen:214 protocol:op_msg 124ms
2020-05-09T06:37:32.679-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:33.600-0700 I  NETWORK  [conn21] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:33.601-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.732-0700 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:33.733-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.764-0700 I  NETWORK  [conn23] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:33.765-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:34.100-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.101-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.102-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:34.102-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 89, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 3) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2097753, timeInactiveMicros:0, 2097ms
2020-05-09T06:37:34.102-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031452, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 89, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 2098ms
2020-05-09T06:37:34.102-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.102-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.731-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.871-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:35.872-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.872-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.873-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.873-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031453, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 89, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1768ms
2020-05-09T06:37:35.873-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.874-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.874-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 83 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031451, 128), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 74, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4005ms
2020-05-09T06:37:35.875-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T06:37:35.878-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 128) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2483, timeActiveMicros:4008117, timeInactiveMicros:715, 4008ms
2020-05-09T06:37:35.880-0700 I  NETWORK  [conn21] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.880-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.880-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.883-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 85 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031452, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 76, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 3784ms
2020-05-09T06:37:35.884-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 76, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 16) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:499, timeActiveMicros:3784505, timeInactiveMicros:653, 3785ms
2020-05-09T06:37:36.686-0700 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:36.690-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.173-0700 I  NETWORK  [conn21] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.187-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.687-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:37.687-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:37.687-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:37.721-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.724-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.724-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.724-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.952-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.952-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.953-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:37.954-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 120), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 87, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1758ms
2020-05-09T06:37:38.187-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:38.333-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 89, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 163) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2073424, timeActiveMicros:2081461, timeInactiveMicros:335, 2081ms
2020-05-09T06:37:38.333-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 111, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 181) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2031529, timeActiveMicros:2038795, timeInactiveMicros:344, 2039ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 169), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 89, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2074ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 182), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 111, autocommit: false } numYields:0 reslen:430 protocol:op_msg 2032ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 87, autocommit: false } numYields:0 reslen:397 protocol:op_msg 378ms
2020-05-09T06:37:38.687-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.187-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.687-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:40.048-0700 I  SHARDING [conn21] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031459, 6), t: 11 }
2020-05-09T06:37:40.048-0700 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:40.049-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.187-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:40.187-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:40.549-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.550-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.551-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 106, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1726ms
2020-05-09T06:37:40.576-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:40.577-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 130, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 443) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:1736413, timeActiveMicros:1751906, timeInactiveMicros:391, 1752ms
2020-05-09T06:37:40.578-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 449), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 130, autocommit: false } numYields:0 reslen:399 protocol:op_msg 1737ms
2020-05-09T06:37:41.534-0700 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:41.537-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:41.538-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 104, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 443) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2696972, timeActiveMicros:2710403, timeInactiveMicros:333, 2710ms
2020-05-09T06:37:41.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.035-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.535-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.535-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.536-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.537-0700 I  COMMAND  [conn23] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 449), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 104, autocommit: false } numYields:0 reslen:496 protocol:op_msg 3695ms
2020-05-09T06:37:42.537-0700 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 106, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1983ms
2020-05-09T06:37:42.538-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:42.538-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:42.550-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 119 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031460, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 131, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031460, 4) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1970ms
2020-05-09T06:37:42.551-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 131, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031460, 4) } }, globalReadTimestamp:{ ts: Timestamp(1589031460, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:921, timeActiveMicros:1971053, timeInactiveMicros:576, 1971ms
2020-05-09T06:37:42.554-0700 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.609-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.674-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.955-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:42.956-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.054-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.054-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.055-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.484-0700 I  NETWORK  [conn21] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.486-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.487-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.488-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.537-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:43.538-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:43.538-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:43.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.908-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.910-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:43.911-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:44.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.257-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.554-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:44.555-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:44.556-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:44.556-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 107, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 70) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1947250, timeInactiveMicros:0, 1947ms
2020-05-09T06:37:44.556-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 70), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 107, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1947ms
2020-05-09T06:37:44.590-0700 I  NETWORK  [conn21] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:44.591-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.591-0700 I  NETWORK  [conn23] Marking host n8:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:44.592-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:45.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.537-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:45.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.368-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:46.537-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:47.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.054-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:47.054-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:47.055-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031464, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 107, autocommit: false } numYields:0 reslen:517 protocol:op_msg 2495ms
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 121 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 132, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 4502ms
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 124 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 100), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 114, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4382ms
2020-05-09T06:37:47.056-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 114, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 100) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:527, timeActiveMicros:4383041, timeInactiveMicros:357, 4383ms
2020-05-09T06:37:47.057-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 132, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:794, timeActiveMicros:4503230, timeInactiveMicros:392, 4503ms
2020-05-09T06:37:47.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.609-0700 I  NETWORK  [conn25] end connection 192.168.122.1:54918 (7 connections now open)
2020-05-09T06:37:47.610-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56434 #62 (8 connections now open)
2020-05-09T06:37:47.611-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56436 #63 (9 connections now open)
2020-05-09T06:37:47.611-0700 I  NETWORK  [conn62] received client metadata from 192.168.122.1:56434 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.611-0700 I  NETWORK  [conn63] received client metadata from 192.168.122.1:56436 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.814-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 116, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 16) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:744272, timeActiveMicros:751118, timeInactiveMicros:259, 751ms
2020-05-09T06:37:47.814-0700 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 116, autocommit: false } numYields:0 reslen:214 protocol:op_msg 744ms
2020-05-09T06:37:47.814-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 133, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:753799, timeActiveMicros:755582, timeInactiveMicros:365, 755ms
2020-05-09T06:37:47.814-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 133, autocommit: false } numYields:0 reslen:214 protocol:op_msg 753ms
2020-05-09T06:37:47.815-0700 I  COMMAND  [conn23] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("02074a1e-8413-46aa-a745-5311c6ac3cf3") }, txnNumber: 107, autocommit: false } numYields:0 reslen:399 protocol:op_msg 758ms
2020-05-09T06:37:47.816-0700 I  NETWORK  [conn23] end connection 192.168.122.1:54912 (8 connections now open)
2020-05-09T06:37:48.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:48.537-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.538-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.538-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:48.540-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 13), t: 15 }
2020-05-09T06:37:49.113-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.114-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn62] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 127 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 1657ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 117, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1451ms
2020-05-09T06:37:49.272-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 134, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 38) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1448910, timeInactiveMicros:0, 1448ms
2020-05-09T06:37:49.272-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 134, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 1449ms
2020-05-09T06:37:49.272-0700 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 16) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1430, timeActiveMicros:1659024, timeInactiveMicros:721, 1659ms
2020-05-09T06:37:49.274-0700 I  NETWORK  [conn62] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.274-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.275-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.275-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.276-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.276-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.311-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 117, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 38) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:39704, timeActiveMicros:1490782, timeInactiveMicros:557, 1491ms
2020-05-09T06:37:49.502-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 121, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 79) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:37095, timeActiveMicros:119585, timeInactiveMicros:761, 120ms
2020-05-09T06:37:49.866-0700 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:49.867-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:49.868-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.216-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T06:37:50.367-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.367-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.368-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 144, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 187) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:679130, timeInactiveMicros:0, 679ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 144, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 679ms
2020-05-09T06:37:50.990-0700 I  NETWORK  [conn62] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:50.991-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.991-0700 I  NETWORK  [conn21] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:50.992-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.491-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.990-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.991-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.992-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 144, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1622ms
2020-05-09T06:37:51.992-0700 I  COMMAND  [conn62] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 2719ms
2020-05-09T06:37:51.992-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 137 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 189), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 127, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2291ms
2020-05-09T06:37:51.994-0700 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 29) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:991, timeActiveMicros:2720093, timeInactiveMicros:692, 2720ms
2020-05-09T06:37:51.994-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 127, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 189) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1103, timeActiveMicros:2292618, timeInactiveMicros:743, 2293ms
2020-05-09T06:37:51.997-0700 I  NETWORK  [conn21] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:53.497-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.497-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.960-0700 I  NETWORK  [conn21] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:56.997-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n4:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1526 timed out, deadline was 2020-05-09T06:37:56.997-0700, op was RemoteCommand 1526 -- target:[n4:27018] db:admin expDate:2020-05-09T06:37:56.997-0700 cmd:{ isMaster: 1 }
2020-05-09T06:37:56.997-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:56.997-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:56.999-0700 I  -        [conn21] operation was interrupted because a client disconnected
2020-05-09T06:37:57.001-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 128, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031471, 24) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004773, timeInactiveMicros:0, 5004ms
2020-05-09T06:37:57.001-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56678 #66 (9 connections now open)
2020-05-09T06:37:57.001-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 134 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031471, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 128, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-09T06:37:57.001-0700 I  NETWORK  [conn21] end connection 192.168.122.1:54894 (8 connections now open)
2020-05-09T06:37:57.001-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.1:56678 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.042-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56680 #67 (9 connections now open)
2020-05-09T06:37:57.042-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.1:56680 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.095-0700 I  -        [conn20] operation was interrupted because a client disconnected
2020-05-09T06:37:57.096-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56688 #68 (10 connections now open)
2020-05-09T06:37:57.096-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 147, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 21) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005523, timeInactiveMicros:0, 5005ms
2020-05-09T06:37:57.096-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 147, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-09T06:37:57.096-0700 I  NETWORK  [conn20] end connection 192.168.122.1:54892 (9 connections now open)
2020-05-09T06:37:57.096-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:56688 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.455-0700 I  NETWORK  [conn24] end connection 192.168.122.1:54914 (8 connections now open)
2020-05-09T06:37:57.455-0700 I  NETWORK  [conn22] end connection 192.168.122.1:54910 (7 connections now open)
2020-05-09T06:37:57.459-0700 I  NETWORK  [conn63] end connection 192.168.122.1:56436 (6 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56706 #69 (7 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:56706 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.468-0700 I  NETWORK  [conn69] end connection 192.168.122.1:56706 (6 connections now open)
2020-05-09T06:38:00.498-0700 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 12) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:8460080, timeInactiveMicros:0, 8460ms
2020-05-09T06:38:00.498-0700 I  COMMAND  [conn68] command admin.$cmd command: abortTransaction { abortTransaction: 1, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7e55ea3e-f5d2-4bcf-935b-4a14245efc81") }, txnNumber: 147, autocommit: false } numYields:0 reslen:399 protocol:op_msg 3401ms
2020-05-09T06:38:00.498-0700 I  COMMAND  [conn66] command admin.$cmd command: abortTransaction { abortTransaction: 1, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a83d102d-69a3-4d89-8bdb-48f20a51e81b") }, txnNumber: 128, autocommit: false } numYields:0 reslen:399 protocol:op_msg 3496ms
2020-05-09T06:38:00.498-0700 I  COMMAND  [conn62] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f6e9df4-dbea-41e7-9e94-5d38b1d8012a") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 8460ms
2020-05-09T06:38:00.498-0700 I  NETWORK  [conn62] end connection 192.168.122.1:56434 (5 connections now open)
2020-05-09T06:38:00.499-0700 I  NETWORK  [conn66] end connection 192.168.122.1:56678 (4 connections now open)
2020-05-09T06:38:00.499-0700 I  NETWORK  [conn68] end connection 192.168.122.1:56688 (3 connections now open)
2020-05-09T06:38:01.162-0700 I  NETWORK  [conn67] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:38:07.163-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
