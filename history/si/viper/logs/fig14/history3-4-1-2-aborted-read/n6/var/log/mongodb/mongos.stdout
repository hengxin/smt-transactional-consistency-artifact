2020-05-09 08:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T08:37:13.084-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.084-0500 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T08:37:13.084-0500 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T08:37:13.084-0500 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T08:37:13.084-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.084-0500 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] modules: none
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] build environment:
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T08:37:13.084-0500 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T08:37:13.085-0500 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.086-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T08:37:13.086-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T08:37:13.086-0500 I  SHARDING [thread1] creating distributed lock ping thread for process n6:27017:1589031433:8913427566368042210 (sleeping for 30000ms)
2020-05-09T08:37:13.086-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T08:37:13.088-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.088-0500 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.616-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T08:37:13.734-0500 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-09T08:37:14.136-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:14.255-0500 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T08:37:14.738-0500 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T08:37:14.738-0500 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T08:37:14.742-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("9d41d5e1-9fca-4817-894b-132264c3a5cb"), lastMod: 0 } took 0 ms
2020-05-09T08:37:14.742-0500 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T08:37:14.742-0500 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T08:37:14.742-0500 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T08:37:14.743-0500 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:14.743-0500 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:15.155-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:51756 #9 (1 connection now open)
2020-05-09T08:37:15.156-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:51760 #10 (2 connections now open)
2020-05-09T08:37:15.156-0500 I  NETWORK  [conn9] received client metadata from 192.168.122.1:51756 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:15.156-0500 I  NETWORK  [conn10] received client metadata from 192.168.122.1:51760 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.829-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:51946 #11 (3 connections now open)
2020-05-09T08:37:17.830-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:51952 #12 (4 connections now open)
2020-05-09T08:37:17.830-0500 I  NETWORK  [conn11] received client metadata from 192.168.122.1:51946 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.830-0500 I  NETWORK  [conn12] received client metadata from 192.168.122.1:51952 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.955-0500 I  COMMAND  [conn11] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188") } } numYields:0 reslen:163 protocol:op_msg 118ms
2020-05-09T08:37:17.966-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T08:37:17.968-0500 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:17.968-0500 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:17.968-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T08:37:17.968-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T08:37:17.968-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T08:37:17.968-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T08:37:17.969-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T08:37:17.969-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T08:37:17.971-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:17.971-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:17.971-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:17.971-0500 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:17.972-0500 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-09T08:37:18.095-0500 I  COMMAND  [conn11] command jepsendb.jepsencoll command: create { create: "jepsencoll", capped: false, writeConcern: { w: "majority" }, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031437, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188") } } numYields:0 reslen:163 protocol:op_msg 129ms
2020-05-09T08:37:18.738-0500 I  COMMAND  [conn11] command jepsendb.jepsencoll command: shardCollection { shardCollection: "jepsendb.jepsencoll", key: { _id: "hashed" }, numInitialChunks: 7, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031438, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188") } } numYields:0 reslen:243 protocol:op_msg 638ms
2020-05-09T08:37:18.743-0500 I  NETWORK  [conn11] end connection 192.168.122.1:51946 (3 connections now open)
2020-05-09T08:37:18.743-0500 I  NETWORK  [conn12] end connection 192.168.122.1:51952 (2 connections now open)
2020-05-09T08:37:22.639-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:52202 #20 (3 connections now open)
2020-05-09T08:37:22.639-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:52208 #21 (4 connections now open)
2020-05-09T08:37:22.639-0500 I  NETWORK  [conn20] received client metadata from 192.168.122.1:52202 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.639-0500 I  NETWORK  [conn21] received client metadata from 192.168.122.1:52208 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.639-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:52214 #22 (5 connections now open)
2020-05-09T08:37:22.640-0500 I  NETWORK  [conn22] received client metadata from 192.168.122.1:52214 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.640-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:52222 #23 (6 connections now open)
2020-05-09T08:37:22.640-0500 I  NETWORK  [conn23] received client metadata from 192.168.122.1:52222 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.641-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:52230 #24 (7 connections now open)
2020-05-09T08:37:22.641-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:52234 #25 (8 connections now open)
2020-05-09T08:37:22.641-0500 I  NETWORK  [conn24] received client metadata from 192.168.122.1:52230 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.641-0500 I  NETWORK  [conn25] received client metadata from 192.168.122.1:52234 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.668-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T08:37:22.679-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T08:37:22.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:23.679-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:23.679-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:23.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:23.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T08:37:24.127-0500 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:24.129-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.131-0500 I  NETWORK  [conn21] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:24.131-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.629-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.754-0500 I  NETWORK  [Sharding-Fixed-2] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:24.756-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.756-0500 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.953-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T08:37:25.128-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.129-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.129-0500 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T08:37:25.130-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 18, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1985ms
2020-05-09T08:37:25.154-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2027677, timeActiveMicros:2039058, timeInactiveMicros:566, 2039ms
2020-05-09T08:37:25.154-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 107) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2010134, timeActiveMicros:2014529, timeInactiveMicros:311, 2014ms
2020-05-09T08:37:25.154-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 16, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2027ms
2020-05-09T08:37:25.155-0500 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 21, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2010ms
2020-05-09T08:37:25.562-0500 I  NETWORK  [conn22] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:25.563-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:25.602-0500 I  NETWORK  [conn21] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T08:37:25.603-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.604-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.604-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:25.605-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:426822, timeInactiveMicros:0, 426ms
2020-05-09T08:37:25.605-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:423121, timeInactiveMicros:0, 423ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 19, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction c3414570-b24b-4d61-8426-0d8ee82e3ec0:19 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 427ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 17, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 2c65f018-c2d2-4ebc-8892-d268bc70b6e0:17 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 423ms
2020-05-09T08:37:25.606-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 54) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:312146, timeInactiveMicros:0, 312ms
2020-05-09T08:37:25.606-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 54), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 29, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 312ms
2020-05-09T08:37:25.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:25.866-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 87) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 87) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:233409, timeActiveMicros:243474, timeInactiveMicros:517, 243ms
2020-05-09T08:37:25.866-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 20, autocommit: false } numYields:0 reslen:214 protocol:op_msg 233ms
2020-05-09T08:37:25.867-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 30, autocommit: false } numYields:0 reslen:321 protocol:op_msg 232ms
2020-05-09T08:37:25.867-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 18, autocommit: false } numYields:0 reslen:321 protocol:op_msg 233ms
2020-05-09T08:37:26.398-0500 I  SHARDING [conn22] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T08:37:26.399-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 23, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 426ms
2020-05-09T08:37:26.416-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 25, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 183) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:433202, timeInactiveMicros:0, 433ms
2020-05-09T08:37:26.416-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 183), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 25, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 433ms
2020-05-09T08:37:26.422-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 177) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:22607, timeActiveMicros:449431, timeInactiveMicros:488, 449ms
2020-05-09T08:37:26.433-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 34 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 36, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 431ms
2020-05-09T08:37:26.434-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 187) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:808, timeActiveMicros:431978, timeInactiveMicros:507, 432ms
2020-05-09T08:37:26.679-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:26.679-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:26.688-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 86) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:228846, timeInactiveMicros:0, 228ms
2020-05-09T08:37:26.688-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031446, 86), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 26, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 229ms
2020-05-09T08:37:26.880-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031446, 73), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 26, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031446, 73) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 438ms
2020-05-09T08:37:26.887-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031446, 86), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 38, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 428ms
2020-05-09T08:37:26.893-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 26, autocommit: false } numYields:0 reslen:321 protocol:op_msg 202ms
2020-05-09T08:37:26.895-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031446, 73) } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 73) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:14042, timeActiveMicros:452730, timeInactiveMicros:1405, 454ms
2020-05-09T08:37:26.910-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 86) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:21399, timeActiveMicros:449459, timeInactiveMicros:1071, 450ms
2020-05-09T08:37:27.305-0500 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-09T08:37:27.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:31.392-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031447, 652), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 56, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 652) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 3385ms
2020-05-09T08:37:31.394-0500 I  SHARDING [conn20] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T08:37:31.394-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.395-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.395-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.396-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T08:37:31.397-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.398-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:31.398-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:31.413-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 56, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 652) } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 652) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:19806, timeActiveMicros:3405520, timeInactiveMicros:1130, 3406ms
2020-05-09T08:37:31.460-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 67, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 652) } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 652) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3454391, timeInactiveMicros:0, 3454ms
2020-05-09T08:37:31.461-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031447, 652), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 67, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 652) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 3454ms
2020-05-09T08:37:31.524-0500 I  NETWORK  [conn21] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.525-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.525-0500 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.580-0500 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T08:37:31.648-0500 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.650-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 61, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 14) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3587326, timeInactiveMicros:0, 3587ms
2020-05-09T08:37:31.650-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031448, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 61, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 3587ms
2020-05-09T08:37:31.828-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 62, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 85) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 85) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:109068, timeActiveMicros:129696, timeInactiveMicros:597, 130ms
2020-05-09T08:37:31.828-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 93), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 62, autocommit: false } numYields:0 reslen:214 protocol:op_msg 109ms
2020-05-09T08:37:31.829-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 85), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 65, autocommit: false } numYields:0 reslen:321 protocol:op_msg 131ms
2020-05-09T08:37:32.828-0500 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:33.829-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:35.829-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.829-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.829-0500 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T08:37:35.830-0500 I  SHARDING [conn22] Received reply from shard n5:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T08:37:35.831-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 66, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3822ms
2020-05-09T08:37:35.877-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 66, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 107) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 111) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:4031662, timeActiveMicros:4046728, timeInactiveMicros:445, 4047ms
2020-05-09T08:37:35.877-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 116), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 66, autocommit: false } numYields:0 reslen:214 protocol:op_msg 4031ms
2020-05-09T08:37:35.877-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 13) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3784591, timeActiveMicros:3792803, timeInactiveMicros:601, 3793ms
2020-05-09T08:37:35.878-0500 I  COMMAND  [conn21] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 80, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3784ms
2020-05-09T08:37:35.880-0500 I  NETWORK  [conn21] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.880-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:35.880-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:36.687-0500 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.690-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:36.691-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.692-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.188-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.688-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.688-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.688-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:37.721-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.725-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.725-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.920-0500 I  NETWORK  [conn21] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:37.921-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.921-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.922-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.922-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 92, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 126) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1725724, timeInactiveMicros:0, 1725ms
2020-05-09T08:37:37.923-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031456, 126), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 92, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1726ms
2020-05-09T08:37:38.188-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.333-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 100 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031456, 149), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 79, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2099ms
2020-05-09T08:37:38.333-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 100 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031456, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 84, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2061ms
2020-05-09T08:37:38.334-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 92, autocommit: false } numYields:0 reslen:397 protocol:op_msg 408ms
2020-05-09T08:37:38.334-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 84, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 170) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:694, timeActiveMicros:2061716, timeInactiveMicros:750, 2062ms
2020-05-09T08:37:38.334-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 79, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 149) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:723, timeActiveMicros:2100007, timeInactiveMicros:750, 2100ms
2020-05-09T08:37:38.688-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.188-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.688-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:40.048-0500 I  SHARDING [conn21] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031459, 6), t: 11 }
2020-05-09T08:37:40.048-0500 I  NETWORK  [conn21] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:40.049-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.051-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:40.052-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.055-0500 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:40.056-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.188-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.189-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.189-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:40.549-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.549-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.551-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 113, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1726ms
2020-05-09T08:37:41.534-0500 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:41.537-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:41.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.035-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.536-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.536-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.537-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:42.537-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 113, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1983ms
2020-05-09T08:37:42.539-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.539-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.548-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 99, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031458, 436) } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 436) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3725103, timeActiveMicros:3727704, timeInactiveMicros:259, 3727ms
2020-05-09T08:37:42.549-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 436), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 99, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3725ms
2020-05-09T08:37:42.549-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 104, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031458, 436) } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 436) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3725747, timeActiveMicros:3728267, timeInactiveMicros:290, 3728ms
2020-05-09T08:37:42.549-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 436), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 104, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3725ms
2020-05-09T08:37:42.619-0500 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:42.620-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:42.671-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:42.675-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:42.954-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:42.955-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.119-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.119-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.120-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.121-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 104, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 84) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:502501, timeInactiveMicros:0, 502ms
2020-05-09T08:37:43.121-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 84), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 104, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 502ms
2020-05-09T08:37:43.484-0500 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.485-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:43.486-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:43.538-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.539-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.539-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:43.619-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:43.908-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.908-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.910-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.119-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:44.257-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.619-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:44.741-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6b20412268df81b113504 to 5eb6b206cf9c9fca3fc26afd; invalidating user cache
2020-05-09T08:37:45.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.119-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:45.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.620-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:46.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.119-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:46.367-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:46.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.619-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.619-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.620-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031463, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 104, autocommit: false } numYields:0 reslen:516 protocol:op_msg 3497ms
2020-05-09T08:37:46.620-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.621-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 110, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 100) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3950321, timeInactiveMicros:0, 3950ms
2020-05-09T08:37:46.621-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 100), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 110, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3950ms
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 121, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4220ms
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 104, autocommit: false } numYields:0 reslen:398 protocol:op_msg 272ms
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 110, autocommit: false } numYields:0 reslen:398 protocol:op_msg 272ms
2020-05-09T08:37:46.896-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 121, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 101) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:795, timeActiveMicros:4221163, timeInactiveMicros:597, 4221ms
2020-05-09T08:37:47.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.619-0500 I  NETWORK  [conn25] end connection 192.168.122.1:52234 (7 connections now open)
2020-05-09T08:37:47.620-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53724 #61 (8 connections now open)
2020-05-09T08:37:47.620-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53726 #62 (9 connections now open)
2020-05-09T08:37:47.620-0500 I  NETWORK  [conn61] received client metadata from 192.168.122.1:53724 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.620-0500 I  NETWORK  [conn62] received client metadata from 192.168.122.1:53726 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.671-0500 I  NETWORK  [conn23] end connection 192.168.122.1:52222 (8 connections now open)
2020-05-09T08:37:47.672-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53736 #63 (9 connections now open)
2020-05-09T08:37:47.672-0500 I  NETWORK  [conn63] received client metadata from 192.168.122.1:53736 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.673-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53738 #64 (10 connections now open)
2020-05-09T08:37:47.673-0500 I  NETWORK  [conn64] received client metadata from 192.168.122.1:53738 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.814-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 105, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:912409, timeActiveMicros:917658, timeInactiveMicros:487, 918ms
2020-05-09T08:37:47.814-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c65f018-c2d2-4ebc-8892-d268bc70b6e0") }, txnNumber: 105, autocommit: false } numYields:0 reslen:214 protocol:op_msg 912ms
2020-05-09T08:37:47.814-0500 I  NETWORK  [conn22] end connection 192.168.122.1:52214 (9 connections now open)
2020-05-09T08:37:47.815-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3414570-b24b-4d61-8426-0d8ee82e3ec0") }, txnNumber: 111, autocommit: false } numYields:0 reslen:322 protocol:op_msg 911ms
2020-05-09T08:37:47.815-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 122, autocommit: false } numYields:0 reslen:322 protocol:op_msg 912ms
2020-05-09T08:37:47.816-0500 I  NETWORK  [conn20] end connection 192.168.122.1:52202 (8 connections now open)
2020-05-09T08:37:48.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:48.538-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.539-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.539-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:48.549-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 14), t: 15 }
2020-05-09T08:37:49.124-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.124-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn61] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1648ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn63] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 129 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1595ms
2020-05-09T08:37:49.271-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 131 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 47), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 125, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1431ms
2020-05-09T08:37:49.272-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 125, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 47) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:769, timeActiveMicros:1431878, timeInactiveMicros:407, 1432ms
2020-05-09T08:37:49.272-0500 I  TXN      [conn63] transaction parameters:{ lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 21) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1208, timeActiveMicros:1596447, timeInactiveMicros:671, 1597ms
2020-05-09T08:37:49.274-0500 I  NETWORK  [conn63] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:49.274-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:49.274-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:49.276-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:49.276-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:49.276-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:49.311-0500 I  TXN      [conn61] transaction parameters:{ lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 21) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:39535, timeActiveMicros:1687951, timeInactiveMicros:707, 1688ms
2020-05-09T08:37:49.495-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 128, autocommit: false } numYields:0 reslen:322 protocol:op_msg 112ms
2020-05-09T08:37:49.867-0500 I  NETWORK  [conn61] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:49.868-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:50.216-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T08:37:50.367-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.367-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.368-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 136, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 190) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:667077, timeInactiveMicros:0, 667ms
2020-05-09T08:37:50.368-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 189), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 136, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 667ms
2020-05-09T08:37:50.990-0500 I  NETWORK  [conn61] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:50.991-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:50.991-0500 I  NETWORK  [conn63] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:50.991-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:51.491-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:51.990-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:51.991-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:51.992-0500 I  COMMAND  [conn21] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 136, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1622ms
2020-05-09T08:37:51.992-0500 I  COMMAND  [conn63] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 2719ms
2020-05-09T08:37:51.992-0500 I  COMMAND  [conn61] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 138 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 209), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2") }, txnNumber: 16, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2207ms
2020-05-09T08:37:51.994-0500 I  TXN      [conn61] transaction parameters:{ lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 209) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:987, timeActiveMicros:2208201, timeInactiveMicros:731, 2208ms
2020-05-09T08:37:51.994-0500 I  TXN      [conn63] transaction parameters:{ lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 29) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1422, timeActiveMicros:2720468, timeInactiveMicros:724, 2721ms
2020-05-09T08:37:51.997-0500 I  NETWORK  [conn61] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:53.498-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:53.498-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:53.499-0500 I  TXN      [conn61] transaction parameters:{ lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031471, 26) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1502644, timeInactiveMicros:0, 1502ms
2020-05-09T08:37:53.499-0500 I  COMMAND  [conn61] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031471, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2") }, txnNumber: 17, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1502ms
2020-05-09T08:37:53.960-0500 I  NETWORK  [conn21] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:56.998-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n4:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1424 timed out, deadline was 2020-05-09T08:37:56.998-0500, op was RemoteCommand 1424 -- target:[n4:27018] db:admin expDate:2020-05-09T08:37:56.998-0500 cmd:{ isMaster: 1 }
2020-05-09T08:37:56.998-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T08:37:56.998-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n4:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T08:37:57.107-0500 I  -        [conn63] operation was interrupted because a client disconnected
2020-05-09T08:37:57.108-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53964 #66 (9 connections now open)
2020-05-09T08:37:57.108-0500 I  TXN      [conn63] transaction parameters:{ lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 23) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002397, timeInactiveMicros:0, 5002ms
2020-05-09T08:37:57.108-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53966 #67 (10 connections now open)
2020-05-09T08:37:57.108-0500 I  COMMAND  [conn63] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 84 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-09T08:37:57.108-0500 I  NETWORK  [conn66] received client metadata from 192.168.122.1:53964 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.108-0500 I  NETWORK  [conn63] end connection 192.168.122.1:53736 (9 connections now open)
2020-05-09T08:37:57.109-0500 I  NETWORK  [conn67] received client metadata from 192.168.122.1:53966 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.457-0500 I  NETWORK  [conn64] end connection 192.168.122.1:53738 (8 connections now open)
2020-05-09T08:37:57.458-0500 I  NETWORK  [conn24] end connection 192.168.122.1:52230 (7 connections now open)
2020-05-09T08:37:57.459-0500 I  NETWORK  [conn62] end connection 192.168.122.1:53726 (6 connections now open)
2020-05-09T08:37:57.465-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:53986 #68 (7 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn68] received client metadata from 192.168.122.1:53986 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.468-0500 I  NETWORK  [conn68] end connection 192.168.122.1:53986 (6 connections now open)
2020-05-09T08:38:00.499-0500 I  COMMAND  [conn61] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031473, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("355f9e5f-4e67-45cc-a2cb-022eb8b0eac2") }, txnNumber: 17, autocommit: false } numYields:0 reslen:515 protocol:op_msg 6997ms
2020-05-09T08:38:00.499-0500 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 140, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 23) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:8393094, timeInactiveMicros:0, 8393ms
2020-05-09T08:38:00.499-0500 I  NETWORK  [conn61] end connection 192.168.122.1:53724 (5 connections now open)
2020-05-09T08:38:00.499-0500 I  COMMAND  [conn21] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("baab58c4-f62c-4b46-b2d5-6954b3871c43") }, txnNumber: 140, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 8393ms
2020-05-09T08:38:00.499-0500 I  NETWORK  [conn21] end connection 192.168.122.1:52208 (4 connections now open)
2020-05-09T08:38:00.499-0500 I  COMMAND  [conn66] command admin.$cmd command: abortTransaction { abortTransaction: 1, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c930de75-069e-4860-8f1d-0842c620a417") }, txnNumber: 7, autocommit: false } numYields:0 reslen:396 protocol:op_msg 3390ms
2020-05-09T08:38:00.500-0500 I  NETWORK  [conn66] end connection 192.168.122.1:53964 (3 connections now open)
2020-05-09T08:38:01.162-0500 I  NETWORK  [conn67] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:38:07.163-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
