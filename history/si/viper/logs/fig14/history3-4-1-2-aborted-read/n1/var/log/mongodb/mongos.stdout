2020-05-09 06:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T06:37:13.081-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T06:37:13.084-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.085-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T06:37:13.085-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.086-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T06:37:13.086-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n1:27017:1589031433:-1857714024415010507 (sleeping for 30000ms)
2020-05-09T06:37:13.086-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:13.086-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:13.087-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.087-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.615-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T06:37:14.257-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T06:37:15.619-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T06:37:15.620-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T06:37:15.622-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("4d7bd14d-f2d3-4d39-8575-f609a19ca07e"), lastMod: 0 } took 0 ms
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:15.623-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T06:37:15.623-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.624-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.660-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58872 #8 (1 connection now open)
2020-05-09T06:37:15.661-0700 I  NETWORK  [conn8] received client metadata from 192.168.122.1:58872 conn8: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.665-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58876 #9 (2 connections now open)
2020-05-09T06:37:15.666-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.1:58876 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.675-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58882 #10 (3 connections now open)
2020-05-09T06:37:15.675-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:58882 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.675-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:58884 #11 (4 connections now open)
2020-05-09T06:37:15.676-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:58884 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:16.952-0700 I  NETWORK  [conn10] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:16.953-0700 I  COMMAND  [conn10] command admin.rs_shard1/n4:27018 command: addShard { addShard: "rs_shard1/n4:27018", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b03b87e-2aa0-40b9-81f7-b15ce3d55ce8") } } numYields:0 reslen:189 protocol:op_msg 1273ms
2020-05-09T06:37:16.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:16.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:16.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:16.956-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:16.956-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:17.813-0700 I  NETWORK  [conn10] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:17.814-0700 I  COMMAND  [conn10] command admin.rs_shard2/n7:27018 command: addShard { addShard: "rs_shard2/n7:27018", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031436, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b03b87e-2aa0-40b9-81f7-b15ce3d55ce8") } } numYields:0 reslen:189 protocol:op_msg 857ms
2020-05-09T06:37:17.814-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:17.814-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:17.814-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:17.817-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:17.817-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:17.818-0700 I  NETWORK  [conn10] end connection 192.168.122.1:58882 (3 connections now open)
2020-05-09T06:37:17.818-0700 I  NETWORK  [conn11] end connection 192.168.122.1:58884 (2 connections now open)
2020-05-09T06:37:17.830-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59022 #18 (3 connections now open)
2020-05-09T06:37:17.830-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.1:59022 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.831-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59030 #19 (4 connections now open)
2020-05-09T06:37:17.832-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:59030 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.506-0700 I  COMMAND  [conn18] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031437, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9925554b-5d88-4567-a31b-a8e5548fd731") } } numYields:0 reslen:163 protocol:op_msg 4665ms
2020-05-09T06:37:22.509-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T06:37:22.592-0700 I  NETWORK  [conn18] end connection 192.168.122.1:59022 (3 connections now open)
2020-05-09T06:37:22.593-0700 I  NETWORK  [conn19] end connection 192.168.122.1:59030 (2 connections now open)
2020-05-09T06:37:22.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59222 #20 (3 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:59222 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.626-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59246 #21 (4 connections now open)
2020-05-09T06:37:22.626-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:59246 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59290 #22 (5 connections now open)
2020-05-09T06:37:22.640-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:59290 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.641-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59304 #23 (6 connections now open)
2020-05-09T06:37:22.641-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:59304 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.650-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59320 #24 (7 connections now open)
2020-05-09T06:37:22.651-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:59324 #25 (8 connections now open)
2020-05-09T06:37:22.651-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:59320 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.651-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.1:59324 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.689-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:22.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T06:37:22.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T06:37:23.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:23.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:23.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:23.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T06:37:24.129-0700 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:24.130-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.630-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.130-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.131-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.131-0700 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T06:37:25.132-0700 I  SHARDING [conn20] Received reply from shard n9:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T06:37:25.132-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.132-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 91), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 12, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2014ms
2020-05-09T06:37:25.153-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 115) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1989587, timeActiveMicros:1996021, timeInactiveMicros:355, 1996ms
2020-05-09T06:37:25.154-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 15, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1989ms
2020-05-09T06:37:25.154-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 78) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2040862, timeActiveMicros:2047928, timeInactiveMicros:532, 2048ms
2020-05-09T06:37:25.155-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 83), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 17, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2041ms
2020-05-09T06:37:25.344-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:25.344-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:25.344-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:25.563-0700 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.564-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.602-0700 I  NETWORK  [conn24] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:25.603-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.603-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.604-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:425571, timeInactiveMicros:0, 425ms
2020-05-09T06:37:25.604-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 13, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a338a4bf-5ea2-4f78-9126-a4e6d72230da:13 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 425ms
2020-05-09T06:37:25.605-0700 I  COMMAND  [conn24] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 56), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 31, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 292ms
2020-05-09T06:37:25.605-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 367ms
2020-05-09T06:37:25.607-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 40) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:972, timeActiveMicros:368422, timeInactiveMicros:1019, 369ms
2020-05-09T06:37:25.607-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 31, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 56) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1198, timeActiveMicros:294107, timeInactiveMicros:1074, 295ms
2020-05-09T06:37:25.609-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:25.866-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 81) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 81) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:246590, timeActiveMicros:247579, timeInactiveMicros:320, 247ms
2020-05-09T06:37:25.866-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 95) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:221729, timeActiveMicros:230687, timeInactiveMicros:464, 231ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 246ms
2020-05-09T06:37:25.866-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 37, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 111) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:207270, timeActiveMicros:209490, timeInactiveMicros:579, 210ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 105), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 24, autocommit: false } numYields:0 reslen:214 protocol:op_msg 221ms
2020-05-09T06:37:25.866-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 111), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 37, autocommit: false } numYields:0 reslen:214 protocol:op_msg 207ms
2020-05-09T06:37:26.272-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:26.372-0700 I  SHARDING [conn22] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T06:37:26.372-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 170) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:413828, timeActiveMicros:419377, timeInactiveMicros:432, 419ms
2020-05-09T06:37:26.372-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 29, autocommit: false } numYields:0 reslen:214 protocol:op_msg 413ms
2020-05-09T06:37:26.373-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 159) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:435303, timeActiveMicros:445873, timeInactiveMicros:565, 446ms
2020-05-09T06:37:26.373-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 161), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 19, autocommit: false } numYields:0 reslen:214 protocol:op_msg 435ms
2020-05-09T06:37:26.373-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 41, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 173) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:403999, timeActiveMicros:408409, timeInactiveMicros:427, 408ms
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 175), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 41, autocommit: false } numYields:0 reslen:214 protocol:op_msg 404ms
2020-05-09T06:37:26.467-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:26.468-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.468-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:26.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:26.884-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 32, autocommit: false } numYields:0 reslen:321 protocol:op_msg 447ms
2020-05-09T06:37:26.884-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 45, autocommit: false } numYields:0 reslen:321 protocol:op_msg 447ms
2020-05-09T06:37:26.892-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 134) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:333852, timeActiveMicros:337816, timeInactiveMicros:426, 338ms
2020-05-09T06:37:26.892-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 137), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 29, autocommit: false } numYields:0 reslen:214 protocol:op_msg 334ms
2020-05-09T06:37:27.727-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:28.640-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:29.040-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:29.042-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:29.043-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:29.541-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.040-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:30.040-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:30.040-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:30.041-0700 I  SHARDING [conn24] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T06:37:30.041-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 77, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1992ms
2020-05-09T06:37:30.041-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 638), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 61, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2044ms
2020-05-09T06:37:30.041-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:30.041-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:30.147-0700 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:30.148-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.149-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.212-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:30.541-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.040-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.540-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.540-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.541-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 77, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1498ms
2020-05-09T06:37:31.542-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 61, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1499ms
2020-05-09T06:37:31.575-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 59, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 632) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3579138, timeActiveMicros:3612932, timeInactiveMicros:349, 3613ms
2020-05-09T06:37:31.575-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 638), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 59, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3579ms
2020-05-09T06:37:31.577-0700 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.578-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.578-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.580-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:31.614-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:31.824-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 65, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 92) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:78171, timeActiveMicros:117354, timeInactiveMicros:693, 118ms
2020-05-09T06:37:31.828-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 85) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 85) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:123899, timeActiveMicros:134639, timeInactiveMicros:712, 135ms
2020-05-09T06:37:31.828-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 80, autocommit: false } numYields:0 reslen:214 protocol:op_msg 124ms
2020-05-09T06:37:32.831-0700 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:32.832-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:32.833-0700 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:32.834-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.332-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.832-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:34.332-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.332-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.333-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:34.334-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.334-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.731-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.012-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 66, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 115) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3159707, timeActiveMicros:3180506, timeInactiveMicros:522, 3181ms
2020-05-09T06:37:35.015-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 89, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 26) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2811002, timeActiveMicros:2821297, timeInactiveMicros:284, 2821ms
2020-05-09T06:37:35.015-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:35.016-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 69, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 153) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3051589, timeActiveMicros:3064568, timeInactiveMicros:619, 3065ms
2020-05-09T06:37:35.016-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:35.517-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.517-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.517-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:35.518-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.519-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 89, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3315ms
2020-05-09T06:37:35.519-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 159), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 69, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3554ms
2020-05-09T06:37:35.519-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.519-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.519-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 123), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 66, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3667ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 69, autocommit: false } numYields:0 reslen:214 protocol:op_msg 275ms
2020-05-09T06:37:35.798-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 66, autocommit: false } numYields:0 reslen:214 protocol:op_msg 162ms
2020-05-09T06:37:35.799-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 89, autocommit: false } numYields:0 reslen:214 protocol:op_msg 276ms
2020-05-09T06:37:35.804-0700 I  NETWORK  [conn22] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.805-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:35.805-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:36.687-0700 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.177-0700 I  NETWORK  [conn24] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:37.178-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:37.678-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.678-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.679-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 107, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1418ms
2020-05-09T06:37:37.679-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 166), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 80, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1423ms
2020-05-09T06:37:37.680-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 136), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 80, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1468ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 80, autocommit: false } numYields:0 reslen:397 protocol:op_msg 652ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 107, autocommit: false } numYields:0 reslen:399 protocol:op_msg 652ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 80, autocommit: false } numYields:0 reslen:397 protocol:op_msg 652ms
2020-05-09T06:37:39.688-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.837-0700 I  NETWORK  [conn24] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:39.839-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.337-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.837-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.837-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:41.188-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:41.188-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:41.189-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-09T06:37:41.536-0700 I  SHARDING [conn24] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:41.536-0700 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:41.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.037-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.538-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.538-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.538-0700 I  CONNPOOL [ShardRegistry] Connecting to n1:27019
2020-05-09T06:37:42.549-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 99, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 474) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3671910, timeActiveMicros:3673259, timeInactiveMicros:267, 3673ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 474), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 99, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3672ms
2020-05-09T06:37:42.549-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 134, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 497) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3623087, timeActiveMicros:3627907, timeInactiveMicros:261, 3628ms
2020-05-09T06:37:42.549-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 101, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031458, 436) } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 436) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3724904, timeActiveMicros:3727754, timeInactiveMicros:1031, 3728ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 498), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 134, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3623ms
2020-05-09T06:37:42.549-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 436), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 101, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3725ms
2020-05-09T06:37:42.554-0700 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.555-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.616-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.648-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.953-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:42.954-0700 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.054-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.054-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.485-0700 I  NETWORK  [conn24] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.487-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.488-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.555-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:44.555-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:44.557-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 139, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 77) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1941243, timeInactiveMicros:0, 1941ms
2020-05-09T06:37:44.557-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 106, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 95) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1909749, timeInactiveMicros:0, 1909ms
2020-05-09T06:37:44.557-0700 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 77), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 139, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1941ms
2020-05-09T06:37:44.557-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 106, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1910ms
2020-05-09T06:37:44.589-0700 I  NETWORK  [conn22] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:44.591-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.054-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.464-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6b20412268df81b113504 to 5eb6b206ee2d3ee1870078ea; invalidating user cache
2020-05-09T06:37:46.554-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:47.054-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:47.054-0700 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031464, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 139, autocommit: false } numYields:0 reslen:517 protocol:op_msg 2496ms
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 121 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 100, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 4502ms
2020-05-09T06:37:47.055-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031464, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 106, autocommit: false } numYields:0 reslen:516 protocol:op_msg 2496ms
2020-05-09T06:37:47.056-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 100, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:587, timeActiveMicros:4502967, timeInactiveMicros:351, 4503ms
2020-05-09T06:37:47.059-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:47.060-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.060-0700 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.135-0700 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:47.136-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:47.560-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.562-0700 I  SHARDING [Sharding-Fixed-8] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.563-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 107, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 34) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:428260, timeInactiveMicros:0, 428ms
2020-05-09T06:37:47.563-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 107, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 428ms
2020-05-09T06:37:47.616-0700 I  NETWORK  [conn25] end connection 192.168.122.1:59324 (7 connections now open)
2020-05-09T06:37:47.617-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60786 #66 (8 connections now open)
2020-05-09T06:37:47.617-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60788 #67 (9 connections now open)
2020-05-09T06:37:47.617-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.1:60786 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.617-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.1:60788 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.647-0700 I  NETWORK  [conn21] end connection 192.168.122.1:59246 (8 connections now open)
2020-05-09T06:37:47.648-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60804 #68 (9 connections now open)
2020-05-09T06:37:47.648-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:60806 #69 (10 connections now open)
2020-05-09T06:37:47.648-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:60804 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.649-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:60806 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.815-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b9c9a30-2d98-4333-b852-29924d275f41") }, txnNumber: 139, autocommit: false } numYields:0 reslen:399 protocol:op_msg 758ms
2020-05-09T06:37:47.815-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a338a4bf-5ea2-4f78-9126-a4e6d72230da") }, txnNumber: 106, autocommit: false } numYields:0 reslen:398 protocol:op_msg 758ms
2020-05-09T06:37:47.816-0700 I  NETWORK  [conn20] end connection 192.168.122.1:59222 (9 connections now open)
2020-05-09T06:37:47.816-0700 I  NETWORK  [conn24] end connection 192.168.122.1:59320 (8 connections now open)
2020-05-09T06:37:47.953-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n2:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1211 timed out, deadline was 2020-05-09T06:37:47.953-0700, op was RemoteCommand 1211 -- target:[n2:27019] db:admin expDate:2020-05-09T06:37:47.953-0700 cmd:{ isMaster: 1 }
2020-05-09T06:37:47.953-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n3:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1212 timed out, deadline was 2020-05-09T06:37:47.953-0700, op was RemoteCommand 1212 -- target:[n3:27019] db:admin expDate:2020-05-09T06:37:47.953-0700 cmd:{ isMaster: 1 }
2020-05-09T06:37:47.953-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:47.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:47.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:47.953-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:47.955-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:48.142-0700 I  NETWORK  [conn66] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:48.144-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.147-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.453-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.454-0700 I  SHARDING [Sharding-Fixed-9] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.455-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 6), t: 15 }
2020-05-09T06:37:48.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:49.143-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.144-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.145-0700 I  TXN      [conn66] transaction parameters:{ lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 37) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1526013, timeInactiveMicros:0, 1526ms
2020-05-09T06:37:49.145-0700 I  COMMAND  [conn66] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1526ms
2020-05-09T06:37:49.145-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 107, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1580ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn66] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 123ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 107, autocommit: false } numYields:0 reslen:399 protocol:op_msg 123ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn68] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 129 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1620ms
2020-05-09T06:37:49.271-0700 I  TXN      [conn68] transaction parameters:{ lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 37) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:627, timeActiveMicros:1620734, timeInactiveMicros:375, 1621ms
2020-05-09T06:37:49.274-0700 I  NETWORK  [conn68] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.275-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.275-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.276-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.276-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.276-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.496-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 110, autocommit: false } numYields:0 reslen:322 protocol:op_msg 113ms
2020-05-09T06:37:49.866-0700 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:49.867-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:49.868-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.216-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T06:37:50.366-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.366-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.368-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 118, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 199) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:631048, timeInactiveMicros:0, 631ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn68] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1090ms
2020-05-09T06:37:50.368-0700 I  TXN      [conn66] transaction parameters:{ lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 213) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:567115, timeInactiveMicros:0, 567ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 199), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 118, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 631ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn66] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 213), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff") }, txnNumber: 17, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 567ms
2020-05-09T06:37:50.991-0700 I  NETWORK  [conn66] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:50.992-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.492-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.991-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.991-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.993-0700 I  COMMAND  [conn66] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff") }, txnNumber: 17, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1623ms
2020-05-09T06:37:51.993-0700 I  COMMAND  [conn68] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1624ms
2020-05-09T06:37:51.993-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 118, autocommit: false } numYields:0 reslen:516 protocol:op_msg 1624ms
2020-05-09T06:37:52.055-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:52.073-0700 I  NETWORK  [conn68] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:52.074-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:52.074-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:52.819-0700 I  NETWORK  [conn68] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:52.820-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:53.320-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.320-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.321-0700 I  COMMAND  [conn68] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 827ms
2020-05-09T06:37:53.961-0700 I  NETWORK  [conn68] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:53.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:54.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:54.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:55.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:55.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:56.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:56.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.095-0700 I  -        [conn66] operation was interrupted because a client disconnected
2020-05-09T06:37:57.096-0700 I  CONNPOOL [conn66] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-09T06:37:57.096-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32798 #78 (9 connections now open)
2020-05-09T06:37:57.097-0700 I  TXN      [conn66] transaction parameters:{ lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 21) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006353, timeInactiveMicros:0, 5006ms
2020-05-09T06:37:57.097-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:32798 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.097-0700 I  COMMAND  [conn66] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-09T06:37:57.097-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.097-0700 I  NETWORK  [conn66] end connection 192.168.122.1:60786 (8 connections now open)
2020-05-09T06:37:57.098-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.099-0700 I  -        [conn22] operation was interrupted because a client disconnected
2020-05-09T06:37:57.100-0700 I  CONNPOOL [conn22] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-09T06:37:57.100-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32800 #79 (9 connections now open)
2020-05-09T06:37:57.100-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.1:32800 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.100-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 122, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 23) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004794, timeInactiveMicros:0, 5004ms
2020-05-09T06:37:57.101-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.101-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 122, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-09T06:37:57.101-0700 I  NETWORK  [conn22] end connection 192.168.122.1:59290 (8 connections now open)
2020-05-09T06:37:57.101-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.457-0700 I  NETWORK  [conn69] end connection 192.168.122.1:60806 (7 connections now open)
2020-05-09T06:37:57.457-0700 I  NETWORK  [conn67] end connection 192.168.122.1:60788 (6 connections now open)
2020-05-09T06:37:57.458-0700 I  NETWORK  [conn23] end connection 192.168.122.1:59304 (5 connections now open)
2020-05-09T06:37:57.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32822 #80 (6 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:32820 #81 (7 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.1:32822 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn81] end connection 192.168.122.1:32820 (6 connections now open)
2020-05-09T06:37:57.467-0700 I  NETWORK  [conn80] end connection 192.168.122.1:32822 (5 connections now open)
2020-05-09T06:37:57.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:58.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:58.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:59.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:59.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:38:00.461-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:38:00.462-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:38:00.463-0700 I  COMMAND  [conn68] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031473, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fa00b3a4-886f-4115-96cb-b43e6f5c2261") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 7140ms
2020-05-09T06:38:00.463-0700 I  COMMAND  [conn79] command admin.$cmd command: abortTransaction { abortTransaction: 1, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("710389cd-d502-4833-b038-8a715215491a") }, txnNumber: 122, autocommit: false } numYields:0 reslen:399 protocol:op_msg 3362ms
2020-05-09T06:38:00.463-0700 I  COMMAND  [conn78] command admin.$cmd command: abortTransaction { abortTransaction: 1, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2ec10b0f-1fc1-4354-8968-9208481540ff") }, txnNumber: 20, autocommit: false } numYields:0 reslen:397 protocol:op_msg 3366ms
2020-05-09T06:38:00.463-0700 I  NETWORK  [conn68] end connection 192.168.122.1:60804 (4 connections now open)
2020-05-09T06:38:00.465-0700 I  NETWORK  [conn79] end connection 192.168.122.1:32800 (3 connections now open)
2020-05-09T06:38:00.465-0700 I  NETWORK  [conn78] end connection 192.168.122.1:32798 (2 connections now open)
