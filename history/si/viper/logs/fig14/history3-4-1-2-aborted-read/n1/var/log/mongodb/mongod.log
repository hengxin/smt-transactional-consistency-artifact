2020-05-09T06:37:05.705-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:05.718-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=4631 port=27019 dbpath=/var/lib/mongodb 64-bit host=n1
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] modules: none
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] build environment:
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-09T06:37:05.718-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-09T06:37:05.719-0700 I  STORAGE  [initandlisten] 
2020-05-09T06:37:05.719-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-09T06:37:05.719-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-09T06:37:05.719-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-09T06:37:06.520-0700 I  STORAGE  [initandlisten] WiredTiger message [1589031426:520263][4631:0x7f75c6449140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-09T06:37:06.568-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-09T06:37:06.626-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-09T06:37:06.659-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.659-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:06.659-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:06.659-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.660-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.660-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-09T06:37:06.660-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-09T06:37:06.660-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-09T06:37:06.660-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.661-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-09T06:37:06.661-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-09T06:37:06.661-0700 I  CONTROL  [initandlisten] 
2020-05-09T06:37:06.662-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-09T06:37:06.662-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-09T06:37:06.662-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-09T06:37:06.663-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-09T06:37:06.663-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: d8aed117-0f8b-48b5-a4f0-c42c2a3d83e1 and options: { capped: true, size: 10485760 }
2020-05-09T06:37:06.714-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-09T06:37:06.714-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-09T06:37:06.714-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-09T06:37:06.719-0700 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-05-09T06:37:06.719-0700 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-05-09T06:37:06.720-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 5833b827-973b-45d1-8ba2-2d26ba8a1a50 and options: {}
2020-05-09T06:37:06.780-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-09T06:37:06.780-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 45125212-5b1d-4600-b0a2-dbe54c90c667 and options: {}
2020-05-09T06:37:06.837-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-09T06:37:06.837-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-09T06:37:06.837-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: ba58cfd4-7d56-4a8c-ab55-6ec49afe0fb9 and options: {}
2020-05-09T06:37:06.889-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-09T06:37:06.889-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-09T06:37:06.889-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-09T06:37:06.889-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-09T06:37:06.889-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: a434f9bb-a488-4795-b727-aae04eccbab9 and options: {}
2020-05-09T06:37:06.937-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-09T06:37:06.937-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-09T06:37:06.938-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-09T06:37:06.938-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-09T06:37:06.940-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("359ac8f2-5043-4b06-b618-1b437885dbda"), lastMod: 0 } took 0 ms
2020-05-09T06:37:06.940-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-05-09T06:37:06.940-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-05-09T06:37:06.940-0700 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-05-09T06:37:06.940-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:06.940-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-05-09T06:37:06.940-0700 I  NETWORK  [listener] waiting for connections on port 27019
2020-05-09T06:37:07.000-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-09T06:37:07.907-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45446 #1 (1 connection now open)
2020-05-09T06:37:07.909-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:45446 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.955-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45448 #2 (2 connections now open)
2020-05-09T06:37:07.956-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:45448 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.966-0700 I  NETWORK  [conn1] end connection 192.168.122.1:45446 (1 connection now open)
2020-05-09T06:37:07.966-0700 I  NETWORK  [conn2] end connection 192.168.122.1:45448 (0 connections now open)
2020-05-09T06:37:07.971-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45456 #3 (1 connection now open)
2020-05-09T06:37:07.971-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45458 #4 (2 connections now open)
2020-05-09T06:37:07.971-0700 I  NETWORK  [conn3] received client metadata from 192.168.122.1:45456 conn3: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.972-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.1:45458 conn4: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:07.998-0700 I  REPL     [conn3] replSetInitiate admin command received from client
2020-05-09T06:37:08.042-0700 I  REPL     [conn3] replSetInitiate config object with 3 members parses ok
2020-05-09T06:37:08.042-0700 I  REPL     [conn3] Scheduling remote command request for initiate quorum check: RemoteCommand 1 -- target:n2:27019 db:admin cmd:{ replSetHeartbeat: "rs_config", checkEmpty: true, configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 0 }
2020-05-09T06:37:08.042-0700 I  REPL     [conn3] Scheduling remote command request for initiate quorum check: RemoteCommand 2 -- target:n3:27019 db:admin cmd:{ replSetHeartbeat: "rs_config", checkEmpty: true, configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 0 }
2020-05-09T06:37:08.042-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:08.042-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T06:37:08.044-0700 I  REPL     [conn3] ******
2020-05-09T06:37:08.044-0700 I  REPL     [conn3] creating replication oplog of size: 36624MB...
2020-05-09T06:37:08.044-0700 I  STORAGE  [conn3] createCollection: local.oplog.rs with generated UUID: 0ff70031-e49c-4599-902e-1f3d43d6eb14 and options: { capped: true, size: 38403905331.0, autoIndexId: false }
2020-05-09T06:37:08.045-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36776 #9 (3 connections now open)
2020-05-09T06:37:08.045-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34804 #10 (4 connections now open)
2020-05-09T06:37:08.045-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.12:36776 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:08.045-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.13:34804 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:08.064-0700 I  STORAGE  [conn3] Starting OplogTruncaterThread local.oplog.rs
2020-05-09T06:37:08.064-0700 I  STORAGE  [conn3] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-09T06:37:08.064-0700 I  STORAGE  [conn3] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:08.064-0700 I  STORAGE  [conn3] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:08.179-0700 I  REPL     [conn3] ******
2020-05-09T06:37:08.179-0700 I  STORAGE  [conn3] createCollection: local.system.replset with generated UUID: 427382fe-c64e-49c4-8e8b-26ea9fccb429 and options: {}
2020-05-09T06:37:08.259-0700 I  INDEX    [conn3] index build: done building index _id_ on ns local.system.replset
2020-05-09T06:37:08.270-0700 I  SHARDING [conn3] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-09T06:37:08.271-0700 I  STORAGE  [conn3] createCollection: admin.system.version with provided UUID: e21ec07c-5ee8-4e45-81d9-11c669b2e1d8 and options: { uuid: UUID("e21ec07c-5ee8-4e45-81d9-11c669b2e1d8") }
2020-05-09T06:37:08.356-0700 I  INDEX    [conn3] index build: done building index _id_ on ns admin.system.version
2020-05-09T06:37:08.357-0700 I  COMMAND  [conn3] setting featureCompatibilityVersion to 4.2
2020-05-09T06:37:08.357-0700 I  NETWORK  [conn3] Skip closing connection for connection # 10
2020-05-09T06:37:08.357-0700 I  NETWORK  [conn3] Skip closing connection for connection # 9
2020-05-09T06:37:08.357-0700 I  NETWORK  [conn3] Skip closing connection for connection # 4
2020-05-09T06:37:08.357-0700 I  NETWORK  [conn3] Skip closing connection for connection # 3
2020-05-09T06:37:08.357-0700 I  REPL     [conn3] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n1:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n2:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n3:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb6b20312268df81b1134ff') } }
2020-05-09T06:37:08.357-0700 I  REPL     [conn3] This node is n1:27019 in the config
2020-05-09T06:37:08.357-0700 I  REPL     [conn3] transition to STARTUP2 from STARTUP
2020-05-09T06:37:08.358-0700 I  REPL     [conn3] Starting replication storage threads
2020-05-09T06:37:08.358-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP
2020-05-09T06:37:08.358-0700 I  REPL     [replexec-1] Member n3:27019 is now in state STARTUP
2020-05-09T06:37:08.362-0700 I  REPL     [conn3] transition to RECOVERING from STARTUP2
2020-05-09T06:37:08.362-0700 I  REPL     [conn3] Starting replication fetcher thread
2020-05-09T06:37:08.362-0700 I  REPL     [conn3] Starting replication applier thread
2020-05-09T06:37:08.362-0700 I  REPL     [conn3] Starting replication reporter thread
2020-05-09T06:37:08.362-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-09T06:37:08.363-0700 I  COMMAND  [conn3] command local.startup_log command: replSetInitiate { replSetInitiate: { _id: "rs_config", configsvr: true, settings: { heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000 }, members: [ { _id: 0, priority: 3, host: "n1:27019" }, { _id: 1, priority: 2, host: "n2:27019" }, { _id: 2, priority: 1, host: "n3:27019" } ] }, $db: "admin", $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "primaryPreferred" } } numYields:0 reslen:252 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 19 } }, ReplicationStateTransition: { acquireCount: { w: 19 } }, Global: { acquireCount: { r: 4, w: 13, W: 2 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 133 } }, Database: { acquireCount: { r: 2, w: 9, W: 4 } }, Collection: { acquireCount: { r: 2, w: 2, W: 13 } }, Mutex: { acquireCount: { r: 16 } }, oplog: { acquireCount: { r: 1, w: 1, W: 1 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 364ms
2020-05-09T06:37:08.363-0700 I  REPL     [rsBackgroundSync] waiting for 2 pings from other members before syncing
2020-05-09T06:37:08.364-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-09T06:37:08.364-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-09T06:37:08.576-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34822 #11 (5 connections now open)
2020-05-09T06:37:08.577-0700 I  NETWORK  [conn11] end connection 192.168.122.13:34822 (4 connections now open)
2020-05-09T06:37:08.588-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36800 #12 (5 connections now open)
2020-05-09T06:37:08.588-0700 I  NETWORK  [conn12] end connection 192.168.122.12:36800 (4 connections now open)
2020-05-09T06:37:08.859-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP2
2020-05-09T06:37:08.859-0700 I  REPL     [replexec-0] Member n3:27019 is now in state STARTUP2
2020-05-09T06:37:09.426-0700 I  ELECTION [replexec-0] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:09.426-0700 I  ELECTION [replexec-0] conducting a dry run election to see if we could be elected. current term: 0
2020-05-09T06:37:09.426-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 9 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.426-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 10 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.427-0700 I  ELECTION [replexec-1] VoteRequester(term 0 dry run) received a yes vote from n2:27019; response message: { term: 0, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589031428, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T06:37:09.427-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 1
2020-05-09T06:37:09.443-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 11 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.443-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 12 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031428, 1), t: -1 } }
2020-05-09T06:37:09.588-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34858 #13 (5 connections now open)
2020-05-09T06:37:09.588-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.13:34858 conn13: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:09.591-0700 I  ELECTION [replexec-1] VoteRequester(term 1) received a yes vote from n3:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589031428, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T06:37:09.591-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 1
2020-05-09T06:37:09.591-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T06:37:09.591-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-09T06:37:09.591-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:09.591-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:09.592-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T06:37:09.592-0700 I  SHARDING [conn13] Marking collection config.transactions as collection version: <unsharded>
2020-05-09T06:37:09.594-0700 I  REPL     [replexec-1] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(0, 0), t: 0 }. My Last Applied: { ts: Timestamp(1589031428, 1), t: -1 }
2020-05-09T06:37:09.594-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-09T06:37:09.594-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-09T06:37:09.594-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 1
2020-05-09T06:37:09.595-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:09.595-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:09.595-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T06:37:09.596-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34862 #15 (6 connections now open)
2020-05-09T06:37:09.596-0700 I  STORAGE  [rsSync-0] createCollection: config.transactions with generated UUID: f1fdd767-8664-404a-85c0-c058b1f9a6e5 and options: {}
2020-05-09T06:37:09.596-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.13:34862 conn15: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:09.605-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36838 #16 (7 connections now open)
2020-05-09T06:37:09.605-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.12:36838 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:09.649-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.transactions
2020-05-09T06:37:09.650-0700 I  STORAGE  [rsSync-0] createCollection: config.chunks with provided UUID: 30857f98-8618-4345-9ef9-9dfb8d9fe020 and options: { uuid: UUID("30857f98-8618-4345-9ef9-9dfb8d9fe020") }
2020-05-09T06:37:09.698-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.chunks
2020-05-09T06:37:09.699-0700 I  SHARDING [rsSync-0] Marking collection config.chunks as collection version: <unsharded>
2020-05-09T06:37:09.772-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:09.772-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:09.772-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:09.774-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:09.780-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-05-09T06:37:09.793-0700 I  COMMAND  [rsSync-0] command config.chunks command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 143ms
2020-05-09T06:37:09.847-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:09.847-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:09.848-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:09.849-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:09.853-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-05-09T06:37:09.907-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T06:37:09.907-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:09.907-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:09.909-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:09.914-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-05-09T06:37:09.919-0700 I  STORAGE  [rsSync-0] createCollection: config.migrations with provided UUID: 90ef7ec6-d003-4d50-920d-7b1bb037da02 and options: { uuid: UUID("90ef7ec6-d003-4d50-920d-7b1bb037da02") }
2020-05-09T06:37:09.946-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.migrations
2020-05-09T06:37:09.946-0700 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-05-09T06:37:09.994-0700 I  INDEX    [rsSync-0] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-05-09T06:37:09.994-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:09.994-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:09.995-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.001-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.migrations
2020-05-09T06:37:10.008-0700 I  STORAGE  [rsSync-0] createCollection: config.shards with provided UUID: 8f635616-875a-4131-bf1c-0238dbecde2e and options: { uuid: UUID("8f635616-875a-4131-bf1c-0238dbecde2e") }
2020-05-09T06:37:10.042-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.shards
2020-05-09T06:37:10.042-0700 I  SHARDING [rsSync-0] Marking collection config.shards as collection version: <unsharded>
2020-05-09T06:37:10.095-0700 I  INDEX    [rsSync-0] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-05-09T06:37:10.095-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.095-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:10.097-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.102-0700 I  INDEX    [rsSync-0] index build: done building index host_1 on ns config.shards
2020-05-09T06:37:10.107-0700 I  STORAGE  [rsSync-0] createCollection: config.locks with provided UUID: dd3d40c6-a31d-4660-9497-ae3227412d13 and options: { uuid: UUID("dd3d40c6-a31d-4660-9497-ae3227412d13") }
2020-05-09T06:37:10.140-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.locks
2020-05-09T06:37:10.174-0700 I  INDEX    [rsSync-0] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-05-09T06:37:10.174-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.175-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:10.176-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.182-0700 I  INDEX    [rsSync-0] index build: done building index ts_1 on ns config.locks
2020-05-09T06:37:10.220-0700 I  INDEX    [rsSync-0] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-05-09T06:37:10.220-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.220-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:10.221-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.226-0700 I  INDEX    [rsSync-0] index build: done building index state_1_process_1 on ns config.locks
2020-05-09T06:37:10.230-0700 I  STORAGE  [rsSync-0] createCollection: config.lockpings with provided UUID: d60b2eae-0875-45e7-945d-da2c28b42ddc and options: { uuid: UUID("d60b2eae-0875-45e7-945d-da2c28b42ddc") }
2020-05-09T06:37:10.254-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.lockpings
2020-05-09T06:37:10.289-0700 I  INDEX    [rsSync-0] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-05-09T06:37:10.289-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.290-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:10.291-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.296-0700 I  INDEX    [rsSync-0] index build: done building index ping_1 on ns config.lockpings
2020-05-09T06:37:10.301-0700 I  STORAGE  [rsSync-0] createCollection: config.tags with provided UUID: db4258f9-f664-4812-beb7-a5326a0f15d9 and options: { uuid: UUID("db4258f9-f664-4812-beb7-a5326a0f15d9") }
2020-05-09T06:37:10.327-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.tags
2020-05-09T06:37:10.327-0700 I  SHARDING [rsSync-0] Marking collection config.tags as collection version: <unsharded>
2020-05-09T06:37:10.391-0700 I  NETWORK  [conn3] end connection 192.168.122.1:45456 (6 connections now open)
2020-05-09T06:37:10.391-0700 I  NETWORK  [conn4] end connection 192.168.122.1:45458 (5 connections now open)
2020-05-09T06:37:10.394-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45592 #17 (6 connections now open)
2020-05-09T06:37:10.395-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.1:45592 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:10.396-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45612 #18 (7 connections now open)
2020-05-09T06:37:10.397-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.1:45612 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:10.416-0700 I  INDEX    [rsSync-0] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-05-09T06:37:10.416-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.416-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:10.418-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.422-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.tags
2020-05-09T06:37:10.430-0700 I  COMMAND  [rsSync-0] command config.tags command: createIndexes { createIndexes: "tags", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 129ms
2020-05-09T06:37:10.456-0700 I  INDEX    [rsSync-0] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-05-09T06:37:10.457-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T06:37:10.457-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T06:37:10.458-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T06:37:10.463-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-05-09T06:37:10.466-0700 I  SHARDING [rsSync-0] Marking collection config.version as collection version: <unsharded>
2020-05-09T06:37:10.466-0700 I  STORAGE  [rsSync-0] createCollection: config.version with generated UUID: 0cf7f778-40b9-464c-b668-4ef14ed770ce and options: {}
2020-05-09T06:37:10.502-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.version
2020-05-09T06:37:10.503-0700 I  SHARDING [rsSync-0] Marking collection config.locks as collection version: <unsharded>
2020-05-09T06:37:10.504-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:10.504-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-05-09T06:37:10.504-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:10.505-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Marking collection config.collections as collection version: <unsharded>
2020-05-09T06:37:10.505-0700 I  COMMAND  [conn13] command admin.$cmd command: listDatabases { listDatabases: true, nameOnly: true, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1589031429, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "admin" } numYields:0 reslen:341 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 909452 } }, Global: { acquireCount: { r: 1 } } } protocol:op_msg 909ms
2020-05-09T06:37:10.505-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-05-09T06:37:10.505-0700 I  COMMAND  [conn16] command local.oplog.rs command: find { find: "oplog.rs", sort: { $natural: -1 }, limit: 1, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1589031429, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 queryHash:87EBF82D planCacheKey:87EBF82D reslen:524 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 898146 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 898ms
2020-05-09T06:37:10.507-0700 I  COMMAND  [conn15] command local.oplog.rs command: find { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031428, 1) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 60000, batchSize: 13981010, term: 1, readConcern: { afterClusterTime: Timestamp(0, 1) }, $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1589031429, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN cursorid:8743733856490070993 keysExamined:0 docsExamined:31 numYields:0 nreturned:31 reslen:6476 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 4 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 907758 } }, Global: { acquireCount: { r: 4 } }, Database: { acquireCount: { r: 3 } }, Mutex: { acquireCount: { r: 3 } }, oplog: { acquireCount: { r: 3 } } } storage:{} protocol:op_msg 909ms
2020-05-09T06:37:10.510-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36894 #19 (8 connections now open)
2020-05-09T06:37:10.510-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.12:36894 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.546-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34922 #20 (9 connections now open)
2020-05-09T06:37:10.547-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.13:34922 conn20: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.548-0700 I  NETWORK  [conn20] end connection 192.168.122.13:34922 (8 connections now open)
2020-05-09T06:37:10.553-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36898 #21 (9 connections now open)
2020-05-09T06:37:10.553-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.12:36898 conn21: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.555-0700 I  NETWORK  [conn21] end connection 192.168.122.12:36898 (8 connections now open)
2020-05-09T06:37:10.593-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:10.594-0700 I  REPL     [replexec-4] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:10.594-0700 I  REPL     [replexec-4] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:10.594-0700 I  REPL     [replexec-4] Stepping down from primary in response to heartbeat
2020-05-09T06:37:10.594-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:10.594-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:10.594-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T06:37:10.595-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-09T06:37:10.595-0700 W  SHARDING [Balancer] Balancer settings could not be loaded and will be retried in 10 seconds :: caused by :: InterruptedDueToReplStateChange: Failed to refresh the balancer settings :: caused by :: Error waiting for snapshot not less than { ts: Timestamp(1589031430, 19), t: 1 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-09T06:37:10.595-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-09T06:37:10.595-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:10.595-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:10.595-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:10.642-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34926 #22 (9 connections now open)
2020-05-09T06:37:10.643-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.13:34926 conn22: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.645-0700 I  NETWORK  [conn22] end connection 192.168.122.13:34926 (8 connections now open)
2020-05-09T06:37:10.653-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36902 #23 (9 connections now open)
2020-05-09T06:37:10.653-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.12:36902 conn23: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.655-0700 I  NETWORK  [conn23] end connection 192.168.122.12:36902 (8 connections now open)
2020-05-09T06:37:10.964-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34930 #24 (9 connections now open)
2020-05-09T06:37:10.965-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.13:34930 conn24: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.966-0700 I  NETWORK  [conn24] end connection 192.168.122.13:34930 (8 connections now open)
2020-05-09T06:37:10.969-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36906 #25 (9 connections now open)
2020-05-09T06:37:10.970-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.12:36906 conn25: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:10.971-0700 I  NETWORK  [conn25] end connection 192.168.122.12:36906 (8 connections now open)
2020-05-09T06:37:11.188-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34934 #26 (9 connections now open)
2020-05-09T06:37:11.189-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.13:34934 conn26: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.190-0700 I  NETWORK  [conn26] end connection 192.168.122.13:34934 (8 connections now open)
2020-05-09T06:37:11.198-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36910 #27 (9 connections now open)
2020-05-09T06:37:11.198-0700 I  NETWORK  [conn27] received client metadata from 192.168.122.12:36910 conn27: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.199-0700 I  NETWORK  [conn27] end connection 192.168.122.12:36910 (8 connections now open)
2020-05-09T06:37:11.382-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34938 #28 (9 connections now open)
2020-05-09T06:37:11.383-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.13:34938 conn28: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.384-0700 I  NETWORK  [conn28] end connection 192.168.122.13:34938 (8 connections now open)
2020-05-09T06:37:11.397-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36914 #29 (9 connections now open)
2020-05-09T06:37:11.397-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.12:36914 conn29: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.398-0700 I  NETWORK  [conn29] end connection 192.168.122.12:36914 (8 connections now open)
2020-05-09T06:37:11.429-0700 I  SHARDING [conn15] Marking collection config.lockpings as collection version: <unsharded>
2020-05-09T06:37:11.569-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34942 #30 (9 connections now open)
2020-05-09T06:37:11.570-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.13:34942 conn30: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.571-0700 I  NETWORK  [conn30] end connection 192.168.122.13:34942 (8 connections now open)
2020-05-09T06:37:11.581-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36918 #31 (9 connections now open)
2020-05-09T06:37:11.582-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.12:36918 conn31: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.583-0700 I  NETWORK  [conn31] end connection 192.168.122.12:36918 (8 connections now open)
2020-05-09T06:37:11.594-0700 I  REPL     [replexec-1] Member n3:27019 is now in state STARTUP2
2020-05-09T06:37:11.595-0700 I  REPL     [replexec-5] Member n2:27019 is now in state STARTUP2
2020-05-09T06:37:11.597-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:11.597-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 1
2020-05-09T06:37:11.597-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 17 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031430, 19), t: 1 } }
2020-05-09T06:37:11.597-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 18 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031430, 19), t: 1 } }
2020-05-09T06:37:11.598-0700 I  ELECTION [replexec-4] VoteRequester(term 1 dry run) received a yes vote from n2:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589031430, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T06:37:11.598-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 2
2020-05-09T06:37:11.602-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 19 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031430, 19), t: 1 } }
2020-05-09T06:37:11.602-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 20 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031430, 19), t: 1 } }
2020-05-09T06:37:11.609-0700 I  ELECTION [replexec-3] VoteRequester(term 2) received a yes vote from n3:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589031430, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T06:37:11.610-0700 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 2
2020-05-09T06:37:11.610-0700 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-05-09T06:37:11.610-0700 I  REPL     [replexec-3] Resetting sync source to empty, which was :27017
2020-05-09T06:37:11.610-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:11.610-0700 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-05-09T06:37:11.610-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:11.612-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(0, 0), t: 0 }. My Last Applied: { ts: Timestamp(1589031430, 19), t: 1 }
2020-05-09T06:37:11.612-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T06:37:11.612-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T06:37:11.612-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 2
2020-05-09T06:37:11.612-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:11.612-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:11.613-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T06:37:11.614-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:11.614-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:11.615-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:11.616-0700 W  QUERY    [conn15] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824838028461080578), stats: { stage: "COLLSCAN", nReturned: 32, executionTimeMillisEstimate: 0, works: 53, advanced: 32, needTime: 10, needYield: 0, saveState: 10, restoreState: 10, isEOF: 0, direction: "forward", docsExamined: 32 }
2020-05-09T06:37:11.616-0700 W  QUERY    [conn16] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824838028461080578), stats: { stage: "COLLSCAN", nReturned: 2, executionTimeMillisEstimate: 0, works: 23, advanced: 2, needTime: 10, needYield: 0, saveState: 10, restoreState: 10, isEOF: 0, direction: "forward", docsExamined: 2 }
2020-05-09T06:37:11.836-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34948 #33 (9 connections now open)
2020-05-09T06:37:11.837-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36924 #34 (10 connections now open)
2020-05-09T06:37:11.837-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.13:34948 conn33: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.837-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.12:36924 conn34: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:11.838-0700 I  NETWORK  [conn33] end connection 192.168.122.13:34948 (9 connections now open)
2020-05-09T06:37:11.839-0700 I  NETWORK  [conn34] end connection 192.168.122.12:36924 (8 connections now open)
2020-05-09T06:37:12.068-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36926 #35 (9 connections now open)
2020-05-09T06:37:12.068-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.12:36926 conn35: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:12.069-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34954 #36 (10 connections now open)
2020-05-09T06:37:12.069-0700 I  NETWORK  [conn36] received client metadata from 192.168.122.13:34954 conn36: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:12.070-0700 I  NETWORK  [conn35] end connection 192.168.122.12:36926 (9 connections now open)
2020-05-09T06:37:12.071-0700 I  NETWORK  [conn36] end connection 192.168.122.13:34954 (8 connections now open)
2020-05-09T06:37:12.190-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36930 #37 (9 connections now open)
2020-05-09T06:37:12.191-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.12:36930 conn37: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:12.192-0700 I  NETWORK  [conn37] end connection 192.168.122.12:36930 (8 connections now open)
2020-05-09T06:37:12.201-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34958 #38 (9 connections now open)
2020-05-09T06:37:12.202-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.13:34958 conn38: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:12.203-0700 I  NETWORK  [conn38] end connection 192.168.122.13:34958 (8 connections now open)
2020-05-09T06:37:12.428-0700 I  NETWORK  [conn17] end connection 192.168.122.1:45592 (7 connections now open)
2020-05-09T06:37:12.428-0700 I  NETWORK  [conn18] end connection 192.168.122.1:45612 (6 connections now open)
2020-05-09T06:37:12.618-0700 I  NETWORK  [conn16] end connection 192.168.122.12:36838 (5 connections now open)
2020-05-09T06:37:12.618-0700 I  NETWORK  [conn15] end connection 192.168.122.13:34862 (4 connections now open)
2020-05-09T06:37:13.084-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:44796 #39 (5 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36942 #40 (6 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.17:44796 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:40644 #41 (7 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.12:36942 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.18:40644 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.085-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41176 #42 (8 connections now open)
2020-05-09T06:37:13.085-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.15:41176 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48422 #43 (9 connections now open)
2020-05-09T06:37:13.086-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.19:48422 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36962 #44 (10 connections now open)
2020-05-09T06:37:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:40662 #45 (11 connections now open)
2020-05-09T06:37:13.086-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.12:36962 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.086-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36968 #46 (12 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.18:40662 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:40672 #47 (13 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.12:36968 conn46: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40018 #48 (14 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.18:40672 conn47: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54564 #49 (15 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.11:40018 conn48: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:44842 #50 (16 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.16:54564 conn49: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41210 #51 (17 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.17:44842 conn50: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:36988 #52 (18 connections now open)
2020-05-09T06:37:13.087-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.15:41210 conn51: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:44852 #53 (19 connections now open)
2020-05-09T06:37:13.088-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.12:36988 conn52: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41220 #54 (20 connections now open)
2020-05-09T06:37:13.088-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.17:44852 conn53: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53186 #55 (21 connections now open)
2020-05-09T06:37:13.088-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.15:41220 conn54: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:40698 #56 (22 connections now open)
2020-05-09T06:37:13.088-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.14:53186 conn55: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:37002 #57 (23 connections now open)
2020-05-09T06:37:13.088-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.18:40698 conn56: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48468 #58 (24 connections now open)
2020-05-09T06:37:13.088-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.12:37002 conn57: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.088-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:40704 #59 (25 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.19:48468 conn58: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48472 #60 (26 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn59] received client metadata from 192.168.122.18:40704 conn59: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:44872 #61 (27 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn60] received client metadata from 192.168.122.19:48472 conn60: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40054 #62 (28 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn61] received client metadata from 192.168.122.17:44872 conn61: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41238 #63 (29 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn62] received client metadata from 192.168.122.11:40054 conn62: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40058 #64 (30 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn63] received client metadata from 192.168.122.15:41238 conn63: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:44880 #65 (31 connections now open)
2020-05-09T06:37:13.089-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.11:40058 conn64: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54606 #66 (32 connections now open)
2020-05-09T06:37:13.090-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.17:44880 conn65: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41246 #67 (33 connections now open)
2020-05-09T06:37:13.090-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.16:54606 conn66: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54612 #68 (34 connections now open)
2020-05-09T06:37:13.090-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.15:41246 conn67: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53216 #69 (35 connections now open)
2020-05-09T06:37:13.090-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.16:54612 conn68: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48496 #70 (36 connections now open)
2020-05-09T06:37:13.090-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.14:53216 conn69: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48498 #71 (37 connections now open)
2020-05-09T06:37:13.091-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.19:48496 conn70: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53224 #72 (38 connections now open)
2020-05-09T06:37:13.091-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.19:48498 conn71: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40080 #73 (39 connections now open)
2020-05-09T06:37:13.091-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.14:53224 conn72: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:40082 #74 (40 connections now open)
2020-05-09T06:37:13.091-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.11:40080 conn73: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53230 #75 (41 connections now open)
2020-05-09T06:37:13.091-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.11:40082 conn74: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.091-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53232 #76 (42 connections now open)
2020-05-09T06:37:13.091-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.14:53230 conn75: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.092-0700 I  NETWORK  [conn76] received client metadata from 192.168.122.14:53232 conn76: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.107-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35074 #77 (43 connections now open)
2020-05-09T06:37:13.107-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.13:35074 conn77: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.109-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35078 #78 (44 connections now open)
2020-05-09T06:37:13.109-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.13:35078 conn78: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.109-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35080 #79 (45 connections now open)
2020-05-09T06:37:13.109-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.13:35080 conn79: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.109-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35082 #80 (46 connections now open)
2020-05-09T06:37:13.110-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.13:35082 conn80: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.110-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35084 #81 (47 connections now open)
2020-05-09T06:37:13.110-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.13:35084 conn81: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:13.612-0700 I  REPL     [replexec-5] Member n3:27019 is now in state SECONDARY
2020-05-09T06:37:13.612-0700 I  STORAGE  [replexec-5] Triggering the first stable checkpoint. Initial Data: Timestamp(1589031428, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1589031431, 2)
2020-05-09T06:37:13.613-0700 I  SHARDING [monitoring-keys-for-HMAC] Marking collection admin.system.keys as collection version: <unsharded>
2020-05-09T06:37:13.613-0700 I  SHARDING [Balancer] Marking collection config.settings as collection version: <unsharded>
2020-05-09T06:37:13.613-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:13.613-0700 I  COMMAND  [conn53] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 525ms
2020-05-09T06:37:13.613-0700 I  COMMAND  [conn45] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 526ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn44] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 526ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn46] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 526ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn59] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 524ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn60] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 524ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn80] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 504ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn71] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 523ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn52] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 526ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn65] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 524ms
2020-05-09T06:37:13.614-0700 I  COMMAND  [conn74] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 522ms
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn73] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 523ms
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn63] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 525ms
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn72] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 523ms
2020-05-09T06:37:13.615-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn76] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 523ms
2020-05-09T06:37:13.615-0700 I  STORAGE  [monitoring-keys-for-HMAC] createCollection: admin.system.keys with generated UUID: 16eb3e02-0d20-421e-ab05-71522f18c333 and options: {}
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn69] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 524ms
2020-05-09T06:37:13.615-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:13.615-0700 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn64] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 524ms
2020-05-09T06:37:13.615-0700 I  COMMAND  [conn51] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 527ms
2020-05-09T06:37:13.616-0700 I  COMMAND  [conn47] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 528ms
2020-05-09T06:37:13.616-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:13.616-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:13.616-0700 I  COMMAND  [conn50] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 528ms
2020-05-09T06:37:13.616-0700 I  COMMAND  [conn81] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 505ms
2020-05-09T06:37:13.616-0700 I  COMMAND  [conn66] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 525ms
2020-05-09T06:37:13.616-0700 I  COMMAND  [conn67] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 525ms
2020-05-09T06:37:13.616-0700 I  COMMAND  [conn70] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 525ms
2020-05-09T06:37:13.617-0700 I  COMMAND  [conn78] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 507ms
2020-05-09T06:37:13.660-0700 I  INDEX    [monitoring-keys-for-HMAC] index build: done building index _id_ on ns admin.system.keys
2020-05-09T06:37:14.234-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:37128 #82 (48 connections now open)
2020-05-09T06:37:14.234-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.12:37128 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:14.254-0700 I  COMMAND  [conn79] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n3:27017:1589031433:-6125704359618895521" }, update: { $set: { ping: new Date(1589031433106) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1144ms
2020-05-09T06:37:14.254-0700 I  COMMAND  [conn54] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27017:1589031433:2030226727092958320" }, update: { $set: { ping: new Date(1589031433084) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1166ms
2020-05-09T06:37:14.254-0700 I  COMMAND  [conn68] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27017:1589031433:8913427566368042210" }, update: { $set: { ping: new Date(1589031433086) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1163ms
2020-05-09T06:37:14.255-0700 I  COMMAND  [conn56] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27017:1589031433:754216153529044378" }, update: { $set: { ping: new Date(1589031433084) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:612 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1165ms
2020-05-09T06:37:14.255-0700 I  COMMAND  [conn61] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27017:1589031433:-6073729396180689879" }, update: { $set: { ping: new Date(1589031433084) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1165ms
2020-05-09T06:37:14.256-0700 I  COMMAND  [conn58] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27017:1589031433:1765043958672717246" }, update: { $set: { ping: new Date(1589031433085) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1165ms
2020-05-09T06:37:14.256-0700 I  COMMAND  [conn57] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n2:27017:1589031433:7244426040151103396" }, update: { $set: { ping: new Date(1589031433084) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1166ms
2020-05-09T06:37:14.256-0700 I  COMMAND  [conn75] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27017:1589031433:6195452691469558094" }, update: { $set: { ping: new Date(1589031433086) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 1163ms
2020-05-09T06:37:14.256-0700 I  COMMAND  [conn62] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1589031433:-1857714024415010507" }, update: { $set: { ping: new Date(1589031433086) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1165ms
2020-05-09T06:37:14.273-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35156 #83 (49 connections now open)
2020-05-09T06:37:14.273-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.13:35156 conn83: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:14.291-0700 I  COMMAND  [conn70] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031431, 2), t: 2 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031433, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(1589031431, 2), t: 2 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 hasSortStage:1 cursorExhausted:1 numYields:1 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 475ms
2020-05-09T06:37:14.291-0700 I  COMMAND  [conn64] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031431, 2), t: 2 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031433, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(1589031431, 2), t: 2 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 hasSortStage:1 cursorExhausted:1 numYields:1 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 475ms
2020-05-09T06:37:14.291-0700 I  COMMAND  [conn50] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031431, 2), t: 2 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031433, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(1589031431, 2), t: 2 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 hasSortStage:1 cursorExhausted:1 numYields:1 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 272ms
2020-05-09T06:37:14.291-0700 I  COMMAND  [conn47] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031431, 2), t: 2 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031433, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(1589031431, 2), t: 2 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 hasSortStage:1 cursorExhausted:1 numYields:1 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 477ms
2020-05-09T06:37:14.297-0700 I  COMMAND  [monitoring-keys-for-HMAC] command admin.system.keys command: insert { insert: "system.keys", bypassDocumentValidation: false, ordered: true, documents: [ { _id: 6824838024166113299, purpose: "HMAC", key: BinData(0, 840030F1F015B4A7F14BC659598B2355C5D2FC9A), expiresAt: Timestamp(1596807430, 0) } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, $db: "admin" } ninserted:1 keysInserted:1 numYields:0 reslen:339 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { W: 3 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 60 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 682ms
2020-05-09T06:37:14.623-0700 I  SHARDING [conn50] Marking collection config.mongos as collection version: <unsharded>
2020-05-09T06:37:14.623-0700 I  STORAGE  [conn50] createCollection: config.mongos with generated UUID: dfc556fb-2d21-4f15-beaf-e1ef4ad5320d and options: {}
2020-05-09T06:37:14.652-0700 I  INDEX    [conn50] index build: done building index _id_ on ns config.mongos
2020-05-09T06:37:15.680-0700 I  NETWORK  [conn64] Starting new replica set monitor for rs_shard1/n4:27018
2020-05-09T06:37:15.680-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:15.682-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:15.683-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:15.683-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:15.688-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53398 #88 (50 connections now open)
2020-05-09T06:37:15.689-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.14:53398 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:15.690-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53402 #89 (51 connections now open)
2020-05-09T06:37:15.691-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53404 #90 (52 connections now open)
2020-05-09T06:37:15.691-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.14:53402 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:15.691-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.14:53404 conn90: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:15.692-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:53408 #91 (53 connections now open)
2020-05-09T06:37:15.692-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.14:53408 conn91: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.727-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41448 #92 (54 connections now open)
2020-05-09T06:37:16.727-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.15:41448 conn92: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.730-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41454 #93 (55 connections now open)
2020-05-09T06:37:16.730-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41456 #94 (56 connections now open)
2020-05-09T06:37:16.730-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.15:41454 conn93: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.731-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.15:41456 conn94: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.732-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:41458 #95 (57 connections now open)
2020-05-09T06:37:16.733-0700 I  NETWORK  [conn95] received client metadata from 192.168.122.15:41458 conn95: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.798-0700 I  SHARDING [conn64] going to insert new entry for shard into config.shards: { _id: "rs_shard1", host: "rs_shard1/n4:27018,n5:27018,n6:27018", state: 1 }
2020-05-09T06:37:16.801-0700 I  STORAGE  [conn64] createCollection: config.changelog with generated UUID: 4e48f34c-cc2b-4d34-8cb7-66507755a530 and options: { capped: true, size: 209715200 }
2020-05-09T06:37:16.815-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54824 #96 (58 connections now open)
2020-05-09T06:37:16.815-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.16:54824 conn96: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.817-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54830 #97 (59 connections now open)
2020-05-09T06:37:16.817-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54832 #98 (60 connections now open)
2020-05-09T06:37:16.817-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.16:54830 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.817-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.16:54832 conn98: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.855-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54834 #99 (61 connections now open)
2020-05-09T06:37:16.856-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.16:54834 conn99: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.883-0700 I  INDEX    [conn64] index build: done building index _id_ on ns config.changelog
2020-05-09T06:37:16.939-0700 I  COMMAND  [conn64] command config.changelog command: create { create: "changelog", capped: true, size: 209715200, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "config" } numYields:0 reslen:272 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { r: 1, W: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 137ms
2020-05-09T06:37:16.939-0700 I  COMMAND  [conn97] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27018:1589031436:-2292684134486611416" }, update: { $set: { ping: new Date(1589031436814) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031436, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 120ms
2020-05-09T06:37:16.939-0700 I  SHARDING [conn64] about to log metadata event into changelog: { _id: "n1:27019-2020-05-09T06:37:16.939-0700-5eb6b20c12268df81b11370e", server: "n1:27019", shard: "config", clientAddr: "192.168.122.11:40058", time: new Date(1589031436939), what: "addShard", ns: "", details: { name: "rs_shard1", host: "rs_shard1/n4:27018" } }
2020-05-09T06:37:16.939-0700 I  SHARDING [conn64] Marking collection config.changelog as collection version: <unsharded>
2020-05-09T06:37:16.950-0700 I  COMMAND  [conn64] command admin.$cmd command: _configsvrAddShard { _configsvrAddShard: "rs_shard1/n4:27018", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("2b03b87e-2aa0-40b9-81f7-b15ce3d55ce8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 06E82E1273736F6FF9BAA4E82D77090E4194BC79), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:58882", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031435, 4), t: 2 } }, $db: "admin" } numYields:0 reslen:531 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 7 } }, Global: { acquireCount: { r: 4, w: 3 } }, Database: { acquireCount: { r: 3, w: 3 } }, Collection: { acquireCount: { r: 4, w: 2, W: 1 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 10, W: 1 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 1271ms
2020-05-09T06:37:16.957-0700 I  NETWORK  [conn64] Starting new replica set monitor for rs_shard2/n7:27018
2020-05-09T06:37:16.957-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:16.960-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:16.960-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:16.960-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:16.969-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:45132 #104 (62 connections now open)
2020-05-09T06:37:16.969-0700 I  NETWORK  [conn104] received client metadata from 192.168.122.17:45132 conn104: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.971-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:45138 #105 (63 connections now open)
2020-05-09T06:37:16.971-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:45140 #106 (64 connections now open)
2020-05-09T06:37:16.971-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.17:45138 conn105: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.972-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.17:45140 conn106: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.973-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:45142 #107 (65 connections now open)
2020-05-09T06:37:16.973-0700 I  NETWORK  [conn107] received client metadata from 192.168.122.17:45142 conn107: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:16.973-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:45144 #108 (66 connections now open)
2020-05-09T06:37:16.973-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.17:45144 conn108: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48762 #109 (67 connections now open)
2020-05-09T06:37:17.745-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.19:48762 conn109: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.747-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48766 #110 (68 connections now open)
2020-05-09T06:37:17.747-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48768 #111 (69 connections now open)
2020-05-09T06:37:17.747-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.19:48766 conn110: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.747-0700 I  NETWORK  [conn111] received client metadata from 192.168.122.19:48768 conn111: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.748-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:48770 #112 (70 connections now open)
2020-05-09T06:37:17.749-0700 I  NETWORK  [conn112] received client metadata from 192.168.122.19:48770 conn112: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.796-0700 I  SHARDING [conn64] going to insert new entry for shard into config.shards: { _id: "rs_shard2", host: "rs_shard2/n7:27018,n8:27018,n9:27018", state: 1 }
2020-05-09T06:37:17.797-0700 I  SHARDING [conn64] about to log metadata event into changelog: { _id: "n1:27019-2020-05-09T06:37:17.797-0700-5eb6b20d12268df81b11374b", server: "n1:27019", shard: "config", clientAddr: "192.168.122.11:40058", time: new Date(1589031437797), what: "addShard", ns: "", details: { name: "rs_shard2", host: "rs_shard2/n7:27018" } }
2020-05-09T06:37:17.811-0700 I  COMMAND  [conn64] command admin.$cmd command: _configsvrAddShard { _configsvrAddShard: "rs_shard2/n7:27018", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("2b03b87e-2aa0-40b9-81f7-b15ce3d55ce8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031436, 7), signature: { hash: BinData(0, 364AFAE3E2AC51FC11C2498ACD10A2F23F28C46D), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:58882", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031436, 7), t: 2 } }, $db: "admin" } numYields:0 reslen:531 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 2 } }, Database: { acquireCount: { r: 3, w: 2 } }, Collection: { acquireCount: { r: 3, w: 2 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 8, W: 1 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 855ms
2020-05-09T06:37:17.823-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:41024 #113 (71 connections now open)
2020-05-09T06:37:17.824-0700 I  NETWORK  [conn113] received client metadata from 192.168.122.18:41024 conn113: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.824-0700 I  NETWORK  [conn113] end connection 192.168.122.18:41024 (70 connections now open)
2020-05-09T06:37:17.850-0700 I  SHARDING [conn68] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b113762
2020-05-09T06:37:17.850-0700 I  SHARDING [conn68] Marking collection config.databases as collection version: <unsharded>
2020-05-09T06:37:17.850-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-09T06:37:17.856-0700 I  SHARDING [conn68] Registering new database { _id: "jepsendb", primary: "rs_shard1", partitioned: false, version: { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } } in sharding catalog
2020-05-09T06:37:17.856-0700 I  STORAGE  [conn68] createCollection: config.databases with generated UUID: c96b7667-3321-4fd3-9bfe-d1bbd40ed124 and options: {}
2020-05-09T06:37:17.895-0700 I  INDEX    [conn68] index build: done building index _id_ on ns config.databases
2020-05-09T06:37:17.942-0700 I  SHARDING [conn68] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:17.955-0700 I  SHARDING [conn68] distributed lock with ts: 5eb6b20d12268df81b113762' unlocked.
2020-05-09T06:37:17.955-0700 I  COMMAND  [conn68] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, D419BF71A37EBB78481E1D3648F74194391389BD), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:51946", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031434, 7), t: 2 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 6 } }, ReplicationStateTransition: { acquireCount: { w: 7 } }, Global: { acquireCount: { r: 1, w: 6 } }, Database: { acquireCount: { r: 1, w: 6 } }, Collection: { acquireCount: { r: 4, w: 5, W: 1 } }, Mutex: { acquireCount: { r: 12 } } } flowControl:{ acquireCount: 6, timeAcquiringMicros: 5 } storage:{} protocol:op_msg 117ms
2020-05-09T06:37:17.972-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:54968 #116 (71 connections now open)
2020-05-09T06:37:17.973-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.16:54968 conn116: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:17.976-0700 I  SHARDING [conn68] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b20d12268df81b1137c1
2020-05-09T06:37:17.985-0700 I  SHARDING [conn68] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b20d12268df81b1137cb
2020-05-09T06:37:18.085-0700 I  SHARDING [conn68] distributed lock with ts: 5eb6b20d12268df81b1137cb' unlocked.
2020-05-09T06:37:18.094-0700 I  SHARDING [conn68] distributed lock with ts: 5eb6b20d12268df81b1137c1' unlocked.
2020-05-09T06:37:18.094-0700 I  COMMAND  [conn68] command admin.$cmd command: _configsvrCreateCollection { _configsvrCreateCollection: "jepsendb.jepsencoll", options: { capped: false, writeConcern: { w: "majority" }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188") } }, writeConcern: { w: "majority" }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031437, 8), signature: { hash: BinData(0, 500984DD3DA52B70A76608ECBFBC4828BF8B1353), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:51946", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031437, 8), t: 2 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 1, w: 4 } }, Database: { acquireCount: { r: 1, w: 4 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { r: 9 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 125ms
2020-05-09T06:37:18.109-0700 I  SHARDING [conn68] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b20e12268df81b1137ec
2020-05-09T06:37:18.116-0700 I  SHARDING [conn68] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b20e12268df81b1137f3
2020-05-09T06:37:18.323-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:41104 #117 (72 connections now open)
2020-05-09T06:37:18.324-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.18:41104 conn117: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.327-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:41110 #118 (73 connections now open)
2020-05-09T06:37:18.327-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.18:41110 conn118: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:18.356-0700 W  SHARDING [conn64] config server local time went backwards, from last seen: 2020-05-09T06:37:18.353-0700 to 2020-05-09T06:37:18.352-0700
2020-05-09T06:37:18.356-0700 W  SHARDING [conn50] config server local time went backwards, from last seen: 2020-05-09T06:37:18.353-0700 to 2020-05-09T06:37:18.352-0700
2020-05-09T06:37:18.398-0700 I  STORAGE  [conn89] createCollection: config.collections with generated UUID: 1baeabe0-91e8-48d8-84aa-25d3730e1b7b and options: {}
2020-05-09T06:37:18.441-0700 I  INDEX    [conn89] index build: done building index _id_ on ns config.collections
2020-05-09T06:37:18.499-0700 I  COMMAND  [conn89] command config.$cmd command: update { update: "collections", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "jepsendb.jepsencoll" }, u: { _id: "jepsendb.jepsencoll", lastmodEpoch: ObjectId('5eb6b20e0f8124bc6bb7e6e0'), lastmod: new Date(4294967302), dropped: false, key: { _id: "hashed" }, unique: false, uuid: UUID("369a08af-19c6-4a50-a50a-0622ffd47ed1") }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031438, 18), signature: { hash: BinData(0, 2C44914469191B3E6FB36829C1681C10AD515352), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:51946", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031438, 18), t: 2 } }, $db: "config" } numYields:0 reslen:650 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { w: 3 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 100ms
2020-05-09T06:37:18.712-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:18.714-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:18.727-0700 I  SHARDING [conn68] distributed lock with ts: 5eb6b20e12268df81b1137f3' unlocked.
2020-05-09T06:37:18.737-0700 I  SHARDING [conn68] distributed lock with ts: 5eb6b20e12268df81b1137ec' unlocked.
2020-05-09T06:37:18.737-0700 I  COMMAND  [conn68] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "jepsendb.jepsencoll", key: { _id: "hashed" }, unique: false, numInitialChunks: 7, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("3c2c5656-dd60-488c-a9a3-3744f925d188"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031438, 2), signature: { hash: BinData(0, 2C44914469191B3E6FB36829C1681C10AD515352), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:51946", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031438, 2), t: 2 } }, $db: "admin" } numYields:0 reslen:585 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 6 } }, Global: { acquireCount: { r: 2, w: 4 } }, Database: { acquireCount: { r: 2, w: 4 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { r: 10, W: 1 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 637ms
2020-05-09T06:37:18.865-0700 I  SHARDING [conn75] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b113768
2020-05-09T06:37:18.866-0700 I  SHARDING [conn75] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:18.875-0700 I  SHARDING [conn75] distributed lock with ts: 5eb6b20d12268df81b113768' unlocked.
2020-05-09T06:37:18.875-0700 I  COMMAND  [conn75] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("48029aeb-51e8-4e2d-8faa-93c2c51a89fb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 06E82E1273736F6FF9BAA4E82D77090E4194BC79), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n4:27017", client: "192.168.122.1:36088", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031435, 4), t: 2 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 7 } }, ReplicationStateTransition: { acquireCount: { w: 14 } }, Global: { acquireCount: { r: 9, w: 5 } }, Database: { acquireCount: { r: 7, w: 5 } }, Collection: { acquireCount: { r: 5, w: 5 } }, Mutex: { acquireCount: { r: 14 } }, oplog: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 5, timeAcquiringMicros: 5 } storage:{} protocol:op_msg 1036ms
2020-05-09T06:37:18.890-0700 I  SHARDING [conn75] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b20e12268df81b1138ad
2020-05-09T06:37:18.905-0700 I  SHARDING [conn75] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b20e12268df81b1138b6
2020-05-09T06:37:18.916-0700 I  SHARDING [conn75] distributed lock with ts: 5eb6b20e12268df81b1138b6' unlocked.
2020-05-09T06:37:18.925-0700 I  SHARDING [conn75] distributed lock with ts: 5eb6b20e12268df81b1138ad' unlocked.
2020-05-09T06:37:18.936-0700 I  SHARDING [conn75] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b20e12268df81b1138d7
2020-05-09T06:37:18.947-0700 I  SHARDING [conn75] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b20e12268df81b1138de
2020-05-09T06:37:18.950-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:18.952-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:18.960-0700 I  SHARDING [conn75] distributed lock with ts: 5eb6b20e12268df81b1138de' unlocked.
2020-05-09T06:37:18.972-0700 I  SHARDING [conn75] distributed lock with ts: 5eb6b20e12268df81b1138d7' unlocked.
2020-05-09T06:37:19.379-0700 I  SHARDING [conn78] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b11376b
2020-05-09T06:37:19.380-0700 I  SHARDING [conn78] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:19.391-0700 I  SHARDING [conn78] distributed lock with ts: 5eb6b20d12268df81b11376b' unlocked.
2020-05-09T06:37:19.392-0700 I  COMMAND  [conn78] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("afd8c811-66cf-4b46-b3f8-dc64d6880149"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, D419BF71A37EBB78481E1D3648F74194391389BD), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:52036", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031434, 7), t: 2 } }, $db: "admin" } numYields:9 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 18 } }, ReplicationStateTransition: { acquireCount: { w: 28 } }, Global: { acquireCount: { r: 13, w: 15 } }, Database: { acquireCount: { r: 10, w: 15 } }, Collection: { acquireCount: { r: 7, w: 15 } }, Mutex: { acquireCount: { r: 18 } }, oplog: { acquireCount: { r: 3 } } } flowControl:{ acquireCount: 15, timeAcquiringMicros: 17 } storage:{} protocol:op_msg 1552ms
2020-05-09T06:37:19.408-0700 I  SHARDING [conn78] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b20f12268df81b113931
2020-05-09T06:37:19.416-0700 I  SHARDING [conn78] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b20f12268df81b11393b
2020-05-09T06:37:19.427-0700 I  SHARDING [conn78] distributed lock with ts: 5eb6b20f12268df81b11393b' unlocked.
2020-05-09T06:37:19.436-0700 I  SHARDING [conn78] distributed lock with ts: 5eb6b20f12268df81b113931' unlocked.
2020-05-09T06:37:19.450-0700 I  SHARDING [conn78] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b20f12268df81b11395b
2020-05-09T06:37:19.459-0700 I  SHARDING [conn78] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b20f12268df81b113962
2020-05-09T06:37:19.463-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:19.465-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:19.473-0700 I  SHARDING [conn78] distributed lock with ts: 5eb6b20f12268df81b113962' unlocked.
2020-05-09T06:37:19.483-0700 I  SHARDING [conn78] distributed lock with ts: 5eb6b20f12268df81b11395b' unlocked.
2020-05-09T06:37:19.895-0700 I  SHARDING [conn67] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b113777
2020-05-09T06:37:19.895-0700 I  SHARDING [conn67] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:19.904-0700 I  SHARDING [conn67] distributed lock with ts: 5eb6b20d12268df81b113777' unlocked.
2020-05-09T06:37:19.905-0700 I  COMMAND  [conn67] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("9d1991f1-eb74-4a93-879f-ddd6ef3d9b59"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 06E82E1273736F6FF9BAA4E82D77090E4194BC79), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:54692", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031435, 4), t: 2 } }, $db: "admin" } numYields:13 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 24 } }, ReplicationStateTransition: { acquireCount: { w: 37 } }, Global: { acquireCount: { r: 17, w: 20 } }, Database: { acquireCount: { r: 13, w: 20 } }, Collection: { acquireCount: { r: 9, w: 20 } }, Mutex: { acquireCount: { r: 22 } }, oplog: { acquireCount: { r: 4 } } } flowControl:{ acquireCount: 20, timeAcquiringMicros: 26 } storage:{} protocol:op_msg 2061ms
2020-05-09T06:37:19.922-0700 I  SHARDING [conn67] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b20f12268df81b1139b0
2020-05-09T06:37:19.932-0700 I  SHARDING [conn67] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b20f12268df81b1139b9
2020-05-09T06:37:19.942-0700 I  SHARDING [conn67] distributed lock with ts: 5eb6b20f12268df81b1139b9' unlocked.
2020-05-09T06:37:19.949-0700 I  SHARDING [conn67] distributed lock with ts: 5eb6b20f12268df81b1139b0' unlocked.
2020-05-09T06:37:19.960-0700 I  SHARDING [conn67] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b20f12268df81b1139da
2020-05-09T06:37:19.968-0700 I  SHARDING [conn67] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b20f12268df81b1139e2
2020-05-09T06:37:19.972-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:19.974-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:19.981-0700 I  SHARDING [conn67] distributed lock with ts: 5eb6b20f12268df81b1139e2' unlocked.
2020-05-09T06:37:19.992-0700 I  SHARDING [conn67] distributed lock with ts: 5eb6b20f12268df81b1139da' unlocked.
2020-05-09T06:37:20.410-0700 I  SHARDING [conn52] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b113765
2020-05-09T06:37:20.410-0700 I  SHARDING [conn52] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:20.425-0700 I  SHARDING [conn52] distributed lock with ts: 5eb6b20d12268df81b113765' unlocked.
2020-05-09T06:37:20.425-0700 I  COMMAND  [conn52] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("b515d294-26d9-44ef-a8c9-26678c33d535"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, D419BF71A37EBB78481E1D3648F74194391389BD), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:44372", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031434, 7), t: 2 } }, $db: "admin" } numYields:23 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 36 } }, ReplicationStateTransition: { acquireCount: { w: 52 } }, Global: { acquireCount: { r: 21, w: 31 } }, Database: { acquireCount: { r: 16, w: 31 } }, Collection: { acquireCount: { r: 11, w: 31 } }, Mutex: { acquireCount: { r: 26 } }, oplog: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 31, timeAcquiringMicros: 36 } storage:{} protocol:op_msg 2587ms
2020-05-09T06:37:20.442-0700 I  SHARDING [conn52] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b21012268df81b113a2c
2020-05-09T06:37:20.452-0700 I  SHARDING [conn52] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b21012268df81b113a36
2020-05-09T06:37:20.463-0700 I  SHARDING [conn52] distributed lock with ts: 5eb6b21012268df81b113a36' unlocked.
2020-05-09T06:37:20.472-0700 I  SHARDING [conn52] distributed lock with ts: 5eb6b21012268df81b113a2c' unlocked.
2020-05-09T06:37:20.483-0700 I  SHARDING [conn52] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b21012268df81b113a56
2020-05-09T06:37:20.491-0700 I  SHARDING [conn52] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b21012268df81b113a5d
2020-05-09T06:37:20.495-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:20.496-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:20.503-0700 I  SHARDING [conn52] distributed lock with ts: 5eb6b21012268df81b113a5d' unlocked.
2020-05-09T06:37:20.510-0700 I  SHARDING [conn52] distributed lock with ts: 5eb6b21012268df81b113a56' unlocked.
2020-05-09T06:37:20.925-0700 I  SHARDING [conn47] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b113774
2020-05-09T06:37:20.926-0700 I  SHARDING [conn47] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:20.935-0700 I  SHARDING [conn47] distributed lock with ts: 5eb6b20d12268df81b113774' unlocked.
2020-05-09T06:37:20.935-0700 I  COMMAND  [conn47] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("d3e7146c-2a1c-4d23-bf7b-a1157b26c2ec"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 06E82E1273736F6FF9BAA4E82D77090E4194BC79), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:36046", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031435, 4), t: 2 } }, $db: "admin" } numYields:29 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 44 } }, ReplicationStateTransition: { acquireCount: { w: 63 } }, Global: { acquireCount: { r: 25, w: 38 } }, Database: { acquireCount: { r: 19, w: 38 } }, Collection: { acquireCount: { r: 13, w: 38 } }, Mutex: { acquireCount: { r: 30 } }, oplog: { acquireCount: { r: 6 } } } flowControl:{ acquireCount: 38, timeAcquiringMicros: 45 } storage:{} protocol:op_msg 3093ms
2020-05-09T06:37:20.955-0700 I  SHARDING [conn47] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b21012268df81b113aa3
2020-05-09T06:37:20.963-0700 I  SHARDING [conn47] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b21012268df81b113aad
2020-05-09T06:37:20.975-0700 I  SHARDING [conn47] distributed lock with ts: 5eb6b21012268df81b113aad' unlocked.
2020-05-09T06:37:20.985-0700 I  SHARDING [conn47] distributed lock with ts: 5eb6b21012268df81b113aa3' unlocked.
2020-05-09T06:37:20.997-0700 I  SHARDING [conn47] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b21012268df81b113acd
2020-05-09T06:37:21.005-0700 I  SHARDING [conn47] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b21012268df81b113ad5
2020-05-09T06:37:21.009-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:21.010-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 0 ms
2020-05-09T06:37:21.017-0700 I  SHARDING [conn47] distributed lock with ts: 5eb6b21012268df81b113ad5' unlocked.
2020-05-09T06:37:21.026-0700 I  SHARDING [conn47] distributed lock with ts: 5eb6b21012268df81b113acd' unlocked.
2020-05-09T06:37:21.448-0700 I  SHARDING [conn70] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b11376e
2020-05-09T06:37:21.448-0700 I  SHARDING [conn70] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:21.458-0700 I  SHARDING [conn70] distributed lock with ts: 5eb6b20d12268df81b11376e' unlocked.
2020-05-09T06:37:21.458-0700 I  COMMAND  [conn70] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("a2590085-a8df-4e70-afe0-7a207781839a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, D419BF71A37EBB78481E1D3648F74194391389BD), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:37818", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031434, 7), t: 2 } }, $db: "admin" } numYields:38 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 55 } }, ReplicationStateTransition: { acquireCount: { w: 77 } }, Global: { acquireCount: { r: 29, w: 48 } }, Database: { acquireCount: { r: 22, w: 48 } }, Collection: { acquireCount: { r: 15, w: 48 } }, Mutex: { acquireCount: { r: 34 } }, oplog: { acquireCount: { r: 7 } } } flowControl:{ acquireCount: 48, timeAcquiringMicros: 52 } storage:{} protocol:op_msg 3617ms
2020-05-09T06:37:21.475-0700 I  SHARDING [conn70] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b21112268df81b113b16
2020-05-09T06:37:21.484-0700 I  SHARDING [conn70] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b21112268df81b113b1f
2020-05-09T06:37:21.495-0700 I  SHARDING [conn70] distributed lock with ts: 5eb6b21112268df81b113b1f' unlocked.
2020-05-09T06:37:21.507-0700 I  SHARDING [conn70] distributed lock with ts: 5eb6b21112268df81b113b16' unlocked.
2020-05-09T06:37:21.518-0700 I  SHARDING [conn70] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b21112268df81b113b40
2020-05-09T06:37:21.525-0700 I  SHARDING [conn70] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b21112268df81b113b48
2020-05-09T06:37:21.529-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:21.530-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:21.539-0700 I  SHARDING [conn70] distributed lock with ts: 5eb6b21112268df81b113b48' unlocked.
2020-05-09T06:37:21.548-0700 I  SHARDING [conn70] distributed lock with ts: 5eb6b21112268df81b113b40' unlocked.
2020-05-09T06:37:21.973-0700 I  SHARDING [conn50] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b11377a
2020-05-09T06:37:21.974-0700 I  SHARDING [conn50] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:21.983-0700 I  SHARDING [conn50] distributed lock with ts: 5eb6b20d12268df81b11377a' unlocked.
2020-05-09T06:37:21.983-0700 I  COMMAND  [conn50] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("b6cc6f8d-d418-4dd8-b936-9b0422f12238"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, D419BF71A37EBB78481E1D3648F74194391389BD), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:35314", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031434, 7), t: 2 } }, $db: "admin" } numYields:48 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 67 } }, ReplicationStateTransition: { acquireCount: { w: 92 } }, Global: { acquireCount: { r: 33, w: 59 } }, Database: { acquireCount: { r: 25, w: 59 } }, Collection: { acquireCount: { r: 17, w: 59 } }, Mutex: { acquireCount: { r: 38 } }, oplog: { acquireCount: { r: 8 } } } flowControl:{ acquireCount: 59, timeAcquiringMicros: 63 } storage:{} protocol:op_msg 4139ms
2020-05-09T06:37:21.998-0700 I  SHARDING [conn50] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b21112268df81b113b86
2020-05-09T06:37:22.007-0700 I  SHARDING [conn50] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b21112268df81b113b8f
2020-05-09T06:37:22.016-0700 I  SHARDING [conn50] distributed lock with ts: 5eb6b21112268df81b113b8f' unlocked.
2020-05-09T06:37:22.025-0700 I  SHARDING [conn50] distributed lock with ts: 5eb6b21112268df81b113b86' unlocked.
2020-05-09T06:37:22.035-0700 I  SHARDING [conn50] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b21212268df81b113bb0
2020-05-09T06:37:22.046-0700 I  SHARDING [conn50] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b21212268df81b113bb7
2020-05-09T06:37:22.050-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:22.051-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:22.059-0700 I  SHARDING [conn50] distributed lock with ts: 5eb6b21212268df81b113bb7' unlocked.
2020-05-09T06:37:22.066-0700 I  SHARDING [conn50] distributed lock with ts: 5eb6b21212268df81b113bb0' unlocked.
2020-05-09T06:37:22.495-0700 I  SHARDING [conn64] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6b20d12268df81b113771
2020-05-09T06:37:22.496-0700 I  SHARDING [conn64] Enabling sharding for database [jepsendb] in config db
2020-05-09T06:37:22.505-0700 I  SHARDING [conn64] distributed lock with ts: 5eb6b20d12268df81b113771' unlocked.
2020-05-09T06:37:22.505-0700 I  COMMAND  [conn64] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("9925554b-5d88-4567-a31b-a8e5548fd731"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031437, 3), signature: { hash: BinData(0, 500984DD3DA52B70A76608ECBFBC4828BF8B1353), keyId: 6824838024166113299 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:59022", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589031437, 3), t: 2 } }, $db: "admin" } numYields:58 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 79 } }, ReplicationStateTransition: { acquireCount: { w: 107 } }, Global: { acquireCount: { r: 37, w: 70 } }, Database: { acquireCount: { r: 28, w: 70 } }, Collection: { acquireCount: { r: 19, w: 70 } }, Mutex: { acquireCount: { r: 42 } }, oplog: { acquireCount: { r: 9 } } } flowControl:{ acquireCount: 70, timeAcquiringMicros: 76 } storage:{} protocol:op_msg 4664ms
2020-05-09T06:37:22.520-0700 I  SHARDING [conn64] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6b21212268df81b113bf5
2020-05-09T06:37:22.529-0700 I  SHARDING [conn64] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6b21212268df81b113bfd
2020-05-09T06:37:22.542-0700 I  SHARDING [conn64] distributed lock with ts: 5eb6b21212268df81b113bfd' unlocked.
2020-05-09T06:37:22.551-0700 I  SHARDING [conn64] distributed lock with ts: 5eb6b21212268df81b113bf5' unlocked.
2020-05-09T06:37:22.561-0700 I  SHARDING [conn64] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6b21212268df81b113c1d
2020-05-09T06:37:22.569-0700 I  SHARDING [conn64] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6b21212268df81b113c25
2020-05-09T06:37:22.572-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 0 ms
2020-05-09T06:37:22.574-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T06:37:22.581-0700 I  SHARDING [conn64] distributed lock with ts: 5eb6b21212268df81b113c25' unlocked.
2020-05-09T06:37:22.588-0700 I  SHARDING [conn64] distributed lock with ts: 5eb6b21212268df81b113c1d' unlocked.
2020-05-09T06:37:22.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46258 #119 (74 connections now open)
2020-05-09T06:37:22.624-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46268 #120 (75 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.1:46258 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:46268 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.645-0700 I  NETWORK  [conn119] end connection 192.168.122.1:46258 (74 connections now open)
2020-05-09T06:37:22.645-0700 I  NETWORK  [conn120] end connection 192.168.122.1:46268 (73 connections now open)
2020-05-09T06:37:23.590-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:23.590-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:23.590-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:23.590-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-09T06:37:23.590-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:23.590-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:23.590-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:23.590-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T06:37:23.590-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:23.839-0700 I  ELECTION [conn10] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031442, 16), t: 2 } }
2020-05-09T06:37:23.839-0700 I  ELECTION [conn10] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-05-09T06:37:23.839-0700 I  NETWORK  [conn10] end connection 192.168.122.13:34804 (72 connections now open)
2020-05-09T06:37:24.027-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:24.031-0700 I  REPL     [replexec-2] Member n3:27019 is now in state PRIMARY
2020-05-09T06:37:24.031-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-09T06:37:25.167-0700
2020-05-09T06:37:24.350-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46704 #121 (73 connections now open)
2020-05-09T06:37:24.350-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.1:46704 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.351-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46714 #122 (74 connections now open)
2020-05-09T06:37:24.351-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:46714 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.353-0700 I  NETWORK  [conn121] end connection 192.168.122.1:46704 (73 connections now open)
2020-05-09T06:37:24.354-0700 I  NETWORK  [conn122] end connection 192.168.122.1:46714 (72 connections now open)
2020-05-09T06:37:24.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35896 #123 (73 connections now open)
2020-05-09T06:37:24.640-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.13:35896 conn123: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:24.643-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35894 #124 (74 connections now open)
2020-05-09T06:37:24.644-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.13:35894 conn124: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:24.983-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46764 #125 (75 connections now open)
2020-05-09T06:37:24.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46772 #126 (76 connections now open)
2020-05-09T06:37:24.984-0700 I  NETWORK  [conn126] received client metadata from 192.168.122.1:46772 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.984-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.1:46764 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:24.988-0700 I  NETWORK  [conn125] end connection 192.168.122.1:46764 (75 connections now open)
2020-05-09T06:37:24.988-0700 I  NETWORK  [conn126] end connection 192.168.122.1:46772 (74 connections now open)
2020-05-09T06:37:25.167-0700 I  REPL     [replexec-1] Canceling priority takeover callback
2020-05-09T06:37:25.167-0700 I  ELECTION [replexec-1] Not starting an election for a priority takeover, since we are not electable due to: Not standing for election because member is not caught up enough to the most up-to-date member to call for priority takeover - must be within 2 seconds (mask 0x80)
2020-05-09T06:37:25.444-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-09T06:37:26.552-0700
2020-05-09T06:37:25.505-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46834 #127 (75 connections now open)
2020-05-09T06:37:25.506-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46838 #128 (76 connections now open)
2020-05-09T06:37:25.506-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.1:46834 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:25.506-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.1:46838 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:25.511-0700 I  NETWORK  [conn127] end connection 192.168.122.1:46834 (75 connections now open)
2020-05-09T06:37:25.511-0700 I  NETWORK  [conn128] end connection 192.168.122.1:46838 (74 connections now open)
2020-05-09T06:37:25.591-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T06:37:25.592-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-09T06:37:25.594-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn78] command config.settings command: find { find: "settings", filter: { _id: "autosplit" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031444, 6), signature: { hash: BinData(0, E76227B2633CD96DE6748BBF0188365F67977AB9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 642ms
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn70] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031444, 6), signature: { hash: BinData(0, E76227B2633CD96DE6748BBF0188365F67977AB9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 642ms
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn110] command config.databases command: find { find: "databases", filter: { _id: "jepsendb" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, F651DB24D25DE253543A0732BAF31D1482E5AB8B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:689 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 433ms
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn112] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031445, 15), signature: { hash: BinData(0, F651DB24D25DE253543A0732BAF31D1482E5AB8B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:2 cursorExhausted:1 numYields:0 nreturned:2 reslen:719 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 410ms
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn68] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031444, 6), signature: { hash: BinData(0, E76227B2633CD96DE6748BBF0188365F67977AB9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 644ms
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn50] command config.settings command: find { find: "settings", filter: { _id: "balancer" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031444, 6), signature: { hash: BinData(0, E76227B2633CD96DE6748BBF0188365F67977AB9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 644ms
2020-05-09T06:37:25.598-0700 I  COMMAND  [conn52] command config.settings command: find { find: "settings", filter: { _id: "chunksize" }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(1589031444, 6), t: 3 } }, limit: 1, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031444, 6), signature: { hash: BinData(0, E76227B2633CD96DE6748BBF0188365F67977AB9), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031444, 6), t: 3 } }, $db: "config" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:571 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 643ms
2020-05-09T06:37:26.065-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031445, 97), t: 3 } }
2020-05-09T06:37:26.065-0700 I  ELECTION [conn9] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-05-09T06:37:26.068-0700 I  REPL     [conn9] Canceling priority takeover callback
2020-05-09T06:37:26.068-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031445, 97), t: 3 } }
2020-05-09T06:37:26.068-0700 I  ELECTION [conn9] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-09T06:37:26.151-0700 I  REPL     [replexec-1] Member n3:27019 is now in state SECONDARY
2020-05-09T06:37:26.556-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46944 #131 (75 connections now open)
2020-05-09T06:37:26.556-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46948 #132 (76 connections now open)
2020-05-09T06:37:26.556-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:46944 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:26.556-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.1:46948 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:26.559-0700 I  NETWORK  [conn131] end connection 192.168.122.1:46944 (75 connections now open)
2020-05-09T06:37:26.560-0700 I  NETWORK  [conn132] end connection 192.168.122.1:46948 (74 connections now open)
2020-05-09T06:37:27.532-0700 I  ELECTION [conn124] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.532-0700 I  ELECTION [conn124] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-09T06:37:27.533-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:27.533-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 4
2020-05-09T06:37:27.533-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 125 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.533-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 126 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.534-0700 I  ELECTION [replexec-5] VoteRequester(term 4 dry run) received a no vote from n3:27019 with reason "candidate's term (4) is lower than mine (5)"; response message: { term: 5, voteGranted: false, reason: "candidate's term (4) is lower than mine (5)", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1589031446, 87), $clusterTime: { clusterTime: Timestamp(1589031446, 141), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031446, 87) }
2020-05-09T06:37:27.534-0700 I  ELECTION [replexec-5] not running for primary, we have been superseded already
2020-05-09T06:37:27.534-0700 I  ELECTION [replexec-5] Lost dry run election due to internal error
2020-05-09T06:37:27.534-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:27.534-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:27.546-0700 I  ELECTION [conn124] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031446, 87), t: 4 } }
2020-05-09T06:37:27.546-0700 I  ELECTION [conn124] Sending vote response: { term: 5, voteGranted: true, reason: "" }
2020-05-09T06:37:28.152-0700 I  REPL     [replexec-1] Member n3:27019 is now in state PRIMARY
2020-05-09T06:37:28.152-0700 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-05-09T06:37:29.194-0700
2020-05-09T06:37:29.140-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n2:27019, my last fetched oplog optime: { ts: Timestamp(1589031446, 87), t: 4 }, latest oplog optime of sync source: { ts: Timestamp(1589031446, 87), t: 4 } (n3:27019 is)
2020-05-09T06:37:29.141-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n2:27019, OpTime { ts: Timestamp(1589031446, 87), t: 4 }, its sync source index:-1
2020-05-09T06:37:29.141-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n2:27019 (config version: 1; last applied optime: { ts: Timestamp(1589031446, 87), t: 4 }; sync source index: -1; primary index: 2) is no longer valid
2020-05-09T06:37:29.141-0700 I  REPL     [rsBackgroundSync] Clearing sync source n2:27019 to choose a new one.
2020-05-09T06:37:29.141-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T06:37:29.141-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-09T06:37:29.144-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-09T06:37:29.145-0700 I  REPL     [rsBackgroundSync] Changed sync source from n2:27019 to n3:27019
2020-05-09T06:37:29.194-0700 I  REPL     [replexec-2] Canceling priority takeover callback
2020-05-09T06:37:29.194-0700 I  ELECTION [replexec-2] Starting an election for a priority takeover
2020-05-09T06:37:29.194-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 5
2020-05-09T06:37:29.194-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 140 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 2), t: 5 } }
2020-05-09T06:37:29.194-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 141 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 2), t: 5 } }
2020-05-09T06:37:29.195-0700 I  ELECTION [replexec-0] VoteRequester(term 5 dry run) received a yes vote from n2:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000004') }, lastCommittedOpTime: Timestamp(1589031446, 87), $clusterTime: { clusterTime: Timestamp(1589031448, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031446, 87) }
2020-05-09T06:37:29.195-0700 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 6
2020-05-09T06:37:29.198-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 142 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 2), t: 5 } }
2020-05-09T06:37:29.198-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 143 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031447, 2), t: 5 } }
2020-05-09T06:37:29.203-0700 I  ELECTION [replexec-2] VoteRequester(term 6) received a yes vote from n2:27019; response message: { term: 6, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000004') }, lastCommittedOpTime: Timestamp(1589031446, 87), $clusterTime: { clusterTime: Timestamp(1589031448, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031446, 87) }
2020-05-09T06:37:29.204-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 6
2020-05-09T06:37:29.204-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:29.204-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was n3:27019
2020-05-09T06:37:29.204-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:29.204-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:37:29.206-0700 I  REPL     [replexec-2] Member n3:27019 is now in state SECONDARY
2020-05-09T06:37:29.206-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031447, 2), t: 5 }. My Last Applied: { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T06:37:29.206-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T06:37:29.207-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T06:37:29.207-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 6
2020-05-09T06:37:29.207-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T06:37:29.207-0700 I  CONNPOOL [RS] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:29.207-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:29.207-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:29.207-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:29.209-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:29.209-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:29.210-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:29.211-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:29.211-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:29.653-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-09T06:37:30.211-0700 I  COMMAND  [conn78] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031450, 8), signature: { hash: BinData(0, C4297C2D1C78681ED2D914EFD9CACD3D542CDEEA), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 167ms
2020-05-09T06:37:30.211-0700 I  COMMAND  [conn70] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031450, 2), signature: { hash: BinData(0, C4297C2D1C78681ED2D914EFD9CACD3D542CDEEA), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 167ms
2020-05-09T06:37:30.211-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, F30AF94DA93FCA6259E955C9FAD699F1CB5AF801), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 169ms
2020-05-09T06:37:30.211-0700 I  COMMAND  [conn64] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, F30AF94DA93FCA6259E955C9FAD699F1CB5AF801), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 169ms
2020-05-09T06:37:30.211-0700 I  COMMAND  [conn50] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, F30AF94DA93FCA6259E955C9FAD699F1CB5AF801), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031447, 2), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 169ms
2020-05-09T06:37:30.211-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:30.211-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:31.920-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47242 #137 (75 connections now open)
2020-05-09T06:37:31.920-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47246 #138 (76 connections now open)
2020-05-09T06:37:31.921-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.1:47242 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:31.921-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.1:47246 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:31.923-0700 I  NETWORK  [conn137] end connection 192.168.122.1:47242 (75 connections now open)
2020-05-09T06:37:31.924-0700 I  NETWORK  [conn138] end connection 192.168.122.1:47246 (74 connections now open)
2020-05-09T06:37:32.503-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:32.712-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:32.712-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:32.712-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T06:37:32.712-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:32.712-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:32.713-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:32.713-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-09T06:37:32.713-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:33.697-0700 I  ELECTION [conn123] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:33.697-0700 I  ELECTION [conn123] Sending vote response: { term: 7, voteGranted: true, reason: "" }
2020-05-09T06:37:33.699-0700 I  NETWORK  [conn82] end connection 192.168.122.12:37128 (73 connections now open)
2020-05-09T06:37:33.704-0700 I  ELECTION [conn123] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031449, 2), t: 6 } }
2020-05-09T06:37:33.704-0700 I  ELECTION [conn123] Sending vote response: { term: 8, voteGranted: true, reason: "" }
2020-05-09T06:37:34.048-0700 I  REPL     [replexec-4] Member n3:27019 is now in state PRIMARY
2020-05-09T06:37:34.048-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-09T06:37:35.122-0700
2020-05-09T06:37:34.052-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:34.144-0700 I  NETWORK  [conn9] end connection 192.168.122.12:36776 (72 connections now open)
2020-05-09T06:37:34.239-0700 I  NETWORK  [conn124] end connection 192.168.122.13:35894 (71 connections now open)
2020-05-09T06:37:34.714-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T06:37:34.717-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-09T06:37:34.721-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-09T06:37:35.122-0700 I  REPL     [replexec-1] Canceling priority takeover callback
2020-05-09T06:37:35.122-0700 I  ELECTION [replexec-1] Starting an election for a priority takeover
2020-05-09T06:37:35.122-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 8
2020-05-09T06:37:35.122-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 168 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:35.122-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 169 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:35.123-0700 I  ELECTION [replexec-4] VoteRequester(term 8 dry run) received a yes vote from n2:27019; response message: { term: 8, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1589031453, 3), $clusterTime: { clusterTime: Timestamp(1589031454, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031453, 3) }
2020-05-09T06:37:35.123-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 9
2020-05-09T06:37:35.132-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 170 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:35.133-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 171 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:35.138-0700 I  ELECTION [replexec-1] VoteRequester(term 9) received a yes vote from n2:27019; response message: { term: 9, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000007') }, lastCommittedOpTime: Timestamp(1589031453, 3), $clusterTime: { clusterTime: Timestamp(1589031454, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031453, 3) }
2020-05-09T06:37:35.138-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 9
2020-05-09T06:37:35.139-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T06:37:35.139-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was n3:27019
2020-05-09T06:37:35.139-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:35.139-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T06:37:35.142-0700 I  REPL     [replexec-1] Member n3:27019 is now in state SECONDARY
2020-05-09T06:37:35.142-0700 I  REPL     [replexec-1] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031453, 3), t: 8 }. My Last Applied: { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.142-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-09T06:37:35.142-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-09T06:37:35.142-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 9
2020-05-09T06:37:35.142-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T06:37:35.142-0700 I  CONNPOOL [RS] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:35.142-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:35.142-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:35.143-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:35.145-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:35.145-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:35.145-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:35.146-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:35.146-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:35.231-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-09T06:37:35.683-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:38540 #141 (72 connections now open)
2020-05-09T06:37:35.683-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:38538 #142 (73 connections now open)
2020-05-09T06:37:35.684-0700 I  NETWORK  [conn141] received client metadata from 192.168.122.12:38540 conn141: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.684-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.12:38538 conn142: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:35.855-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47404 #143 (74 connections now open)
2020-05-09T06:37:35.864-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47412 #144 (75 connections now open)
2020-05-09T06:37:35.864-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.1:47404 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:35.864-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.1:47412 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:35.867-0700 I  NETWORK  [conn143] end connection 192.168.122.1:47404 (74 connections now open)
2020-05-09T06:37:35.868-0700 I  NETWORK  [conn144] end connection 192.168.122.1:47412 (73 connections now open)
2020-05-09T06:37:36.637-0700 I  REPL     [replexec-4] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:36.684-0700 I  REPL     [replexec-0] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:36.684-0700 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:36.684-0700 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-05-09T06:37:36.684-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:36.685-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:36.685-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 23, userOpsRunning: 0 }
2020-05-09T06:37:36.686-0700 W  COMMAND  [conn56] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.686-0700 I  COMMAND  [conn56] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1589031456575), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 109ms
2020-05-09T06:37:36.686-0700 W  COMMAND  [conn54] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.686-0700 I  COMMAND  [conn54] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1589031456575), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031456, 182), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 109ms
2020-05-09T06:37:36.686-0700 W  COMMAND  [conn68] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.686-0700 I  COMMAND  [conn68] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1589031455600), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031452, 30), signature: { hash: BinData(0, 1051F2617C96A0AB5057D8571EC318BC4C0AA14C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1084ms
2020-05-09T06:37:36.686-0700 W  COMMAND  [conn67] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.686-0700 I  COMMAND  [conn67] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 27), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 812ms
2020-05-09T06:37:36.687-0700 W  COMMAND  [conn73] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.687-0700 I  COMMAND  [conn73] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1589031456480), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031456, 170), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 204ms
2020-05-09T06:37:36.687-0700 W  COMMAND  [conn59] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.687-0700 I  COMMAND  [conn59] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 6), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 880ms
2020-05-09T06:37:36.688-0700 W  COMMAND  [conn65] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.688-0700 I  COMMAND  [conn65] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 6), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 882ms
2020-05-09T06:37:36.688-0700 W  COMMAND  [conn51] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.688-0700 I  COMMAND  [conn51] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 30), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 806ms
2020-05-09T06:37:36.688-0700 W  COMMAND  [conn81] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.688-0700 W  COMMAND  [conn47] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.688-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-09T06:37:36.688-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1170ms
2020-05-09T06:37:36.688-0700 I  COMMAND  [conn81] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 6), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 882ms
2020-05-09T06:37:36.688-0700 W  COMMAND  [conn70] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn70] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1171ms
2020-05-09T06:37:36.689-0700 W  COMMAND  [conn116] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 W  COMMAND  [conn50] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn116] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031452, 30), signature: { hash: BinData(0, 1051F2617C96A0AB5057D8571EC318BC4C0AA14C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031449, 2), t: 6 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 858ms
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn50] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1169ms
2020-05-09T06:37:36.689-0700 W  COMMAND  [conn78] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn78] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1170ms
2020-05-09T06:37:36.689-0700 W  COMMAND  [conn58] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 W  COMMAND  [conn75] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn58] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1589031455599), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1088ms
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn75] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1589031456575), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031456, 15), signature: { hash: BinData(0, F67FFEC0B1F02E36BA84E468C00036870588A78B), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 111ms
2020-05-09T06:37:36.689-0700 W  COMMAND  [conn46] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.689-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1589031455599), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1089ms
2020-05-09T06:37:36.690-0700 W  COMMAND  [conn52] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.690-0700 I  COMMAND  [conn52] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1171ms
2020-05-09T06:37:36.690-0700 W  COMMAND  [conn61] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.690-0700 W  COMMAND  [conn64] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.690-0700 I  COMMAND  [conn61] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1589031455600), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1088ms
2020-05-09T06:37:36.690-0700 I  COMMAND  [conn64] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1170ms
2020-05-09T06:37:36.690-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-09T06:37:36.690-0700 W  COMMAND  [conn66] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.690-0700 W  COMMAND  [conn62] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.690-0700 I  COMMAND  [conn66] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 30), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 809ms
2020-05-09T06:37:36.690-0700 W  COMMAND  [conn71] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:36.690-0700 I  COMMAND  [conn62] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 6), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 884ms
2020-05-09T06:37:36.690-0700 I  COMMAND  [conn71] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031455, 17), signature: { hash: BinData(0, 416956498D97724BFE686DE0110AF14E62B6CF52), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 865ms
2020-05-09T06:37:37.828-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T06:37:38.140-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:38.140-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:38.142-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:38.142-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T06:37:38.960-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T06:37:39.169-0700 I  REPL     [replexec-5] Member n3:27019 is now in state SECONDARY
2020-05-09T06:37:39.169-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-09T06:37:39.169-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-09T06:37:40.265-0700
2020-05-09T06:37:39.488-0700 I  NETWORK  [conn123] end connection 192.168.122.13:35896 (72 connections now open)
2020-05-09T06:37:39.519-0700 I  NETWORK  [conn142] end connection 192.168.122.12:38538 (71 connections now open)
2020-05-09T06:37:39.584-0700 I  NETWORK  [conn19] end connection 192.168.122.12:36894 (70 connections now open)
2020-05-09T06:37:39.691-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T06:37:39.693-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589031456, 185), t: 9 }. source's GTE: { ts: Timestamp(1589031457, 1), t: 10 }
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-09T06:37:39.695-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 1, userOpsRunning: 70 }
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-09T06:37:39.695-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 141
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 118
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 117
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 116
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 112
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 111
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 110
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 109
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 108
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 107
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 105
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 104
2020-05-09T06:37:39.695-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 99
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 98
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 96
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 95
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 94
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 93
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 92
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 91
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 78
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 75
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 74
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 71
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 57
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 56
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 55
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 54
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 53
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-09T06:37:39.696-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 13
2020-05-09T06:37:39.697-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T06:37:39.697-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T06:37:39.697-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T06:37:39.702-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:39.706-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-09T06:37:39.706-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T06:37:39.706-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid dfc556fb-2d21-4f15-beaf-e1ef4ad5320d to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-09T13-37-39.0.bson
2020-05-09T06:37:39.707-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T06:37:39.707-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T06:37:39.707-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T06:37:39.707-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T06:37:39.708-0700 W  QUERY    [conn13] GetMore command executor error: FAILURE, status: InterruptedDueToReplStateChange: operation was interrupted, stats: { stage: "COLLSCAN", nReturned: 10, executionTimeMillisEstimate: 0, works: 16, advanced: 10, needTime: 3, needYield: 0, saveState: 3, restoreState: 2, isEOF: 0, direction: "forward", docsExamined: 10 }
2020-05-09T06:37:39.743-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:38726 #148 (71 connections now open)
2020-05-09T06:37:39.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:38728 #149 (72 connections now open)
2020-05-09T06:37:39.744-0700 I  NETWORK  [conn148] received client metadata from 192.168.122.12:38726 conn148: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:39.744-0700 I  NETWORK  [conn149] received client metadata from 192.168.122.12:38728 conn149: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:39.784-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589031453, 3) Initial Data Timestamp: Timestamp(1589031428, 1)
2020-05-09T06:37:39.785-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T06:37:39.801-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T06:37:39.801-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 193 records totaling to 42505 bytes
2020-05-09T06:37:39.801-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:39.801-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:39.805-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T06:37:39.805-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T06:37:39.821-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T06:37:39.821-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T06:37:39.821-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589031453, 3)
2020-05-09T06:37:39.821-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 8 update operations and 0 delete operations.
2020-05-09T06:37:39.821-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589031455, 2), t: 9 }
2020-05-09T06:37:39.822-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589031455, 2) }
2020-05-09T06:37:39.822-0700 I  COMMAND  [conn13] command local.oplog.rs command: find { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1589031456, 185) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 11, readConcern: { afterClusterTime: Timestamp(0, 1) }, $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1589031458, 1), signature: { hash: BinData(0, 3B3DDEFF29369B9FE235BE5129E9CBA9633E0192), keyId: 6824838024166113299 } }, $db: "local" } numYields:0 ok:0 errMsg:"Oplog collection reads are not allowed while in the rollback or startup state." errName:NotMasterOrSecondary errCode:13436 reslen:807 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 3 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 112727 } }, Database: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } }, oplog: { acquireCount: { r: 2 } } } protocol:op_msg 113ms
2020-05-09T06:37:39.822-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T06:37:39.824-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589031453, 3) (top of oplog: { ts: Timestamp(1589031453, 3), t: 8 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T06:37:39.824-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589031453, 3)
2020-05-09T06:37:39.824-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T06:37:39.695-0700
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T06:37:39.825-0700
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.mongos
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589031456, 185), t: 9 }
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T06:37:36.578-0700
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T06:37:35.144-0700
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 1 second(s)
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589031455, 2)
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589031453, 3)
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 		update: 8
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 9
2020-05-09T06:37:39.825-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T06:37:39.825-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T06:37:39.826-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T06:37:39.871-0700 I  ELECTION [conn141] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031453, 3), t: 8 } }
2020-05-09T06:37:39.871-0700 I  ELECTION [conn141] Sending vote response: { term: 11, voteGranted: false, reason: "candidate's term (9) is lower than mine (11)" }
2020-05-09T06:37:39.872-0700 I  NETWORK  [conn141] end connection 192.168.122.12:38540 (71 connections now open)
2020-05-09T06:37:40.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47560 #150 (72 connections now open)
2020-05-09T06:37:40.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47558 #151 (73 connections now open)
2020-05-09T06:37:40.078-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.1:47560 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:40.078-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.1:47558 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:40.082-0700 I  NETWORK  [conn151] end connection 192.168.122.1:47558 (72 connections now open)
2020-05-09T06:37:40.082-0700 I  NETWORK  [conn150] end connection 192.168.122.1:47560 (71 connections now open)
2020-05-09T06:37:40.159-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36764 #152 (72 connections now open)
2020-05-09T06:37:40.160-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.13:36764 conn152: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:41.140-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T06:37:41.140-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 11
2020-05-09T06:37:41.140-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 207 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:41.140-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 208 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:41.140-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:41.141-0700 I  ELECTION [replexec-0] VoteRequester(term 11 dry run) received a yes vote from n3:27019; response message: { term: 11, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000008') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031460, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:41.142-0700 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 12
2020-05-09T06:37:41.146-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 210 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:41.146-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 211 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:41.149-0700 I  ELECTION [replexec-3] VoteRequester(term 12) received a yes vote from n2:27019; response message: { term: 12, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031460, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:41.150-0700 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 12
2020-05-09T06:37:41.150-0700 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-05-09T06:37:41.150-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:41.150-0700 I  REPL     [replexec-3] Resetting sync source to empty, which was n2:27019
2020-05-09T06:37:41.150-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T06:37:41.150-0700 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-05-09T06:37:41.150-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:41.151-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:41.152-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031460, 1), t: 11 }. My Last Applied: { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:41.152-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T06:37:41.152-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T06:37:41.152-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 12
2020-05-09T06:37:41.152-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T06:37:41.152-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:41.153-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:41.153-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:41.153-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:41.155-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:41.155-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:41.156-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:41.156-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:41.156-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:41.156-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:41.157-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:41.158-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:41.158-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:41.158-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:41.190-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41918 #156 (73 connections now open)
2020-05-09T06:37:41.190-0700 I  NETWORK  [conn156] received client metadata from 192.168.122.11:41918 conn156: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:41.307-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47606 #157 (74 connections now open)
2020-05-09T06:37:41.307-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47610 #158 (75 connections now open)
2020-05-09T06:37:41.307-0700 I  NETWORK  [conn157] received client metadata from 192.168.122.1:47606 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.309-0700 I  NETWORK  [conn158] received client metadata from 192.168.122.1:47610 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.312-0700 I  NETWORK  [conn157] end connection 192.168.122.1:47606 (74 connections now open)
2020-05-09T06:37:41.312-0700 I  NETWORK  [conn158] end connection 192.168.122.1:47610 (73 connections now open)
2020-05-09T06:37:41.657-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:41.964-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47628 #159 (74 connections now open)
2020-05-09T06:37:41.964-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47632 #160 (75 connections now open)
2020-05-09T06:37:41.964-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.1:47628 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.965-0700 I  NETWORK  [conn160] received client metadata from 192.168.122.1:47632 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:41.969-0700 I  NETWORK  [conn159] end connection 192.168.122.1:47628 (74 connections now open)
2020-05-09T06:37:41.969-0700 I  NETWORK  [conn160] end connection 192.168.122.1:47632 (73 connections now open)
2020-05-09T06:37:42.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:41962 #161 (74 connections now open)
2020-05-09T06:37:42.540-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.11:41962 conn161: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:42.877-0700 I  REPL     [replexec-0] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:42.951-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T06:37:42.951-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-09T06:37:42.951-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-09T06:37:42.951-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:42.952-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:42.952-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 13, userOpsRunning: 0 }
2020-05-09T06:37:42.952-0700 W  COMMAND  [conn64] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.952-0700 I  COMMAND  [conn64] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031459, 5), signature: { hash: BinData(0, 8CC9B0BCA078CDA6AC3402E5FF65228E0A17174C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1763ms
2020-05-09T06:37:42.953-0700 W  COMMAND  [conn61] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.953-0700 I  COMMAND  [conn61] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 3), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 412ms
2020-05-09T06:37:42.953-0700 W  COMMAND  [conn156] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.953-0700 I  COMMAND  [conn156] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031459, 5), signature: { hash: BinData(0, 8CC9B0BCA078CDA6AC3402E5FF65228E0A17174C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1761ms
2020-05-09T06:37:42.953-0700 W  COMMAND  [conn74] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.953-0700 I  COMMAND  [conn74] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031459, 5), signature: { hash: BinData(0, 8CC9B0BCA078CDA6AC3402E5FF65228E0A17174C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1764ms
2020-05-09T06:37:42.953-0700 W  COMMAND  [conn62] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.953-0700 I  COMMAND  [conn62] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031459, 5), signature: { hash: BinData(0, 8CC9B0BCA078CDA6AC3402E5FF65228E0A17174C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1764ms
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn66] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 I  COMMAND  [conn66] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 3), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 414ms
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn75] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 I  COMMAND  [conn75] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 2), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 610ms
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn71] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn161] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn47] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 I  COMMAND  [conn161] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031461, 2), signature: { hash: BinData(0, 8A711F9EF45D56D5FD0A10F78107349040FB9A57), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 412ms
2020-05-09T06:37:42.954-0700 I  COMMAND  [conn71] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 3), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 414ms
2020-05-09T06:37:42.954-0700 I  COMMAND  [conn47] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 3), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 415ms
2020-05-09T06:37:42.954-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn78] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 W  COMMAND  [conn51] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.954-0700 I  COMMAND  [conn78] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031461, 1), signature: { hash: BinData(0, 8A711F9EF45D56D5FD0A10F78107349040FB9A57), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1700ms
2020-05-09T06:37:42.955-0700 I  COMMAND  [conn51] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031462, 3), signature: { hash: BinData(0, 6E3C6F4F9BA06EADE0FC0E0B735A33FFA1B59503), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 416ms
2020-05-09T06:37:42.955-0700 W  COMMAND  [conn73] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T06:37:42.955-0700 I  COMMAND  [conn73] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1589031456480), up: 20, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031459, 5), signature: { hash: BinData(0, 8CC9B0BCA078CDA6AC3402E5FF65228E0A17174C), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031453, 3), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1765ms
2020-05-09T06:37:42.955-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-09T06:37:44.024-0700 I  ELECTION [replexec-4] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T06:37:44.151-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:44.151-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T06:37:44.152-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:44.152-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T06:37:45.151-0700 I  ELECTION [replexec-3] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T06:37:46.220-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T06:37:46.463-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:39002 #162 (75 connections now open)
2020-05-09T06:37:46.464-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.12:39002 conn162: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:46.465-0700 I  ELECTION [conn162] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:46.465-0700 I  ELECTION [conn162] Sending vote response: { term: 14, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:46.874-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47756 #163 (76 connections now open)
2020-05-09T06:37:46.875-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47758 #164 (77 connections now open)
2020-05-09T06:37:46.875-0700 I  NETWORK  [conn163] received client metadata from 192.168.122.1:47756 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:46.875-0700 I  NETWORK  [conn164] received client metadata from 192.168.122.1:47758 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:46.877-0700 I  NETWORK  [conn163] end connection 192.168.122.1:47756 (76 connections now open)
2020-05-09T06:37:46.877-0700 I  NETWORK  [conn164] end connection 192.168.122.1:47758 (75 connections now open)
2020-05-09T06:37:47.263-0700 I  ELECTION [conn149] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:47.263-0700 I  ELECTION [conn149] Sending vote response: { term: 14, voteGranted: false, reason: "candidate's term (13) is lower than mine (14)" }
2020-05-09T06:37:47.263-0700 I  NETWORK  [conn149] end connection 192.168.122.12:38728 (74 connections now open)
2020-05-09T06:37:47.577-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T06:37:47.647-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37008 #167 (75 connections now open)
2020-05-09T06:37:47.648-0700 I  NETWORK  [conn167] received client metadata from 192.168.122.13:37008 conn167: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:47.652-0700 I  REPL     [replexec-5] Member n2:27019 is now in state SECONDARY
2020-05-09T06:37:47.653-0700 I  REPL     [replexec-0] Member n3:27019 is now in state PRIMARY
2020-05-09T06:37:47.653-0700 I  ELECTION [replexec-0] Scheduling priority takeover at 2020-05-09T06:37:48.694-0700
2020-05-09T06:37:47.828-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-09T06:37:47.956-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T06:37:47.958-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589031461, 3), t: 12 }. source's GTE: { ts: Timestamp(1589031463, 1), t: 13 }
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n3:27019)
2020-05-09T06:37:47.959-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 76 }
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-09T06:37:47.959-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 167
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 162
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 161
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 156
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 152
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 148
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 118
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 117
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 116
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 112
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 111
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 110
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 109
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 108
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 107
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 105
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 104
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 99
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 98
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 96
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 95
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 94
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 93
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 92
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 91
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-09T06:37:47.959-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 79
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 78
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 77
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 76
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 75
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 74
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 71
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 57
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 56
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 55
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 54
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 53
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-09T06:37:47.960-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 13
2020-05-09T06:37:47.960-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T06:37:47.960-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T06:37:47.960-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T06:37:47.963-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:47.966-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 3
2020-05-09T06:37:47.966-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T06:37:47.966-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.mongos with uuid dfc556fb-2d21-4f15-beaf-e1ef4ad5320d to /var/lib/mongodb/rollback/config.mongos/removed.2020-05-09T13-37-47.1.bson
2020-05-09T06:37:47.966-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T06:37:47.966-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T06:37:47.966-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T06:37:47.966-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T06:37:47.967-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:38988 #169 (76 connections now open)
2020-05-09T06:37:47.967-0700 I  NETWORK  [conn169] received client metadata from 192.168.122.12:38988 conn169: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:47.995-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589031460, 1) Initial Data Timestamp: Timestamp(1589031428, 1)
2020-05-09T06:37:47.996-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T06:37:48.007-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T06:37:48.007-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 196 records totaling to 42918 bytes
2020-05-09T06:37:48.007-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T06:37:48.007-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T06:37:48.011-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T06:37:48.011-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T06:37:48.028-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T06:37:48.028-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T06:37:48.028-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589031460, 1)
2020-05-09T06:37:48.028-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 1 update operations and 0 delete operations.
2020-05-09T06:37:48.028-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589031461, 2), t: 12 }
2020-05-09T06:37:48.028-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589031461, 2) }
2020-05-09T06:37:48.028-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T06:37:48.030-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589031460, 1) (top of oplog: { ts: Timestamp(1589031460, 1), t: 11 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T06:37:48.030-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589031460, 1)
2020-05-09T06:37:48.030-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-09T06:37:48.030-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-09T06:37:48.030-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T06:37:48.030-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T06:37:48.030-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T06:37:48.030-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T06:37:47.959-0700
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T06:37:48.031-0700
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n3:27019
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.mongos
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 3
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589031461, 3), t: 12 }
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T06:37:41.189-0700
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T06:37:41.154-0700
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589031461, 2)
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589031460, 1)
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 		config.mongos
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 		update: 1
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 2
2020-05-09T06:37:48.031-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T06:37:48.031-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T06:37:48.031-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n3:27019
2020-05-09T06:37:48.031-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T06:37:48.031-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T06:37:48.031-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T06:37:48.031-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T06:37:48.032-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-09T06:37:48.032-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-09T06:37:48.154-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-09T06:37:49.204-0700
2020-05-09T06:37:48.183-0700 I  ELECTION [conn169] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:48.184-0700 I  ELECTION [conn169] Sending vote response: { term: 15, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:49.120-0700 I  NETWORK  [conn148] end connection 192.168.122.12:38726 (75 connections now open)
2020-05-09T06:37:49.120-0700 I  NETWORK  [conn152] end connection 192.168.122.13:36764 (74 connections now open)
2020-05-09T06:37:49.204-0700 I  REPL     [replexec-2] Canceling priority takeover callback
2020-05-09T06:37:49.204-0700 I  ELECTION [replexec-2] Starting an election for a priority takeover
2020-05-09T06:37:49.204-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 15
2020-05-09T06:37:49.204-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 310 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031468, 18), t: 15 } }
2020-05-09T06:37:49.204-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 311 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 15, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031468, 18), t: 15 } }
2020-05-09T06:37:49.205-0700 I  ELECTION [replexec-3] VoteRequester(term 15 dry run) received a yes vote from n2:27019; response message: { term: 15, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031469, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:49.205-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 16
2020-05-09T06:37:49.207-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 312 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031468, 18), t: 15 } }
2020-05-09T06:37:49.207-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 313 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 16, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031468, 18), t: 15 } }
2020-05-09T06:37:49.212-0700 I  ELECTION [replexec-2] VoteRequester(term 16) received a yes vote from n2:27019; response message: { term: 16, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589031460, 1), $clusterTime: { clusterTime: Timestamp(1589031469, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589031460, 1) }
2020-05-09T06:37:49.212-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 16
2020-05-09T06:37:49.212-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T06:37:49.212-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was n3:27019
2020-05-09T06:37:49.212-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T06:37:49.212-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T06:37:49.212-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T06:37:49.214-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-09T06:37:49.214-0700 I  REPL     [replexec-0] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589031468, 18), t: 15 }. My Last Applied: { ts: Timestamp(1589031468, 18), t: 15 }
2020-05-09T06:37:49.214-0700 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-05-09T06:37:49.215-0700 I  REPL     [replexec-0] Stopping replication producer
2020-05-09T06:37:49.215-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 16
2020-05-09T06:37:49.215-0700 I  CONNPOOL [RS] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T06:37:49.215-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T06:37:49.215-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T06:37:49.215-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T06:37:49.215-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T06:37:49.217-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T06:37:49.217-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T06:37:49.218-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T06:37:49.218-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T06:37:49.218-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T06:37:49.219-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.219-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.220-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.220-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.562-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-09T06:37:49.887-0700 I  -        [conn13] operation was interrupted because a client disconnected
2020-05-09T06:37:49.888-0700 I  NETWORK  [conn13] end connection 192.168.122.13:34858 (73 connections now open)
2020-05-09T06:37:50.143-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36962 #172 (74 connections now open)
2020-05-09T06:37:50.143-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36960 #173 (75 connections now open)
2020-05-09T06:37:50.144-0700 I  NETWORK  [conn173] received client metadata from 192.168.122.13:36960 conn173: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:50.144-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.13:36962 conn172: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:50.211-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:37264 #174 (76 connections now open)
2020-05-09T06:37:50.211-0700 I  NETWORK  [conn174] received client metadata from 192.168.122.13:37264 conn174: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn51] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 939ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn66] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 939ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn61] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 54), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 880ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn44] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 938ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn80] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1589031469838), up: 35, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 215), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 376ms
2020-05-09T06:37:50.216-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn71] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 939ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn73] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 939ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn46] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031461, 2), signature: { hash: BinData(0, 8A711F9EF45D56D5FD0A10F78107349040FB9A57), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 840ms
2020-05-09T06:37:50.216-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn78] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 151), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 579ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn57] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1589031470044), up: 35, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 215), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 170ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn81] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031461, 2), signature: { hash: BinData(0, 8A711F9EF45D56D5FD0A10F78107349040FB9A57), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031460, 1), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 841ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn167] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 54), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 881ms
2020-05-09T06:37:50.216-0700 I  COMMAND  [conn75] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589031469, 188), signature: { hash: BinData(0, 5EFA626765D53768BD2905260B5A8F3B00CEB9C4), keyId: 6824838024166113299 } }, $configServerState: { opTime: { ts: Timestamp(1589031468, 18), t: 15 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 534ms
2020-05-09T06:37:50.222-0700 I  ELECTION [conn169] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:50.222-0700 I  ELECTION [conn169] Sending vote response: { term: 16, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:51.577-0700 I  ELECTION [conn169] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 16, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589031460, 1), t: 11 } }
2020-05-09T06:37:51.578-0700 I  ELECTION [conn169] Sending vote response: { term: 16, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589031460, 1), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T06:37:51.924-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48004 #175 (77 connections now open)
2020-05-09T06:37:51.924-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48012 #176 (78 connections now open)
2020-05-09T06:37:51.924-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.1:48004 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:51.924-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.1:48012 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:51.927-0700 I  NETWORK  [conn175] end connection 192.168.122.1:48004 (77 connections now open)
2020-05-09T06:37:51.927-0700 I  NETWORK  [conn176] end connection 192.168.122.1:48012 (76 connections now open)
2020-05-09T06:37:52.447-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:38740 #177 (77 connections now open)
2020-05-09T06:37:52.448-0700 I  NETWORK  [conn177] received client metadata from 192.168.122.12:38740 conn177: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:37:52.452-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:39300 #178 (78 connections now open)
2020-05-09T06:37:52.453-0700 I  NETWORK  [conn178] received client metadata from 192.168.122.12:39300 conn178: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T06:38:06.728-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
