2020-05-09 08:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T08:37:13.077-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.082-0500 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain] modules: none
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain] build environment:
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T08:37:13.083-0500 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T08:37:13.084-0500 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.084-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T08:37:13.084-0500 I  SHARDING [thread1] creating distributed lock ping thread for process n8:27017:1589031433:754216153529044378 (sleeping for 30000ms)
2020-05-09T08:37:13.084-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T08:37:13.084-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T08:37:13.085-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.085-0500 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.614-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T08:37:14.255-0500 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T08:37:14.492-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:15.618-0500 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T08:37:15.618-0500 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T08:37:15.622-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("f15bd6b7-8022-48d8-823c-6ec3a13dc0b0"), lastMod: 0 } took 0 ms
2020-05-09T08:37:15.622-0500 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T08:37:15.622-0500 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T08:37:15.622-0500 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T08:37:15.622-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:15.625-0500 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:15.625-0500 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:15.660-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35870 #10 (1 connection now open)
2020-05-09T08:37:15.662-0500 I  NETWORK  [conn10] received client metadata from 192.168.122.1:35870 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:15.667-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35880 #11 (2 connections now open)
2020-05-09T08:37:15.668-0500 I  NETWORK  [conn11] received client metadata from 192.168.122.1:35880 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.834-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36046 #12 (3 connections now open)
2020-05-09T08:37:17.834-0500 I  NETWORK  [conn12] received client metadata from 192.168.122.1:36046 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.835-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36052 #13 (4 connections now open)
2020-05-09T08:37:17.835-0500 I  NETWORK  [conn13] received client metadata from 192.168.122.1:36052 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:20.936-0500 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031435, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3e7146c-2a1c-4d23-bf7b-a1157b26c2ec") } } numYields:0 reslen:163 protocol:op_msg 3095ms
2020-05-09T08:37:20.939-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T08:37:20.942-0500 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:20.942-0500 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:20.942-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T08:37:20.943-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T08:37:20.943-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T08:37:20.943-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T08:37:20.943-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T08:37:20.943-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T08:37:20.946-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:20.946-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:20.947-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:20.948-0500 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:21.030-0500 I  NETWORK  [conn12] end connection 192.168.122.1:36046 (3 connections now open)
2020-05-09T08:37:21.030-0500 I  NETWORK  [conn13] end connection 192.168.122.1:36052 (2 connections now open)
2020-05-09T08:37:22.623-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36228 #20 (3 connections now open)
2020-05-09T08:37:22.625-0500 I  NETWORK  [conn20] received client metadata from 192.168.122.1:36228 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.625-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36242 #21 (4 connections now open)
2020-05-09T08:37:22.625-0500 I  NETWORK  [conn21] received client metadata from 192.168.122.1:36242 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.632-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36262 #22 (5 connections now open)
2020-05-09T08:37:22.637-0500 I  NETWORK  [conn22] received client metadata from 192.168.122.1:36262 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.637-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36272 #23 (6 connections now open)
2020-05-09T08:37:22.638-0500 I  NETWORK  [conn23] received client metadata from 192.168.122.1:36272 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.646-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36314 #24 (7 connections now open)
2020-05-09T08:37:22.646-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:36316 #25 (8 connections now open)
2020-05-09T08:37:22.646-0500 I  NETWORK  [conn24] received client metadata from 192.168.122.1:36314 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.647-0500 I  NETWORK  [conn25] received client metadata from 192.168.122.1:36316 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.668-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 1 ms
2020-05-09T08:37:22.683-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T08:37:22.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:23.683-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:23.683-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:23.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T08:37:23.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:24.335-0500 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:24.336-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.837-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:24.837-0500 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:24.837-0500 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T08:37:24.838-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 88), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 15, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1720ms
2020-05-09T08:37:24.838-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:24.838-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 88), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 20, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1721ms
2020-05-09T08:37:24.840-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.840-0500 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.953-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T08:37:25.154-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031443, 80) } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 82) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2037978, timeActiveMicros:2041992, timeInactiveMicros:610, 2042ms
2020-05-09T08:37:25.154-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 88), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 19, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2038ms
2020-05-09T08:37:25.155-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031444, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 20, autocommit: false } numYields:0 reslen:397 protocol:op_msg 310ms
2020-05-09T08:37:25.155-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031444, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 15, autocommit: false } numYields:0 reslen:397 protocol:op_msg 311ms
2020-05-09T08:37:25.563-0500 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:25.563-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:26.063-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:26.063-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:26.063-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:26.064-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 16, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:885715, timeInactiveMicros:0, 885ms
2020-05-09T08:37:26.064-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:885882, timeInactiveMicros:0, 885ms
2020-05-09T08:37:26.064-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:882842, timeInactiveMicros:0, 882ms
2020-05-09T08:37:26.064-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 16, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a3f8e68d-5ad2-4a5f-a69f-48811aa1549a:16 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 885ms
2020-05-09T08:37:26.064-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 21, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 42330c98-7ecf-444e-8596-f232df78a70d:21 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 886ms
2020-05-09T08:37:26.064-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 57bdd1a3-c100-49b5-8b97-747191521968:20 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:627 protocol:op_msg 882ms
2020-05-09T08:37:26.069-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:26.070-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:26.081-0500 I  SHARDING [conn24] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T08:37:26.373-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 15) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:268846, timeActiveMicros:271473, timeInactiveMicros:336, 271ms
2020-05-09T08:37:26.373-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 15) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:272399, timeActiveMicros:274712, timeInactiveMicros:360, 275ms
2020-05-09T08:37:26.373-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 10) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:291455, timeActiveMicros:293718, timeInactiveMicros:265, 293ms
2020-05-09T08:37:26.373-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 24, autocommit: false } numYields:0 reslen:214 protocol:op_msg 268ms
2020-05-09T08:37:26.373-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 19, autocommit: false } numYields:0 reslen:214 protocol:op_msg 272ms
2020-05-09T08:37:26.373-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 23, autocommit: false } numYields:0 reslen:214 protocol:op_msg 291ms
2020-05-09T08:37:26.471-0500 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T08:37:26.570-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:26.570-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:26.571-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:26.892-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 128) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:351849, timeActiveMicros:360469, timeInactiveMicros:576, 361ms
2020-05-09T08:37:26.892-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 35, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 150) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:270292, timeActiveMicros:275287, timeInactiveMicros:366, 275ms
2020-05-09T08:37:26.892-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 129), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 29, autocommit: false } numYields:0 reslen:214 protocol:op_msg 352ms
2020-05-09T08:37:26.892-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 35, autocommit: false } numYields:0 reslen:214 protocol:op_msg 270ms
2020-05-09T08:37:26.892-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 124) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:363065, timeActiveMicros:367106, timeInactiveMicros:583, 367ms
2020-05-09T08:37:26.892-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 124), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 36, autocommit: false } numYields:0 reslen:214 protocol:op_msg 363ms
2020-05-09T08:37:29.038-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:29.043-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:29.540-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.039-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:30.040-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:30.040-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T08:37:30.040-0500 I  SHARDING [conn24] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T08:37:30.041-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 64, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1992ms
2020-05-09T08:37:30.041-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:30.042-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:30.042-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:30.148-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 3) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2100642, timeActiveMicros:2118969, timeInactiveMicros:694, 2119ms
2020-05-09T08:37:30.148-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 71, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 640) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2113821, timeActiveMicros:2149472, timeInactiveMicros:554, 2150ms
2020-05-09T08:37:30.149-0500 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:30.150-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.212-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T08:37:30.540-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:31.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:31.539-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.541-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 71, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3506ms
2020-05-09T08:37:31.541-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 64, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1498ms
2020-05-09T08:37:31.541-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 70, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3494ms
2020-05-09T08:37:31.544-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T08:37:31.583-0500 I  NETWORK  [conn24] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.584-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.584-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.612-0500 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T08:37:31.683-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:31.784-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 69, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 77) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:87380, timeActiveMicros:108762, timeInactiveMicros:511, 109ms
2020-05-09T08:37:31.830-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 85), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 73, autocommit: false } numYields:0 reslen:321 protocol:op_msg 132ms
2020-05-09T08:37:31.852-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 99) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:50925, timeActiveMicros:103391, timeInactiveMicros:633, 104ms
2020-05-09T08:37:32.828-0500 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:32.833-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:32.834-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.329-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.829-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:34.329-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:34.329-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:34.330-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:34.330-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 116), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 74, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2484ms
2020-05-09T08:37:34.330-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:34.330-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:34.731-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T08:37:35.014-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 79, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 127) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3120229, timeActiveMicros:3145110, timeInactiveMicros:566, 3145ms
2020-05-09T08:37:35.015-0500 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.015-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 161) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3034234, timeActiveMicros:3043330, timeInactiveMicros:581, 3043ms
2020-05-09T08:37:35.016-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:35.515-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.516-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.516-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.517-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 163), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 75, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3536ms
2020-05-09T08:37:35.517-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031454, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 74, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1185ms
2020-05-09T08:37:35.517-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:35.518-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:35.518-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 137), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 79, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3623ms
2020-05-09T08:37:35.521-0500 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 79, autocommit: false } numYields:0 reslen:214 protocol:op_msg 276ms
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 75, autocommit: false } numYields:0 reslen:214 protocol:op_msg 277ms
2020-05-09T08:37:35.805-0500 I  NETWORK  [conn24] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.806-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:35.806-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:35.809-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031455, 2) } }, globalReadTimestamp:{ ts: Timestamp(1589031455, 2) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:287544, timeInactiveMicros:0, 287ms
2020-05-09T08:37:35.809-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 75, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031455, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 57bdd1a3-c100-49b5-8b97-747191521968:75 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 287ms
2020-05-09T08:37:36.686-0500 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.690-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.177-0500 I  NETWORK  [conn22] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.179-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:37.187-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.677-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.678-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.679-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.680-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 94, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1482ms
2020-05-09T08:37:37.680-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.680-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:37.723-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.723-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.724-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.725-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.223-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.332-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 88, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 137) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2108713, timeActiveMicros:2120335, timeInactiveMicros:584, 2120ms
2020-05-09T08:37:38.332-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 91, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 142) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2104558, timeActiveMicros:2113990, timeInactiveMicros:436, 2114ms
2020-05-09T08:37:38.333-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 147), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 91, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2105ms
2020-05-09T08:37:38.334-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 88, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2109ms
2020-05-09T08:37:38.334-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 94, autocommit: false } numYields:0 reslen:397 protocol:op_msg 652ms
2020-05-09T08:37:38.723-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.223-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.723-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.836-0500 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:39.839-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:39.841-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.223-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.223-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.224-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T08:37:40.337-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.837-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.837-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.838-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 449), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 117, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1996ms
2020-05-09T08:37:40.839-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 111, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2014ms
2020-05-09T08:37:41.534-0500 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:41.537-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:41.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.035-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.535-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.535-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.536-0500 I  NETWORK  [Sharding-Fixed-4] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:42.537-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 111, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1696ms
2020-05-09T08:37:42.537-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 117, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1697ms
2020-05-09T08:37:42.537-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.537-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.549-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 107, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 455) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3691789, timeActiveMicros:3705974, timeInactiveMicros:282, 3706ms
2020-05-09T08:37:42.549-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 465), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 107, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3691ms
2020-05-09T08:37:42.955-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:42.956-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.037-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.047-0500 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:43.049-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.049-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.050-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.050-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 112, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 87) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:425054, timeInactiveMicros:0, 425ms
2020-05-09T08:37:43.050-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 112, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 425ms
2020-05-09T08:37:43.080-0500 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:43.097-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 118, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 100) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:424286, timeInactiveMicros:0, 424ms
2020-05-09T08:37:43.097-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 100), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 118, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 424ms
2020-05-09T08:37:43.537-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.538-0500 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.909-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.909-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.911-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.037-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.257-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.037-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.537-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.621-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6b20412268df81b113504 to 5eb6b206ee2d3ee1870078ea; invalidating user cache
2020-05-09T08:37:46.038-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.537-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.815-0500 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:46.816-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.816-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.817-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.880-0500 I  NETWORK  [conn24] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 124 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 123, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4247ms
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031463, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 118, autocommit: false } numYields:0 reslen:399 protocol:op_msg 3354ms
2020-05-09T08:37:46.896-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 123, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 95) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:587, timeActiveMicros:4248110, timeInactiveMicros:745, 4248ms
2020-05-09T08:37:46.903-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:46.904-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:46.904-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:46.905-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.037-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.404-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:47.405-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:47.406-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.537-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.625-0500 I  NETWORK  [conn23] end connection 192.168.122.1:36272 (7 connections now open)
2020-05-09T08:37:47.626-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37802 #62 (8 connections now open)
2020-05-09T08:37:47.626-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37804 #63 (9 connections now open)
2020-05-09T08:37:47.627-0500 I  NETWORK  [conn62] received client metadata from 192.168.122.1:37802 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.627-0500 I  NETWORK  [conn63] received client metadata from 192.168.122.1:37804 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.674-0500 I  NETWORK  [conn25] end connection 192.168.122.1:36316 (8 connections now open)
2020-05-09T08:37:47.675-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37814 #64 (9 connections now open)
2020-05-09T08:37:47.675-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37816 #65 (10 connections now open)
2020-05-09T08:37:47.675-0500 I  NETWORK  [conn64] received client metadata from 192.168.122.1:37814 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.676-0500 I  NETWORK  [conn65] received client metadata from 192.168.122.1:37816 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.813-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 129, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 30) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:879129, timeActiveMicros:882420, timeInactiveMicros:365, 882ms
2020-05-09T08:37:47.813-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 129, autocommit: false } numYields:0 reslen:214 protocol:op_msg 879ms
2020-05-09T08:37:47.815-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a3f8e68d-5ad2-4a5f-a69f-48811aa1549a") }, txnNumber: 119, autocommit: false } numYields:0 reslen:322 protocol:op_msg 912ms
2020-05-09T08:37:47.816-0500 I  NETWORK  [conn24] end connection 192.168.122.1:36314 (9 connections now open)
2020-05-09T08:37:48.037-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:48.142-0500 I  NETWORK  [conn64] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:48.144-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.146-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.537-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.538-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.538-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:48.540-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 13), t: 15 }
2020-05-09T08:37:48.644-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:49.143-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.143-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.144-0500 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("e6ee430c-3198-46e5-8efa-bbe1792f1d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 30) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1515774, timeInactiveMicros:0, 1515ms
2020-05-09T08:37:49.145-0500 I  COMMAND  [conn62] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6ee430c-3198-46e5-8efa-bbe1792f1d6e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1516ms
2020-05-09T08:37:49.145-0500 I  TXN      [conn64] transaction parameters:{ lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 30) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1467013, timeInactiveMicros:0, 1467ms
2020-05-09T08:37:49.145-0500 I  COMMAND  [conn64] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1467ms
2020-05-09T08:37:49.269-0500 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 123ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn62] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6ee430c-3198-46e5-8efa-bbe1792f1d6e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 124ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 127 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 130, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:363 protocol:op_msg 1455ms
2020-05-09T08:37:49.272-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 130, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 34) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:688, timeActiveMicros:1456441, timeInactiveMicros:453, 1456ms
2020-05-09T08:37:49.494-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 133, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031469, 74) } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 74) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:113318, timeActiveMicros:120038, timeInactiveMicros:322, 120ms
2020-05-09T08:37:49.494-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 133, autocommit: false } numYields:0 reslen:214 protocol:op_msg 113ms
2020-05-09T08:37:49.495-0500 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13") }, txnNumber: 4, autocommit: false } numYields:0 reslen:320 protocol:op_msg 112ms
2020-05-09T08:37:49.495-0500 I  COMMAND  [conn62] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6ee430c-3198-46e5-8efa-bbe1792f1d6e") }, txnNumber: 4, autocommit: false } numYields:0 reslen:320 protocol:op_msg 112ms
2020-05-09T08:37:49.680-0500 I  NETWORK  [conn20] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:50.181-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.181-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.182-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T08:37:50.182-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 140, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 187) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:502289, timeInactiveMicros:0, 502ms
2020-05-09T08:37:50.182-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 140, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 502ms
2020-05-09T08:37:50.182-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:50.183-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:50.183-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:50.216-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T08:37:50.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:50.688-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:52.352-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:52.671-0500 I  NETWORK  [conn62] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:52.673-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:53.172-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:53.173-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:53.174-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 140, autocommit: false } numYields:0 reslen:517 protocol:op_msg 2990ms
2020-05-09T08:37:53.174-0500 I  TXN      [conn64] transaction parameters:{ lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 187) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3484851, timeInactiveMicros:0, 3484ms
2020-05-09T08:37:53.174-0500 I  COMMAND  [conn64] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13") }, txnNumber: 10, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3485ms
2020-05-09T08:37:53.513-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("42330c98-7ecf-444e-8596-f232df78a70d") }, txnNumber: 140, autocommit: false } numYields:0 reslen:399 protocol:op_msg 337ms
2020-05-09T08:37:53.513-0500 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a96524b1-e5c9-4e28-8354-7d7fb4736f13") }, txnNumber: 10, autocommit: false } numYields:0 reslen:397 protocol:op_msg 337ms
2020-05-09T08:37:53.514-0500 I  TXN      [conn62] transaction parameters:{ lsid: { id: UUID("e6ee430c-3198-46e5-8efa-bbe1792f1d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 187) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3824689, timeInactiveMicros:0, 3824ms
2020-05-09T08:37:53.514-0500 I  COMMAND  [conn62] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 137 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e6ee430c-3198-46e5-8efa-bbe1792f1d6e") }, txnNumber: 9, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction e6ee430c-3198-46e5-8efa-bbe1792f1d6e:9 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1589031469, 187) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 3824ms
2020-05-09T08:37:57.313-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031463, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("57bdd1a3-c100-49b5-8b97-747191521968") }, txnNumber: 112, autocommit: false } numYields:0 reslen:517 protocol:op_msg 14261ms
2020-05-09T08:37:57.313-0500 I  NETWORK  [conn22] end connection 192.168.122.1:36262 (8 connections now open)
2020-05-09T08:37:57.456-0500 I  NETWORK  [conn62] end connection 192.168.122.1:37802 (7 connections now open)
2020-05-09T08:37:57.456-0500 I  NETWORK  [conn20] end connection 192.168.122.1:36228 (6 connections now open)
2020-05-09T08:37:57.457-0500 I  NETWORK  [conn64] end connection 192.168.122.1:37814 (5 connections now open)
2020-05-09T08:37:57.458-0500 I  NETWORK  [conn63] end connection 192.168.122.1:37804 (4 connections now open)
2020-05-09T08:37:57.458-0500 I  NETWORK  [conn21] end connection 192.168.122.1:36242 (3 connections now open)
2020-05-09T08:37:57.458-0500 I  NETWORK  [conn65] end connection 192.168.122.1:37816 (2 connections now open)
2020-05-09T08:37:57.465-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38066 #71 (3 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:38070 #72 (4 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn71] received client metadata from 192.168.122.1:38066 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn72] received client metadata from 192.168.122.1:38070 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn72] end connection 192.168.122.1:38070 (3 connections now open)
2020-05-09T08:37:57.468-0500 I  NETWORK  [conn71] end connection 192.168.122.1:38066 (2 connections now open)
