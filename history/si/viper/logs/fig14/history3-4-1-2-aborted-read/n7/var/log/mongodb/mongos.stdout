2020-05-09 08:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T08:37:13.080-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T08:37:13.082-0500 I  CONTROL  [main] 
2020-05-09T08:37:13.082-0500 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] modules: none
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] build environment:
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T08:37:13.082-0500 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T08:37:13.083-0500 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.084-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T08:37:13.084-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T08:37:13.084-0500 I  SHARDING [thread1] creating distributed lock ping thread for process n7:27017:1589031433:-6073729396180689879 (sleeping for 30000ms)
2020-05-09T08:37:13.084-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T08:37:13.086-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.086-0500 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:13.614-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T08:37:13.616-0500 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-09T08:37:14.255-0500 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T08:37:14.620-0500 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T08:37:14.620-0500 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T08:37:14.624-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("71f3b221-dfe7-47b4-9b11-218aa039b7d1"), lastMod: 0 } took 0 ms
2020-05-09T08:37:14.624-0500 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T08:37:14.624-0500 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T08:37:14.624-0500 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T08:37:14.625-0500 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:14.625-0500 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T08:37:14.711-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:15.156-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35112 #10 (1 connection now open)
2020-05-09T08:37:15.157-0500 I  NETWORK  [conn10] received client metadata from 192.168.122.1:35112 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:15.157-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35122 #11 (2 connections now open)
2020-05-09T08:37:15.158-0500 I  NETWORK  [conn11] received client metadata from 192.168.122.1:35122 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.833-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35314 #12 (3 connections now open)
2020-05-09T08:37:17.834-0500 I  NETWORK  [conn12] received client metadata from 192.168.122.1:35314 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:17.834-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35324 #13 (4 connections now open)
2020-05-09T08:37:17.835-0500 I  NETWORK  [conn13] received client metadata from 192.168.122.1:35324 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:21.984-0500 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b6cc6f8d-d418-4dd8-b936-9b0422f12238") } } numYields:0 reslen:163 protocol:op_msg 4140ms
2020-05-09T08:37:21.987-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T08:37:21.989-0500 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:21.989-0500 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:21.989-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T08:37:21.989-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T08:37:21.989-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T08:37:21.989-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T08:37:21.989-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T08:37:21.990-0500 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T08:37:21.993-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:21.993-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:21.994-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:21.994-0500 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:22.070-0500 I  NETWORK  [conn12] end connection 192.168.122.1:35314 (3 connections now open)
2020-05-09T08:37:22.070-0500 I  NETWORK  [conn13] end connection 192.168.122.1:35324 (2 connections now open)
2020-05-09T08:37:22.623-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35484 #20 (3 connections now open)
2020-05-09T08:37:22.623-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35500 #21 (4 connections now open)
2020-05-09T08:37:22.625-0500 I  NETWORK  [conn21] received client metadata from 192.168.122.1:35500 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.625-0500 I  NETWORK  [conn20] received client metadata from 192.168.122.1:35484 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.625-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35518 #22 (5 connections now open)
2020-05-09T08:37:22.626-0500 I  NETWORK  [conn22] received client metadata from 192.168.122.1:35518 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.628-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35532 #23 (6 connections now open)
2020-05-09T08:37:22.629-0500 I  NETWORK  [conn23] received client metadata from 192.168.122.1:35532 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.637-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35540 #24 (7 connections now open)
2020-05-09T08:37:22.637-0500 I  NETWORK  [conn24] received client metadata from 192.168.122.1:35540 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.638-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:35548 #25 (8 connections now open)
2020-05-09T08:37:22.638-0500 I  NETWORK  [conn25] received client metadata from 192.168.122.1:35548 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:22.668-0500 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 2 ms
2020-05-09T08:37:23.669-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:23.669-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:23.901-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T08:37:23.901-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:24.129-0500 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:24.335-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.630-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T08:37:24.716-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:24.717-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.717-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:24.953-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T08:37:25.129-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.130-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.130-0500 I  CONNPOOL [ShardRegistry] Connecting to n9:27018
2020-05-09T08:37:25.154-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 106) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2009408, timeActiveMicros:2014302, timeInactiveMicros:546, 2014ms
2020-05-09T08:37:25.154-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 20, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2009ms
2020-05-09T08:37:25.154-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031443, 127) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1953527, timeActiveMicros:1958123, timeInactiveMicros:340, 1958ms
2020-05-09T08:37:25.155-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 128), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 21, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1953ms
2020-05-09T08:37:25.233-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 20, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2105ms
2020-05-09T08:37:25.603-0500 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T08:37:25.604-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.604-0500 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:25.605-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 37) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:374487, timeInactiveMicros:0, 374ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 20, autocommit: false } numYields:0 reslen:397 protocol:op_msg 371ms
2020-05-09T08:37:25.605-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 26, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 374ms
2020-05-09T08:37:25.866-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 108) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:211255, timeActiveMicros:218813, timeInactiveMicros:570, 219ms
2020-05-09T08:37:25.866-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 109), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 24, autocommit: false } numYields:0 reslen:214 protocol:op_msg 211ms
2020-05-09T08:37:25.867-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 27, autocommit: false } numYields:0 reslen:321 protocol:op_msg 232ms
2020-05-09T08:37:26.372-0500 I  SHARDING [conn20] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T08:37:26.372-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 33, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 170) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:413933, timeActiveMicros:419646, timeInactiveMicros:349, 419ms
2020-05-09T08:37:26.372-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 33, autocommit: false } numYields:0 reslen:214 protocol:op_msg 414ms
2020-05-09T08:37:26.372-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 184) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:379990, timeActiveMicros:385462, timeInactiveMicros:587, 386ms
2020-05-09T08:37:26.373-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 186), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 32, autocommit: false } numYields:0 reslen:214 protocol:op_msg 380ms
2020-05-09T08:37:26.580-0500 I  NETWORK  [conn24] Marking host n9:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T08:37:26.580-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 31, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 58) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1254246, timeInactiveMicros:0, 1254ms
2020-05-09T08:37:26.580-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 58), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 31, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1254ms
2020-05-09T08:37:26.669-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:26.669-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T08:37:26.892-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 45, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 123) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:362548, timeActiveMicros:366529, timeInactiveMicros:600, 367ms
2020-05-09T08:37:26.892-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 124), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 45, autocommit: false } numYields:0 reslen:214 protocol:op_msg 362ms
2020-05-09T08:37:26.892-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 152), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 33, autocommit: false } numYields:0 reslen:321 protocol:op_msg 268ms
2020-05-09T08:37:26.893-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 116), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 40, autocommit: false } numYields:0 reslen:321 protocol:op_msg 382ms
2020-05-09T08:37:26.937-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T08:37:29.040-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:29.042-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:29.042-0500 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:29.043-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:29.541-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.040-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:30.040-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:30.040-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T08:37:30.041-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T08:37:30.041-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:30.041-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 65, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2005ms
2020-05-09T08:37:30.042-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:30.042-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:30.148-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 72, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031447, 652) } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 2) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2100938, timeActiveMicros:2141040, timeInactiveMicros:405, 2141ms
2020-05-09T08:37:30.148-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 78, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 5) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2101112, timeActiveMicros:2118211, timeInactiveMicros:400, 2118ms
2020-05-09T08:37:30.148-0500 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:30.149-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:30.212-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T08:37:30.541-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:31.041-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:31.540-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:31.542-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 72, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3495ms
2020-05-09T08:37:31.542-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 65, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1499ms
2020-05-09T08:37:31.542-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 78, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3495ms
2020-05-09T08:37:31.576-0500 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T08:37:31.644-0500 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:31.645-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.646-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:31.828-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 85) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 85) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:124247, timeActiveMicros:135942, timeInactiveMicros:459, 136ms
2020-05-09T08:37:31.828-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 68, autocommit: false } numYields:0 reslen:214 protocol:op_msg 124ms
2020-05-09T08:37:31.828-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 67) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:150911, timeActiveMicros:184464, timeInactiveMicros:637, 185ms
2020-05-09T08:37:31.829-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 80, autocommit: false } numYields:0 reslen:214 protocol:op_msg 151ms
2020-05-09T08:37:31.831-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:32.830-0500 I  NETWORK  [conn20] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:32.832-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:32.833-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.331-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:33.832-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:34.331-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:34.331-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:34.332-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:34.332-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:34.332-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:34.731-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T08:37:35.015-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 85, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 4) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2971974, timeActiveMicros:2976493, timeInactiveMicros:480, 2976ms
2020-05-09T08:37:35.015-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 9) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2962567, timeActiveMicros:2971531, timeInactiveMicros:641, 2972ms
2020-05-09T08:37:35.016-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 81, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 29) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2802579, timeActiveMicros:2805556, timeInactiveMicros:265, 2805ms
2020-05-09T08:37:35.016-0500 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.016-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:35.517-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.517-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:35.517-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T08:37:35.518-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.519-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 85, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3475ms
2020-05-09T08:37:35.519-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 81, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3305ms
2020-05-09T08:37:35.519-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:35.519-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:35.520-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 74, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3466ms
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 85, autocommit: false } numYields:0 reslen:214 protocol:op_msg 275ms
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 74, autocommit: false } numYields:0 reslen:214 protocol:op_msg 277ms
2020-05-09T08:37:35.798-0500 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 81, autocommit: false } numYields:0 reslen:214 protocol:op_msg 276ms
2020-05-09T08:37:35.803-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:35.803-0500 I  NETWORK  [conn22] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:35.804-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:35.804-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:36.688-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.690-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:36.691-0500 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:36.692-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:37.176-0500 I  NETWORK  [conn24] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.177-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:37.178-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:37.189-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.189-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:37.190-0500 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T08:37:37.678-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.678-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:37.680-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 96, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1419ms
2020-05-09T08:37:37.680-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 153), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 101, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1441ms
2020-05-09T08:37:37.724-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.724-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:37.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.224-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:38.332-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 93, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 155) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2086730, timeActiveMicros:2089203, timeInactiveMicros:296, 2089ms
2020-05-09T08:37:38.333-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 96, autocommit: false } numYields:0 reslen:397 protocol:op_msg 650ms
2020-05-09T08:37:38.333-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 93, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2087ms
2020-05-09T08:37:38.334-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 101, autocommit: false } numYields:0 reslen:398 protocol:op_msg 651ms
2020-05-09T08:37:38.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.224-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.724-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:39.838-0500 I  NETWORK  [conn24] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:39.840-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:39.841-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.224-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.224-0500 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:40.225-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031460, 1), t: 11 }
2020-05-09T08:37:40.338-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:40.838-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.838-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:40.840-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 127, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2014ms
2020-05-09T08:37:40.840-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 466), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 118, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1981ms
2020-05-09T08:37:41.536-0500 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:41.538-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.036-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:42.536-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.537-0500 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:42.538-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:42.539-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 118, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1697ms
2020-05-09T08:37:42.539-0500 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 127, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1697ms
2020-05-09T08:37:42.540-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:42.549-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 119, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 462) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3685031, timeActiveMicros:3697009, timeInactiveMicros:345, 3697ms
2020-05-09T08:37:42.549-0500 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 469), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 119, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3685ms
2020-05-09T08:37:42.610-0500 I  NETWORK  [conn24] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:42.953-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:42.954-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.027-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.028-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:43.029-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.029-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 124, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 72) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:419031, timeInactiveMicros:0, 419ms
2020-05-09T08:37:43.029-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 72), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 124, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 419ms
2020-05-09T08:37:43.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:43.540-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:43.540-0500 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T08:37:43.910-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.910-0500 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/n4:27018,n5:27018,n6:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:43.912-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.257-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:44.623-0500 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6b20412268df81b113504 to 5eb6b206cf9c9fca3fc26afd; invalidating user cache
2020-05-09T08:37:45.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:45.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.815-0500 I  NETWORK  [conn22] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:46.816-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.816-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:46.818-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 131, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 73) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4203811, timeInactiveMicros:0, 4203ms
2020-05-09T08:37:46.818-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:46.818-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 73), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 131, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 4204ms
2020-05-09T08:37:46.820-0500 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031462, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 124, autocommit: false } numYields:0 reslen:517 protocol:op_msg 3789ms
2020-05-09T08:37:46.895-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 73), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 122, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4280ms
2020-05-09T08:37:46.896-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 122, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 73) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:596, timeActiveMicros:4281253, timeInactiveMicros:731, 4281ms
2020-05-09T08:37:47.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.539-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:47.610-0500 I  NETWORK  [conn25] end connection 192.168.122.1:35548 (7 connections now open)
2020-05-09T08:37:47.611-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37054 #65 (8 connections now open)
2020-05-09T08:37:47.611-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37056 #66 (9 connections now open)
2020-05-09T08:37:47.612-0500 I  NETWORK  [conn65] received client metadata from 192.168.122.1:37054 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.612-0500 I  NETWORK  [conn66] received client metadata from 192.168.122.1:37056 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.614-0500 I  NETWORK  [conn21] end connection 192.168.122.1:35500 (8 connections now open)
2020-05-09T08:37:47.615-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37058 #67 (9 connections now open)
2020-05-09T08:37:47.615-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37060 #68 (10 connections now open)
2020-05-09T08:37:47.615-0500 I  NETWORK  [conn67] received client metadata from 192.168.122.1:37058 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.616-0500 I  NETWORK  [conn68] received client metadata from 192.168.122.1:37060 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:47.617-0500 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T08:37:47.747-0500 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 132, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:850915, timeInactiveMicros:0, 850ms
2020-05-09T08:37:47.747-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 123, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:849219, timeInactiveMicros:0, 849ms
2020-05-09T08:37:47.747-0500 I  COMMAND  [conn67] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 130ms
2020-05-09T08:37:47.747-0500 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3049097-7cca-4f75-8406-5509ab480d6e") }, txnNumber: 132, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 851ms
2020-05-09T08:37:47.747-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 123, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 849ms
2020-05-09T08:37:47.747-0500 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 125, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:851443, timeInactiveMicros:0, 851ms
2020-05-09T08:37:47.747-0500 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5466143c-6e64-4c36-a7b9-0c13071e589b") }, txnNumber: 125, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 851ms
2020-05-09T08:37:47.749-0500 I  NETWORK  [conn24] end connection 192.168.122.1:35540 (9 connections now open)
2020-05-09T08:37:47.749-0500 I  NETWORK  [conn20] end connection 192.168.122.1:35484 (8 connections now open)
2020-05-09T08:37:47.814-0500 I  TXN      [conn67] transaction parameters:{ lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 11) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:64475, timeActiveMicros:194527, timeInactiveMicros:2251, 196ms
2020-05-09T08:37:48.039-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T08:37:48.143-0500 I  NETWORK  [conn67] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:48.144-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.145-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:48.540-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.540-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:48.558-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 17), t: 15 }
2020-05-09T08:37:48.644-0500 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T08:37:49.144-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.144-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T08:37:49.146-0500 I  TXN      [conn67] transaction parameters:{ lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 38) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1329059, timeInactiveMicros:0, 1329ms
2020-05-09T08:37:49.146-0500 I  TXN      [conn65] transaction parameters:{ lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 11) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1532689, timeInactiveMicros:0, 1532ms
2020-05-09T08:37:49.146-0500 I  COMMAND  [conn67] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1329ms
2020-05-09T08:37:49.146-0500 I  COMMAND  [conn65] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031466, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1533ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn67] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 122ms
2020-05-09T08:37:49.270-0500 I  COMMAND  [conn65] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 122ms
2020-05-09T08:37:49.271-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 131 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 127, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1405ms
2020-05-09T08:37:49.272-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 127, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 53) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:879, timeActiveMicros:1406187, timeInactiveMicros:503, 1406ms
2020-05-09T08:37:49.333-0500 I  NETWORK  [conn67] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:49.334-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:49.334-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:49.334-0500 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:49.335-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:49.335-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T08:37:49.495-0500 I  TXN      [conn65] transaction parameters:{ lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031469, 74) } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 74) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:114282, timeActiveMicros:121035, timeInactiveMicros:325, 121ms
2020-05-09T08:37:49.495-0500 I  COMMAND  [conn65] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4") }, txnNumber: 4, autocommit: false } numYields:0 reslen:214 protocol:op_msg 114ms
2020-05-09T08:37:49.495-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 130, autocommit: false } numYields:0 reslen:322 protocol:op_msg 112ms
2020-05-09T08:37:49.867-0500 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T08:37:49.868-0500 I  NETWORK  [conn67] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T08:37:50.216-0500 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T08:37:50.251-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.252-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:50.253-0500 I  TXN      [conn65] transaction parameters:{ lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 187) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:573854, timeInactiveMicros:0, 573ms
2020-05-09T08:37:50.253-0500 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 136, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 187) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:572711, timeInactiveMicros:0, 572ms
2020-05-09T08:37:50.253-0500 I  COMMAND  [conn67] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 173), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8") }, txnNumber: 4, autocommit: false } numYields:0 reslen:513 protocol:op_msg 604ms
2020-05-09T08:37:50.253-0500 I  COMMAND  [conn65] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 184), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4") }, txnNumber: 12, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 574ms
2020-05-09T08:37:50.253-0500 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 136, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 572ms
2020-05-09T08:37:52.673-0500 I  NETWORK  [conn67] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T08:37:53.173-0500 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:53.173-0500 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T08:37:53.175-0500 I  COMMAND  [conn67] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8") }, txnNumber: 4, autocommit: false } numYields:0 reslen:513 protocol:op_msg 2920ms
2020-05-09T08:37:53.175-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 136, autocommit: false } numYields:0 reslen:517 protocol:op_msg 2921ms
2020-05-09T08:37:53.175-0500 I  COMMAND  [conn65] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4") }, txnNumber: 12, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2921ms
2020-05-09T08:37:53.513-0500 I  COMMAND  [conn65] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4d61bb6-4fee-4d34-a565-5d2ac744d6e4") }, txnNumber: 12, autocommit: false } numYields:0 reslen:397 protocol:op_msg 337ms
2020-05-09T08:37:53.513-0500 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("419126d6-c1e0-4faa-8b24-4f387e6c33d6") }, txnNumber: 136, autocommit: false } numYields:0 reslen:399 protocol:op_msg 337ms
2020-05-09T08:37:53.514-0500 I  COMMAND  [conn67] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031472, 30) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 337ms
2020-05-09T08:37:53.537-0500 I  TXN      [conn67] transaction parameters:{ lsid: { id: UUID("4a6dac8a-02f1-4386-ad3e-579d85a4b8c8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031472, 30) } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 30) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:22642, timeActiveMicros:360390, timeInactiveMicros:559, 360ms
2020-05-09T08:37:57.456-0500 I  NETWORK  [conn67] end connection 192.168.122.1:37058 (7 connections now open)
2020-05-09T08:37:57.456-0500 I  NETWORK  [conn65] end connection 192.168.122.1:37054 (6 connections now open)
2020-05-09T08:37:57.456-0500 I  NETWORK  [conn22] end connection 192.168.122.1:35518 (5 connections now open)
2020-05-09T08:37:57.457-0500 I  NETWORK  [conn66] end connection 192.168.122.1:37056 (4 connections now open)
2020-05-09T08:37:57.457-0500 I  NETWORK  [conn68] end connection 192.168.122.1:37060 (3 connections now open)
2020-05-09T08:37:57.458-0500 I  NETWORK  [conn23] end connection 192.168.122.1:35532 (2 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37342 #70 (3 connections now open)
2020-05-09T08:37:57.466-0500 I  NETWORK  [conn70] received client metadata from 192.168.122.1:37342 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T08:37:57.467-0500 I  NETWORK  [listener] connection accepted from 192.168.122.1:37348 #71 (4 connections now open)
2020-05-09T08:37:57.467-0500 I  NETWORK  [conn71] end connection 192.168.122.1:37348 (3 connections now open)
2020-05-09T08:37:57.468-0500 I  NETWORK  [conn70] end connection 192.168.122.1:37342 (2 connections now open)
