2020-05-09 06:37:12 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T06:37:13.077-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T06:37:13.082-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.082-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T06:37:13.082-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T06:37:13.082-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T06:37:13.082-0700 I  CONTROL  [main] 
2020-05-09T06:37:13.083-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T06:37:13.083-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T06:37:13.084-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.084-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T06:37:13.084-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T06:37:13.084-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T06:37:13.084-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n2:27017:1589031433:7244426040151103396 (sleeping for 30000ms)
2020-05-09T06:37:13.085-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.085-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:13.614-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589031431, 2), t: 2 }
2020-05-09T06:37:13.615-0700 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-09T06:37:14.256-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T06:37:14.615-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:14.621-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T06:37:14.621-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T06:37:14.624-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("c8438dc5-5d4e-4afd-98b4-537028b5df62"), lastMod: 0 } took 0 ms
2020-05-09T06:37:14.624-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T06:37:14.624-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T06:37:14.625-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T06:37:14.625-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:14.625-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T06:37:15.155-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44186 #10 (1 connection now open)
2020-05-09T06:37:15.156-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:44186 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:15.157-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44204 #11 (2 connections now open)
2020-05-09T06:37:15.158-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:44204 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.830-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44372 #12 (3 connections now open)
2020-05-09T06:37:17.830-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44382 #13 (4 connections now open)
2020-05-09T06:37:17.830-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:44372 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:17.831-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:44382 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:20.426-0700 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031434, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b515d294-26d9-44ef-a8c9-26678c33d535") } } numYields:0 reslen:163 protocol:op_msg 2588ms
2020-05-09T06:37:20.430-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("c2eb148b-f5ae-488e-9582-0960c43101b7"), lastMod: 1 } took 1 ms
2020-05-09T06:37:20.433-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:20.433-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:20.433-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T06:37:20.433-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T06:37:20.433-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T06:37:20.433-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T06:37:20.433-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T06:37:20.433-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T06:37:20.437-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:20.437-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:20.437-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:20.437-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:20.513-0700 I  NETWORK  [conn12] end connection 192.168.122.1:44372 (3 connections now open)
2020-05-09T06:37:20.514-0700 I  NETWORK  [conn13] end connection 192.168.122.1:44382 (2 connections now open)
2020-05-09T06:37:22.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44570 #20 (3 connections now open)
2020-05-09T06:37:22.623-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44574 #21 (4 connections now open)
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:44574 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.625-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:44570 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.639-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44634 #22 (5 connections now open)
2020-05-09T06:37:22.639-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:44634 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.640-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44656 #23 (6 connections now open)
2020-05-09T06:37:22.641-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:44656 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.649-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44672 #24 (7 connections now open)
2020-05-09T06:37:22.649-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:44672 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.651-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:44682 #25 (8 connections now open)
2020-05-09T06:37:22.651-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.1:44682 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:22.668-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6b20e0f8124bc6bb7e6e0 took 2 ms
2020-05-09T06:37:22.675-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T06:37:22.676-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T06:37:23.675-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T06:37:23.675-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T06:37:23.676-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:23.676-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:24.130-0700 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:24.131-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.131-0700 I  NETWORK  [conn20] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:24.132-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.632-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:24.714-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:24.715-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:24.715-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:24.953-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031442, 16), t: 2 }, now { ts: Timestamp(1589031444, 6), t: 3 }
2020-05-09T06:37:25.131-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.132-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.133-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 121), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 21, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1956ms
2020-05-09T06:37:25.133-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 83), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 16, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2018ms
2020-05-09T06:37:25.134-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031443, 125), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 20, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1947ms
2020-05-09T06:37:25.563-0700 I  NETWORK  [conn20] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:25.563-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:25.631-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.631-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:25.632-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 17, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:454092, timeInactiveMicros:0, 454ms
2020-05-09T06:37:25.632-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 17, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 0d4d0c6b-195a-4ac2-8e77-1c6195fb2440:17 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 454ms
2020-05-09T06:37:25.632-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:454415, timeInactiveMicros:0, 454ms
2020-05-09T06:37:25.633-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 21, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 8) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:454467, timeInactiveMicros:0, 454ms
2020-05-09T06:37:25.633-0700 I  COMMAND  [conn24] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 22, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction ad3faa0a-dddc-427a-b759-609ae813328b:22 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 454ms
2020-05-09T06:37:25.633-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031445, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 21, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031445, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction ac2b3d97-0851-4773-80ff-9b9af9506658:21 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 454ms
2020-05-09T06:37:25.867-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 21, autocommit: false } numYields:0 reslen:397 protocol:op_msg 233ms
2020-05-09T06:37:25.867-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 22, autocommit: false } numYields:0 reslen:397 protocol:op_msg 233ms
2020-05-09T06:37:25.867-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 87), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 17, autocommit: false } numYields:0 reslen:397 protocol:op_msg 233ms
2020-05-09T06:37:26.272-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:26.272-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.272-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:26.273-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031444, 6), t: 3 }, now { ts: Timestamp(1589031446, 9), t: 4 }
2020-05-09T06:37:26.373-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 23, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031445, 180) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:396583, timeActiveMicros:398024, timeInactiveMicros:261, 398ms
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 180), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 23, autocommit: false } numYields:0 reslen:214 protocol:op_msg 396ms
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 188), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 26, autocommit: false } numYields:0 reslen:321 protocol:op_msg 370ms
2020-05-09T06:37:26.374-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031445, 181), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 26, autocommit: false } numYields:0 reslen:321 protocol:op_msg 395ms
2020-05-09T06:37:26.892-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031446, 73) } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 73) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:427994, timeActiveMicros:450350, timeInactiveMicros:431, 450ms
2020-05-09T06:37:26.892-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 86), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 29, autocommit: false } numYields:0 reslen:214 protocol:op_msg 428ms
2020-05-09T06:37:26.893-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 39, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031446, 147) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:295527, timeActiveMicros:297788, timeInactiveMicros:526, 298ms
2020-05-09T06:37:26.893-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 147), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 39, autocommit: false } numYields:0 reslen:214 protocol:op_msg 295ms
2020-05-09T06:37:26.893-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031446, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 36, autocommit: false } numYields:0 reslen:321 protocol:op_msg 304ms
2020-05-09T06:37:29.040-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:29.042-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:29.541-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.041-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:30.041-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:30.041-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T06:37:30.042-0700 I  SHARDING [conn24] Received reply from shard n6:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031446, 87), t: 4 }, now { ts: Timestamp(1589031447, 2), t: 5 }
2020-05-09T06:37:30.042-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 63, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1993ms
2020-05-09T06:37:30.043-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:30.112-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:30.112-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:30.146-0700 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:30.147-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.148-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 71, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031448, 23) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2027810, timeActiveMicros:2029297, timeInactiveMicros:272, 2029ms
2020-05-09T06:37:30.149-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:30.211-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031447, 2), t: 5 }, now { ts: Timestamp(1589031449, 2), t: 6 }
2020-05-09T06:37:30.541-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.041-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:31.542-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.542-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:31.542-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T06:37:31.543-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031448, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 71, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3422ms
2020-05-09T06:37:31.544-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031449, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 63, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1500ms
2020-05-09T06:37:31.575-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031447, 632) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3578951, timeActiveMicros:3613053, timeInactiveMicros:367, 3613ms
2020-05-09T06:37:31.575-0700 I  COMMAND  [conn22] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031447, 638), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 68, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3579ms
2020-05-09T06:37:31.676-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:31.745-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 67) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 67) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:67215, timeActiveMicros:101254, timeInactiveMicros:637, 101ms
2020-05-09T06:37:31.747-0700 I  NETWORK  [conn22] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:31.749-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.749-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:31.830-0700 I  COMMAND  [conn24] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 66, autocommit: false } numYields:0 reslen:321 protocol:op_msg 109ms
2020-05-09T06:37:31.830-0700 I  COMMAND  [conn20] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 73, autocommit: false } numYields:0 reslen:321 protocol:op_msg 152ms
2020-05-09T06:37:32.058-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:32.829-0700 I  NETWORK  [conn24] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:32.832-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:32.833-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:32.905-0700 I  NETWORK  [conn25] end connection 192.168.122.1:44682 (7 connections now open)
2020-05-09T06:37:32.907-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45596 #52 (8 connections now open)
2020-05-09T06:37:32.907-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45598 #53 (9 connections now open)
2020-05-09T06:37:32.908-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:45596 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:32.908-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:45598 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:32.911-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.120-0700 I  NETWORK  [conn21] end connection 192.168.122.1:44574 (8 connections now open)
2020-05-09T06:37:33.122-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45600 #54 (9 connections now open)
2020-05-09T06:37:33.122-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45602 #55 (10 connections now open)
2020-05-09T06:37:33.123-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:45600 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:33.123-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:45602 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:33.127-0700 I  NETWORK  [conn55] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:33.128-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:33.128-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:33.329-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.693-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.829-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:33.984-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:33.985-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:33.985-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:34.329-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.329-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:34.329-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:34.330-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031452, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 76, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2225ms
2020-05-09T06:37:34.731-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031449, 2), t: 6 }, now { ts: Timestamp(1589031453, 3), t: 8 }
2020-05-09T06:37:35.015-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:35.016-0700 I  TXN      [conn24] transaction parameters:{ lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 67, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 107) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 111) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3170144, timeActiveMicros:3184473, timeInactiveMicros:408, 3184ms
2020-05-09T06:37:35.016-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031451, 107) } }, globalReadTimestamp:{ ts: Timestamp(1589031451, 111) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3170245, timeActiveMicros:3184553, timeInactiveMicros:432, 3184ms
2020-05-09T06:37:35.016-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:35.516-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.516-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:35.517-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T06:37:35.517-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:35.518-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031454, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 76, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1185ms
2020-05-09T06:37:35.518-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.518-0700 I  COMMAND  [conn24] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad3faa0a-dddc-427a-b759-609ae813328b") }, txnNumber: 67, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3672ms
2020-05-09T06:37:35.518-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:35.518-0700 I  COMMAND  [conn20] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031451, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d4d0c6b-195a-4ac2-8e77-1c6195fb2440") }, txnNumber: 74, autocommit: false } numYields:0 reslen:495 protocol:op_msg 3672ms
2020-05-09T06:37:35.518-0700 I  NETWORK  [conn24] end connection 192.168.122.1:44672 (9 connections now open)
2020-05-09T06:37:35.518-0700 I  NETWORK  [conn20] end connection 192.168.122.1:44570 (8 connections now open)
2020-05-09T06:37:35.519-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031452, 30) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2608298, timeInactiveMicros:0, 2608ms
2020-05-09T06:37:35.519-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031453, 3) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1826222, timeInactiveMicros:0, 1826ms
2020-05-09T06:37:35.519-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031453, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1826ms
2020-05-09T06:37:35.519-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031452, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2608ms
2020-05-09T06:37:35.799-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 3, autocommit: false } numYields:0 reslen:396 protocol:op_msg 277ms
2020-05-09T06:37:35.800-0700 I  COMMAND  [conn52] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 277ms
2020-05-09T06:37:35.808-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031455, 2) } }, globalReadTimestamp:{ ts: Timestamp(1589031455, 2) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:286829, timeInactiveMicros:0, 286ms
2020-05-09T06:37:35.809-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031455, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 77, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031455, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction ac2b3d97-0851-4773-80ff-9b9af9506658:77 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:696 protocol:op_msg 287ms
2020-05-09T06:37:35.908-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T06:37:37.173-0700 I  NETWORK  [conn52] Marking host n5:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:37.176-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:37.177-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:37.178-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:37.675-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.675-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:37.676-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 172), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 92, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1412ms
2020-05-09T06:37:38.333-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 172) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2061607, timeActiveMicros:2064119, timeInactiveMicros:330, 2064ms
2020-05-09T06:37:38.333-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031456, 179) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2033714, timeActiveMicros:2041277, timeInactiveMicros:332, 2041ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031457, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 92, autocommit: false } numYields:0 reslen:397 protocol:op_msg 654ms
2020-05-09T06:37:38.334-0700 I  COMMAND  [conn55] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 173), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 19, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2062ms
2020-05-09T06:37:38.335-0700 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031456, 181), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 22, autocommit: false } numYields:0 reslen:427 protocol:op_msg 2035ms
2020-05-09T06:37:39.360-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.364-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:39.365-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:39.840-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:39.841-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:39.842-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:39.865-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:39.865-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:39.867-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031453, 3), t: 8 }, now { ts: Timestamp(1589031459, 6), t: 11 }
2020-05-09T06:37:40.032-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:40.032-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T06:37:40.340-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:40.840-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.841-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:40.842-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 474), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 37, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1964ms
2020-05-09T06:37:40.842-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 466), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 116, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1984ms
2020-05-09T06:37:41.215-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:41.216-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:41.534-0700 I  NETWORK  [conn52] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:41.537-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:41.538-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.035-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:42.534-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.535-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:42.536-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 116, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1692ms
2020-05-09T06:37:42.537-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031460, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 37, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1692ms
2020-05-09T06:37:42.548-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 41, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031458, 449) } }, globalReadTimestamp:{ ts: Timestamp(1589031458, 449) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3707367, timeActiveMicros:3716084, timeInactiveMicros:413, 3716ms
2020-05-09T06:37:42.548-0700 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031458, 450), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 41, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3707ms
2020-05-09T06:37:42.603-0700 I  NETWORK  [conn52] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:42.604-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.617-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:42.619-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.103-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.103-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:43.484-0700 I  NETWORK  [conn55] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:43.486-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:43.603-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.103-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:44.603-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.103-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:45.604-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.103-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:46.528-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:46.529-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.603-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:46.603-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:46.604-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 43, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 83) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3987311, timeInactiveMicros:0, 3987ms
2020-05-09T06:37:46.604-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 83), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 43, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3987ms
2020-05-09T06:37:46.604-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:46.895-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 124 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 62), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 46, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4292ms
2020-05-09T06:37:46.895-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 125 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031462, 84), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 121, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4276ms
2020-05-09T06:37:46.895-0700 I  COMMAND  [conn55] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 43, autocommit: false } numYields:0 reslen:397 protocol:op_msg 288ms
2020-05-09T06:37:46.895-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T06:37:46.896-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 121, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 84) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:736, timeActiveMicros:4276944, timeInactiveMicros:543, 4277ms
2020-05-09T06:37:46.896-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 46, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031462, 63) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1150, timeActiveMicros:4293263, timeInactiveMicros:600, 4293ms
2020-05-09T06:37:46.903-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:46.904-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:46.904-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:46.905-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.029-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.404-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.405-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:47.406-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.529-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.584-0700 I  NETWORK  [Sharding-Fixed-5] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:47.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:47.617-0700 I  NETWORK  [conn54] end connection 192.168.122.1:45600 (7 connections now open)
2020-05-09T06:37:47.618-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46148 #64 (8 connections now open)
2020-05-09T06:37:47.618-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46150 #65 (9 connections now open)
2020-05-09T06:37:47.618-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.1:46148 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.619-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.1:46150 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:47.813-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 58, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 3) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:803518, timeActiveMicros:806063, timeInactiveMicros:273, 806ms
2020-05-09T06:37:47.813-0700 I  COMMAND  [conn52] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031467, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 58, autocommit: false } numYields:0 reslen:214 protocol:op_msg 803ms
2020-05-09T06:37:47.814-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 44, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1589031466, 8) } }, globalReadTimestamp:{ ts: Timestamp(1589031466, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:912495, timeActiveMicros:917851, timeInactiveMicros:401, 918ms
2020-05-09T06:37:47.814-0700 I  COMMAND  [conn55] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b8678949-c9e9-4b4d-9995-da5acd5a4fc9") }, txnNumber: 44, autocommit: false } numYields:0 reslen:214 protocol:op_msg 912ms
2020-05-09T06:37:47.814-0700 I  NETWORK  [conn55] end connection 192.168.122.1:45602 (8 connections now open)
2020-05-09T06:37:47.815-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031466, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 122, autocommit: false } numYields:0 reslen:322 protocol:op_msg 912ms
2020-05-09T06:37:48.029-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T06:37:48.142-0700 I  NETWORK  [conn64] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:48.143-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.145-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:48.529-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.530-0700 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:48.530-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T06:37:48.530-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031460, 1), t: 11 }, now { ts: Timestamp(1589031468, 12), t: 15 }
2020-05-09T06:37:48.643-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:49.143-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.144-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:49.145-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 126, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 52) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1282869, timeInactiveMicros:0, 1282ms
2020-05-09T06:37:49.145-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 52), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 126, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1283ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031468, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 126, autocommit: false } numYields:0 reslen:399 protocol:op_msg 123ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 127 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 59, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:363 protocol:op_msg 1454ms
2020-05-09T06:37:49.270-0700 I  COMMAND  [conn64] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 130 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031467, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1650ms
2020-05-09T06:37:49.272-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 59, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 38) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:850, timeActiveMicros:1454923, timeInactiveMicros:639, 1455ms
2020-05-09T06:37:49.272-0700 I  TXN      [conn64] transaction parameters:{ lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031467, 38) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:907, timeActiveMicros:1651047, timeInactiveMicros:1002, 1652ms
2020-05-09T06:37:49.274-0700 I  NETWORK  [conn64] Marking host n8:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.275-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.275-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:49.276-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:49.276-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.277-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T06:37:49.495-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 129, autocommit: false } numYields:0 reslen:322 protocol:op_msg 112ms
2020-05-09T06:37:49.867-0700 I  NETWORK  [conn52] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:49.868-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:49.868-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.216-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589031468, 18), t: 15 }, now { ts: Timestamp(1589031470, 3), t: 16 }
2020-05-09T06:37:50.367-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.367-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:50.368-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 62, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 51) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1045476, timeInactiveMicros:0, 1045ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031469, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1091ms
2020-05-09T06:37:50.368-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 62, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1045ms
2020-05-09T06:37:50.990-0700 I  NETWORK  [conn22] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T06:37:50.991-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:50.992-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.491-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T06:37:51.990-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.991-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T06:37:51.992-0700 I  COMMAND  [conn64] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1623ms
2020-05-09T06:37:51.992-0700 I  COMMAND  [conn52] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031470, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29dac40d-f8cc-40d2-8750-948aba1d1c87") }, txnNumber: 62, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1623ms
2020-05-09T06:37:51.992-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 138 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031469, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 136, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2234ms
2020-05-09T06:37:51.994-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 136, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031469, 203) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1126, timeActiveMicros:2235622, timeInactiveMicros:716, 2236ms
2020-05-09T06:37:51.997-0700 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:51.999-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:51.999-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:52.819-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T06:37:52.821-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:53.320-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.320-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:37:53.322-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031471, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 137, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1319ms
2020-05-09T06:37:53.961-0700 I  NETWORK  [conn22] Marking host n5:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T06:37:53.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:54.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:54.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:55.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:55.962-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:56.462-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:56.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.056-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46382 #68 (9 connections now open)
2020-05-09T06:37:57.056-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:46382 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.101-0700 I  -        [conn64] operation was interrupted because a client disconnected
2020-05-09T06:37:57.101-0700 I  CONNPOOL [conn64] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-09T06:37:57.101-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46390 #69 (10 connections now open)
2020-05-09T06:37:57.102-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:46390 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.102-0700 I  TXN      [conn64] transaction parameters:{ lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1589031472, 23) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006568, timeInactiveMicros:0, 5006ms
2020-05-09T06:37:57.102-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.102-0700 I  COMMAND  [conn64] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809") }, txnNumber: 6, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-09T06:37:57.103-0700 I  NETWORK  [conn64] end connection 192.168.122.1:46148 (9 connections now open)
2020-05-09T06:37:57.103-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.456-0700 I  NETWORK  [conn53] end connection 192.168.122.1:45598 (8 connections now open)
2020-05-09T06:37:57.456-0700 I  NETWORK  [conn23] end connection 192.168.122.1:44656 (7 connections now open)
2020-05-09T06:37:57.458-0700 I  NETWORK  [conn65] end connection 192.168.122.1:46150 (6 connections now open)
2020-05-09T06:37:57.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:57.464-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46400 #70 (7 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46406 #71 (8 connections now open)
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.1:46400 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.465-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.1:46406 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T06:37:57.466-0700 I  NETWORK  [conn71] end connection 192.168.122.1:46406 (7 connections now open)
2020-05-09T06:37:57.467-0700 I  NETWORK  [conn70] end connection 192.168.122.1:46400 (6 connections now open)
2020-05-09T06:37:57.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:58.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:58.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:59.461-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:37:59.961-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T06:38:00.461-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:38:00.462-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T06:38:00.463-0700 I  COMMAND  [conn22] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031473, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ac2b3d97-0851-4773-80ff-9b9af9506658") }, txnNumber: 137, autocommit: false } numYields:0 reslen:517 protocol:op_msg 7140ms
2020-05-09T06:38:00.463-0700 I  NETWORK  [conn22] end connection 192.168.122.1:44634 (5 connections now open)
2020-05-09T06:38:00.464-0700 I  COMMAND  [conn69] command admin.$cmd command: abortTransaction { abortTransaction: 1, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589031472, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("805535d5-69cc-4072-b4ad-1606b6b65809") }, txnNumber: 6, autocommit: false } numYields:0 reslen:396 protocol:op_msg 3361ms
2020-05-09T06:38:00.465-0700 I  NETWORK  [conn69] end connection 192.168.122.1:46390 (4 connections now open)
