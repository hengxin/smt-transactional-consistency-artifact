2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.221+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.223+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.223+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.223+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.223+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.223+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.224+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.224+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.224+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.225+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.225+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.225+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-15-208:27017:1588975035:3222597137907732724 (sleeping for 30000ms)
2020-05-08T21:57:15.227+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.227+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.227+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.229+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 10), t: 1 }
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:17.236+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:17.236+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:17.238+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("47c4c0af-f8db-4a39-9a35-33649eab0769"), lastMod: 0 } took 0 ms
2020-05-08T21:57:17.238+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:17.238+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:17.238+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:17.238+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:17.238+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:17.301+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60254 #9 (1 connection now open)
2020-05-08T21:57:17.302+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60256 #10 (2 connections now open)
2020-05-08T21:57:17.302+0000 I  NETWORK  [conn9] received client metadata from 172.31.0.221:60254 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.302+0000 I  NETWORK  [conn10] received client metadata from 172.31.0.221:60256 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60300 #11 (3 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:60300 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.457+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60336 #12 (4 connections now open)
2020-05-08T21:57:17.457+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:60336 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.459+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60338 #13 (5 connections now open)
2020-05-08T21:57:17.459+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:60338 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60352 #14 (6 connections now open)
2020-05-08T21:57:17.705+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:60352 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.870+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60404 #15 (7 connections now open)
2020-05-08T21:57:18.870+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:60404 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.508+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60420 #16 (8 connections now open)
2020-05-08T21:57:19.509+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:60420 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60444 #17 (9 connections now open)
2020-05-08T21:57:19.561+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:60444 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.849+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60460 #18 (10 connections now open)
2020-05-08T21:57:19.850+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:60460 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.996+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60470 #19 (11 connections now open)
2020-05-08T21:57:19.996+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:60470 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.202+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60490 #20 (12 connections now open)
2020-05-08T21:57:20.202+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60498 #21 (13 connections now open)
2020-05-08T21:57:20.202+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:60490 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.202+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:60498 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.009+0000 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b347503a-3920-41dc-92b3-e223b5993ad3") } } numYields:0 reslen:163 protocol:op_msg 3549ms
2020-05-08T21:57:21.010+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:21.011+0000 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.011+0000 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.011+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.011+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.011+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.011+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.011+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.012+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.013+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.013+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.014+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.014+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.014+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:21.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60528 #29 (14 connections now open)
2020-05-08T21:57:21.350+0000 I  NETWORK  [conn29] received client metadata from 172.31.0.221:60528 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.529+0000 I  COMMAND  [conn12] command jepsendb.jepsencoll command: create { create: "jepsencoll", capped: false, writeConcern: { w: "majority" }, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975041, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b347503a-3920-41dc-92b3-e223b5993ad3") } } numYields:0 reslen:163 protocol:op_msg 519ms
2020-05-08T21:57:21.549+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60536 #30 (15 connections now open)
2020-05-08T21:57:21.550+0000 I  NETWORK  [conn30] received client metadata from 172.31.0.221:60536 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.782+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60548 #31 (16 connections now open)
2020-05-08T21:57:21.782+0000 I  NETWORK  [conn31] received client metadata from 172.31.0.221:60548 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60572 #32 (17 connections now open)
2020-05-08T21:57:21.907+0000 I  NETWORK  [conn32] received client metadata from 172.31.0.221:60572 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.049+0000 I  COMMAND  [conn12] command jepsendb.jepsencoll command: shardCollection { shardCollection: "jepsendb.jepsencoll", key: { _id: "hashed" }, numInitialChunks: 7, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975041, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b347503a-3920-41dc-92b3-e223b5993ad3") } } numYields:0 reslen:243 protocol:op_msg 519ms
2020-05-08T21:57:22.050+0000 I  NETWORK  [conn12] end connection 172.31.0.221:60336 (16 connections now open)
2020-05-08T21:57:22.050+0000 I  NETWORK  [conn13] end connection 172.31.0.221:60338 (15 connections now open)
2020-05-08T21:57:22.066+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60664 #33 (16 connections now open)
2020-05-08T21:57:22.066+0000 I  NETWORK  [conn33] received client metadata from 172.31.0.221:60664 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.066+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60666 #34 (17 connections now open)
2020-05-08T21:57:22.067+0000 I  NETWORK  [conn34] received client metadata from 172.31.0.221:60666 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.073+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60676 #35 (18 connections now open)
2020-05-08T21:57:22.073+0000 I  NETWORK  [conn35] received client metadata from 172.31.0.221:60676 conn35: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.073+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60678 #36 (19 connections now open)
2020-05-08T21:57:22.074+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:60678 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.076+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.077+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60692 #37 (20 connections now open)
2020-05-08T21:57:22.077+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60696 #38 (21 connections now open)
2020-05-08T21:57:22.078+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:60696 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.078+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:60692 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn37] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 234ms
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn35] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 216ms
2020-05-08T21:57:22.323+0000 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 236ms
2020-05-08T21:57:22.325+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.516+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60748 #49 (22 connections now open)
2020-05-08T21:57:22.516+0000 I  NETWORK  [conn49] received client metadata from 172.31.0.221:60748 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.082+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60780 #56 (23 connections now open)
2020-05-08T21:57:23.082+0000 I  NETWORK  [conn56] received client metadata from 172.31.0.221:60780 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.101+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60792 #57 (24 connections now open)
2020-05-08T21:57:23.101+0000 I  NETWORK  [conn57] received client metadata from 172.31.0.221:60792 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.325+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.325+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.365+0000 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 329), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 10, autocommit: false } numYields:0 reslen:321 protocol:op_msg 853ms
2020-05-08T21:57:23.368+0000 I  COMMAND  [conn35] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 345), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 8, autocommit: false } numYields:0 reslen:320 protocol:op_msg 844ms
2020-05-08T21:57:23.419+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60816 #60 (25 connections now open)
2020-05-08T21:57:23.419+0000 I  NETWORK  [conn60] received client metadata from 172.31.0.221:60816 conn60: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.740+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60846 #61 (26 connections now open)
2020-05-08T21:57:23.741+0000 I  NETWORK  [conn61] received client metadata from 172.31.0.221:60846 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.194+0000 I  COMMAND  [conn37] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 341), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76") }, txnNumber: 11, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1673ms
2020-05-08T21:57:24.228+0000 I  TXN      [conn35] transaction parameters:{ lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 21) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 21) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:843027, timeInactiveMicros:704, 843ms
2020-05-08T21:57:24.228+0000 I  COMMAND  [conn35] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975043, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 10, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 836ms
2020-05-08T21:57:24.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60896 #62 (27 connections now open)
2020-05-08T21:57:24.471+0000 I  NETWORK  [conn62] received client metadata from 172.31.0.221:60896 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.619+0000 I  TXN      [conn37] transaction parameters:{ lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 201) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 201) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:420939, timeActiveMicros:423179, timeInactiveMicros:812, 423ms
2020-05-08T21:57:24.619+0000 I  COMMAND  [conn37] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76") }, txnNumber: 12, autocommit: false } numYields:0 reslen:214 protocol:op_msg 421ms
2020-05-08T21:57:24.619+0000 I  COMMAND  [conn35] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 10, autocommit: false } numYields:0 reslen:352 protocol:op_msg 391ms
2020-05-08T21:57:24.969+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60924 #63 (28 connections now open)
2020-05-08T21:57:24.970+0000 I  NETWORK  [conn63] received client metadata from 172.31.0.221:60924 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.149+0000 I  COMMAND  [conn33] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 12, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975043, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1745ms
2020-05-08T21:57:25.150+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.182+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60934 #64 (29 connections now open)
2020-05-08T21:57:25.183+0000 I  NETWORK  [conn64] received client metadata from 172.31.0.221:60934 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.325+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.325+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.348+0000 I  COMMAND  [conn33] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 29 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 13, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 197ms
2020-05-08T21:57:25.348+0000 I  TXN      [conn35] transaction parameters:{ lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 11, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975044, 187) } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 187) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:727632, timeInactiveMicros:1169, 728ms
2020-05-08T21:57:25.348+0000 I  COMMAND  [conn35] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 189), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 11, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 724ms
2020-05-08T21:57:25.349+0000 I  TXN      [conn33] transaction parameters:{ lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 22) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:198784, timeInactiveMicros:346, 199ms
2020-05-08T21:57:25.422+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60972 #69 (30 connections now open)
2020-05-08T21:57:25.423+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:60972 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.503+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60984 #70 (31 connections now open)
2020-05-08T21:57:25.503+0000 I  NETWORK  [conn70] received client metadata from 172.31.0.221:60984 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.543+0000 I  COMMAND  [conn37] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 188), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76") }, txnNumber: 13, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:350 protocol:op_msg 921ms
2020-05-08T21:57:25.549+0000 I  COMMAND  [conn35] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 80), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 11, autocommit: false } numYields:0 reslen:352 protocol:op_msg 199ms
2020-05-08T21:57:25.558+0000 I  TXN      [conn37] transaction parameters:{ lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 187) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:8599, timeActiveMicros:936589, timeInactiveMicros:1897, 938ms
2020-05-08T21:57:25.559+0000 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 80), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 13, autocommit: false } numYields:0 reslen:321 protocol:op_msg 209ms
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:60998 #71 (32 connections now open)
2020-05-08T21:57:25.671+0000 I  NETWORK  [conn71] received client metadata from 172.31.0.221:60998 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.819+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32786 #72 (33 connections now open)
2020-05-08T21:57:25.819+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:32786 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.120+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32800 #73 (34 connections now open)
2020-05-08T21:57:26.121+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:32800 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.367+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32816 #75 (35 connections now open)
2020-05-08T21:57:26.367+0000 I  NETWORK  [conn75] received client metadata from 172.31.0.221:32816 conn75: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.608+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32838 #76 (36 connections now open)
2020-05-08T21:57:26.608+0000 I  NETWORK  [conn76] received client metadata from 172.31.0.221:32838 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.885+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32840 #77 (37 connections now open)
2020-05-08T21:57:26.886+0000 I  NETWORK  [conn77] received client metadata from 172.31.0.221:32840 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.937+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32842 #78 (38 connections now open)
2020-05-08T21:57:26.937+0000 I  NETWORK  [conn78] received client metadata from 172.31.0.221:32842 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.949+0000 I  SHARDING [conn33] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 95), t: 3 }
2020-05-08T21:57:26.953+0000 I  NETWORK  [conn33] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:26.954+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.099+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32844 #79 (39 connections now open)
2020-05-08T21:57:27.099+0000 I  NETWORK  [conn79] received client metadata from 172.31.0.221:32844 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:27.454+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.954+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:28.319+0000 I  NETWORK  [conn35] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:28.320+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.454+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.454+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.455+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.455+0000 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 683), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 28, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2502ms
2020-05-08T21:57:28.820+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.820+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.821+0000 I  TXN      [conn35] transaction parameters:{ lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 679) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 679) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2874645, timeInactiveMicros:0, 2874ms
2020-05-08T21:57:28.821+0000 I  COMMAND  [conn35] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 679), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 29, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 679) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 2874ms
2020-05-08T21:57:29.170+0000 I  NETWORK  [conn35] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:30.704+0000 I  NETWORK  [conn33] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:30.705+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:30.707+0000 I  NETWORK  [conn37] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator d3901a60-f7fb-4c36-92c1-288fba3fca76:31 stopped due to: operation was interrupted
2020-05-08T21:57:30.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:30.757+0000 I  NETWORK  [conn38] end connection 172.31.0.221:60696 (38 connections now open)
2020-05-08T21:57:30.758+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32894 #81 (39 connections now open)
2020-05-08T21:57:30.758+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32896 #82 (40 connections now open)
2020-05-08T21:57:30.758+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:32894 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.758+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:32896 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.759+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.820+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.883+0000 I  NETWORK  [conn36] end connection 172.31.0.221:60678 (39 connections now open)
2020-05-08T21:57:30.883+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32924 #83 (40 connections now open)
2020-05-08T21:57:30.883+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:32924 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.883+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32926 #84 (41 connections now open)
2020-05-08T21:57:30.883+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:32926 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.885+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.885+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.885+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.886+0000 I  TXN      [conn33] transaction parameters:{ lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 12) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2422275, timeInactiveMicros:270, 2422ms
2020-05-08T21:57:30.886+0000 I  COMMAND  [conn33] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 56 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 29, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 29 does not match any in-progress transactions. The active transaction number is 25" errName:NoSuchTransaction errCode:251 reslen:438 protocol:op_msg 2421ms
2020-05-08T21:57:30.889+0000 I  NETWORK  [conn34] end connection 172.31.0.221:60666 (40 connections now open)
2020-05-08T21:57:30.889+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32928 #86 (41 connections now open)
2020-05-08T21:57:30.890+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:32930 #87 (42 connections now open)
2020-05-08T21:57:30.890+0000 I  NETWORK  [conn86] received client metadata from 172.31.0.221:32928 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.890+0000 I  NETWORK  [conn87] received client metadata from 172.31.0.221:32930 conn87: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.891+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.895+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.926+0000 I  CONNPOOL [conn37] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T21:57:30.926+0000 I  COMMAND  [conn37] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 635), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d3901a60-f7fb-4c36-92c1-288fba3fca76") }, txnNumber: 31, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:57:30.926+0000 I  NETWORK  [conn37] end connection 172.31.0.221:60692 (41 connections now open)
2020-05-08T21:57:31.320+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.320+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.321+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.321+0000 I  COMMAND  [conn35] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e326c9ad-0aa4-4525-aac1-f76d6b95dfb0") }, txnNumber: 29, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2499ms
2020-05-08T21:57:31.321+0000 I  NETWORK  [conn35] end connection 172.31.0.221:60676 (40 connections now open)
2020-05-08T21:57:31.990+0000 I  COMMAND  [conn86] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1099ms
2020-05-08T21:57:32.962+0000 I  NETWORK  [conn86] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:32.962+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:32.966+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.413+0000 I  NETWORK  [conn83] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:33.413+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.913+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.913+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.914+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:33.914+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.914+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.915+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:33.962+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:34.155+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78177f54-7770-48ed-a332-28cdb1d8dcaa") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3260ms
2020-05-08T21:57:34.156+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d64ac11b-fffe-4633-a175-f29491fbb111") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 3397ms
2020-05-08T21:57:34.174+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.175+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.175+0000 I  COMMAND  [conn33] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975050, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dc821313-5827-485a-961f-c69a9415cc9e") }, txnNumber: 29, autocommit: false } numYields:0 reslen:515 protocol:op_msg 3288ms
2020-05-08T21:57:34.176+0000 I  NETWORK  [conn33] end connection 172.31.0.221:60664 (39 connections now open)
2020-05-08T21:57:34.182+0000 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 2) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:2184244, timeActiveMicros:3290196, timeInactiveMicros:1062, 3291ms
2020-05-08T21:57:34.183+0000 I  COMMAND  [conn86] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975051, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 2184ms
2020-05-08T21:57:34.311+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:35.047+0000 I  COMMAND  [conn86] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 111 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 857), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294") }, txnNumber: 36, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 218ms
2020-05-08T21:57:35.048+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 29, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 794), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d64ac11b-fffe-4633-a175-f29491fbb111") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 270ms
2020-05-08T21:57:35.049+0000 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 857) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:219672, timeInactiveMicros:511, 220ms
2020-05-08T21:57:35.052+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 35, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 856), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78177f54-7770-48ed-a332-28cdb1d8dcaa") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 223ms
2020-05-08T21:57:35.814+0000 I  NETWORK  [conn86] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:57:35.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:35.815+0000 I  NETWORK  [conn82] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:35.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.286+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33136 #92 (40 connections now open)
2020-05-08T21:57:36.286+0000 I  NETWORK  [conn92] received client metadata from 172.31.0.221:33136 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.314+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.814+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.254+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975057, 1), t: 6 }
2020-05-08T21:57:37.314+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.814+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.314+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.814+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.314+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.814+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.814+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.815+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.815+0000 I  SHARDING [conn82] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:39.815+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 420), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d64ac11b-fffe-4633-a175-f29491fbb111") }, txnNumber: 45, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4443ms
2020-05-08T21:57:39.815+0000 I  COMMAND  [conn83] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 428), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78177f54-7770-48ed-a332-28cdb1d8dcaa") }, txnNumber: 51, autocommit: false } numYields:0 reslen:470 protocol:op_msg 4437ms
2020-05-08T21:57:39.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.053+0000 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 52, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975055, 379) } }, globalReadTimestamp:{ ts: Timestamp(1588975055, 379) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:4709365, timeActiveMicros:4715267, timeInactiveMicros:563, 4715ms
2020-05-08T21:57:40.053+0000 I  COMMAND  [conn86] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 385), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2a1bda21-4351-4e77-8ee6-c6687ad96294") }, txnNumber: 52, autocommit: false } numYields:0 reslen:311 protocol:op_msg 4709ms
2020-05-08T21:57:40.054+0000 I  NETWORK  [conn82] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.054+0000 I  NETWORK  [conn86] end connection 172.31.0.221:32928 (39 connections now open)
2020-05-08T21:57:40.054+0000 I  NETWORK  [conn87] end connection 172.31.0.221:32930 (38 connections now open)
2020-05-08T21:57:40.055+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33182 #93 (39 connections now open)
2020-05-08T21:57:40.055+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33184 #94 (40 connections now open)
2020-05-08T21:57:40.056+0000 I  NETWORK  [conn94] received client metadata from 172.31.0.221:33184 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.056+0000 I  NETWORK  [conn93] received client metadata from 172.31.0.221:33182 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.056+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.057+0000 I  NETWORK  [conn93] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.057+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.058+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.058+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.291+0000 I  NETWORK  [conn84] end connection 172.31.0.221:32926 (39 connections now open)
2020-05-08T21:57:40.292+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33208 #95 (40 connections now open)
2020-05-08T21:57:40.292+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33210 #96 (41 connections now open)
2020-05-08T21:57:40.292+0000 I  NETWORK  [conn95] received client metadata from 172.31.0.221:33208 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.292+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:33210 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.293+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.314+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.350+0000 I  NETWORK  [conn81] end connection 172.31.0.221:32894 (40 connections now open)
2020-05-08T21:57:40.351+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33252 #97 (41 connections now open)
2020-05-08T21:57:40.351+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:33252 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.351+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33254 #98 (42 connections now open)
2020-05-08T21:57:40.351+0000 I  NETWORK  [conn98] received client metadata from 172.31.0.221:33254 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.814+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.314+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.410+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.414+0000 I  NETWORK  [conn93] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:41.415+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.525+0000 I  NETWORK  [conn97] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.526+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.526+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.526+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.527+0000 I  TXN      [conn97] transaction parameters:{ lsid: { id: UUID("e61f1f11-5012-4027-8851-e6211f6e3753"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975060, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1175383, timeInactiveMicros:0, 1175ms
2020-05-08T21:57:41.527+0000 I  COMMAND  [conn97] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e61f1f11-5012-4027-8851-e6211f6e3753") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1175ms
2020-05-08T21:57:41.573+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33312 #99 (43 connections now open)
2020-05-08T21:57:41.573+0000 I  NETWORK  [conn99] received client metadata from 172.31.0.221:33312 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:41.814+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.814+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.815+0000 I  COMMAND  [conn83] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("78177f54-7770-48ed-a332-28cdb1d8dcaa") }, txnNumber: 51, autocommit: false } numYields:0 reslen:546 protocol:op_msg 1998ms
2020-05-08T21:57:41.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.815+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d64ac11b-fffe-4633-a175-f29491fbb111") }, txnNumber: 45, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1999ms
2020-05-08T21:57:41.815+0000 I  NETWORK  [conn83] end connection 172.31.0.221:32924 (42 connections now open)
2020-05-08T21:57:41.815+0000 I  NETWORK  [conn82] end connection 172.31.0.221:32896 (41 connections now open)
2020-05-08T21:57:42.063+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0ec3a321-d573-4702-a157-6540bd4b037c") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1770ms
2020-05-08T21:57:42.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.037+0000 I  NETWORK  [conn93] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:43.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.815+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.815+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.815+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.212+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.707+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.037+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.056+0000 I  NETWORK  [conn94] end connection 172.31.0.221:33184 (40 connections now open)
2020-05-08T21:57:45.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33352 #103 (41 connections now open)
2020-05-08T21:57:45.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33350 #104 (42 connections now open)
2020-05-08T21:57:45.057+0000 I  NETWORK  [conn103] received client metadata from 172.31.0.221:33352 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.057+0000 I  NETWORK  [conn104] received client metadata from 172.31.0.221:33350 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.252+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33386 #105 (43 connections now open)
2020-05-08T21:57:45.252+0000 I  NETWORK  [conn105] received client metadata from 172.31.0.221:33386 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.351+0000 I  NETWORK  [conn98] end connection 172.31.0.221:33254 (42 connections now open)
2020-05-08T21:57:45.352+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33444 #106 (43 connections now open)
2020-05-08T21:57:45.352+0000 I  NETWORK  [conn106] received client metadata from 172.31.0.221:33444 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.352+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33446 #107 (44 connections now open)
2020-05-08T21:57:45.352+0000 I  NETWORK  [conn107] received client metadata from 172.31.0.221:33446 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.537+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.537+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.538+0000 I  COMMAND  [conn93] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c3cdd065-4df0-431b-afda-87c643956bf4") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 4981ms
2020-05-08T21:57:45.538+0000 I  COMMAND  [conn97] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975061, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e61f1f11-5012-4027-8851-e6211f6e3753") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 4009ms
2020-05-08T21:57:45.538+0000 I  NETWORK  [conn93] end connection 172.31.0.221:33182 (43 connections now open)
2020-05-08T21:57:45.538+0000 I  NETWORK  [conn97] end connection 172.31.0.221:33252 (42 connections now open)
2020-05-08T21:57:45.712+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:45.791+0000 I  NETWORK  [conn104] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.792+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:45.794+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.212+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.292+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.712+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.792+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.065+0000 I  NETWORK  [conn95] end connection 172.31.0.221:33208 (41 connections now open)
2020-05-08T21:57:47.065+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33492 #108 (42 connections now open)
2020-05-08T21:57:47.065+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33494 #109 (43 connections now open)
2020-05-08T21:57:47.065+0000 I  NETWORK  [conn108] received client metadata from 172.31.0.221:33492 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.066+0000 I  NETWORK  [conn109] received client metadata from 172.31.0.221:33494 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.067+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.212+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.292+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.517+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.712+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.792+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.212+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.292+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.292+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.293+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.293+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.293+0000 I  COMMAND  [conn96] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975064, 150), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0ec3a321-d573-4702-a157-6540bd4b037c") }, txnNumber: 515, autocommit: false } numYields:0 reslen:440 protocol:op_msg 3504ms
2020-05-08T21:57:48.293+0000 I  COMMAND  [conn106] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cf4f64a9-0d4b-4016-a9db-ffa91b11d00b") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2940ms
2020-05-08T21:57:48.293+0000 I  NETWORK  [conn96] end connection 172.31.0.221:33210 (42 connections now open)
2020-05-08T21:57:48.294+0000 I  TXN      [conn104] transaction parameters:{ lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975064, 150) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:3235835, timeInactiveMicros:271, 3236ms
2020-05-08T21:57:48.294+0000 I  COMMAND  [conn104] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 140 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 3234ms
2020-05-08T21:57:48.295+0000 I  TXN      [conn108] transaction parameters:{ lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 14) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1228319, timeInactiveMicros:0, 1228ms
2020-05-08T21:57:48.295+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction e314e087-2e67-4595-9816-fbc7c5f8aec4:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975065, 14) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:593 protocol:op_msg 1228ms
2020-05-08T21:57:48.713+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.713+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.713+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:50.320+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:51.013+0000 I  NETWORK  [conn104] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:51.014+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.077+0000 I  NETWORK  [conn106] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:51.078+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.081+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.513+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.696+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33612 #112 (43 connections now open)
2020-05-08T21:57:51.696+0000 I  NETWORK  [conn112] received client metadata from 172.31.0.221:33612 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.013+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.013+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.014+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:52.014+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975071, 44), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4") }, txnNumber: 360, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 933ms
2020-05-08T21:57:52.014+0000 I  TXN      [conn106] transaction parameters:{ lsid: { id: UUID("cf4f64a9-0d4b-4016-a9db-ffa91b11d00b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 9) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3719493, timeInactiveMicros:472, 3719ms
2020-05-08T21:57:52.014+0000 I  COMMAND  [conn106] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cf4f64a9-0d4b-4016-a9db-ffa91b11d00b") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3716ms
2020-05-08T21:57:52.015+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.015+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.015+0000 I  TXN      [conn104] transaction parameters:{ lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 28) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3704568, timeInactiveMicros:0, 3704ms
2020-05-08T21:57:52.015+0000 I  COMMAND  [conn104] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 2c0a6f61-28c0-4962-8b39-e05e8891d052:3 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975068, 28) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 3704ms
2020-05-08T21:57:52.030+0000 I  TXN      [conn108] transaction parameters:{ lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 360, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975071, 43) } }, globalReadTimestamp:{ ts: Timestamp(1588975071, 43) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:14312, timeActiveMicros:950116, timeInactiveMicros:1202, 951ms
2020-05-08T21:57:52.198+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.726+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33642 #113 (44 connections now open)
2020-05-08T21:57:52.726+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:33642 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.888+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33646 #114 (45 connections now open)
2020-05-08T21:57:52.889+0000 I  NETWORK  [conn114] received client metadata from 172.31.0.221:33646 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:53.715+0000 I  COMMAND  [conn104] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 646), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052") }, txnNumber: 84, autocommit: false } numYields:0 reslen:321 protocol:op_msg 221ms
2020-05-08T21:57:54.129+0000 I  COMMAND  [conn104] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 782), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052") }, txnNumber: 104, autocommit: false } numYields:0 reslen:322 protocol:op_msg 214ms
2020-05-08T21:57:54.332+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33714 #115 (46 connections now open)
2020-05-08T21:57:54.332+0000 I  NETWORK  [conn115] received client metadata from 172.31.0.221:33714 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.749+0000 I  COMMAND  [conn104] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 247), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052") }, txnNumber: 140, autocommit: false } numYields:0 reslen:322 protocol:op_msg 216ms
2020-05-08T21:57:54.913+0000 I  SHARDING [conn104] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:55.799+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33826 #116 (47 connections now open)
2020-05-08T21:57:55.799+0000 I  NETWORK  [conn116] received client metadata from 172.31.0.221:33826 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.160+0000 I  NETWORK  [conn106] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:56.160+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.164+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.660+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.788+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33858 #117 (48 connections now open)
2020-05-08T21:57:56.788+0000 I  NETWORK  [conn117] received client metadata from 172.31.0.221:33858 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.964+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33870 #118 (49 connections now open)
2020-05-08T21:57:56.964+0000 I  NETWORK  [conn118] received client metadata from 172.31.0.221:33870 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.160+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:57.626+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33922 #119 (50 connections now open)
2020-05-08T21:57:57.626+0000 I  NETWORK  [conn119] received client metadata from 172.31.0.221:33922 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.660+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.660+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.661+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:57.661+0000 I  TXN      [conn108] transaction parameters:{ lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 428, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 595) } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 595) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4252038, timeInactiveMicros:466, 4252ms
2020-05-08T21:57:57.661+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:57.661+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975073, 595), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4") }, txnNumber: 428, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 4249ms
2020-05-08T21:57:57.661+0000 I  COMMAND  [conn104] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c0a6f61-28c0-4962-8b39-e05e8891d052") }, txnNumber: 179, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2498ms
2020-05-08T21:57:57.661+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:58.342+0000 I  NETWORK  [conn107] end connection 172.31.0.221:33446 (49 connections now open)
2020-05-08T21:57:58.343+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33964 #120 (50 connections now open)
2020-05-08T21:57:58.343+0000 I  NETWORK  [conn120] received client metadata from 172.31.0.221:33964 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.343+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33966 #121 (51 connections now open)
2020-05-08T21:57:58.344+0000 I  NETWORK  [conn121] received client metadata from 172.31.0.221:33966 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.345+0000 I  NETWORK  [conn120] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:58.353+0000 I  NETWORK  [conn109] end connection 172.31.0.221:33494 (50 connections now open)
2020-05-08T21:57:58.354+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33968 #122 (51 connections now open)
2020-05-08T21:57:58.354+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:33970 #123 (52 connections now open)
2020-05-08T21:57:58.354+0000 I  NETWORK  [conn122] received client metadata from 172.31.0.221:33968 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.354+0000 I  NETWORK  [conn123] received client metadata from 172.31.0.221:33970 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.386+0000 I  NETWORK  [conn104] end connection 172.31.0.221:33350 (51 connections now open)
2020-05-08T21:57:58.387+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34014 #124 (52 connections now open)
2020-05-08T21:57:58.387+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:34014 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.387+0000 I  NETWORK  [conn103] end connection 172.31.0.221:33352 (51 connections now open)
2020-05-08T21:57:58.388+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34016 #125 (52 connections now open)
2020-05-08T21:57:58.388+0000 I  NETWORK  [conn124] end connection 172.31.0.221:34014 (51 connections now open)
2020-05-08T21:57:58.389+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:34016 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34020 #126 (52 connections now open)
2020-05-08T21:57:58.389+0000 I  NETWORK  [conn126] received client metadata from 172.31.0.221:34020 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.421+0000 I  -        [conn106] operation was interrupted because a client disconnected
2020-05-08T21:57:58.421+0000 I  CONNPOOL [conn106] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:57:58.421+0000 I  TXN      [conn106] transaction parameters:{ lsid: { id: UUID("cf4f64a9-0d4b-4016-a9db-ffa91b11d00b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 597) } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 597) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004995, timeInactiveMicros:0, 5004ms
2020-05-08T21:57:58.421+0000 I  COMMAND  [conn106] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 260 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975073, 597), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cf4f64a9-0d4b-4016-a9db-ffa91b11d00b") }, txnNumber: 68, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 597) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:57:58.421+0000 I  NETWORK  [conn106] end connection 172.31.0.221:33444 (51 connections now open)
2020-05-08T21:57:58.608+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34044 #127 (52 connections now open)
2020-05-08T21:57:58.608+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:34044 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.845+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.845+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.845+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:59.846+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:59.870+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34080 #128 (53 connections now open)
2020-05-08T21:57:59.870+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:34080 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.326+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.326+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.332+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975080, 9), t: 13 }
2020-05-08T21:58:00.403+0000 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975079, 591), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60bf5bf2-f4d6-4eee-966e-0747a127401e") }, txnNumber: 176, autocommit: false } numYields:0 reslen:322 protocol:op_msg 413ms
2020-05-08T21:58:00.829+0000 I  COMMAND  [conn122] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 185 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c54bfe26-4801-433c-b99d-0819641d8c82") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 2474ms
2020-05-08T21:58:00.886+0000 I  NETWORK  [conn120] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.240+0000 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975080, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60bf5bf2-f4d6-4eee-966e-0747a127401e") }, txnNumber: 199, autocommit: false } numYields:0 reslen:322 protocol:op_msg 632ms
2020-05-08T21:58:01.240+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975077, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e314e087-2e67-4595-9816-fbc7c5f8aec4") }, txnNumber: 429, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 3568ms
2020-05-08T21:58:01.240+0000 I  NETWORK  [conn108] end connection 172.31.0.221:33492 (52 connections now open)
2020-05-08T21:58:01.887+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.887+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.889+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:01.889+0000 I  TXN      [conn122] transaction parameters:{ lsid: { id: UUID("c54bfe26-4801-433c-b99d-0819641d8c82"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 177) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:3533748, timeInactiveMicros:431, 3534ms
2020-05-08T21:58:01.889+0000 I  COMMAND  [conn122] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 270 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975080, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c54bfe26-4801-433c-b99d-0819641d8c82") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 1059ms
2020-05-08T21:58:01.889+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.889+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.904+0000 I  NETWORK  [conn120] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.905+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.907+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.249+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:02.249+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.372+0000 I  NETWORK  [conn125] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:02.373+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.389+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.873+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.889+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:02.889+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.343+0000 I  NETWORK  [conn121] end connection 172.31.0.221:33966 (51 connections now open)
2020-05-08T21:58:03.344+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34220 #129 (52 connections now open)
2020-05-08T21:58:03.344+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34222 #130 (53 connections now open)
2020-05-08T21:58:03.344+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:34220 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.344+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:34222 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.346+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.346+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.346+0000 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60bf5bf2-f4d6-4eee-966e-0747a127401e") }, txnNumber: 234, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1811ms
2020-05-08T21:58:03.349+0000 I  -        [conn120] operation was interrupted because a client disconnected
2020-05-08T21:58:03.349+0000 I  TXN      [conn120] transaction parameters:{ lsid: { id: UUID("75ad1dd6-6370-4c64-a4ce-eb4b8dfcd56f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 172) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004862, timeInactiveMicros:0, 5004ms
2020-05-08T21:58:03.349+0000 I  COMMAND  [conn120] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 270 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 172), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75ad1dd6-6370-4c64-a4ce-eb4b8dfcd56f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:58:03.349+0000 I  NETWORK  [conn120] end connection 172.31.0.221:33964 (52 connections now open)
2020-05-08T21:58:03.354+0000 I  NETWORK  [conn123] end connection 172.31.0.221:33970 (51 connections now open)
2020-05-08T21:58:03.354+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34224 #131 (52 connections now open)
2020-05-08T21:58:03.355+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:34224 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.355+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34226 #132 (53 connections now open)
2020-05-08T21:58:03.355+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:34226 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.388+0000 I  NETWORK  [conn126] end connection 172.31.0.221:34020 (52 connections now open)
2020-05-08T21:58:03.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34256 #133 (53 connections now open)
2020-05-08T21:58:03.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34258 #134 (54 connections now open)
2020-05-08T21:58:03.389+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:34256 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.389+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:34258 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.504+0000 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 251 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975082, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 158ms
2020-05-08T21:58:03.504+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 275 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 148ms
2020-05-08T21:58:03.507+0000 I  COMMAND  [conn125] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975083, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("60bf5bf2-f4d6-4eee-966e-0747a127401e") }, txnNumber: 234, autocommit: false } numYields:0 reslen:398 protocol:op_msg 159ms
2020-05-08T21:58:03.507+0000 I  NETWORK  [conn125] end connection 172.31.0.221:34016 (53 connections now open)
2020-05-08T21:58:03.509+0000 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975082, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:164029, timeInactiveMicros:360, 164ms
2020-05-08T21:58:03.510+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:153994, timeInactiveMicros:516, 154ms
2020-05-08T21:58:04.066+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.120+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.387+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.887+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.887+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.888+0000 I  COMMAND  [conn122] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c54bfe26-4801-433c-b99d-0819641d8c82") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2998ms
2020-05-08T21:58:04.888+0000 I  NETWORK  [conn122] end connection 172.31.0.221:33968 (52 connections now open)
2020-05-08T21:58:04.889+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1333ms
2020-05-08T21:58:04.897+0000 I  NETWORK  [conn131] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:04.898+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:05.397+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:05.897+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:05.941+0000 I  COMMAND  [conn133] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2156a183-24e8-4062-a147-db3f13d5c17d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 2551ms
2020-05-08T21:58:05.941+0000 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 55), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2362ms
2020-05-08T21:58:05.942+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.942+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.942+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.943+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.943+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.949+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 5, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975084, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 1059ms
2020-05-08T21:58:05.950+0000 I  TXN      [conn133] transaction parameters:{ lsid: { id: UUID("2156a183-24e8-4062-a147-db3f13d5c17d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 2) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2559258, timeInactiveMicros:1293, 2560ms
2020-05-08T21:58:05.966+0000 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 55) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:20028, timeActiveMicros:2385485, timeInactiveMicros:1291, 2386ms
2020-05-08T21:58:06.554+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.555+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.054+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.554+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.554+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.654+0000 I  NETWORK  [conn133] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:07.654+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.813+0000 I  NETWORK  [conn131] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:07.814+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.814+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.815+0000 I  TXN      [conn133] transaction parameters:{ lsid: { id: UUID("2156a183-24e8-4062-a147-db3f13d5c17d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 34) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1845197, timeInactiveMicros:0, 1845ms
2020-05-08T21:58:07.815+0000 I  COMMAND  [conn133] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975085, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2156a183-24e8-4062-a147-db3f13d5c17d") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1845ms
2020-05-08T21:58:08.389+0000 I  NETWORK  [conn134] end connection 172.31.0.221:34258 (51 connections now open)
2020-05-08T21:58:08.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34378 #135 (52 connections now open)
2020-05-08T21:58:08.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34380 #136 (53 connections now open)
2020-05-08T21:58:08.390+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:34378 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.390+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:34380 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.562+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.939+0000 I  NETWORK  [conn135] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:08.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.056+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 13) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3095188, timeActiveMicros:3104646, timeInactiveMicros:1193, 3105ms
2020-05-08T21:58:09.056+0000 I  COMMAND  [conn129] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 8, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975085, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3090ms
2020-05-08T21:58:09.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.063+0000 I  COMMAND  [conn133] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 219), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2156a183-24e8-4062-a147-db3f13d5c17d") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1247ms
2020-05-08T21:58:09.063+0000 I  NETWORK  [conn133] end connection 172.31.0.221:34256 (52 connections now open)
2020-05-08T21:58:09.265+0000 I  SHARDING [conn129] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.939+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.939+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.940+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.940+0000 I  COMMAND  [conn135] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4cf54436-6735-4bed-811e-545076a3b408") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1546ms
2020-05-08T21:58:09.940+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.940+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.944+0000 I  COMMAND  [conn131] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0") }, txnNumber: 6, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3982ms
2020-05-08T21:58:10.075+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34484 #137 (53 connections now open)
2020-05-08T21:58:10.075+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:34484 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.180+0000 I  NETWORK  [conn131] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:10.180+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.182+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.387+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.387+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.440+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.951+0000 I  NETWORK  [conn132] end connection 172.31.0.221:34226 (52 connections now open)
2020-05-08T21:58:10.951+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34490 #138 (53 connections now open)
2020-05-08T21:58:10.952+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34492 #139 (54 connections now open)
2020-05-08T21:58:10.952+0000 I  NETWORK  [conn138] received client metadata from 172.31.0.221:34490 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.952+0000 I  NETWORK  [conn139] received client metadata from 172.31.0.221:34492 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.953+0000 I  NETWORK  [conn138] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.954+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.263+0000 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975089, 199) } }, globalReadTimestamp:{ ts: Timestamp(1588975089, 199) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1681666, timeInactiveMicros:0, 1681ms
2020-05-08T21:58:11.263+0000 I  COMMAND  [conn129] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 199), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 80, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975089, 199) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 1681ms
2020-05-08T21:58:11.264+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.439+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.440+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.440+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.440+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.441+0000 I  SHARDING [conn135] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 3), t: 19 }
2020-05-08T21:58:11.441+0000 I  COMMAND  [conn135] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4cf54436-6735-4bed-811e-545076a3b408") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1499ms
2020-05-08T21:58:11.442+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 287 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 212), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c89a58e1-c652-497f-8548-5875a05e86d0") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975089, 212) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1498ms
2020-05-08T21:58:11.443+0000 I  NETWORK  [conn131] end connection 172.31.0.221:34224 (53 connections now open)
2020-05-08T21:58:11.453+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.453+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.454+0000 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("9e17e9c7-3616-4d12-adf6-eb6ecc56f9b7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975089, 213) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:501225, timeInactiveMicros:0, 501ms
2020-05-08T21:58:11.454+0000 I  COMMAND  [conn138] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 213), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e17e9c7-3616-4d12-adf6-eb6ecc56f9b7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 501ms
2020-05-08T21:58:12.292+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34548 #140 (54 connections now open)
2020-05-08T21:58:12.292+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:34548 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.365+0000 I  COMMAND  [conn129] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975090, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 80, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1101ms
2020-05-08T21:58:12.366+0000 I  COMMAND  [conn138] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e17e9c7-3616-4d12-adf6-eb6ecc56f9b7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 911ms
2020-05-08T21:58:12.375+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.434+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.735+0000 I  NETWORK  [conn129] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:13.736+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.235+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.235+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.236+0000 I  COMMAND  [conn129] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 526), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 125, autocommit: false } numYields:0 reslen:322 protocol:op_msg 812ms
2020-05-08T21:58:14.929+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34590 #145 (55 connections now open)
2020-05-08T21:58:14.929+0000 I  NETWORK  [conn145] received client metadata from 172.31.0.221:34590 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.170+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34600 #146 (56 connections now open)
2020-05-08T21:58:15.170+0000 I  NETWORK  [conn146] received client metadata from 172.31.0.221:34600 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.780+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34622 #147 (57 connections now open)
2020-05-08T21:58:15.780+0000 I  NETWORK  [conn147] received client metadata from 172.31.0.221:34622 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:16.648+0000 I  NETWORK  [conn129] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:16.649+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:16.655+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.146+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34644 #148 (58 connections now open)
2020-05-08T21:58:17.146+0000 I  NETWORK  [conn148] received client metadata from 172.31.0.221:34644 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:17.149+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.149+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.150+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:17.150+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:17.150+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:17.151+0000 I  NETWORK  [conn129] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:17.152+0000 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("9e17e9c7-3616-4d12-adf6-eb6ecc56f9b7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 405, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 174) } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 174) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:506173, timeInactiveMicros:245, 506ms
2020-05-08T21:58:17.152+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.152+0000 I  COMMAND  [conn138] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 364 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 174), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e17e9c7-3616-4d12-adf6-eb6ecc56f9b7") }, txnNumber: 405, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 405 does not match any in-progress transactions. The active transaction number is 42" errName:NoSuchTransaction errCode:251 reslen:439 protocol:op_msg 505ms
2020-05-08T21:58:17.152+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.153+0000 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 126, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975094, 92) } }, globalReadTimestamp:{ ts: Timestamp(1588975094, 92) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2915867, timeInactiveMicros:501, 2916ms
2020-05-08T21:58:17.153+0000 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 363 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975094, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 126, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 126 does not match any in-progress transactions. The active transaction number is 123" errName:NoSuchTransaction errCode:251 reslen:440 protocol:op_msg 2914ms
2020-05-08T21:58:17.364+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.364+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.365+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.366+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.650+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.668+0000 I  NETWORK  [conn135] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.668+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.671+0000 I  NETWORK  [conn138] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:17.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.150+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:18.168+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.363+0000 I  NETWORK  [conn139] end connection 172.31.0.221:34492 (57 connections now open)
2020-05-08T21:58:18.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34696 #149 (58 connections now open)
2020-05-08T21:58:18.364+0000 I  NETWORK  [conn149] received client metadata from 172.31.0.221:34696 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34698 #150 (59 connections now open)
2020-05-08T21:58:18.365+0000 I  NETWORK  [conn150] received client metadata from 172.31.0.221:34698 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.400+0000 I  NETWORK  [conn136] end connection 172.31.0.221:34380 (58 connections now open)
2020-05-08T21:58:18.400+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34736 #151 (59 connections now open)
2020-05-08T21:58:18.400+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:34736 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.400+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34738 #152 (60 connections now open)
2020-05-08T21:58:18.400+0000 I  NETWORK  [conn152] received client metadata from 172.31.0.221:34738 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.401+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.404+0000 I  -        [conn135] operation was interrupted because a client disconnected
2020-05-08T21:58:18.405+0000 I  TXN      [conn135] transaction parameters:{ lsid: { id: UUID("4cf54436-6735-4bed-811e-545076a3b408"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 142, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 509) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005430, timeInactiveMicros:0, 5005ms
2020-05-08T21:58:18.405+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.405+0000 I  COMMAND  [conn135] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 363 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 509), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4cf54436-6735-4bed-811e-545076a3b408") }, txnNumber: 142, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:58:18.405+0000 I  NETWORK  [conn135] end connection 172.31.0.221:34378 (59 connections now open)
2020-05-08T21:58:18.419+0000 I  NETWORK  [conn130] end connection 172.31.0.221:34222 (58 connections now open)
2020-05-08T21:58:18.420+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34748 #153 (59 connections now open)
2020-05-08T21:58:18.420+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34750 #154 (60 connections now open)
2020-05-08T21:58:18.420+0000 I  NETWORK  [conn153] received client metadata from 172.31.0.221:34748 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.420+0000 I  NETWORK  [conn154] received client metadata from 172.31.0.221:34750 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.421+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.650+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.650+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.668+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.150+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.150+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.168+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.354+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.356+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.371+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.669+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.669+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.670+0000 I  COMMAND  [conn129] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 217), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("395e0869-dda9-4110-b8dc-055ea2e3f3b9") }, txnNumber: 126, autocommit: false } numYields:0 reslen:430 protocol:op_msg 2516ms
2020-05-08T21:58:19.670+0000 I  NETWORK  [conn129] end connection 172.31.0.221:34220 (59 connections now open)
2020-05-08T21:58:19.670+0000 I  COMMAND  [conn138] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 217), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e17e9c7-3616-4d12-adf6-eb6ecc56f9b7") }, txnNumber: 405, autocommit: false } numYields:0 reslen:516 protocol:op_msg 2518ms
2020-05-08T21:58:19.670+0000 I  COMMAND  [conn153] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d976ccbe-658d-4bf1-bbeb-fc48b5f1adb1") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1249ms
2020-05-08T21:58:19.670+0000 I  NETWORK  [conn138] end connection 172.31.0.221:34490 (58 connections now open)
2020-05-08T21:58:20.098+0000 I  NETWORK  [conn149] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:20.099+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:20.099+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:20.099+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:20.100+0000 I  TXN      [conn149] transaction parameters:{ lsid: { id: UUID("94b69882-4b4c-450c-83d1-50524100b7e6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1734130, timeInactiveMicros:0, 1734ms
2020-05-08T21:58:20.100+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94b69882-4b4c-450c-83d1-50524100b7e6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 1734ms
2020-05-08T21:58:20.100+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.100+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.390+0000 I  NETWORK  [conn153] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:20.391+0000 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("d976ccbe-658d-4bf1-bbeb-fc48b5f1adb1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975099, 12) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:720015, timeInactiveMicros:0, 720ms
2020-05-08T21:58:20.391+0000 I  COMMAND  [conn153] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d976ccbe-658d-4bf1-bbeb-fc48b5f1adb1") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 720ms
2020-05-08T21:58:20.447+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.180+0000 I  NETWORK  [conn151] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:21.180+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.680+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.180+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.680+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.680+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.227+0000 I  NETWORK  [conn151] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.364+0000 I  NETWORK  [conn150] end connection 172.31.0.221:34698 (57 connections now open)
2020-05-08T21:58:23.365+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34842 #155 (58 connections now open)
2020-05-08T21:58:23.365+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34844 #156 (59 connections now open)
2020-05-08T21:58:23.365+0000 I  NETWORK  [conn155] received client metadata from 172.31.0.221:34842 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.365+0000 I  NETWORK  [conn156] received client metadata from 172.31.0.221:34844 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.400+0000 I  NETWORK  [conn152] end connection 172.31.0.221:34738 (58 connections now open)
2020-05-08T21:58:23.401+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34858 #157 (59 connections now open)
2020-05-08T21:58:23.401+0000 I  NETWORK  [conn157] received client metadata from 172.31.0.221:34858 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.401+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34860 #158 (60 connections now open)
2020-05-08T21:58:23.401+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:34860 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.402+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.404+0000 I  NETWORK  [conn157] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.404+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.405+0000 I  -        [conn151] operation was interrupted because a client disconnected
2020-05-08T21:58:23.405+0000 I  TXN      [conn151] transaction parameters:{ lsid: { id: UUID("273d7201-ac37-463c-8e9c-58e1fc3a62b2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004356, timeInactiveMicros:0, 5004ms
2020-05-08T21:58:23.405+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.405+0000 I  COMMAND  [conn151] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("273d7201-ac37-463c-8e9c-58e1fc3a62b2") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:58:23.405+0000 I  NETWORK  [conn151] end connection 172.31.0.221:34736 (59 connections now open)
2020-05-08T21:58:23.519+0000 I  NETWORK  [conn153] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.520+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.578+0000 I  NETWORK  [conn155] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.579+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.904+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.671+0000 I  NETWORK  [conn154] end connection 172.31.0.221:34750 (58 connections now open)
2020-05-08T21:58:24.672+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34920 #160 (59 connections now open)
2020-05-08T21:58:24.672+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:34922 #161 (60 connections now open)
2020-05-08T21:58:24.672+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:34920 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:24.672+0000 I  NETWORK  [conn161] received client metadata from 172.31.0.221:34922 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:24.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.904+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:24.904+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:24.904+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:24.905+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:24.905+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1503338, timeInactiveMicros:0, 1503ms
2020-05-08T21:58:24.905+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1503ms
2020-05-08T21:58:24.905+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:24.905+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:24.906+0000 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("d976ccbe-658d-4bf1-bbeb-fc48b5f1adb1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975100, 60) } }, globalReadTimestamp:{ ts: Timestamp(1588975100, 60) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4508408, timeInactiveMicros:0, 4508ms
2020-05-08T21:58:24.906+0000 I  COMMAND  [conn153] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975100, 60), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d976ccbe-658d-4bf1-bbeb-fc48b5f1adb1") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975100, 60) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 4508ms
2020-05-08T21:58:24.907+0000 I  NETWORK  [conn153] end connection 172.31.0.221:34748 (59 connections now open)
2020-05-08T21:58:25.071+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.071+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.256+0000 I  NETWORK  [conn155] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.405+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.905+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.905+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.082+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.082+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.083+0000 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975104, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1177ms
2020-05-08T21:58:26.152+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.227+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.227+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.377+0000 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975105, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 292ms
2020-05-08T21:58:26.491+0000 I  COMMAND  [conn160] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 379 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975103, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1818ms
2020-05-08T21:58:26.493+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975103, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1820494, timeInactiveMicros:348, 1820ms
2020-05-08T21:58:26.496+0000 I  COMMAND  [conn155] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 374 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 3130ms
2020-05-08T21:58:26.502+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:124379, timeInactiveMicros:0, 124ms
2020-05-08T21:58:26.502+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 124ms
2020-05-08T21:58:26.505+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:7035, timeActiveMicros:3138784, timeInactiveMicros:1202, 3139ms
2020-05-08T21:58:26.732+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:27.171+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.351+0000 I  COMMAND  [conn149] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975101, 133), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94b69882-4b4c-450c-83d1-50524100b7e6") }, txnNumber: 311, autocommit: false } numYields:0 reslen:322 protocol:op_msg 6682ms
2020-05-08T21:58:28.351+0000 I  NETWORK  [conn149] end connection 172.31.0.221:34696 (58 connections now open)
2020-05-08T21:58:29.298+0000 I  NETWORK  [conn160] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:29.299+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:29.299+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:29.301+0000 I  COMMAND  [conn160] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 435 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975108, 555), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b") }, txnNumber: 213, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:383 protocol:op_msg 416ms
2020-05-08T21:58:29.319+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 213, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975108, 550) } }, globalReadTimestamp:{ ts: Timestamp(1588975108, 550) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:16916, timeActiveMicros:438553, timeInactiveMicros:1854, 440ms
2020-05-08T21:58:29.326+0000 I  NETWORK  [conn157] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:29.328+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 222, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975108, 559) } }, globalReadTimestamp:{ ts: Timestamp(1588975108, 559) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:438043, timeInactiveMicros:746, 438ms
2020-05-08T21:58:29.328+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975108, 574), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 222, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 426ms
2020-05-08T21:58:29.734+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 226, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 644) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:218444, timeActiveMicros:221393, timeInactiveMicros:791, 222ms
2020-05-08T21:58:29.734+0000 I  COMMAND  [conn160] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 648), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b") }, txnNumber: 226, autocommit: false } numYields:0 reslen:214 protocol:op_msg 218ms
2020-05-08T21:58:29.736+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 250, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 649) } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 651) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:207757, timeActiveMicros:216813, timeInactiveMicros:964, 217ms
2020-05-08T21:58:29.736+0000 I  COMMAND  [conn155] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 659), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45") }, txnNumber: 250, autocommit: false } numYields:0 reslen:214 protocol:op_msg 207ms
2020-05-08T21:58:29.738+0000 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 667), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 229, autocommit: false } numYields:0 reslen:322 protocol:op_msg 206ms
2020-05-08T21:58:30.233+0000 I  NETWORK  [conn160] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:30.234+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.242+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.734+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.734+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.736+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 466 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 325), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 256, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:383 protocol:op_msg 494ms
2020-05-08T21:58:31.251+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 253, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 302) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 302) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1022024, timeActiveMicros:1031477, timeInactiveMicros:991, 1032ms
2020-05-08T21:58:31.253+0000 I  COMMAND  [conn160] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 314), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b") }, txnNumber: 253, autocommit: false } numYields:0 reslen:430 protocol:op_msg 1024ms
2020-05-08T21:58:31.278+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 276, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 249) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 249) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1091149, timeActiveMicros:1095256, timeInactiveMicros:1538, 1096ms
2020-05-08T21:58:31.278+0000 I  COMMAND  [conn155] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 258), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45") }, txnNumber: 276, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1091ms
2020-05-08T21:58:31.279+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 256, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 321) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 322) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:542029, timeActiveMicros:1041025, timeInactiveMicros:1103, 1042ms
2020-05-08T21:58:31.279+0000 I  COMMAND  [conn157] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 256, autocommit: false } numYields:0 reslen:214 protocol:op_msg 542ms
2020-05-08T21:58:31.394+0000 I  NETWORK  [conn157] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b:260 stopped due to: Transaction coordinator service stepping down
2020-05-08T21:58:31.394+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.395+0000 I  NETWORK  [conn155] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.396+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.894+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.394+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.394+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.395+0000 I  COMMAND  [conn155] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 498 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45") }, txnNumber: 282, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:372 protocol:op_msg 1013ms
2020-05-08T21:58:32.398+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 282, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 166) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 166) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1018220, timeInactiveMicros:811, 1019ms
2020-05-08T21:58:33.388+0000 I  SHARDING [conn155] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:34.744+0000 I  NETWORK  [conn157] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b:260 stopped due to: operation was interrupted
2020-05-08T21:58:34.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.751+0000 I  NETWORK  [conn160] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.752+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.752+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.753+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:34.753+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:34.753+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.074+0000 I  NETWORK  [conn155] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:35.075+0000 I  COMMAND  [conn155] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45") }, txnNumber: 282, autocommit: false } numYields:0 reslen:353 protocol:op_msg 2676ms
2020-05-08T21:58:35.077+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.172+0000 I  NETWORK  [conn160] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:36.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.279+0000 I  NETWORK  [conn156] end connection 172.31.0.221:34844 (57 connections now open)
2020-05-08T21:58:36.281+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35082 #165 (58 connections now open)
2020-05-08T21:58:36.281+0000 I  NETWORK  [conn158] end connection 172.31.0.221:34860 (57 connections now open)
2020-05-08T21:58:36.281+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35084 #166 (58 connections now open)
2020-05-08T21:58:36.281+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:35082 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.281+0000 I  NETWORK  [conn166] received client metadata from 172.31.0.221:35084 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.282+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35086 #167 (59 connections now open)
2020-05-08T21:58:36.282+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35088 #168 (60 connections now open)
2020-05-08T21:58:36.282+0000 I  NETWORK  [conn167] received client metadata from 172.31.0.221:35086 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.282+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:35088 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.283+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.283+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.292+0000 I  NETWORK  [conn161] end connection 172.31.0.221:34922 (59 connections now open)
2020-05-08T21:58:36.292+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35090 #169 (60 connections now open)
2020-05-08T21:58:36.293+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35092 #170 (61 connections now open)
2020-05-08T21:58:36.293+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:35090 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.293+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:35092 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.372+0000 I  COMMAND  [conn157] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 146), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0ae1cdd-d4c3-46d2-ae3e-fc36d460fe4b") }, txnNumber: 260, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:58:36.373+0000 I  NETWORK  [conn157] end connection 172.31.0.221:34858 (60 connections now open)
2020-05-08T21:58:36.385+0000 I  -        [conn160] operation was interrupted because a client disconnected
2020-05-08T21:58:36.385+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 260, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 170) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 170) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002937, timeInactiveMicros:0, 5002ms
2020-05-08T21:58:36.385+0000 I  COMMAND  [conn160] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 495 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43b0f007-22e1-42bf-abcb-00989b4c4e1b") }, txnNumber: 260, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 170) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:36.385+0000 I  NETWORK  [conn160] end connection 172.31.0.221:34920 (59 connections now open)
2020-05-08T21:58:36.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.746+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.746+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 506 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef5f89c4-dec7-4c02-9f37-2873729ad5c0") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 463ms
2020-05-08T21:58:36.746+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.746+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.753+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 503 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 470ms
2020-05-08T21:58:36.756+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:473094, timeInactiveMicros:358, 473ms
2020-05-08T21:58:37.026+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.201+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.201+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.852+0000 I  NETWORK  [conn167] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.853+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:38.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.246+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.246+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.353+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.353+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.354+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 239) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 241) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1068963, timeInactiveMicros:257, 1069ms
2020-05-08T21:58:38.354+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 245), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 32, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1063ms
2020-05-08T21:58:38.518+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.518+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.520+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.672+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.672+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.673+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.674+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 283, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 10) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3597754, timeInactiveMicros:249, 3598ms
2020-05-08T21:58:38.674+0000 I  COMMAND  [conn155] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 498 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f434905-cb51-45d8-9955-4a7b3bdc0e45") }, txnNumber: 283, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 1f434905-cb51-45d8-9955-4a7b3bdc0e45:283 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975114, 10) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:548 protocol:op_msg 3597ms
2020-05-08T21:58:38.674+0000 I  NETWORK  [conn155] end connection 172.31.0.221:34842 (58 connections now open)
2020-05-08T21:58:38.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.856+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 508 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef5f89c4-dec7-4c02-9f37-2873729ad5c0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2109ms
2020-05-08T21:58:38.860+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2566648, timeInactiveMicros:0, 2566ms
2020-05-08T21:58:38.860+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2566ms
2020-05-08T21:58:38.863+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 33, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 7) } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 7) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:501799, timeInactiveMicros:252, 502ms
2020-05-08T21:58:38.863+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 33, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 500ms
2020-05-08T21:58:38.863+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("ef5f89c4-dec7-4c02-9f37-2873729ad5c0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 14) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2115021, timeInactiveMicros:970, 2115ms
2020-05-08T21:58:39.246+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.246+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.357+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:40.540+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:40.540+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.542+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.542+0000 I  NETWORK  [conn169] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.040+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.771+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:41.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.040+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.040+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.041+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1010), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 35, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3342ms
2020-05-08T21:58:43.041+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1018), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 68, autocommit: false } numYields:0 reslen:321 protocol:op_msg 3337ms
2020-05-08T21:58:43.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.056+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 574 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975122, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 69, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975122, 1) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 1013ms
2020-05-08T21:58:44.057+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975122, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 35, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1015ms
2020-05-08T21:58:44.177+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 69, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975122, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588975122, 1) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1133810, timeInactiveMicros:1564, 1135ms
2020-05-08T21:58:44.177+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 69, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 117ms
2020-05-08T21:58:44.184+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("ef5f89c4-dec7-4c02-9f37-2873729ad5c0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975119, 910) } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 910) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:4526144, timeActiveMicros:4547758, timeInactiveMicros:4523, 4552ms
2020-05-08T21:58:44.184+0000 I  COMMAND  [conn165] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 953), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef5f89c4-dec7-4c02-9f37-2873729ad5c0") }, txnNumber: 28, autocommit: false } numYields:0 reslen:214 protocol:op_msg 4526ms
2020-05-08T21:58:44.212+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:44.214+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:44.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.428+0000 I  NETWORK  [conn167] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:45.429+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:45.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.079+0000 I  NETWORK  [conn169] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:46.080+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:46.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.540+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 18604 timed out, deadline was 2020-05-08T21:58:46.540+0000, op was RemoteCommand 18604 -- target:[ec2-54-236-6-178.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:46.540+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:46.540+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:46.540+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.579+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.579+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.580+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.580+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 304, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975126, 16) } }, globalReadTimestamp:{ ts: Timestamp(1588975126, 16) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:501261, timeInactiveMicros:0, 501ms
2020-05-08T21:58:46.580+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975126, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 304, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975126, 16) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 501ms
2020-05-08T21:58:46.771+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.771+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.772+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.776+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 21), t: 33 }
2020-05-08T21:58:46.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.086+0000 I  NETWORK  [conn169] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:47.087+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:47.237+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b9883dd86ab8e095b5; invalidating user cache
2020-05-08T21:58:47.271+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.271+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.429+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.586+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:48.086+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.086+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.087+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975126, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 304, autocommit: false } numYields:0 reslen:516 protocol:op_msg 1505ms
2020-05-08T21:58:48.490+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:48.990+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:48.990+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.309+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.309+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.358+0000 I  NETWORK  [conn166] end connection 172.31.0.221:35084 (57 connections now open)
2020-05-08T21:58:49.358+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35364 #173 (58 connections now open)
2020-05-08T21:58:49.359+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:35364 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35366 #174 (59 connections now open)
2020-05-08T21:58:49.359+0000 I  NETWORK  [conn174] received client metadata from 172.31.0.221:35366 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.361+0000 I  NETWORK  [conn173] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.362+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.362+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.362+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.371+0000 I  NETWORK  [conn168] end connection 172.31.0.221:35088 (58 connections now open)
2020-05-08T21:58:49.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35380 #175 (59 connections now open)
2020-05-08T21:58:49.372+0000 I  NETWORK  [conn175] received client metadata from 172.31.0.221:35380 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35382 #176 (60 connections now open)
2020-05-08T21:58:49.372+0000 I  NETWORK  [conn176] received client metadata from 172.31.0.221:35382 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.373+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.374+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.375+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 306, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1271ms
2020-05-08T21:58:49.375+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 415), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1cab40e-7f40-4659-9f42-3dce36a3fdca") }, txnNumber: 80, autocommit: false } numYields:0 reslen:321 protocol:op_msg 4945ms
2020-05-08T21:58:49.375+0000 I  COMMAND  [conn165] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 397), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef5f89c4-dec7-4c02-9f37-2873729ad5c0") }, txnNumber: 38, autocommit: false } numYields:0 reslen:352 protocol:op_msg 4958ms
2020-05-08T21:58:49.375+0000 I  NETWORK  [conn167] end connection 172.31.0.221:35086 (59 connections now open)
2020-05-08T21:58:49.375+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.376+0000 I  NETWORK  [conn165] end connection 172.31.0.221:35082 (58 connections now open)
2020-05-08T21:58:49.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.990+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.320+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.658+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c8e89e8-6695-4e5e-b9e6-4679aaa17e7e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 798ms
2020-05-08T21:58:50.756+0000 I  NETWORK  [conn169] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:50.990+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:51.257+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.257+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.257+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.258+0000 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("37ed4936-348b-407d-b2f7-afa4454dae1e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 4) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1884806, timeInactiveMicros:0, 1884ms
2020-05-08T21:58:51.258+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 306, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 7) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:3154462, timeInactiveMicros:765, 3155ms
2020-05-08T21:58:51.258+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 306, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Given transaction number 306 does not match any in-progress transactions. The active transaction number is 305" errName:NoSuchTransaction errCode:251 reslen:487 protocol:op_msg 1882ms
2020-05-08T21:58:51.258+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("37ed4936-348b-407d-b2f7-afa4454dae1e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1884ms
2020-05-08T21:58:51.491+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.492+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.492+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.873+0000 I  COMMAND  [conn175] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("37ed4936-348b-407d-b2f7-afa4454dae1e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 614ms
2020-05-08T21:58:51.873+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 306, autocommit: false } numYields:0 reslen:430 protocol:op_msg 615ms
2020-05-08T21:58:51.881+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("6c8e89e8-6695-4e5e-b9e6-4679aaa17e7e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588975130, 15) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1209649, timeInactiveMicros:0, 1209ms
2020-05-08T21:58:51.881+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975130, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6c8e89e8-6695-4e5e-b9e6-4679aaa17e7e") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 15) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1209ms
2020-05-08T21:58:52.115+0000 I  NETWORK  [replSetDistLockPinger] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.115+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.117+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.122+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.123+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.125+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.560+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.615+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.103+0000 I  NETWORK  [conn170] end connection 172.31.0.221:35092 (57 connections now open)
2020-05-08T21:58:53.103+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35540 #179 (58 connections now open)
2020-05-08T21:58:53.103+0000 I  NETWORK  [conn179] received client metadata from 172.31.0.221:35540 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:53.103+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35542 #180 (59 connections now open)
2020-05-08T21:58:53.104+0000 I  NETWORK  [conn180] received client metadata from 172.31.0.221:35542 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:53.105+0000 I  NETWORK  [conn179] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:53.106+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:53.115+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.115+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.116+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.162+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:58:53.285+0000 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("37ed4936-348b-407d-b2f7-afa4454dae1e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 78) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 78) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1393217, timeInactiveMicros:0, 1393ms
2020-05-08T21:58:53.285+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 78), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("37ed4936-348b-407d-b2f7-afa4454dae1e") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 78) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1393ms
2020-05-08T21:58:53.286+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.286+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.573+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 90), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907e2884-115a-464b-88c7-4d039b88a4f9") }, txnNumber: 308, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1671ms
2020-05-08T21:58:53.573+0000 I  NETWORK  [conn169] end connection 172.31.0.221:35090 (58 connections now open)
2020-05-08T21:58:53.931+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.932+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.934+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.937+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:54.359+0000 I  NETWORK  [conn174] end connection 172.31.0.221:35366 (57 connections now open)
2020-05-08T21:58:54.360+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35602 #183 (58 connections now open)
2020-05-08T21:58:54.360+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35600 #184 (59 connections now open)
2020-05-08T21:58:54.360+0000 I  NETWORK  [conn183] received client metadata from 172.31.0.221:35602 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.360+0000 I  NETWORK  [conn184] received client metadata from 172.31.0.221:35600 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.372+0000 I  NETWORK  [conn176] end connection 172.31.0.221:35382 (58 connections now open)
2020-05-08T21:58:54.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35614 #185 (59 connections now open)
2020-05-08T21:58:54.373+0000 I  NETWORK  [conn185] received client metadata from 172.31.0.221:35614 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.373+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35616 #186 (60 connections now open)
2020-05-08T21:58:54.373+0000 I  NETWORK  [conn186] received client metadata from 172.31.0.221:35616 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.432+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.432+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.433+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 4), t: 38 }
2020-05-08T21:58:54.604+0000 I  NETWORK  [conn183] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:58.104+0000 I  NETWORK  [conn180] end connection 172.31.0.221:35542 (59 connections now open)
2020-05-08T21:58:58.104+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35820 #187 (60 connections now open)
2020-05-08T21:58:58.104+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35822 #188 (61 connections now open)
2020-05-08T21:58:58.105+0000 I  NETWORK  [conn187] received client metadata from 172.31.0.221:35820 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:58.105+0000 I  NETWORK  [conn188] received client metadata from 172.31.0.221:35822 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:58.106+0000 I  -        [conn179] operation was interrupted because a client disconnected
2020-05-08T21:58:58.106+0000 I  TXN      [conn179] transaction parameters:{ lsid: { id: UUID("bdcad509-b216-482b-8c29-5ea104ac7081"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975132, 3) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002016, timeInactiveMicros:0, 5002ms
2020-05-08T21:58:58.106+0000 I  COMMAND  [conn179] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 610 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975132, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bdcad509-b216-482b-8c29-5ea104ac7081") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:58:58.107+0000 I  NETWORK  [conn179] end connection 172.31.0.221:35540 (60 connections now open)
2020-05-08T21:58:59.360+0000 I  NETWORK  [conn184] end connection 172.31.0.221:35600 (59 connections now open)
2020-05-08T21:58:59.360+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35894 #189 (60 connections now open)
2020-05-08T21:58:59.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35896 #190 (61 connections now open)
2020-05-08T21:58:59.361+0000 I  NETWORK  [conn189] received client metadata from 172.31.0.221:35894 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.361+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:35896 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.373+0000 I  NETWORK  [conn186] end connection 172.31.0.221:35616 (60 connections now open)
2020-05-08T21:58:59.374+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35906 #191 (61 connections now open)
2020-05-08T21:58:59.374+0000 I  NETWORK  [conn191] received client metadata from 172.31.0.221:35906 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.374+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:35908 #192 (62 connections now open)
2020-05-08T21:58:59.374+0000 I  NETWORK  [conn192] received client metadata from 172.31.0.221:35908 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.375+0000 I  SHARDING [conn191] Received reply from shard ec2-35-172-222-251.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 2), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.376+0000 I  COMMAND  [conn175] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("37ed4936-348b-407d-b2f7-afa4454dae1e") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 6090ms
2020-05-08T21:58:59.376+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("88f4ed17-50cc-488a-8fd5-ccfba807aad5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:5015409, timeInactiveMicros:0, 5015ms
2020-05-08T21:58:59.376+0000 I  COMMAND  [conn183] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("88f4ed17-50cc-488a-8fd5-ccfba807aad5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 5015ms
2020-05-08T21:58:59.376+0000 I  NETWORK  [conn175] end connection 172.31.0.221:35380 (61 connections now open)
2020-05-08T21:58:59.376+0000 I  NETWORK  [conn183] end connection 172.31.0.221:35602 (60 connections now open)
2020-05-08T21:58:59.376+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.377+0000 I  -        [conn185] operation was interrupted because a client disconnected
2020-05-08T21:58:59.377+0000 I  CONNPOOL [conn185] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:58:59.377+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("a32dfb03-84ff-4af7-b523-cc0314b82e61"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003382, timeInactiveMicros:0, 5003ms
2020-05-08T21:58:59.377+0000 I  COMMAND  [conn185] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 613 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a32dfb03-84ff-4af7-b523-cc0314b82e61") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:59.377+0000 I  NETWORK  [conn185] end connection 172.31.0.221:35614 (59 connections now open)
2020-05-08T21:58:59.604+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 20165 timed out, deadline was 2020-05-08T21:58:59.604+0000, op was RemoteCommand 20165 -- target:[ec2-34-207-119-213.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:59.604+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:59.604+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.604+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:59:00.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:00.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:03.105+0000 I  NETWORK  [conn188] end connection 172.31.0.221:35822 (58 connections now open)
2020-05-08T21:59:03.105+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36082 #196 (59 connections now open)
2020-05-08T21:59:03.106+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36084 #197 (60 connections now open)
2020-05-08T21:59:03.106+0000 I  NETWORK  [conn196] received client metadata from 172.31.0.221:36082 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:03.106+0000 I  NETWORK  [conn197] received client metadata from 172.31.0.221:36084 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:03.106+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:03.109+0000 I  -        [conn187] operation was interrupted because a client disconnected
2020-05-08T21:59:03.109+0000 I  CONNPOOL [conn187] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:03.109+0000 I  TXN      [conn187] transaction parameters:{ lsid: { id: UUID("54acf256-9a60-4332-a159-d82b7a6f87c0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975136, 4) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003629, timeInactiveMicros:0, 5003ms
2020-05-08T21:59:03.109+0000 I  COMMAND  [conn187] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 617 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975136, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("54acf256-9a60-4332-a159-d82b7a6f87c0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:03.109+0000 I  NETWORK  [conn187] end connection 172.31.0.221:35820 (59 connections now open)
2020-05-08T21:59:04.361+0000 I  NETWORK  [conn190] end connection 172.31.0.221:35896 (58 connections now open)
2020-05-08T21:59:04.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36150 #199 (59 connections now open)
2020-05-08T21:59:04.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36152 #200 (60 connections now open)
2020-05-08T21:59:04.362+0000 I  NETWORK  [conn199] received client metadata from 172.31.0.221:36150 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.362+0000 I  NETWORK  [conn200] received client metadata from 172.31.0.221:36152 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.363+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.377+0000 I  NETWORK  [conn192] end connection 172.31.0.221:35908 (59 connections now open)
2020-05-08T21:59:04.377+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36162 #202 (60 connections now open)
2020-05-08T21:59:04.378+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36164 #203 (61 connections now open)
2020-05-08T21:59:04.378+0000 I  NETWORK  [conn202] received client metadata from 172.31.0.221:36162 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.378+0000 I  NETWORK  [conn203] received client metadata from 172.31.0.221:36164 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.888+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:05.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:06.786+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975145, 427), t: 41 }
2020-05-08T21:59:06.786+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:06.787+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:06.787+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:08.106+0000 I  NETWORK  [conn197] end connection 172.31.0.221:36084 (60 connections now open)
2020-05-08T21:59:08.107+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36234 #209 (61 connections now open)
2020-05-08T21:59:08.107+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36236 #210 (62 connections now open)
2020-05-08T21:59:08.107+0000 I  NETWORK  [conn210] received client metadata from 172.31.0.221:36236 conn210: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:08.107+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:36234 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:08.108+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:08.109+0000 I  -        [conn196] operation was interrupted because a client disconnected
2020-05-08T21:59:08.109+0000 I  CONNPOOL [conn196] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T21:59:08.109+0000 I  COMMAND  [conn196] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 622 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ec400876-ef89-4c37-8ffe-91897d506f04") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:08.109+0000 I  NETWORK  [conn196] end connection 172.31.0.221:36082 (61 connections now open)
2020-05-08T21:59:09.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36276 #212 (62 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [conn212] end connection 172.31.0.221:36276 (61 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36284 #213 (62 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:36284 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.378+0000 I  NETWORK  [conn200] end connection 172.31.0.221:36152 (61 connections now open)
2020-05-08T21:59:09.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36288 #214 (62 connections now open)
2020-05-08T21:59:09.379+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:36288 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36290 #215 (63 connections now open)
2020-05-08T21:59:09.379+0000 I  NETWORK  [conn215] received client metadata from 172.31.0.221:36290 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.381+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.381+0000 I  -        [conn203] operation was interrupted because a client disconnected
2020-05-08T21:59:09.381+0000 I  CONNPOOL [conn203] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T21:59:09.381+0000 I  TXN      [conn203] transaction parameters:{ lsid: { id: UUID("cd38be66-39fe-4356-891e-48f3f802d530"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002936, timeInactiveMicros:0, 5002ms
2020-05-08T21:59:09.381+0000 I  COMMAND  [conn203] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 618 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cd38be66-39fe-4356-891e-48f3f802d530") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:09.381+0000 I  NETWORK  [conn203] end connection 172.31.0.221:36164 (62 connections now open)
2020-05-08T21:59:09.382+0000 I  NETWORK  [conn202] end connection 172.31.0.221:36162 (61 connections now open)
2020-05-08T21:59:09.382+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36306 #216 (62 connections now open)
2020-05-08T21:59:09.383+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36308 #218 (63 connections now open)
2020-05-08T21:59:09.383+0000 I  NETWORK  [conn218] received client metadata from 172.31.0.221:36308 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.383+0000 I  NETWORK  [conn216] received client metadata from 172.31.0.221:36306 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.384+0000 I  NETWORK  [conn216] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:09.885+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.885+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.107+0000 I  NETWORK  [conn210] end connection 172.31.0.221:36236 (62 connections now open)
2020-05-08T21:59:13.108+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36420 #219 (63 connections now open)
2020-05-08T21:59:13.108+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36422 #220 (64 connections now open)
2020-05-08T21:59:13.108+0000 I  NETWORK  [conn219] received client metadata from 172.31.0.221:36420 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:13.108+0000 I  NETWORK  [conn220] received client metadata from 172.31.0.221:36422 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:13.109+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.113+0000 I  -        [conn209] operation was interrupted because a client disconnected
2020-05-08T21:59:13.113+0000 I  CONNPOOL [conn209] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T21:59:13.113+0000 I  COMMAND  [conn209] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 686 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 500), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4c338a07-82db-464a-b8ec-894613d47b5b") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:13.113+0000 I  NETWORK  [conn209] end connection 172.31.0.221:36234 (63 connections now open)
2020-05-08T21:59:13.323+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:59:14.379+0000 I  NETWORK  [conn215] end connection 172.31.0.221:36290 (62 connections now open)
2020-05-08T21:59:14.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36444 #222 (63 connections now open)
2020-05-08T21:59:14.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36446 #223 (64 connections now open)
2020-05-08T21:59:14.380+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:36444 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.380+0000 I  NETWORK  [conn223] received client metadata from 172.31.0.221:36446 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.384+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.384+0000 I  NETWORK  [conn218] end connection 172.31.0.221:36308 (63 connections now open)
2020-05-08T21:59:14.385+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36456 #225 (64 connections now open)
2020-05-08T21:59:14.385+0000 I  NETWORK  [conn225] received client metadata from 172.31.0.221:36456 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.385+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36458 #226 (65 connections now open)
2020-05-08T21:59:14.386+0000 I  NETWORK  [conn226] received client metadata from 172.31.0.221:36458 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.655+0000 I  NETWORK  [conn216] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:14.704+0000 I  COMMAND  [conn216] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 500), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0d70e34a-4789-4562-bfa6-f77034bad345") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 5320ms
2020-05-08T21:59:14.704+0000 I  NETWORK  [conn216] end connection 172.31.0.221:36306 (64 connections now open)
2020-05-08T21:59:15.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.077+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:16.794+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.795+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.795+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.800+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 5), t: 43 }
2020-05-08T21:59:18.109+0000 I  NETWORK  [conn220] end connection 172.31.0.221:36422 (63 connections now open)
2020-05-08T21:59:18.111+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36586 #233 (64 connections now open)
2020-05-08T21:59:18.111+0000 I  NETWORK  [conn233] received client metadata from 172.31.0.221:36586 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:18.111+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36588 #234 (65 connections now open)
2020-05-08T21:59:18.111+0000 I  NETWORK  [conn234] received client metadata from 172.31.0.221:36588 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:18.112+0000 I  NETWORK  [conn234] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:18.113+0000 I  -        [conn219] operation was interrupted because a client disconnected
2020-05-08T21:59:18.113+0000 I  CONNPOOL [conn219] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:18.114+0000 I  TXN      [conn219] transaction parameters:{ lsid: { id: UUID("a4d9355c-655d-4b6d-9291-f814405a4e1a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 101) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004928, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:18.114+0000 I  COMMAND  [conn219] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 691 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a4d9355c-655d-4b6d-9291-f814405a4e1a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:18.114+0000 I  NETWORK  [conn219] end connection 172.31.0.221:36420 (64 connections now open)
2020-05-08T21:59:18.946+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.113+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.381+0000 I  NETWORK  [conn223] end connection 172.31.0.221:36446 (63 connections now open)
2020-05-08T21:59:19.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36620 #235 (64 connections now open)
2020-05-08T21:59:19.381+0000 I  NETWORK  [conn235] received client metadata from 172.31.0.221:36620 conn235: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36622 #236 (65 connections now open)
2020-05-08T21:59:19.382+0000 I  NETWORK  [conn236] received client metadata from 172.31.0.221:36622 conn236: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.383+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.385+0000 I  NETWORK  [conn226] end connection 172.31.0.221:36458 (64 connections now open)
2020-05-08T21:59:19.386+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36632 #238 (65 connections now open)
2020-05-08T21:59:19.386+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36634 #239 (66 connections now open)
2020-05-08T21:59:19.386+0000 I  NETWORK  [conn238] received client metadata from 172.31.0.221:36632 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.387+0000 I  NETWORK  [conn239] received client metadata from 172.31.0.221:36634 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.818+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.861+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.861+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.862+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.862+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.862+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:20.113+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:20.113+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:20.115+0000 I  TXN      [conn234] transaction parameters:{ lsid: { id: UUID("318f3129-6b0a-49b0-9471-4a885ef86ce5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 4) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2003115, timeInactiveMicros:0, 2003ms
2020-05-08T21:59:20.115+0000 I  COMMAND  [conn234] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 741 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("318f3129-6b0a-49b0-9471-4a885ef86ce5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 318f3129-6b0a-49b0-9471-4a885ef86ce5:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975157, 4) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 2003ms
2020-05-08T21:59:20.283+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:23.404+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:24.388+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36784 #240 (67 connections now open)
2020-05-08T21:59:24.388+0000 I  NETWORK  [conn240] received client metadata from 172.31.0.221:36784 conn240: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.434+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:24.435+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.435+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.471+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:24.907+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:25.323+0000 I  -        [conn234] operation was interrupted because a client disconnected
2020-05-08T21:59:25.323+0000 I  CONNPOOL [conn234] Ending connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:59:25.323+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36794 #241 (68 connections now open)
2020-05-08T21:59:25.323+0000 I  TXN      [conn234] transaction parameters:{ lsid: { id: UUID("318f3129-6b0a-49b0-9471-4a885ef86ce5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975160, 183) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001705, timeInactiveMicros:0, 5001ms
2020-05-08T21:59:25.324+0000 I  COMMAND  [conn234] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 744 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975160, 183), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("318f3129-6b0a-49b0-9471-4a885ef86ce5") }, txnNumber: 26, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:25.324+0000 I  NETWORK  [conn234] end connection 172.31.0.221:36588 (67 connections now open)
2020-05-08T21:59:25.324+0000 I  NETWORK  [conn241] received client metadata from 172.31.0.221:36794 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:26.421+0000 I  NETWORK  [conn239] end connection 172.31.0.221:36634 (66 connections now open)
2020-05-08T21:59:26.423+0000 I  NETWORK  [conn236] end connection 172.31.0.221:36622 (65 connections now open)
2020-05-08T21:59:26.424+0000 I  NETWORK  [conn233] end connection 172.31.0.221:36586 (64 connections now open)
2020-05-08T21:59:26.429+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:36816 #242 (65 connections now open)
2020-05-08T21:59:26.429+0000 I  NETWORK  [conn242] end connection 172.31.0.221:36816 (64 connections now open)
2020-05-08T21:59:27.314+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:59:27.382+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975166, 4), t: 47 }
2020-05-08T21:59:27.382+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:27.383+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:27.383+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:29.418+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:30.233+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
