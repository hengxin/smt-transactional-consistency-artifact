2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.229+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.231+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.231+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.231+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.231+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.231+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.233+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.233+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.235+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.235+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.236+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.236+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.236+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-13-182:27017:1588975035:6890725273302322250 (sleeping for 30000ms)
2020-05-08T21:57:15.240+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.240+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.240+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.245+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 12), t: 1 }
2020-05-08T21:57:15.422+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.424+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.426+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.426+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.427+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("1ee5f451-93be-48f4-98be-eb3e59a95820"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.427+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.428+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.429+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.429+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.522+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49062 #10 (1 connection now open)
2020-05-08T21:57:16.523+0000 I  NETWORK  [conn10] received client metadata from 172.31.0.221:49062 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.887+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49086 #11 (2 connections now open)
2020-05-08T21:57:16.888+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:49086 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.927+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49094 #12 (3 connections now open)
2020-05-08T21:57:16.927+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:49094 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.948+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49110 #13 (4 connections now open)
2020-05-08T21:57:16.948+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:49110 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.092+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49120 #14 (5 connections now open)
2020-05-08T21:57:17.093+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:49120 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.145+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49132 #15 (6 connections now open)
2020-05-08T21:57:17.145+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:49132 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49176 #16 (7 connections now open)
2020-05-08T21:57:17.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49178 #17 (8 connections now open)
2020-05-08T21:57:17.306+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:49176 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.306+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:49178 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49188 #18 (9 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:49188 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.452+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49210 #19 (10 connections now open)
2020-05-08T21:57:17.452+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:49210 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.453+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49216 #20 (11 connections now open)
2020-05-08T21:57:17.454+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:49216 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49244 #21 (12 connections now open)
2020-05-08T21:57:17.705+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:49244 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.786+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49270 #22 (13 connections now open)
2020-05-08T21:57:17.787+0000 I  NETWORK  [conn22] received client metadata from 172.31.0.221:49270 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.829+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49278 #23 (14 connections now open)
2020-05-08T21:57:17.830+0000 I  NETWORK  [conn23] received client metadata from 172.31.0.221:49278 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.869+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49300 #24 (15 connections now open)
2020-05-08T21:57:18.869+0000 I  NETWORK  [conn24] received client metadata from 172.31.0.221:49300 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.509+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49320 #25 (16 connections now open)
2020-05-08T21:57:19.509+0000 I  NETWORK  [conn25] received client metadata from 172.31.0.221:49320 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.567+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49348 #26 (17 connections now open)
2020-05-08T21:57:19.568+0000 I  NETWORK  [conn26] received client metadata from 172.31.0.221:49348 conn26: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.995+0000 I  COMMAND  [conn19] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a2129b9f-d194-4ca5-aad1-e2cd25129870") } } numYields:0 reslen:163 protocol:op_msg 2536ms
2020-05-08T21:57:19.996+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:19.997+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.997+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.000+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.000+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.010+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.010+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.027+0000 I  NETWORK  [conn19] end connection 172.31.0.221:49210 (16 connections now open)
2020-05-08T21:57:20.028+0000 I  NETWORK  [conn20] end connection 172.31.0.221:49216 (15 connections now open)
2020-05-08T21:57:20.089+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49378 #33 (16 connections now open)
2020-05-08T21:57:20.089+0000 I  NETWORK  [conn33] received client metadata from 172.31.0.221:49378 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.191+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49394 #34 (17 connections now open)
2020-05-08T21:57:20.191+0000 I  NETWORK  [conn34] received client metadata from 172.31.0.221:49394 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.351+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49428 #35 (18 connections now open)
2020-05-08T21:57:21.351+0000 I  NETWORK  [conn35] received client metadata from 172.31.0.221:49428 conn35: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.557+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49438 #36 (19 connections now open)
2020-05-08T21:57:21.558+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:49438 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.782+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49448 #37 (20 connections now open)
2020-05-08T21:57:21.783+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:49448 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.845+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49458 #38 (21 connections now open)
2020-05-08T21:57:21.846+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:49458 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.935+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49482 #39 (22 connections now open)
2020-05-08T21:57:21.935+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:49482 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.958+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49486 #40 (23 connections now open)
2020-05-08T21:57:21.959+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:49486 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49514 #41 (24 connections now open)
2020-05-08T21:57:22.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49516 #42 (25 connections now open)
2020-05-08T21:57:22.058+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:49514 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.059+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:49516 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.073+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 2 ms
2020-05-08T21:57:22.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.076+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49586 #44 (26 connections now open)
2020-05-08T21:57:22.076+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:49586 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.077+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49598 #45 (27 connections now open)
2020-05-08T21:57:22.078+0000 I  NETWORK  [conn45] received client metadata from 172.31.0.221:49598 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.080+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49604 #46 (28 connections now open)
2020-05-08T21:57:22.080+0000 I  NETWORK  [conn46] received client metadata from 172.31.0.221:49604 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.083+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49610 #47 (29 connections now open)
2020-05-08T21:57:22.083+0000 I  NETWORK  [conn47] received client metadata from 172.31.0.221:49610 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 216ms
2020-05-08T21:57:22.325+0000 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 221ms
2020-05-08T21:57:22.515+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49640 #56 (30 connections now open)
2020-05-08T21:57:22.516+0000 I  NETWORK  [conn56] received client metadata from 172.31.0.221:49640 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.834+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 409), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa") }, txnNumber: 22, autocommit: false } numYields:0 reslen:352 protocol:op_msg 210ms
2020-05-08T21:57:23.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.082+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49678 #61 (31 connections now open)
2020-05-08T21:57:23.082+0000 I  NETWORK  [conn61] received client metadata from 172.31.0.221:49678 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.124+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49694 #64 (32 connections now open)
2020-05-08T21:57:23.124+0000 I  NETWORK  [conn64] received client metadata from 172.31.0.221:49694 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.372+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 19, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 403) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:764306, timeActiveMicros:767757, timeInactiveMicros:909, 768ms
2020-05-08T21:57:23.372+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 405), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6") }, txnNumber: 19, autocommit: false } numYields:0 reslen:214 protocol:op_msg 764ms
2020-05-08T21:57:23.417+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49712 #65 (33 connections now open)
2020-05-08T21:57:23.418+0000 I  NETWORK  [conn65] received client metadata from 172.31.0.221:49712 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.772+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49758 #66 (34 connections now open)
2020-05-08T21:57:23.772+0000 I  NETWORK  [conn66] received client metadata from 172.31.0.221:49758 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49778 #67 (35 connections now open)
2020-05-08T21:57:24.365+0000 I  NETWORK  [conn67] received client metadata from 172.31.0.221:49778 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.484+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49804 #68 (36 connections now open)
2020-05-08T21:57:24.484+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49802 #69 (37 connections now open)
2020-05-08T21:57:24.484+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:49804 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.484+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:49802 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.614+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 47, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 367) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 367) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:2064226, timeActiveMicros:2067815, timeInactiveMicros:1136, 2068ms
2020-05-08T21:57:24.614+0000 I  COMMAND  [conn41] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 370), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf") }, txnNumber: 47, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2064ms
2020-05-08T21:57:24.616+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 439), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa") }, txnNumber: 37, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1676ms
2020-05-08T21:57:25.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.134+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 27 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975043, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6") }, txnNumber: 22, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 36) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 1716ms
2020-05-08T21:57:25.137+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 36) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 38) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1718603, timeInactiveMicros:391, 1718ms
2020-05-08T21:57:25.183+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49836 #72 (38 connections now open)
2020-05-08T21:57:25.184+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:49836 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.420+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49862 #73 (39 connections now open)
2020-05-08T21:57:25.420+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:49862 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.517+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49894 #74 (40 connections now open)
2020-05-08T21:57:25.517+0000 I  NETWORK  [conn74] received client metadata from 172.31.0.221:49894 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.543+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa") }, txnNumber: 50, autocommit: false } numYields:0 reslen:321 protocol:op_msg 851ms
2020-05-08T21:57:25.544+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6") }, txnNumber: 24, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 382ms
2020-05-08T21:57:25.548+0000 I  COMMAND  [conn41] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 48, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 152), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 933ms
2020-05-08T21:57:25.558+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 27) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:12038, timeActiveMicros:396459, timeInactiveMicros:927, 397ms
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49910 #75 (41 connections now open)
2020-05-08T21:57:25.672+0000 I  NETWORK  [conn75] received client metadata from 172.31.0.221:49910 conn75: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.902+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:26.120+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49932 #77 (42 connections now open)
2020-05-08T21:57:26.121+0000 I  NETWORK  [conn77] received client metadata from 172.31.0.221:49932 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.458+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 93), t: 3 }
2020-05-08T21:57:26.949+0000 I  NETWORK  [conn41] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:26.949+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.954+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.949+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:28.449+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.449+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.449+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.451+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 676), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa") }, txnNumber: 68, autocommit: false } numYields:0 reslen:352 protocol:op_msg 2507ms
2020-05-08T21:57:28.463+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 668) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 668) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2516056, timeActiveMicros:2524434, timeInactiveMicros:1250, 2525ms
2020-05-08T21:57:28.463+0000 I  NETWORK  [conn41] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:28.464+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.467+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.964+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.964+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.965+0000 I  COMMAND  [conn41] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 679), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf") }, txnNumber: 70, autocommit: false } numYields:0 reslen:428 protocol:op_msg 3018ms
2020-05-08T21:57:29.164+0000 I  NETWORK  [conn44] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:29.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.464+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.964+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.464+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.707+0000 I  NETWORK  [conn45] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:57:30.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:30.821+0000 I  NETWORK  [conn47] end connection 172.31.0.221:49610 (41 connections now open)
2020-05-08T21:57:30.821+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50034 #81 (42 connections now open)
2020-05-08T21:57:30.821+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50036 #82 (43 connections now open)
2020-05-08T21:57:30.822+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:50034 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.822+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:50036 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.823+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.909+0000 I  NETWORK  [conn42] end connection 172.31.0.221:49516 (42 connections now open)
2020-05-08T21:57:30.910+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50074 #83 (43 connections now open)
2020-05-08T21:57:30.910+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:50074 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.910+0000 I  NETWORK  [conn46] end connection 172.31.0.221:49604 (42 connections now open)
2020-05-08T21:57:30.910+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50076 #84 (43 connections now open)
2020-05-08T21:57:30.911+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:50076 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.911+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50078 #85 (44 connections now open)
2020-05-08T21:57:30.911+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50080 #86 (45 connections now open)
2020-05-08T21:57:30.911+0000 I  NETWORK  [conn85] received client metadata from 172.31.0.221:50078 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.911+0000 I  NETWORK  [conn86] received client metadata from 172.31.0.221:50080 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.912+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.913+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.913+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 626), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d935bf38-6b80-439f-a6c9-c998f26af9f6") }, txnNumber: 40, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:57:30.913+0000 I  NETWORK  [conn45] end connection 172.31.0.221:49598 (44 connections now open)
2020-05-08T21:57:30.964+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:31.207+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.207+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.464+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.464+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.464+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.465+0000 I  TXN      [conn44] transaction parameters:{ lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 12) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3000761, timeInactiveMicros:258, 3001ms
2020-05-08T21:57:31.465+0000 I  COMMAND  [conn44] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc9b251-2e83-4276-ba83-7605e5e2e3aa") }, txnNumber: 70, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2999ms
2020-05-08T21:57:31.466+0000 I  NETWORK  [conn44] end connection 172.31.0.221:49586 (43 connections now open)
2020-05-08T21:57:31.993+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 55 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb9e5fa8-00f2-4035-b9a0-dbbe410f70aa") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1170ms
2020-05-08T21:57:31.993+0000 I  COMMAND  [conn86] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc3afe3-4e34-4dc3-bb72-577f556a220e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1080ms
2020-05-08T21:57:31.997+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1085423, timeInactiveMicros:0, 1085ms
2020-05-08T21:57:31.997+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1085ms
2020-05-08T21:57:32.001+0000 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("3fc3afe3-4e34-4dc3-bb72-577f556a220e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1088391, timeInactiveMicros:318, 1088ms
2020-05-08T21:57:32.031+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.936+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:32.937+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:32.964+0000 I  NETWORK  [conn82] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:32.964+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.128+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:33.129+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.129+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.129+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.129+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:33.204+0000 I  NETWORK  [conn41] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:33.206+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.207+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.464+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.705+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.705+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.707+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975052, 44) } }, globalReadTimestamp:{ ts: Timestamp(1588975052, 44) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1637557, timeInactiveMicros:0, 1637ms
2020-05-08T21:57:33.707+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975052, 44), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975052, 44) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1637ms
2020-05-08T21:57:33.708+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 71, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 15) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4742581, timeInactiveMicros:0, 4742ms
2020-05-08T21:57:33.708+0000 I  COMMAND  [conn41] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 50 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8852e742-29f5-4ec3-a769-75179fb569cf") }, txnNumber: 71, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 15) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 8852e742-29f5-4ec3-a769-75179fb569cf:71 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975048, 15) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 4742ms
2020-05-08T21:57:33.708+0000 I  NETWORK  [conn41] end connection 172.31.0.221:49514 (42 connections now open)
2020-05-08T21:57:33.964+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:34.146+0000 I  COMMAND  [conn86] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975052, 44), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc3afe3-4e34-4dc3-bb72-577f556a220e") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975052, 44) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2076ms
2020-05-08T21:57:34.148+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975053, 13) } }, globalReadTimestamp:{ ts: Timestamp(1588975053, 13) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:427699, timeInactiveMicros:0, 427ms
2020-05-08T21:57:34.149+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d") }, txnNumber: 8, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975053, 13) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 427ms
2020-05-08T21:57:34.149+0000 I  TXN      [conn86] transaction parameters:{ lsid: { id: UUID("3fc3afe3-4e34-4dc3-bb72-577f556a220e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975052, 44) } }, globalReadTimestamp:{ ts: Timestamp(1588975052, 44) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2079568, timeInactiveMicros:384, 2079ms
2020-05-08T21:57:34.174+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.174+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.182+0000 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("eb9e5fa8-00f2-4035-b9a0-dbbe410f70aa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 1) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2183038, timeActiveMicros:3358411, timeInactiveMicros:991, 3359ms
2020-05-08T21:57:34.183+0000 I  COMMAND  [conn82] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975051, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb9e5fa8-00f2-4035-b9a0-dbbe410f70aa") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 2184ms
2020-05-08T21:57:34.261+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:35.056+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 43, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 858) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:216734, timeActiveMicros:224174, timeInactiveMicros:532, 224ms
2020-05-08T21:57:35.056+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 866), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d") }, txnNumber: 43, autocommit: false } numYields:0 reslen:183 protocol:op_msg 216ms
2020-05-08T21:57:35.056+0000 I  COMMAND  [conn86] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 863), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc3afe3-4e34-4dc3-bb72-577f556a220e") }, txnNumber: 41, autocommit: false } numYields:0 reslen:321 protocol:op_msg 219ms
2020-05-08T21:57:35.058+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 869), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb9e5fa8-00f2-4035-b9a0-dbbe410f70aa") }, txnNumber: 31, autocommit: false } numYields:0 reslen:321 protocol:op_msg 217ms
2020-05-08T21:57:35.811+0000 I  NETWORK  [conn83] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:35.811+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:35.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:35.848+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:35.849+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.199+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50260 #94 (43 connections now open)
2020-05-08T21:57:36.199+0000 I  NETWORK  [conn94] received client metadata from 172.31.0.221:50260 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.349+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.811+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.849+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.849+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.850+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 79), t: 6 }
2020-05-08T21:57:37.187+0000 I  NETWORK  [conn86] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 3fc3afe3-4e34-4dc3-bb72-577f556a220e:53 stopped due to: operation was interrupted
2020-05-08T21:57:37.188+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:37.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.687+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.687+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.687+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.811+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.811+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.047+0000 I  NETWORK  [conn86] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 3fc3afe3-4e34-4dc3-bb72-577f556a220e:53 stopped due to: operation was interrupted
2020-05-08T21:57:39.047+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:39.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.547+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.547+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.811+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.811+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.812+0000 I  SHARDING [conn82] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:39.812+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 424), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb9e5fa8-00f2-4035-b9a0-dbbe410f70aa") }, txnNumber: 45, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4436ms
2020-05-08T21:57:40.054+0000 I  NETWORK  [conn82] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.054+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.055+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 58, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975055, 411) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:4685137, timeActiveMicros:4686676, timeInactiveMicros:2438, 4689ms
2020-05-08T21:57:40.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.152+0000 I  NETWORK  [conn85] end connection 172.31.0.221:50078 (42 connections now open)
2020-05-08T21:57:40.152+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50316 #96 (43 connections now open)
2020-05-08T21:57:40.152+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50318 #97 (44 connections now open)
2020-05-08T21:57:40.152+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:50316 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.153+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:50318 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.154+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.349+0000 I  NETWORK  [conn81] end connection 172.31.0.221:50034 (43 connections now open)
2020-05-08T21:57:40.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50378 #98 (44 connections now open)
2020-05-08T21:57:40.350+0000 I  NETWORK  [conn98] received client metadata from 172.31.0.221:50378 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.351+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50380 #99 (45 connections now open)
2020-05-08T21:57:40.351+0000 I  NETWORK  [conn99] received client metadata from 172.31.0.221:50380 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.371+0000 I  NETWORK  [conn84] end connection 172.31.0.221:50076 (44 connections now open)
2020-05-08T21:57:40.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50410 #100 (45 connections now open)
2020-05-08T21:57:40.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50412 #101 (46 connections now open)
2020-05-08T21:57:40.375+0000 I  NETWORK  [conn100] received client metadata from 172.31.0.221:50410 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.375+0000 I  NETWORK  [conn101] received client metadata from 172.31.0.221:50412 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.377+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.379+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 417), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e86db344-d42a-4bbb-9c87-40d4bcad7b8d") }, txnNumber: 58, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5009ms
2020-05-08T21:57:40.379+0000 I  NETWORK  [conn83] end connection 172.31.0.221:50074 (45 connections now open)
2020-05-08T21:57:40.385+0000 I  CONNPOOL [conn86] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T21:57:40.385+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.386+0000 I  COMMAND  [conn86] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 422), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3fc3afe3-4e34-4dc3-bb72-577f556a220e") }, txnNumber: 53, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:57:40.386+0000 I  NETWORK  [conn86] end connection 172.31.0.221:50080 (44 connections now open)
2020-05-08T21:57:40.811+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.320+0000 I  NETWORK  [conn98] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.321+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.567+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50432 #103 (45 connections now open)
2020-05-08T21:57:41.567+0000 I  NETWORK  [conn103] received client metadata from 172.31.0.221:50432 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:41.812+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.812+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.812+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:41.813+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb9e5fa8-00f2-4035-b9a0-dbbe410f70aa") }, txnNumber: 45, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1999ms
2020-05-08T21:57:41.813+0000 I  NETWORK  [conn82] end connection 172.31.0.221:50036 (44 connections now open)
2020-05-08T21:57:41.820+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.820+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:42.062+0000 I  COMMAND  [conn100] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("01bec94a-6e06-44b9-bcbe-b6ddc7396ff4") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1685ms
2020-05-08T21:57:42.064+0000 I  TXN      [conn96] transaction parameters:{ lsid: { id: UUID("0be4bb80-bca6-41bb-971d-83a7d52541a7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1910409, timeInactiveMicros:0, 1910ms
2020-05-08T21:57:42.064+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0be4bb80-bca6-41bb-971d-83a7d52541a7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1910ms
2020-05-08T21:57:42.076+0000 I  TXN      [conn100] transaction parameters:{ lsid: { id: UUID("01bec94a-6e06-44b9-bcbe-b6ddc7396ff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:10865, timeActiveMicros:1698667, timeInactiveMicros:800, 1699ms
2020-05-08T21:57:42.825+0000 I  NETWORK  [Sharding-Fixed-4] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:42.826+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.826+0000 I  NETWORK  [Sharding-Fixed-5] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:42.826+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.888+0000 I  NETWORK  [Sharding-Fixed-4] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:42.889+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.028+0000 I  NETWORK  [conn98] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:43.028+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.032+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.144+0000 I  NETWORK  [Sharding-Fixed-5] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:43.145+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.325+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.528+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.528+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.529+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.529+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.529+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.170+0000 I  NETWORK  [conn96] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:44.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.211+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.670+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.153+0000 I  NETWORK  [conn97] end connection 172.31.0.221:50318 (43 connections now open)
2020-05-08T21:57:45.154+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50498 #110 (44 connections now open)
2020-05-08T21:57:45.155+0000 I  NETWORK  [conn110] received client metadata from 172.31.0.221:50498 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.155+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50500 #111 (45 connections now open)
2020-05-08T21:57:45.155+0000 I  NETWORK  [conn111] received client metadata from 172.31.0.221:50500 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.255+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50520 #112 (46 connections now open)
2020-05-08T21:57:45.255+0000 I  NETWORK  [conn112] received client metadata from 172.31.0.221:50520 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.351+0000 I  NETWORK  [conn99] end connection 172.31.0.221:50380 (45 connections now open)
2020-05-08T21:57:45.351+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50570 #113 (46 connections now open)
2020-05-08T21:57:45.351+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50572 #114 (47 connections now open)
2020-05-08T21:57:45.352+0000 I  NETWORK  [conn114] received client metadata from 172.31.0.221:50572 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.352+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:50570 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.670+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.670+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.711+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.793+0000 I  NETWORK  [conn100] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.793+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:45.802+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.293+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.793+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.085+0000 I  -        [conn96] operation was interrupted because a client disconnected
2020-05-08T21:57:47.085+0000 I  CONNPOOL [conn96] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:57:47.085+0000 I  TXN      [conn96] transaction parameters:{ lsid: { id: UUID("0be4bb80-bca6-41bb-971d-83a7d52541a7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975062, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975062, 13) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5007308, timeInactiveMicros:903, 5008ms
2020-05-08T21:57:47.086+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 132 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0be4bb80-bca6-41bb-971d-83a7d52541a7") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:57:47.086+0000 I  NETWORK  [conn96] end connection 172.31.0.221:50316 (46 connections now open)
2020-05-08T21:57:47.086+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.104+0000 I  NETWORK  [conn101] end connection 172.31.0.221:50412 (45 connections now open)
2020-05-08T21:57:47.105+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50642 #115 (46 connections now open)
2020-05-08T21:57:47.105+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50644 #116 (47 connections now open)
2020-05-08T21:57:47.105+0000 I  NETWORK  [conn115] received client metadata from 172.31.0.221:50642 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.105+0000 I  NETWORK  [conn116] received client metadata from 172.31.0.221:50644 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.107+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.293+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.368+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.711+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.793+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.211+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.293+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.293+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.294+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.294+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.294+0000 I  COMMAND  [conn111] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975064, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4d3f4007-fc78-4480-aafc-ce153625df4a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 3136ms
2020-05-08T21:57:48.295+0000 I  COMMAND  [conn114] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997555b9-a275-400c-b156-a1801c7ea0f2") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2939ms
2020-05-08T21:57:48.295+0000 I  TXN      [conn100] transaction parameters:{ lsid: { id: UUID("01bec94a-6e06-44b9-bcbe-b6ddc7396ff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975062, 30) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6190657, timeInactiveMicros:0, 6190ms
2020-05-08T21:57:48.295+0000 I  COMMAND  [conn100] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("01bec94a-6e06-44b9-bcbe-b6ddc7396ff4") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 6190ms
2020-05-08T21:57:48.295+0000 I  NETWORK  [conn100] end connection 172.31.0.221:50410 (46 connections now open)
2020-05-08T21:57:48.296+0000 I  TXN      [conn115] transaction parameters:{ lsid: { id: UUID("96cb8f2f-7546-4b1b-a51c-508309f4c501"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 14) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1190421, timeInactiveMicros:0, 1190ms
2020-05-08T21:57:48.296+0000 I  COMMAND  [conn115] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("96cb8f2f-7546-4b1b-a51c-508309f4c501") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 96cb8f2f-7546-4b1b-a51c-508309f4c501:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975065, 14) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:593 protocol:op_msg 1190ms
2020-05-08T21:57:48.711+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.711+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:49.343+0000 I  NETWORK  [conn111] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:49.343+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.344+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.352+0000 I  COMMAND  [conn98] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3c7840d8-e3ab-4c7f-98b3-49b61cc8e69b") } } nShards:1 nMatched:0 nModified:0 numYields:0 reslen:316 protocol:op_msg 9000ms
2020-05-08T21:57:49.352+0000 I  NETWORK  [conn98] end connection 172.31.0.221:50378 (45 connections now open)
2020-05-08T21:57:49.843+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.320+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.343+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.843+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.343+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.691+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50732 #118 (46 connections now open)
2020-05-08T21:57:51.691+0000 I  NETWORK  [conn118] received client metadata from 172.31.0.221:50732 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.844+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.844+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.845+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.845+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.850+0000 I  TXN      [conn114] transaction parameters:{ lsid: { id: UUID("997555b9-a275-400c-b156-a1801c7ea0f2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 29) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3534949, timeInactiveMicros:0, 3534ms
2020-05-08T21:57:51.850+0000 I  COMMAND  [conn114] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 148 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997555b9-a275-400c-b156-a1801c7ea0f2") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 997555b9-a275-400c-b156-a1801c7ea0f2:3 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975068, 29) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 3535ms
2020-05-08T21:57:51.855+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 4, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4d3f4007-fc78-4480-aafc-ce153625df4a") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3522ms
2020-05-08T21:57:52.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.202+0000 I  SHARDING [conn114] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.345+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.345+0000 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.718+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50766 #120 (47 connections now open)
2020-05-08T21:57:52.719+0000 I  NETWORK  [conn120] received client metadata from 172.31.0.221:50766 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.902+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50784 #121 (48 connections now open)
2020-05-08T21:57:52.902+0000 I  NETWORK  [conn121] received client metadata from 172.31.0.221:50784 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.336+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50852 #122 (49 connections now open)
2020-05-08T21:57:54.336+0000 I  NETWORK  [conn122] received client metadata from 172.31.0.221:50852 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.399+0000 I  NETWORK  [conn115] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:54.399+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:54.899+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.899+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.900+0000 I  NETWORK  [Sharding-Fixed-6] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:54.900+0000 I  COMMAND  [conn114] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 569), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997555b9-a275-400c-b156-a1801c7ea0f2") }, txnNumber: 72, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1512ms
2020-05-08T21:57:54.900+0000 I  COMMAND  [conn115] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 574), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("96cb8f2f-7546-4b1b-a51c-508309f4c501") }, txnNumber: 547, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1507ms
2020-05-08T21:57:54.900+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.900+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.908+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:55.508+0000 I  NETWORK  [conn115] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:55.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:55.508+0000 I  NETWORK  [conn114] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:55.509+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:55.797+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50950 #123 (50 connections now open)
2020-05-08T21:57:55.798+0000 I  NETWORK  [conn123] received client metadata from 172.31.0.221:50950 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.164+0000 I  NETWORK  [conn111] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 4d3f4007-fc78-4480-aafc-ce153625df4a:76 stopped due to: operation was interrupted
2020-05-08T21:57:56.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.664+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.791+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50998 #124 (51 connections now open)
2020-05-08T21:57:56.791+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:50998 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.966+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51004 #125 (52 connections now open)
2020-05-08T21:57:56.966+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:51004 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.164+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:57.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.627+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51056 #126 (53 connections now open)
2020-05-08T21:57:57.628+0000 I  NETWORK  [conn126] received client metadata from 172.31.0.221:51056 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.664+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.664+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:58.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.305+0000 I  NETWORK  [conn110] end connection 172.31.0.221:50498 (52 connections now open)
2020-05-08T21:57:58.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51070 #127 (53 connections now open)
2020-05-08T21:57:58.306+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:51070 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51072 #128 (54 connections now open)
2020-05-08T21:57:58.306+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:51072 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.317+0000 I  NETWORK  [conn116] end connection 172.31.0.221:50644 (53 connections now open)
2020-05-08T21:57:58.317+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51076 #129 (54 connections now open)
2020-05-08T21:57:58.317+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51078 #130 (55 connections now open)
2020-05-08T21:57:58.317+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:51076 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.318+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:51078 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.320+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.385+0000 I  NETWORK  [conn113] end connection 172.31.0.221:50570 (54 connections now open)
2020-05-08T21:57:58.386+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51142 #131 (55 connections now open)
2020-05-08T21:57:58.387+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:51142 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.388+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51148 #132 (56 connections now open)
2020-05-08T21:57:58.389+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:51148 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.404+0000 I  CONNPOOL [conn111] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T21:57:58.404+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:58.404+0000 I  COMMAND  [conn111] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 575), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4d3f4007-fc78-4480-aafc-ce153625df4a") }, txnNumber: 76, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5009ms
2020-05-08T21:57:58.405+0000 I  NETWORK  [conn111] end connection 172.31.0.221:50500 (55 connections now open)
2020-05-08T21:57:58.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.604+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51172 #134 (56 connections now open)
2020-05-08T21:57:58.604+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:51172 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.508+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.508+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.509+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.509+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:59.509+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:59.509+0000 I  COMMAND  [conn114] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 349), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997555b9-a275-400c-b156-a1801c7ea0f2") }, txnNumber: 72, autocommit: false } numYields:0 reslen:515 protocol:op_msg 4608ms
2020-05-08T21:57:59.509+0000 I  COMMAND  [conn115] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 349), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("96cb8f2f-7546-4b1b-a51c-508309f4c501") }, txnNumber: 547, autocommit: false } numYields:0 reslen:517 protocol:op_msg 4608ms
2020-05-08T21:57:59.509+0000 I  NETWORK  [conn114] end connection 172.31.0.221:50572 (55 connections now open)
2020-05-08T21:57:59.510+0000 I  NETWORK  [conn115] end connection 172.31.0.221:50642 (54 connections now open)
2020-05-08T21:57:59.778+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51190 #136 (55 connections now open)
2020-05-08T21:57:59.778+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:51190 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.009+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.009+0000 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.010+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.403+0000 I  COMMAND  [conn131] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975079, 592), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2") }, txnNumber: 141, autocommit: false } numYields:0 reslen:353 protocol:op_msg 412ms
2020-05-08T21:58:00.889+0000 I  NETWORK  [conn127] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:00.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:00.891+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.234+0000 I  COMMAND  [conn131] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975080, 109), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2") }, txnNumber: 160, autocommit: false } numYields:0 reslen:353 protocol:op_msg 631ms
2020-05-08T21:58:01.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.891+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.891+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.891+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:01.899+0000 I  NETWORK  [conn129] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.900+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.902+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.134+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:03.307+0000 I  NETWORK  [conn128] end connection 172.31.0.221:51072 (54 connections now open)
2020-05-08T21:58:03.307+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51326 #137 (55 connections now open)
2020-05-08T21:58:03.307+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51328 #138 (56 connections now open)
2020-05-08T21:58:03.307+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:51326 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.308+0000 I  NETWORK  [conn138] received client metadata from 172.31.0.221:51328 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.309+0000 I  NETWORK  [conn137] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:03.309+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.310+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.310+0000 I  -        [conn127] operation was interrupted because a client disconnected
2020-05-08T21:58:03.311+0000 I  TXN      [conn127] transaction parameters:{ lsid: { id: UUID("b641168e-ec5b-47b9-8160-fb549baf7d50"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975075, 101) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003459, timeInactiveMicros:0, 5003ms
2020-05-08T21:58:03.311+0000 I  COMMAND  [conn127] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 264 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975075, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b641168e-ec5b-47b9-8160-fb549baf7d50") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:03.311+0000 I  NETWORK  [conn127] end connection 172.31.0.221:51070 (55 connections now open)
2020-05-08T21:58:03.311+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.318+0000 I  NETWORK  [conn130] end connection 172.31.0.221:51078 (54 connections now open)
2020-05-08T21:58:03.318+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51334 #139 (55 connections now open)
2020-05-08T21:58:03.318+0000 I  NETWORK  [conn139] received client metadata from 172.31.0.221:51334 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.319+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51336 #140 (56 connections now open)
2020-05-08T21:58:03.319+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:51336 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.321+0000 I  -        [conn129] operation was interrupted because a client disconnected
2020-05-08T21:58:03.322+0000 I  TXN      [conn129] transaction parameters:{ lsid: { id: UUID("72ec9f8a-3261-449c-965d-3368e854d6a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975075, 101) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002319, timeInactiveMicros:0, 5002ms
2020-05-08T21:58:03.322+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.322+0000 I  COMMAND  [conn129] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 270 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975075, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("72ec9f8a-3261-449c-965d-3368e854d6a0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:58:03.322+0000 I  NETWORK  [conn129] end connection 172.31.0.221:51076 (55 connections now open)
2020-05-08T21:58:03.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.503+0000 I  COMMAND  [conn139] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975082, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5112f8a3-f9a5-4f73-8b63-c6509735c305") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 183ms
2020-05-08T21:58:03.505+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.506+0000 I  COMMAND  [conn137] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 275 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e294b74-b4bd-4365-b374-f01430c5dd00") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 197ms
2020-05-08T21:58:03.518+0000 I  TXN      [conn137] transaction parameters:{ lsid: { id: UUID("0e294b74-b4bd-4365-b374-f01430c5dd00"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 127) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:11054, timeActiveMicros:209521, timeInactiveMicros:588, 210ms
2020-05-08T21:58:03.571+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.120+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.890+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.890+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.891+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 164, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 26) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3619693, timeInactiveMicros:0, 3619ms
2020-05-08T21:58:04.891+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2") }, txnNumber: 164, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 3619ms
2020-05-08T21:58:05.942+0000 I  COMMAND  [conn137] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e294b74-b4bd-4365-b374-f01430c5dd00") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 2371ms
2020-05-08T21:58:05.944+0000 I  NETWORK  [conn137] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.945+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.945+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.945+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.946+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.946+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.948+0000 I  TXN      [conn139] transaction parameters:{ lsid: { id: UUID("5112f8a3-f9a5-4f73-8b63-c6509735c305"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 4) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2443893, timeInactiveMicros:0, 2443ms
2020-05-08T21:58:05.948+0000 I  COMMAND  [conn139] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5112f8a3-f9a5-4f73-8b63-c6509735c305") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2444ms
2020-05-08T21:58:05.949+0000 I  TXN      [conn137] transaction parameters:{ lsid: { id: UUID("0e294b74-b4bd-4365-b374-f01430c5dd00"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 49) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2378048, timeInactiveMicros:927, 2378ms
2020-05-08T21:58:05.952+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 165, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975084, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975084, 6) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1051933, timeInactiveMicros:0, 1051ms
2020-05-08T21:58:05.952+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975084, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2") }, txnNumber: 165, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975084, 6) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1052ms
2020-05-08T21:58:06.272+0000 I  NETWORK  [conn132] end connection 172.31.0.221:51148 (54 connections now open)
2020-05-08T21:58:06.274+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51438 #141 (55 connections now open)
2020-05-08T21:58:06.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51440 #142 (56 connections now open)
2020-05-08T21:58:06.275+0000 I  NETWORK  [conn141] received client metadata from 172.31.0.221:51438 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:06.275+0000 I  NETWORK  [conn142] received client metadata from 172.31.0.221:51440 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:06.553+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.556+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:06.969+0000 I  NETWORK  [conn137] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:06.970+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:06.971+0000 I  NETWORK  [conn131] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:06.972+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.054+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.469+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.554+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.554+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.970+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.970+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.971+0000 I  COMMAND  [conn137] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e294b74-b4bd-4365-b374-f01430c5dd00") }, txnNumber: 8, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1990ms
2020-05-08T21:58:07.971+0000 I  COMMAND  [conn139] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5112f8a3-f9a5-4f73-8b63-c6509735c305") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1990ms
2020-05-08T21:58:07.971+0000 I  COMMAND  [conn131] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 46), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2a81290-3f72-4603-8d76-bf6c20e58ad2") }, txnNumber: 166, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1990ms
2020-05-08T21:58:07.971+0000 I  NETWORK  [conn131] end connection 172.31.0.221:51142 (55 connections now open)
2020-05-08T21:58:08.505+0000 I  NETWORK  [conn140] end connection 172.31.0.221:51336 (54 connections now open)
2020-05-08T21:58:08.505+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51520 #143 (55 connections now open)
2020-05-08T21:58:08.505+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51522 #144 (56 connections now open)
2020-05-08T21:58:08.505+0000 I  NETWORK  [conn143] received client metadata from 172.31.0.221:51520 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.505+0000 I  NETWORK  [conn144] received client metadata from 172.31.0.221:51522 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.562+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.572+0000 I  NETWORK  [conn138] end connection 172.31.0.221:51328 (55 connections now open)
2020-05-08T21:58:08.573+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51544 #145 (56 connections now open)
2020-05-08T21:58:08.573+0000 I  NETWORK  [conn145] received client metadata from 172.31.0.221:51544 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.573+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51546 #146 (57 connections now open)
2020-05-08T21:58:08.574+0000 I  NETWORK  [conn146] received client metadata from 172.31.0.221:51546 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.575+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:08.939+0000 I  NETWORK  [conn141] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:08.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.059+0000 I  COMMAND  [conn137] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 231), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e294b74-b4bd-4365-b374-f01430c5dd00") }, txnNumber: 8, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1087ms
2020-05-08T21:58:09.060+0000 I  NETWORK  [conn137] end connection 172.31.0.221:51326 (56 connections now open)
2020-05-08T21:58:09.061+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.062+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975088, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 487ms
2020-05-08T21:58:09.063+0000 I  COMMAND  [conn139] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 231), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5112f8a3-f9a5-4f73-8b63-c6509735c305") }, txnNumber: 3, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1091ms
2020-05-08T21:58:09.063+0000 I  NETWORK  [conn139] end connection 172.31.0.221:51334 (55 connections now open)
2020-05-08T21:58:09.072+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975088, 5) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:5238, timeActiveMicros:496885, timeInactiveMicros:856, 497ms
2020-05-08T21:58:09.075+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.939+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.940+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.941+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.941+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.941+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 215), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7d43ded0-84cd-4a1b-93e5-b77886ad71de") }, txnNumber: 106, autocommit: false } numYields:0 reslen:471 protocol:op_msg 2539ms
2020-05-08T21:58:09.941+0000 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 1429ms
2020-05-08T21:58:09.944+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 291 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 869ms
2020-05-08T21:58:10.052+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51590 #148 (56 connections now open)
2020-05-08T21:58:10.053+0000 I  NETWORK  [conn148] received client metadata from 172.31.0.221:51590 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:10.177+0000 I  NETWORK  [conn145] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:10.177+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.178+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.580+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.582+0000 I  NETWORK  [conn143] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:10.582+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:10.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:11.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.273+0000 I  NETWORK  [conn142] end connection 172.31.0.221:51440 (55 connections now open)
2020-05-08T21:58:11.274+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51656 #150 (56 connections now open)
2020-05-08T21:58:11.274+0000 I  NETWORK  [conn150] received client metadata from 172.31.0.221:51656 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:11.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51662 #151 (57 connections now open)
2020-05-08T21:58:11.276+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:51662 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:11.278+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.439+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.440+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.441+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.441+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.441+0000 I  SHARDING [conn145] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 3), t: 19 }
2020-05-08T21:58:11.442+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975089, 9) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2367492, timeInactiveMicros:844, 2368ms
2020-05-08T21:58:11.442+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 212), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 1496ms
2020-05-08T21:58:11.442+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7d43ded0-84cd-4a1b-93e5-b77886ad71de") }, txnNumber: 106, autocommit: false } numYields:0 reslen:547 protocol:op_msg 1500ms
2020-05-08T21:58:11.443+0000 I  NETWORK  [conn141] end connection 172.31.0.221:51438 (56 connections now open)
2020-05-08T21:58:11.443+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.443+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.444+0000 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 1501ms
2020-05-08T21:58:12.286+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51670 #152 (57 connections now open)
2020-05-08T21:58:12.286+0000 I  NETWORK  [conn152] received client metadata from 172.31.0.221:51670 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.363+0000 I  COMMAND  [conn150] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 292 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975090, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d55f5069-06dd-4b03-89a0-b6b88b7a2b1f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1085ms
2020-05-08T21:58:12.366+0000 I  COMMAND  [conn145] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 923ms
2020-05-08T21:58:12.378+0000 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("d55f5069-06dd-4b03-89a0-b6b88b7a2b1f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975090, 1) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:9038, timeActiveMicros:1099204, timeInactiveMicros:1456, 1100ms
2020-05-08T21:58:12.421+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.534+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.731+0000 I  NETWORK  [conn143] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:13.732+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.232+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.232+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.753+0000 I  NETWORK  [conn143] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:14.753+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.767+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.941+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 7053 timed out, deadline was 2020-05-08T21:58:14.941+0000, op was RemoteCommand 7053 -- target:[ec2-3-80-27-189.compute-1.amazonaws.com:27019] db:admin expDate:2020-05-08T21:58:14.941+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:14.941+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:14.941+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:15.170+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51728 #158 (58 connections now open)
2020-05-08T21:58:15.170+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:51728 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.253+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.753+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.753+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.427+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:58:16.649+0000 I  NETWORK  [conn145] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:16.649+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:16.764+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 168, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 467) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 467) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:3384228, timeActiveMicros:3390111, timeInactiveMicros:2273, 3392ms
2020-05-08T21:58:16.764+0000 I  COMMAND  [conn143] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 480), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b") }, txnNumber: 168, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3384ms
2020-05-08T21:58:16.764+0000 I  COMMAND  [conn150] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 243, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975094, 293), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d55f5069-06dd-4b03-89a0-b6b88b7a2b1f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 1998ms
2020-05-08T21:58:16.769+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.769+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.770+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.772+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 56, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 520) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 520) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:3361363, timeInactiveMicros:319, 3361ms
2020-05-08T21:58:16.772+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 363 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 520), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f") }, txnNumber: 56, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 56 does not match any in-progress transactions. The active transaction number is 51" errName:NoSuchTransaction errCode:251 reslen:438 protocol:op_msg 3359ms
2020-05-08T21:58:16.834+0000 I  NETWORK  [conn143] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:16.835+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.835+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.976+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.976+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:17.333+0000 I  COMMAND  [conn143] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 170, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 184), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 559ms
2020-05-08T21:58:17.367+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.484+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.662+0000 I  NETWORK  [conn143] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.663+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.669+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.163+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.367+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.367+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.378+0000 I  NETWORK  [conn146] end connection 172.31.0.221:51546 (57 connections now open)
2020-05-08T21:58:18.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51846 #159 (58 connections now open)
2020-05-08T21:58:18.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51848 #160 (59 connections now open)
2020-05-08T21:58:18.379+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:51848 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.380+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:51846 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.381+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.663+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.163+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.356+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.356+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.663+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.663+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.664+0000 I  SHARDING [conn159] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.664+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1a4cadc4-65e0-488a-a5ff-b1abbba04948") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1283ms
2020-05-08T21:58:19.664+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 171, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2329038, timeInactiveMicros:0, 2329ms
2020-05-08T21:58:19.664+0000 I  COMMAND  [conn143] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b") }, txnNumber: 171, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2329ms
2020-05-08T21:58:19.666+0000 I  NETWORK  [conn159] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:19.666+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.666+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.669+0000 I  COMMAND  [conn145] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 179), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44fa393d-3abf-4f0c-9c37-3b6d39636a5f") }, txnNumber: 56, autocommit: false } numYields:0 reslen:546 protocol:op_msg 2896ms
2020-05-08T21:58:19.669+0000 I  NETWORK  [conn145] end connection 172.31.0.221:51544 (58 connections now open)
2020-05-08T21:58:19.857+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.857+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.447+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.184+0000 I  TXN      [conn150] transaction parameters:{ lsid: { id: UUID("d55f5069-06dd-4b03-89a0-b6b88b7a2b1f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 244, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 174) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:4412798, timeActiveMicros:4417836, timeInactiveMicros:691, 4418ms
2020-05-08T21:58:21.188+0000 I  NETWORK  [conn159] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:21.188+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.191+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.688+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.769+0000 I  NETWORK  [conn151] end connection 172.31.0.221:51662 (57 connections now open)
2020-05-08T21:58:21.771+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51928 #161 (58 connections now open)
2020-05-08T21:58:21.772+0000 I  NETWORK  [conn161] received client metadata from 172.31.0.221:51928 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.772+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51932 #162 (59 connections now open)
2020-05-08T21:58:21.773+0000 I  NETWORK  [conn162] received client metadata from 172.31.0.221:51932 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.778+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.781+0000 I  COMMAND  [conn150] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 179), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d55f5069-06dd-4b03-89a0-b6b88b7a2b1f") }, txnNumber: 244, autocommit: false } numYields:0 reslen:466 protocol:op_msg 5010ms
2020-05-08T21:58:21.782+0000 I  NETWORK  [conn150] end connection 172.31.0.221:51656 (58 connections now open)
2020-05-08T21:58:22.188+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.336+0000 I  NETWORK  [conn144] end connection 172.31.0.221:51522 (57 connections now open)
2020-05-08T21:58:22.336+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51940 #163 (58 connections now open)
2020-05-08T21:58:22.337+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51942 #164 (59 connections now open)
2020-05-08T21:58:22.337+0000 I  NETWORK  [conn163] received client metadata from 172.31.0.221:51940 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.337+0000 I  NETWORK  [conn164] received client metadata from 172.31.0.221:51942 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.339+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.688+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.688+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.689+0000 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ec9d1d5-a10e-467e-9972-874650df1b8b") }, txnNumber: 171, autocommit: false } numYields:0 reslen:517 protocol:op_msg 3023ms
2020-05-08T21:58:22.689+0000 I  NETWORK  [conn143] end connection 172.31.0.221:51520 (58 connections now open)
2020-05-08T21:58:22.689+0000 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 375 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 912ms
2020-05-08T21:58:22.690+0000 I  NETWORK  [conn161] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:22.691+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.190+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.228+0000 I  NETWORK  [conn163] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.228+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.229+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.234+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("1a4cadc4-65e0-488a-a5ff-b1abbba04948"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975099, 9) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3562750, timeActiveMicros:3568226, timeInactiveMicros:710, 3568ms
2020-05-08T21:58:23.234+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.235+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.690+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.690+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.728+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.900+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.901+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.190+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.228+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.360+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:24.361+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.401+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.665+0000 I  NETWORK  [conn160] end connection 172.31.0.221:51848 (57 connections now open)
2020-05-08T21:58:24.666+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52046 #165 (58 connections now open)
2020-05-08T21:58:24.666+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52048 #166 (59 connections now open)
2020-05-08T21:58:24.666+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:52046 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:24.666+0000 I  NETWORK  [conn166] received client metadata from 172.31.0.221:52048 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:24.668+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.682+0000 I  COMMAND  [conn159] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1a4cadc4-65e0-488a-a5ff-b1abbba04948") }, txnNumber: 1, autocommit: false } numYields:0 reslen:494 protocol:op_msg 5010ms
2020-05-08T21:58:24.682+0000 I  NETWORK  [conn159] end connection 172.31.0.221:51846 (58 connections now open)
2020-05-08T21:58:24.728+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.901+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:24.901+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.070+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.070+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.167+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.167+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.168+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.228+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.260+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.261+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.401+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.667+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.728+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.901+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.901+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.152+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.167+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.167+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.168+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975103, 8) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1500994, timeInactiveMicros:0, 1500ms
2020-05-08T21:58:26.168+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975103, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1501ms
2020-05-08T21:58:26.229+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.229+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.230+0000 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 134) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:4452740, timeInactiveMicros:896, 4453ms
2020-05-08T21:58:26.230+0000 I  COMMAND  [conn161] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 3540ms
2020-05-08T21:58:26.377+0000 I  COMMAND  [conn165] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 208ms
2020-05-08T21:58:26.477+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 246ms
2020-05-08T21:58:26.477+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 134) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4138714, timeInactiveMicros:0, 4138ms
2020-05-08T21:58:26.477+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 375 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 771a977a-721b-44f5-9b56-7d200725305b:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975101, 134) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 4138ms
2020-05-08T21:58:26.502+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:124507, timeInactiveMicros:0, 124ms
2020-05-08T21:58:26.502+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 124ms
2020-05-08T21:58:26.910+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.328+0000 I  NETWORK  [conn161] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:28.328+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.828+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.828+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.829+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 441), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 44, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1481ms
2020-05-08T21:58:28.864+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 47, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 438) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 438) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1515478, timeActiveMicros:1520696, timeInactiveMicros:1134, 1521ms
2020-05-08T21:58:28.864+0000 I  COMMAND  [conn163] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 445), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 47, autocommit: false } numYields:0 reslen:343 protocol:op_msg 1515ms
2020-05-08T21:58:29.737+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 236, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 652) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:208615, timeActiveMicros:214325, timeInactiveMicros:1059, 215ms
2020-05-08T21:58:29.737+0000 I  COMMAND  [conn165] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 658), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 236, autocommit: false } numYields:0 reslen:214 protocol:op_msg 208ms
2020-05-08T21:58:29.739+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 654), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 75, autocommit: false } numYields:0 reslen:352 protocol:op_msg 211ms
2020-05-08T21:58:29.739+0000 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 658), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 88, autocommit: false } numYields:0 reslen:321 protocol:op_msg 211ms
2020-05-08T21:58:30.245+0000 I  NETWORK  [conn165] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.246+0000 I  NETWORK  [conn161] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.247+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.746+0000 I  COMMAND  [conn165] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 307), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 259, autocommit: false } numYields:0 reslen:353 protocol:op_msg 522ms
2020-05-08T21:58:30.750+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 316), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 101, autocommit: false } numYields:0 reslen:471 protocol:op_msg 520ms
2020-05-08T21:58:31.254+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 471), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 101, autocommit: false } numYields:0 reslen:353 protocol:op_msg 503ms
2020-05-08T21:58:31.260+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 468), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 171, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 509ms
2020-05-08T21:58:31.262+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 260, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 465) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 465) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:515372, timeInactiveMicros:330, 515ms
2020-05-08T21:58:31.262+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 465), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 260, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 514ms
2020-05-08T21:58:31.273+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 171, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 466) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 466) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:12534, timeActiveMicros:524168, timeInactiveMicros:1137, 525ms
2020-05-08T21:58:31.395+0000 I  NETWORK  [conn161] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.396+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.896+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.396+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.396+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.397+0000 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 164), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 176, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1017ms
2020-05-08T21:58:33.388+0000 I  SHARDING [conn163] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.391+0000 I  COMMAND  [conn161] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 504 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 169), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 106, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 169) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 2008ms
2020-05-08T21:58:33.391+0000 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 176, autocommit: false } numYields:0 reslen:399 protocol:op_msg 522ms
2020-05-08T21:58:33.400+0000 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 106, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 169) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 169) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2016874, timeInactiveMicros:988, 2017ms
2020-05-08T21:58:33.916+0000 I  NETWORK  [conn165] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:33.916+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:34.416+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.416+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.743+0000 I  NETWORK  [conn161] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:34.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.209+0000 I  NETWORK  [conn166] end connection 172.31.0.221:52048 (57 connections now open)
2020-05-08T21:58:35.209+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52192 #168 (58 connections now open)
2020-05-08T21:58:35.209+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52194 #169 (59 connections now open)
2020-05-08T21:58:35.209+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:52192 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.209+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:52194 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.211+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.243+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.272+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:35.273+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.273+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.743+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.816+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.179+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:36.179+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.243+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.355+0000 I  NETWORK  [conn162] end connection 172.31.0.221:51932 (58 connections now open)
2020-05-08T21:58:36.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52260 #170 (59 connections now open)
2020-05-08T21:58:36.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52262 #171 (60 connections now open)
2020-05-08T21:58:36.360+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:52260 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.360+0000 I  NETWORK  [conn171] received client metadata from 172.31.0.221:52262 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.361+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.367+0000 I  COMMAND  [conn165] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 142), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("16537f50-f385-4a37-a95c-c2482f8e96e0") }, txnNumber: 264, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:58:36.367+0000 I  NETWORK  [conn165] end connection 172.31.0.221:52046 (59 connections now open)
2020-05-08T21:58:36.374+0000 I  NETWORK  [conn164] end connection 172.31.0.221:51942 (58 connections now open)
2020-05-08T21:58:36.374+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52276 #172 (59 connections now open)
2020-05-08T21:58:36.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52278 #173 (60 connections now open)
2020-05-08T21:58:36.375+0000 I  NETWORK  [conn172] received client metadata from 172.31.0.221:52276 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.375+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:52278 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.376+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.679+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.743+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.744+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.744+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.744+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.745+0000 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("771a977a-721b-44f5-9b56-7d200725305b") }, txnNumber: 177, autocommit: false } numYields:0 reslen:440 protocol:op_msg 3347ms
2020-05-08T21:58:36.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.745+0000 I  NETWORK  [conn163] end connection 172.31.0.221:51940 (59 connections now open)
2020-05-08T21:58:36.750+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff36ccef-a839-4dd0-baef-f9c413f8425f") }, txnNumber: 106, autocommit: false } numYields:0 reslen:471 protocol:op_msg 3349ms
2020-05-08T21:58:36.750+0000 I  NETWORK  [conn161] end connection 172.31.0.221:51928 (58 connections now open)
2020-05-08T21:58:36.754+0000 I  TXN      [conn171] transaction parameters:{ lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:393443, timeInactiveMicros:0, 393ms
2020-05-08T21:58:36.754+0000 I  COMMAND  [conn171] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 393ms
2020-05-08T21:58:36.759+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 383ms
2020-05-08T21:58:36.760+0000 I  COMMAND  [conn168] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1549ms
2020-05-08T21:58:36.781+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.872+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.179+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.179+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.180+0000 I  COMMAND  [conn171] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 508 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 7, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 308ms
2020-05-08T21:58:37.202+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.204+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.571+0000 I  NETWORK  [conn172] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.571+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.572+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.679+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.855+0000 I  NETWORK  [conn168] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T21:58:37.856+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:38.179+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.245+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.245+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.356+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.356+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.363+0000 I  COMMAND  [conn168] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 5, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 84), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1546ms
2020-05-08T21:58:38.368+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.368+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.370+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 46) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1591861, timeInactiveMicros:317, 1592ms
2020-05-08T21:58:38.370+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 46), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 3, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 1589ms
2020-05-08T21:58:38.514+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.515+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.518+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.518+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.519+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.519+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.856+0000 I  TXN      [conn171] transaction parameters:{ lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 133) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1675746, timeActiveMicros:1987039, timeInactiveMicros:863, 1987ms
2020-05-08T21:58:38.857+0000 I  COMMAND  [conn171] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 7, autocommit: false } numYields:0 reslen:427 protocol:op_msg 1676ms
2020-05-08T21:58:38.857+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 3, autocommit: false } numYields:0 reslen:426 protocol:op_msg 487ms
2020-05-08T21:58:38.867+0000 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 10) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:497412, timeActiveMicros:501104, timeInactiveMicros:575, 501ms
2020-05-08T21:58:38.867+0000 I  COMMAND  [conn168] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") }, txnNumber: 6, autocommit: false } numYields:0 reslen:214 protocol:op_msg 497ms
2020-05-08T21:58:39.245+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.245+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.357+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:40.541+0000 I  NETWORK  [conn171] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.542+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.541+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.541+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.542+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1019), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 37, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1835ms
2020-05-08T21:58:41.542+0000 I  COMMAND  [conn171] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1009), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 47, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1845ms
2020-05-08T21:58:41.543+0000 I  COMMAND  [conn168] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1017), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") }, txnNumber: 45, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1842ms
2020-05-08T21:58:42.051+0000 I  NETWORK  [conn172] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:42.051+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.051+0000 I  NETWORK  [conn172] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:42.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.551+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.552+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.825+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-107-21-173-199.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:43.051+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.051+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.552+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:44.052+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.052+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.053+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975121, 6) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2509853, timeInactiveMicros:269, 2510ms
2020-05-08T21:58:44.053+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975121, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 38, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 2508ms
2020-05-08T21:58:44.056+0000 I  COMMAND  [conn168] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 565 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975121, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") }, txnNumber: 46, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 7) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 2512ms
2020-05-08T21:58:44.057+0000 I  COMMAND  [conn171] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 584 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975121, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 48, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 6) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 2514ms
2020-05-08T21:58:44.063+0000 I  TXN      [conn171] transaction parameters:{ lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 48, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975121, 6) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2519698, timeInactiveMicros:740, 2520ms
2020-05-08T21:58:44.179+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 38, autocommit: false } numYields:0 reslen:428 protocol:op_msg 125ms
2020-05-08T21:58:44.179+0000 I  COMMAND  [conn171] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 48, autocommit: false } numYields:0 reslen:321 protocol:op_msg 115ms
2020-05-08T21:58:44.186+0000 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 46, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 7) } }, globalReadTimestamp:{ ts: Timestamp(1588975121, 7) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:124134, timeActiveMicros:2641557, timeInactiveMicros:1378, 2642ms
2020-05-08T21:58:44.186+0000 I  COMMAND  [conn168] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") }, txnNumber: 46, autocommit: false } numYields:0 reslen:214 protocol:op_msg 124ms
2020-05-08T21:58:44.211+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:44.776+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.777+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.936+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.937+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.968+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.969+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.277+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.424+0000 I  NETWORK  [conn168] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:45.425+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.426+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.428+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.777+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.924+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.277+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.424+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.777+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.778+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.778+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.780+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 22), t: 33 }
2020-05-08T21:58:46.924+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.277+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.277+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.424+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.924+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.296+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:48.424+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.424+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.425+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 405), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 48, autocommit: false } numYields:0 reslen:321 protocol:op_msg 4005ms
2020-05-08T21:58:48.425+0000 I  COMMAND  [conn171] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 397), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 61, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4010ms
2020-05-08T21:58:48.426+0000 I  NETWORK  [conn172] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:48.427+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.427+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.436+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.467+0000 I  TXN      [conn168] transaction parameters:{ lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 59, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 397) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:4043713, timeActiveMicros:4051488, timeInactiveMicros:1366, 4052ms
2020-05-08T21:58:48.473+0000 I  NETWORK  [conn172] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.473+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.474+0000 I  NETWORK  [conn168] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:48.474+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.474+0000 I  NETWORK  [conn171] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:48.475+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.924+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:49.359+0000 I  NETWORK  [conn170] end connection 172.31.0.221:52260 (57 connections now open)
2020-05-08T21:58:49.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52498 #178 (58 connections now open)
2020-05-08T21:58:49.360+0000 I  NETWORK  [conn178] received client metadata from 172.31.0.221:52498 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.360+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52500 #179 (59 connections now open)
2020-05-08T21:58:49.360+0000 I  NETWORK  [conn179] received client metadata from 172.31.0.221:52500 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.361+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.361+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.362+0000 I  COMMAND  [conn171] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975128, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f191170-17af-4ecb-b973-62458c000307") }, txnNumber: 61, autocommit: false } numYields:0 reslen:515 protocol:op_msg 936ms
2020-05-08T21:58:49.363+0000 I  COMMAND  [conn168] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 408), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") }, txnNumber: 59, autocommit: false } numYields:0 reslen:495 protocol:op_msg 4939ms
2020-05-08T21:58:49.363+0000 I  NETWORK  [conn171] end connection 172.31.0.221:52262 (58 connections now open)
2020-05-08T21:58:49.377+0000 I  NETWORK  [conn173] end connection 172.31.0.221:52278 (57 connections now open)
2020-05-08T21:58:49.378+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52514 #180 (58 connections now open)
2020-05-08T21:58:49.378+0000 I  NETWORK  [conn180] received client metadata from 172.31.0.221:52514 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.378+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52516 #181 (59 connections now open)
2020-05-08T21:58:49.378+0000 I  NETWORK  [conn181] received client metadata from 172.31.0.221:52516 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.379+0000 I  NETWORK  [conn180] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.380+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.380+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.415+0000 I  NETWORK  [conn169] end connection 172.31.0.221:52194 (58 connections now open)
2020-05-08T21:58:49.416+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52552 #182 (59 connections now open)
2020-05-08T21:58:49.416+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52554 #183 (60 connections now open)
2020-05-08T21:58:49.416+0000 I  NETWORK  [conn182] received client metadata from 172.31.0.221:52552 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.416+0000 I  NETWORK  [conn183] received client metadata from 172.31.0.221:52554 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.572+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.573+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.596+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.597+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.073+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.088+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:50.089+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.152+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:50.153+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.448+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.573+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.656+0000 I  COMMAND  [conn180] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6bf4baff-e683-48d0-93e5-dafbd23a8a56") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 778ms
2020-05-08T21:58:50.657+0000 I  COMMAND  [conn182] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("54303d58-c26e-4c46-a815-01ecc9ce42ec") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1240ms
2020-05-08T21:58:50.659+0000 I  TXN      [conn182] transaction parameters:{ lsid: { id: UUID("54303d58-c26e-4c46-a815-01ecc9ce42ec"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 8) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1242008, timeInactiveMicros:434, 1242ms
2020-05-08T21:58:50.753+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 49, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 8) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2320994, timeActiveMicros:2326661, timeInactiveMicros:978, 2327ms
2020-05-08T21:58:50.764+0000 I  NETWORK  [conn178] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:50.764+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.770+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:51.073+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.264+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.264+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.265+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.265+0000 I  COMMAND  [conn172] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975128, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("df30f987-1a0c-40aa-a69b-405fa974a04b") }, txnNumber: 49, autocommit: false } numYields:0 reslen:495 protocol:op_msg 2832ms
2020-05-08T21:58:51.265+0000 I  COMMAND  [conn168] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("44c56d76-535e-41c6-bdcd-33fccec79a96") }, txnNumber: 59, autocommit: false } numYields:0 reslen:495 protocol:op_msg 1901ms
2020-05-08T21:58:51.265+0000 I  NETWORK  [conn172] end connection 172.31.0.221:52276 (59 connections now open)
2020-05-08T21:58:51.266+0000 I  COMMAND  [conn182] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975130, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("54303d58-c26e-4c46-a815-01ecc9ce42ec") }, txnNumber: 1, autocommit: false } numYields:0 reslen:351 protocol:op_msg 606ms
2020-05-08T21:58:51.266+0000 I  NETWORK  [conn168] end connection 172.31.0.221:52192 (58 connections now open)
2020-05-08T21:58:51.876+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f251cf7-e634-4f1b-bc55-fc278e8bec1d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2515ms
2020-05-08T21:58:51.886+0000 I  TXN      [conn182] transaction parameters:{ lsid: { id: UUID("54303d58-c26e-4c46-a815-01ecc9ce42ec"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 51) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 51) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:611827, timeInactiveMicros:0, 611ms
2020-05-08T21:58:51.886+0000 I  COMMAND  [conn182] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("54303d58-c26e-4c46-a815-01ecc9ce42ec") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 51) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 611ms
2020-05-08T21:58:51.889+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("4f251cf7-e634-4f1b-bc55-fc278e8bec1d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 22) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:11618, timeActiveMicros:2527394, timeInactiveMicros:1005, 2528ms
2020-05-08T21:58:51.897+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("6bf4baff-e683-48d0-93e5-dafbd23a8a56"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588975130, 1) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1234920, timeActiveMicros:1239250, timeInactiveMicros:1203, 1240ms
2020-05-08T21:58:51.898+0000 I  COMMAND  [conn180] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975130, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6bf4baff-e683-48d0-93e5-dafbd23a8a56") }, txnNumber: 2, autocommit: false } numYields:0 reslen:343 protocol:op_msg 1234ms
2020-05-08T21:58:52.104+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.104+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.105+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.120+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.123+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.125+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.573+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.866+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:53.014+0000 I  NETWORK  [conn178] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.014+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:53.073+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.073+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.073+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.296+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:53.514+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.514+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.515+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("4f251cf7-e634-4f1b-bc55-fc278e8bec1d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 96) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 97) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1608905, timeInactiveMicros:0, 1608ms
2020-05-08T21:58:53.515+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 96), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f251cf7-e634-4f1b-bc55-fc278e8bec1d") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 96) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 1609ms
2020-05-08T21:58:53.929+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.929+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.929+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.935+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.941+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.941+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.944+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:54.081+0000 I  NETWORK  [conn178] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:54.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:54.378+0000 I  NETWORK  [conn181] end connection 172.31.0.221:52516 (57 connections now open)
2020-05-08T21:58:54.378+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52748 #190 (58 connections now open)
2020-05-08T21:58:54.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52750 #191 (59 connections now open)
2020-05-08T21:58:54.379+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:52748 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.379+0000 I  NETWORK  [conn191] received client metadata from 172.31.0.221:52750 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.380+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:54.416+0000 I  NETWORK  [conn183] end connection 172.31.0.221:52554 (58 connections now open)
2020-05-08T21:58:54.416+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52764 #192 (59 connections now open)
2020-05-08T21:58:54.417+0000 I  NETWORK  [conn192] received client metadata from 172.31.0.221:52764 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.417+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52766 #193 (60 connections now open)
2020-05-08T21:58:54.417+0000 I  NETWORK  [conn193] received client metadata from 172.31.0.221:52766 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.418+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:54.434+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.434+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.435+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 4), t: 38 }
2020-05-08T21:58:54.582+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:55.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:55.582+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.582+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.583+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f251cf7-e634-4f1b-bc55-fc278e8bec1d") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2066ms
2020-05-08T21:58:56.890+0000 I  NETWORK  [conn179] end connection 172.31.0.221:52500 (59 connections now open)
2020-05-08T21:58:56.891+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52872 #194 (60 connections now open)
2020-05-08T21:58:56.891+0000 I  NETWORK  [conn194] received client metadata from 172.31.0.221:52872 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.892+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52874 #195 (61 connections now open)
2020-05-08T21:58:56.892+0000 I  NETWORK  [conn195] received client metadata from 172.31.0.221:52874 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.917+0000 I  CONNPOOL [conn182] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:58:56.917+0000 I  COMMAND  [conn182] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 97), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("54303d58-c26e-4c46-a815-01ecc9ce42ec") }, txnNumber: 4, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:58:56.917+0000 I  NETWORK  [conn182] end connection 172.31.0.221:52552 (60 connections now open)
2020-05-08T21:58:57.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.167+0000 I  NETWORK  [conn194] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:57.168+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.668+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:58.168+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:58.668+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:58.668+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:58.669+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:58.669+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f251cf7-e634-4f1b-bc55-fc278e8bec1d") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3085ms
2020-05-08T21:58:58.669+0000 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("5c13f40d-3c9b-4f55-9ff1-754d398fb871"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4251692, timeInactiveMicros:0, 4251ms
2020-05-08T21:58:58.669+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:58.669+0000 I  COMMAND  [conn192] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5c13f40d-3c9b-4f55-9ff1-754d398fb871") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 4251ms
2020-05-08T21:58:58.669+0000 I  SHARDING [Sharding-Fixed-8] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:58.670+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("3288600e-f9ba-48ef-8bf2-022cde13ee9b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4289828, timeInactiveMicros:0, 4289ms
2020-05-08T21:58:58.670+0000 I  COMMAND  [conn190] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3288600e-f9ba-48ef-8bf2-022cde13ee9b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 4289ms
2020-05-08T21:58:58.670+0000 I  NETWORK  [conn178] end connection 172.31.0.221:52498 (59 connections now open)
2020-05-08T21:58:58.869+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 6), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.379+0000 I  NETWORK  [conn191] end connection 172.31.0.221:52750 (58 connections now open)
2020-05-08T21:58:59.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53040 #198 (59 connections now open)
2020-05-08T21:58:59.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53042 #199 (60 connections now open)
2020-05-08T21:58:59.379+0000 I  NETWORK  [conn198] received client metadata from 172.31.0.221:53040 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.380+0000 I  NETWORK  [conn199] received client metadata from 172.31.0.221:53042 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.405+0000 I  COMMAND  [conn192] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5c13f40d-3c9b-4f55-9ff1-754d398fb871") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 734ms
2020-05-08T21:58:59.405+0000 I  COMMAND  [conn190] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3288600e-f9ba-48ef-8bf2-022cde13ee9b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 734ms
2020-05-08T21:58:59.405+0000 I  NETWORK  [conn190] end connection 172.31.0.221:52748 (59 connections now open)
2020-05-08T21:58:59.406+0000 I  TXN      [conn194] transaction parameters:{ lsid: { id: UUID("5421fd57-0642-4264-b670-6a7fcbbc1682"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975136, 5) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2512486, timeInactiveMicros:0, 2512ms
2020-05-08T21:58:59.406+0000 I  COMMAND  [conn194] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 613 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975136, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5421fd57-0642-4264-b670-6a7fcbbc1682") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 5421fd57-0642-4264-b670-6a7fcbbc1682:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975136, 5) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 2512ms
2020-05-08T21:58:59.417+0000 I  NETWORK  [conn193] end connection 172.31.0.221:52766 (58 connections now open)
2020-05-08T21:58:59.417+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53052 #200 (59 connections now open)
2020-05-08T21:58:59.417+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53054 #201 (60 connections now open)
2020-05-08T21:58:59.418+0000 I  NETWORK  [conn200] received client metadata from 172.31.0.221:53052 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.418+0000 I  NETWORK  [conn201] received client metadata from 172.31.0.221:53054 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:00.668+0000 I  NETWORK  [conn192] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:00.669+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:00.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:00.678+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:01.169+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:01.669+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:01.891+0000 I  NETWORK  [conn195] end connection 172.31.0.221:52874 (59 connections now open)
2020-05-08T21:59:01.892+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53136 #202 (60 connections now open)
2020-05-08T21:59:01.893+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53138 #203 (61 connections now open)
2020-05-08T21:59:01.893+0000 I  NETWORK  [conn202] received client metadata from 172.31.0.221:53136 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.893+0000 I  NETWORK  [conn203] received client metadata from 172.31.0.221:53138 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.894+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.894+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.895+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.895+0000 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("5c13f40d-3c9b-4f55-9ff1-754d398fb871"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975138, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2489666, timeInactiveMicros:336, 2490ms
2020-05-08T21:59:01.895+0000 I  COMMAND  [conn192] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5c13f40d-3c9b-4f55-9ff1-754d398fb871") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2485ms
2020-05-08T21:59:01.895+0000 I  TXN      [conn200] transaction parameters:{ lsid: { id: UUID("af506e96-838f-4da5-bec4-2ccb0f15176f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 10) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2476999, timeInactiveMicros:0, 2476ms
2020-05-08T21:59:01.895+0000 I  COMMAND  [conn200] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af506e96-838f-4da5-bec4-2ccb0f15176f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2477ms
2020-05-08T21:59:01.896+0000 I  NETWORK  [conn192] end connection 172.31.0.221:52764 (60 connections now open)
2020-05-08T21:59:01.896+0000 I  TXN      [conn198] transaction parameters:{ lsid: { id: UUID("bf68158e-c648-4ff7-8c60-b963414c02a3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975138, 6) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2515383, timeInactiveMicros:0, 2515ms
2020-05-08T21:59:01.896+0000 I  COMMAND  [conn198] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bf68158e-c648-4ff7-8c60-b963414c02a3") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2515ms
2020-05-08T21:59:02.324+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:02.325+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:02.325+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:02.374+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975142, 1), t: 40 }
2020-05-08T21:59:02.686+0000 I  COMMAND  [conn200] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975141, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af506e96-838f-4da5-bec4-2ccb0f15176f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 789ms
2020-05-08T21:59:02.686+0000 I  COMMAND  [conn198] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975141, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bf68158e-c648-4ff7-8c60-b963414c02a3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 789ms
2020-05-08T21:59:04.380+0000 I  NETWORK  [conn199] end connection 172.31.0.221:53042 (59 connections now open)
2020-05-08T21:59:04.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53296 #205 (60 connections now open)
2020-05-08T21:59:04.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53298 #206 (61 connections now open)
2020-05-08T21:59:04.380+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:53296 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.380+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:53298 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.417+0000 I  -        [conn194] operation was interrupted because a client disconnected
2020-05-08T21:59:04.417+0000 I  CONNPOOL [conn194] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:04.417+0000 I  TXN      [conn194] transaction parameters:{ lsid: { id: UUID("5421fd57-0642-4264-b670-6a7fcbbc1682"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975139, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 10) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004208, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:04.418+0000 I  COMMAND  [conn194] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 613 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5421fd57-0642-4264-b670-6a7fcbbc1682") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975139, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:04.418+0000 I  NETWORK  [conn194] end connection 172.31.0.221:52872 (60 connections now open)
2020-05-08T21:59:04.418+0000 I  NETWORK  [conn201] end connection 172.31.0.221:53054 (59 connections now open)
2020-05-08T21:59:04.419+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53308 #207 (60 connections now open)
2020-05-08T21:59:04.419+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53310 #208 (61 connections now open)
2020-05-08T21:59:04.419+0000 I  NETWORK  [conn207] received client metadata from 172.31.0.221:53308 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.419+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:53310 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.420+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.088+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.480+0000 I  SHARDING [conn202] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975142, 1), t: 40 }, now { ts: Timestamp(1588975144, 2), t: 41 }
2020-05-08T21:59:05.482+0000 I  COMMAND  [conn198] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975142, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bf68158e-c648-4ff7-8c60-b963414c02a3") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975141, 5) }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 2795ms
2020-05-08T21:59:05.482+0000 I  COMMAND  [conn205] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975143, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f") }, txnNumber: 1, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1099ms
2020-05-08T21:59:05.482+0000 I  NETWORK  [conn198] end connection 172.31.0.221:53040 (60 connections now open)
2020-05-08T21:59:05.482+0000 I  COMMAND  [conn207] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 624 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975143, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("170c20f7-a5bf-4688-b953-935b7f0a6618") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1062ms
2020-05-08T21:59:05.483+0000 I  TXN      [conn202] transaction parameters:{ lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975140, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3589133, timeInactiveMicros:0, 3589ms
2020-05-08T21:59:05.483+0000 I  COMMAND  [conn202] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975140, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 3589ms
2020-05-08T21:59:05.483+0000 I  TXN      [conn200] transaction parameters:{ lsid: { id: UUID("af506e96-838f-4da5-bec4-2ccb0f15176f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975141, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975142, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2797124, timeInactiveMicros:0, 2797ms
2020-05-08T21:59:05.483+0000 I  COMMAND  [conn200] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975142, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af506e96-838f-4da5-bec4-2ccb0f15176f") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975141, 5) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 2797ms
2020-05-08T21:59:05.484+0000 I  NETWORK  [conn207] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:05.484+0000 I  NETWORK  [conn200] end connection 172.31.0.221:53052 (59 connections now open)
2020-05-08T21:59:05.484+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.484+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.485+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:05.485+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:05.485+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:05.486+0000 I  TXN      [conn207] transaction parameters:{ lsid: { id: UUID("170c20f7-a5bf-4688-b953-935b7f0a6618"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975143, 2) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1065608, timeInactiveMicros:372, 1065ms
2020-05-08T21:59:05.491+0000 I  TXN      [conn205] transaction parameters:{ lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975142, 1) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:8117, timeActiveMicros:1109284, timeInactiveMicros:973, 1110ms
2020-05-08T21:59:07.273+0000 I  COMMAND  [conn207] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975146, 408), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("170c20f7-a5bf-4688-b953-935b7f0a6618") }, txnNumber: 73, autocommit: false } numYields:0 reslen:321 protocol:op_msg 814ms
2020-05-08T21:59:07.273+0000 I  COMMAND  [conn205] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975146, 396), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f") }, txnNumber: 71, autocommit: false } numYields:0 reslen:352 protocol:op_msg 831ms
2020-05-08T21:59:07.292+0000 I  TXN      [conn202] transaction parameters:{ lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975146, 403) } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 403) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:843125, timeActiveMicros:846330, timeInactiveMicros:528, 846ms
2020-05-08T21:59:07.292+0000 I  COMMAND  [conn202] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975146, 405), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46") }, txnNumber: 75, autocommit: false } numYields:0 reslen:214 protocol:op_msg 843ms
2020-05-08T21:59:07.607+0000 I  NETWORK  [conn207] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:07.607+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:07.608+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:07.608+0000 I  NETWORK  [conn205] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:07.609+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:08.107+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:08.607+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:09.059+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:09.107+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.107+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.108+0000 I  COMMAND  [conn202] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 685 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975147, 376), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1501ms
2020-05-08T21:59:09.109+0000 I  TXN      [conn205] transaction parameters:{ lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 96, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975147, 373) } }, globalReadTimestamp:{ ts: Timestamp(1588975147, 373) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1506106, timeInactiveMicros:793, 1506ms
2020-05-08T21:59:09.110+0000 I  COMMAND  [conn205] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975147, 376), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f") }, txnNumber: 96, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1503ms
2020-05-08T21:59:09.616+0000 I  NETWORK  [conn202] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:09.616+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.617+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.617+0000 I  TXN      [conn202] transaction parameters:{ lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 101, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 20) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:508056, timeInactiveMicros:0, 508ms
2020-05-08T21:59:09.617+0000 I  COMMAND  [conn202] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46") }, txnNumber: 101, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 508ms
2020-05-08T21:59:09.620+0000 I  COMMAND  [conn205] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975149, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f") }, txnNumber: 96, autocommit: false } numYields:0 reslen:546 protocol:op_msg 509ms
2020-05-08T21:59:10.485+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 13868 timed out, deadline was 2020-05-08T21:59:10.485+0000, op was RemoteCommand 13868 -- target:[ec2-107-21-173-199.compute-1.amazonaws.com:27019] db:admin expDate:2020-05-08T21:59:10.485+0000 cmd:{ isMaster: 1 }
2020-05-08T21:59:10.485+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-107-21-173-199.compute-1.amazonaws.com:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:59:10.485+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:59:11.207+0000 I  NETWORK  [conn205] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:11.208+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.208+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.546+0000 I  NETWORK  [conn206] end connection 172.31.0.221:53298 (58 connections now open)
2020-05-08T21:59:12.548+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53502 #212 (59 connections now open)
2020-05-08T21:59:12.548+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53504 #213 (60 connections now open)
2020-05-08T21:59:12.548+0000 I  NETWORK  [conn212] received client metadata from 172.31.0.221:53502 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.548+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:53504 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.549+0000 I  NETWORK  [conn212] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:12.550+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:12.603+0000 I  NETWORK  [conn208] end connection 172.31.0.221:53310 (59 connections now open)
2020-05-08T21:59:12.604+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53534 #214 (60 connections now open)
2020-05-08T21:59:12.604+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53536 #215 (61 connections now open)
2020-05-08T21:59:12.604+0000 I  NETWORK  [conn215] received client metadata from 172.31.0.221:53536 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.604+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:53534 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:12.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:13.050+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:13.167+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:13.208+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.208+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.209+0000 I  COMMAND  [conn202] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975149, 102), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46") }, txnNumber: 101, autocommit: false } numYields:0 reslen:517 protocol:op_msg 3591ms
2020-05-08T21:59:13.209+0000 I  COMMAND  [conn205] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975149, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8b7e0033-dcd8-46d4-8833-b087bddd669f") }, txnNumber: 96, autocommit: false } numYields:0 reslen:546 protocol:op_msg 3588ms
2020-05-08T21:59:13.210+0000 I  NETWORK  [conn205] end connection 172.31.0.221:53296 (60 connections now open)
2020-05-08T21:59:13.550+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:13.743+0000 I  NETWORK  [conn207] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:59:13.743+0000 I  COMMAND  [conn207] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 95, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975147, 371), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("170c20f7-a5bf-4688-b953-935b7f0a6618") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:375 protocol:op_msg 6141ms
2020-05-08T21:59:13.743+0000 I  NETWORK  [conn207] end connection 172.31.0.221:53308 (59 connections now open)
2020-05-08T21:59:13.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:14.050+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.050+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.051+0000 I  TXN      [conn212] transaction parameters:{ lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 110) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1502100, timeInactiveMicros:0, 1502ms
2020-05-08T21:59:14.051+0000 I  COMMAND  [conn212] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 1502ms
2020-05-08T21:59:14.110+0000 I  NETWORK  [conn203] end connection 172.31.0.221:53138 (58 connections now open)
2020-05-08T21:59:14.110+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53558 #216 (59 connections now open)
2020-05-08T21:59:14.110+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53560 #217 (60 connections now open)
2020-05-08T21:59:14.110+0000 I  NETWORK  [conn216] received client metadata from 172.31.0.221:53558 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.111+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:53560 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.245+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.245+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.246+0000 I  COMMAND  [conn202] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975153, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fece3fe8-8d6b-46ba-9114-a308f229fa46") }, txnNumber: 101, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1035ms
2020-05-08T21:59:14.246+0000 I  NETWORK  [conn202] end connection 172.31.0.221:53136 (59 connections now open)
2020-05-08T21:59:14.626+0000 I  COMMAND  [conn216] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975154, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 514ms
2020-05-08T21:59:14.627+0000 I  COMMAND  [conn212] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975154, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 575ms
2020-05-08T21:59:14.628+0000 I  TXN      [conn214] transaction parameters:{ lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 110) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2022265, timeInactiveMicros:0, 2022ms
2020-05-08T21:59:14.628+0000 I  COMMAND  [conn214] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 691 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 25702af5-39bb-49a0-b67e-839475e33c0d:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975149, 110) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 2022ms
2020-05-08T21:59:14.776+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.569+0000 I  NETWORK  [conn212] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:15.570+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:15.576+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:16.040+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.070+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:16.570+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:16.616+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.714+0000 I  NETWORK  [conn216] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:59:16.715+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:16.748+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.748+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.749+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 3), t: 43 }
2020-05-08T21:59:17.070+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.070+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.071+0000 I  TXN      [conn212] transaction parameters:{ lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 67, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975155, 520) } }, globalReadTimestamp:{ ts: Timestamp(1588975155, 520) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1509007, timeInactiveMicros:522, 1509ms
2020-05-08T21:59:17.071+0000 I  TXN      [conn214] transaction parameters:{ lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 62, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975155, 521) } }, globalReadTimestamp:{ ts: Timestamp(1588975155, 521) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1505119, timeInactiveMicros:249, 1505ms
2020-05-08T21:59:17.071+0000 I  COMMAND  [conn214] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975155, 522), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 62, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:423 protocol:op_msg 1502ms
2020-05-08T21:59:17.071+0000 I  COMMAND  [conn212] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975155, 522), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 67, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1503ms
2020-05-08T21:59:17.073+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.215+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.480+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:17.586+0000 I  COMMAND  [conn214] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975156, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 62, autocommit: false } numYields:0 reslen:397 protocol:op_msg 513ms
2020-05-08T21:59:17.715+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.715+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.720+0000 I  COMMAND  [conn212] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975156, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 67, autocommit: false } numYields:0 reslen:397 protocol:op_msg 648ms
2020-05-08T21:59:17.723+0000 I  TXN      [conn216] transaction parameters:{ lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 69, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975155, 502) } }, globalReadTimestamp:{ ts: Timestamp(1588975155, 502) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:2175621, timeActiveMicros:2178527, timeInactiveMicros:1074, 2179ms
2020-05-08T21:59:17.723+0000 I  COMMAND  [conn216] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975155, 503), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d") }, txnNumber: 69, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2175ms
2020-05-08T21:59:18.796+0000 I  COMMAND  [conn214] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 137, autocommit: false } numYields:0 reslen:353 protocol:op_msg 700ms
2020-05-08T21:59:18.797+0000 I  COMMAND  [conn212] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 88, autocommit: false } numYields:0 reslen:321 protocol:op_msg 886ms
2020-05-08T21:59:18.797+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d") }, txnNumber: 92, autocommit: false } numYields:0 reslen:321 protocol:op_msg 887ms
2020-05-08T21:59:18.854+0000 I  NETWORK  [conn214] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:18.855+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.355+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.856+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.857+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.857+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.857+0000 I  TXN      [conn214] transaction parameters:{ lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 140, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 51) } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 51) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1009148, timeInactiveMicros:0, 1009ms
2020-05-08T21:59:19.858+0000 I  COMMAND  [conn212] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 47), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 91, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1013ms
2020-05-08T21:59:19.858+0000 I  COMMAND  [conn214] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 140, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 51) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1009ms
2020-05-08T21:59:19.858+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.858+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.858+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 47), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d") }, txnNumber: 95, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1014ms
2020-05-08T21:59:20.283+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:21.130+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975160, 280), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d") }, txnNumber: 178, autocommit: false } numYields:0 reslen:322 protocol:op_msg 624ms
2020-05-08T21:59:21.131+0000 I  COMMAND  [conn214] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975160, 278), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 223, autocommit: false } numYields:0 reslen:353 protocol:op_msg 628ms
2020-05-08T21:59:21.131+0000 I  COMMAND  [conn212] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975160, 280), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 173, autocommit: false } numYields:0 reslen:322 protocol:op_msg 624ms
2020-05-08T21:59:22.862+0000 I  NETWORK  [conn214] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:22.862+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.362+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.862+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.862+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.863+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:23.863+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.863+0000 I  COMMAND  [conn212] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975161, 375), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("46271a54-5e80-4f31-9e9a-a392b148aef3") }, txnNumber: 271, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2012ms
2020-05-08T21:59:23.863+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.864+0000 I  COMMAND  [conn214] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975161, 373), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("25702af5-39bb-49a0-b67e-839475e33c0d") }, txnNumber: 313, autocommit: false } numYields:0 reslen:471 protocol:op_msg 2015ms
2020-05-08T21:59:23.864+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975161, 376), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("404fd0f4-5417-4030-9fdd-be7eae60d55d") }, txnNumber: 275, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2008ms
2020-05-08T21:59:23.864+0000 I  NETWORK  [conn212] end connection 172.31.0.221:53502 (58 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [conn214] end connection 172.31.0.221:53534 (57 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53900 #219 (58 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53902 #220 (59 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53904 #221 (60 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [conn220] received client metadata from 172.31.0.221:53902 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:23.864+0000 I  NETWORK  [conn216] end connection 172.31.0.221:53558 (59 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [conn221] received client metadata from 172.31.0.221:53904 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:23.865+0000 I  NETWORK  [conn219] received client metadata from 172.31.0.221:53900 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.471+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn213] end connection 172.31.0.221:53504 (58 connections now open)
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn215] end connection 172.31.0.221:53536 (57 connections now open)
2020-05-08T21:59:26.424+0000 I  NETWORK  [conn217] end connection 172.31.0.221:53560 (56 connections now open)
2020-05-08T21:59:26.427+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53936 #222 (57 connections now open)
2020-05-08T21:59:26.427+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:53936 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:26.430+0000 I  NETWORK  [conn222] end connection 172.31.0.221:53936 (56 connections now open)
2020-05-08T21:59:27.382+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975166, 4), t: 47 }
2020-05-08T21:59:27.382+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:27.383+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:27.383+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:29.754+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
