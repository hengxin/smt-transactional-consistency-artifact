2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.229+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.229+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.229+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.229+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.229+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.230+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.230+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.230+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.231+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.231+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.231+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-11-34:27017:1588975035:-8327296168716420678 (sleeping for 30000ms)
2020-05-08T21:57:15.233+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.233+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.233+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.237+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 12), t: 1 }
2020-05-08T21:57:15.422+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.423+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.425+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.425+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.426+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("c51e8ddf-82b2-4cb1-8b7c-0017abd7dba1"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.427+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.427+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.435+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:40998 #9 (1 connection now open)
2020-05-08T21:57:16.435+0000 I  NETWORK  [conn9] received client metadata from 172.31.0.221:40998 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.452+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.887+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41038 #11 (2 connections now open)
2020-05-08T21:57:16.887+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:41038 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.933+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41052 #12 (3 connections now open)
2020-05-08T21:57:16.933+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:41052 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.955+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41070 #13 (4 connections now open)
2020-05-08T21:57:16.956+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:41070 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.153+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41100 #14 (5 connections now open)
2020-05-08T21:57:17.153+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:41100 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.303+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41116 #15 (6 connections now open)
2020-05-08T21:57:17.304+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41118 #16 (7 connections now open)
2020-05-08T21:57:17.304+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:41116 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.304+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:41118 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.416+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41158 #17 (8 connections now open)
2020-05-08T21:57:17.416+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:41158 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.454+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41174 #18 (9 connections now open)
2020-05-08T21:57:17.455+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41176 #19 (10 connections now open)
2020-05-08T21:57:17.455+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:41176 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.455+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:41174 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41206 #20 (11 connections now open)
2020-05-08T21:57:17.706+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:41206 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.785+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41216 #21 (12 connections now open)
2020-05-08T21:57:17.785+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:41216 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.830+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41236 #22 (13 connections now open)
2020-05-08T21:57:17.830+0000 I  NETWORK  [conn22] received client metadata from 172.31.0.221:41236 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.976+0000 I  COMMAND  [conn18] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("afc866fe-bd6a-48a1-9b04-605fc45cf7bc") } } numYields:0 reslen:163 protocol:op_msg 516ms
2020-05-08T21:57:17.977+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:17.978+0000 I  NETWORK  [conn18] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  NETWORK  [conn18] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.978+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.980+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.980+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.984+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.984+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.011+0000 I  NETWORK  [conn18] end connection 172.31.0.221:41174 (12 connections now open)
2020-05-08T21:57:18.011+0000 I  NETWORK  [conn19] end connection 172.31.0.221:41176 (11 connections now open)
2020-05-08T21:57:18.252+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41242 #29 (12 connections now open)
2020-05-08T21:57:18.252+0000 I  NETWORK  [conn29] received client metadata from 172.31.0.221:41242 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.866+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41250 #30 (13 connections now open)
2020-05-08T21:57:18.866+0000 I  NETWORK  [conn30] received client metadata from 172.31.0.221:41250 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41264 #31 (14 connections now open)
2020-05-08T21:57:19.338+0000 I  NETWORK  [conn31] received client metadata from 172.31.0.221:41264 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.508+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41270 #32 (15 connections now open)
2020-05-08T21:57:19.509+0000 I  NETWORK  [conn32] received client metadata from 172.31.0.221:41270 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41298 #33 (16 connections now open)
2020-05-08T21:57:19.562+0000 I  NETWORK  [conn33] received client metadata from 172.31.0.221:41298 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.084+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41328 #34 (17 connections now open)
2020-05-08T21:57:20.084+0000 I  NETWORK  [conn34] received client metadata from 172.31.0.221:41328 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.202+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41352 #35 (18 connections now open)
2020-05-08T21:57:20.202+0000 I  NETWORK  [conn35] received client metadata from 172.31.0.221:41352 conn35: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.213+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41360 #36 (19 connections now open)
2020-05-08T21:57:20.213+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:41360 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41384 #37 (20 connections now open)
2020-05-08T21:57:21.413+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:41384 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.782+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41404 #38 (21 connections now open)
2020-05-08T21:57:21.783+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:41404 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.852+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41418 #39 (22 connections now open)
2020-05-08T21:57:21.852+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:41418 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.890+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41422 #40 (23 connections now open)
2020-05-08T21:57:21.890+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:41422 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.932+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41434 #41 (24 connections now open)
2020-05-08T21:57:21.933+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:41434 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.965+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41444 #42 (25 connections now open)
2020-05-08T21:57:21.965+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:41444 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.056+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41450 #43 (26 connections now open)
2020-05-08T21:57:22.056+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41452 #44 (27 connections now open)
2020-05-08T21:57:22.056+0000 I  NETWORK  [conn43] received client metadata from 172.31.0.221:41450 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.057+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:41452 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41460 #45 (28 connections now open)
2020-05-08T21:57:22.057+0000 I  NETWORK  [conn45] received client metadata from 172.31.0.221:41460 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41462 #46 (29 connections now open)
2020-05-08T21:57:22.058+0000 I  NETWORK  [conn46] received client metadata from 172.31.0.221:41462 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.063+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41502 #47 (30 connections now open)
2020-05-08T21:57:22.063+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41504 #48 (31 connections now open)
2020-05-08T21:57:22.063+0000 I  NETWORK  [conn47] received client metadata from 172.31.0.221:41502 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.063+0000 I  NETWORK  [conn48] received client metadata from 172.31.0.221:41504 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.071+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.308+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1ff2385d-11f4-4826-be5e-2ebe2ff87bf5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 214ms
2020-05-08T21:57:22.311+0000 I  COMMAND  [conn48] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 6 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 223ms
2020-05-08T21:57:22.324+0000 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 240ms
2020-05-08T21:57:22.328+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("1ff2385d-11f4-4826-be5e-2ebe2ff87bf5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 14) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:17823, timeActiveMicros:233945, timeInactiveMicros:1287, 235ms
2020-05-08T21:57:22.356+0000 I  TXN      [conn48] transaction parameters:{ lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 10) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:41955, timeActiveMicros:266546, timeInactiveMicros:860, 267ms
2020-05-08T21:57:22.515+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41592 #58 (32 connections now open)
2020-05-08T21:57:22.516+0000 I  NETWORK  [conn58] received client metadata from 172.31.0.221:41592 conn58: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.091+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41638 #62 (33 connections now open)
2020-05-08T21:57:23.092+0000 I  NETWORK  [conn62] received client metadata from 172.31.0.221:41638 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.114+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41652 #68 (34 connections now open)
2020-05-08T21:57:23.114+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:41652 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.364+0000 I  COMMAND  [conn48] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 21 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 344), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4") }, txnNumber: 13, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:361 protocol:op_msg 842ms
2020-05-08T21:57:23.368+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 336), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1ff2385d-11f4-4826-be5e-2ebe2ff87bf5") }, txnNumber: 6, autocommit: false } numYields:0 reslen:320 protocol:op_msg 849ms
2020-05-08T21:57:23.379+0000 I  TXN      [conn48] transaction parameters:{ lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 334) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 334) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:14740, timeActiveMicros:859303, timeInactiveMicros:4805, 864ms
2020-05-08T21:57:23.440+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 26 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 398), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c") }, txnNumber: 20, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 847ms
2020-05-08T21:57:23.442+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 20, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 398) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:848411, timeInactiveMicros:384, 848ms
2020-05-08T21:57:23.768+0000 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 111), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c") }, txnNumber: 29, autocommit: false } numYields:0 reslen:321 protocol:op_msg 215ms
2020-05-08T21:57:24.088+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41718 #69 (35 connections now open)
2020-05-08T21:57:24.088+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:41718 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41752 #70 (36 connections now open)
2020-05-08T21:57:24.472+0000 I  NETWORK  [conn70] received client metadata from 172.31.0.221:41752 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.856+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1ff2385d-11f4-4826-be5e-2ebe2ff87bf5") }, txnNumber: 9, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1428ms
2020-05-08T21:57:25.110+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41782 #71 (37 connections now open)
2020-05-08T21:57:25.110+0000 I  NETWORK  [conn71] received client metadata from 172.31.0.221:41782 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.124+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 82, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975044, 179) } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 179) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:850064, timeInactiveMicros:351, 850ms
2020-05-08T21:57:25.124+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 179), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c") }, txnNumber: 82, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 849ms
2020-05-08T21:57:25.186+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41796 #72 (38 connections now open)
2020-05-08T21:57:25.187+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:41796 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.426+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41828 #73 (39 connections now open)
2020-05-08T21:57:25.426+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:41828 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.503+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41838 #74 (40 connections now open)
2020-05-08T21:57:25.503+0000 I  NETWORK  [conn74] received client metadata from 172.31.0.221:41838 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.543+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 206), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1ff2385d-11f4-4826-be5e-2ebe2ff87bf5") }, txnNumber: 10, autocommit: false } numYields:0 reslen:321 protocol:op_msg 682ms
2020-05-08T21:57:25.544+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 24 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c") }, txnNumber: 84, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 391ms
2020-05-08T21:57:25.553+0000 I  TXN      [conn48] transaction parameters:{ lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 15) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:2162094, timeActiveMicros:2172831, timeInactiveMicros:840, 2173ms
2020-05-08T21:57:25.553+0000 I  COMMAND  [conn48] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2162ms
2020-05-08T21:57:25.558+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 84, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 22) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:11692, timeActiveMicros:404522, timeInactiveMicros:666, 405ms
2020-05-08T21:57:25.559+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41852 #76 (41 connections now open)
2020-05-08T21:57:25.671+0000 I  NETWORK  [conn76] received client metadata from 172.31.0.221:41852 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.891+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:26.365+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:41898 #78 (42 connections now open)
2020-05-08T21:57:26.366+0000 I  NETWORK  [conn78] received client metadata from 172.31.0.221:41898 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.458+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 93), t: 3 }
2020-05-08T21:57:30.901+0000 I  NETWORK  [conn47] end connection 172.31.0.221:41502 (41 connections now open)
2020-05-08T21:57:30.902+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42020 #79 (42 connections now open)
2020-05-08T21:57:30.902+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42022 #80 (43 connections now open)
2020-05-08T21:57:30.902+0000 I  NETWORK  [conn79] received client metadata from 172.31.0.221:42020 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.902+0000 I  NETWORK  [conn80] received client metadata from 172.31.0.221:42022 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.903+0000 I  NETWORK  [conn79] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:30.904+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.907+0000 I  NETWORK  [conn44] end connection 172.31.0.221:41452 (42 connections now open)
2020-05-08T21:57:30.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42024 #81 (43 connections now open)
2020-05-08T21:57:30.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42026 #82 (44 connections now open)
2020-05-08T21:57:30.907+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:42024 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.908+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:42026 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.909+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.931+0000 I  NETWORK  [conn46] end connection 172.31.0.221:41462 (43 connections now open)
2020-05-08T21:57:30.931+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42054 #83 (44 connections now open)
2020-05-08T21:57:30.931+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:42054 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.931+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42056 #84 (45 connections now open)
2020-05-08T21:57:30.932+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:42056 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.933+0000 I  NETWORK  [conn83] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:57:30.934+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.934+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.937+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.947+0000 I  CONNPOOL [conn45] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:57:30.948+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 662), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b163ed3e-f132-4f9a-b342-14072dbbde0c") }, txnNumber: 103, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5013ms
2020-05-08T21:57:30.948+0000 I  NETWORK  [conn45] end connection 172.31.0.221:41460 (44 connections now open)
2020-05-08T21:57:30.948+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:31.404+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.404+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.404+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.991+0000 I  COMMAND  [conn81] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1082ms
2020-05-08T21:57:31.993+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1056ms
2020-05-08T21:57:31.993+0000 I  COMMAND  [conn79] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975046, 96), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1090ms
2020-05-08T21:57:31.998+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.001+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 3) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1063955, timeInactiveMicros:709, 1064ms
2020-05-08T21:57:32.961+0000 I  NETWORK  [conn81] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:33.215+0000 I  NETWORK  [conn83] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 30e316dc-4b77-46fc-a166-24b8a9d5fe44:5 stopped due to: operation was interrupted
2020-05-08T21:57:33.216+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.716+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.716+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.717+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:33.717+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.717+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.718+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:34.164+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975052, 33) } }, globalReadTimestamp:{ ts: Timestamp(1588975052, 33) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:2108295, timeActiveMicros:2112957, timeInactiveMicros:1022, 2113ms
2020-05-08T21:57:34.164+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975052, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44") }, txnNumber: 5, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2108ms
2020-05-08T21:57:34.640+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.640+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.640+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.641+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:34.641+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 674), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1ff2385d-11f4-4826-be5e-2ebe2ff87bf5") }, txnNumber: 28, autocommit: false } numYields:0 reslen:439 protocol:op_msg 8698ms
2020-05-08T21:57:34.641+0000 I  NETWORK  [conn43] end connection 172.31.0.221:41450 (43 connections now open)
2020-05-08T21:57:34.641+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:34.642+0000 I  TXN      [conn81] transaction parameters:{ lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 20) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3732234, timeInactiveMicros:1012, 3733ms
2020-05-08T21:57:34.642+0000 I  COMMAND  [conn81] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975051, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2643ms
2020-05-08T21:57:34.645+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 50) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:479894, timeInactiveMicros:393, 480ms
2020-05-08T21:57:34.645+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44") }, txnNumber: 6, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 478ms
2020-05-08T21:57:34.656+0000 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975046, 96) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:2658513, timeActiveMicros:3752023, timeInactiveMicros:1332, 3753ms
2020-05-08T21:57:34.657+0000 I  COMMAND  [conn79] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975051, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 2659ms
2020-05-08T21:57:35.055+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975054, 857) } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 857) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:218657, timeActiveMicros:226141, timeInactiveMicros:508, 226ms
2020-05-08T21:57:35.055+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 863), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44") }, txnNumber: 14, autocommit: false } numYields:0 reslen:214 protocol:op_msg 218ms
2020-05-08T21:57:35.056+0000 I  TXN      [conn79] transaction parameters:{ lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 857) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:214241, timeActiveMicros:226098, timeInactiveMicros:834, 226ms
2020-05-08T21:57:35.056+0000 I  COMMAND  [conn79] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 869), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c") }, txnNumber: 10, autocommit: false } numYields:0 reslen:183 protocol:op_msg 214ms
2020-05-08T21:57:35.061+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 860), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a") }, txnNumber: 9, autocommit: false } numYields:0 reslen:320 protocol:op_msg 229ms
2020-05-08T21:57:35.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:35.141+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:35.141+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:35.510+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:35.511+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:35.641+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:35.789+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 409), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a") }, txnNumber: 25, autocommit: false } numYields:0 reslen:321 protocol:op_msg 428ms
2020-05-08T21:57:35.816+0000 I  NETWORK  [conn79] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:35.817+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.141+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.270+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42216 #92 (44 connections now open)
2020-05-08T21:57:36.270+0000 I  NETWORK  [conn92] received client metadata from 172.31.0.221:42216 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.641+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.641+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.641+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.642+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 2), t: 6 }
2020-05-08T21:57:38.000+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.816+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.816+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.818+0000 I  SHARDING [conn48] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:39.818+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.818+0000 I  COMMAND  [conn48] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 655), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15e38e22-ba53-4577-a271-65c7ee5c2ff4") }, txnNumber: 30, autocommit: false } numYields:0 reslen:321 protocol:op_msg 13892ms
2020-05-08T21:57:39.818+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 434), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a") }, txnNumber: 26, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4026ms
2020-05-08T21:57:39.819+0000 I  COMMAND  [conn79] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 417), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c") }, txnNumber: 26, autocommit: false } numYields:0 reslen:470 protocol:op_msg 4448ms
2020-05-08T21:57:39.819+0000 I  NETWORK  [conn48] end connection 172.31.0.221:41504 (43 connections now open)
2020-05-08T21:57:39.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.056+0000 I  NETWORK  [conn79] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.267+0000 I  NETWORK  [conn84] end connection 172.31.0.221:42056 (42 connections now open)
2020-05-08T21:57:40.267+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42284 #94 (43 connections now open)
2020-05-08T21:57:40.267+0000 I  NETWORK  [conn94] received client metadata from 172.31.0.221:42284 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.267+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42286 #95 (44 connections now open)
2020-05-08T21:57:40.267+0000 I  NETWORK  [conn95] received client metadata from 172.31.0.221:42286 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.295+0000 I  NETWORK  [conn80] end connection 172.31.0.221:42022 (43 connections now open)
2020-05-08T21:57:40.295+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42300 #96 (44 connections now open)
2020-05-08T21:57:40.296+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:42300 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.296+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42302 #97 (45 connections now open)
2020-05-08T21:57:40.296+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:42302 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.319+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.336+0000 I  NETWORK  [conn82] end connection 172.31.0.221:42026 (44 connections now open)
2020-05-08T21:57:40.337+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42316 #98 (45 connections now open)
2020-05-08T21:57:40.337+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42318 #99 (46 connections now open)
2020-05-08T21:57:40.338+0000 I  NETWORK  [conn99] received client metadata from 172.31.0.221:42318 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.338+0000 I  NETWORK  [conn98] received client metadata from 172.31.0.221:42316 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.339+0000 I  NETWORK  [conn99] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.340+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.340+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.340+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.319+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.328+0000 I  NETWORK  [conn99] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:41.329+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.568+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42390 #100 (47 connections now open)
2020-05-08T21:57:41.568+0000 I  NETWORK  [conn100] received client metadata from 172.31.0.221:42390 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:41.816+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.817+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.817+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.817+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.817+0000 I  COMMAND  [conn79] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b7c446a9-9176-4b61-8e6c-29ff0d2fb70c") }, txnNumber: 26, autocommit: false } numYields:0 reslen:546 protocol:op_msg 1997ms
2020-05-08T21:57:41.817+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("573558bb-8cad-4f61-945b-fe2ce5025c1a") }, txnNumber: 26, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1998ms
2020-05-08T21:57:41.818+0000 I  NETWORK  [conn81] end connection 172.31.0.221:42024 (45 connections now open)
2020-05-08T21:57:41.818+0000 I  NETWORK  [conn79] end connection 172.31.0.221:42020 (46 connections now open)
2020-05-08T21:57:41.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.829+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.829+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.829+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.830+0000 I  COMMAND  [conn99] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("239356bc-b744-411c-9903-cfa6b8e65a98") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 991ms
2020-05-08T21:57:42.061+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 136 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5063000c-1f40-4a70-bd71-d7c3a2d1d285") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:288 protocol:op_msg 1793ms
2020-05-08T21:57:42.063+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 136 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5784e579-58c2-463f-917b-60dbecf94d46") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1766ms
2020-05-08T21:57:42.066+0000 I  TXN      [conn96] transaction parameters:{ lsid: { id: UUID("5784e579-58c2-463f-917b-60dbecf94d46"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1768693, timeInactiveMicros:602, 1769ms
2020-05-08T21:57:42.070+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:42.319+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.032+0000 I  NETWORK  [conn94] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:43.032+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.038+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.038+0000 I  NETWORK  [conn99] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:43.039+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.316+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 1409 timed out, deadline was 2020-05-08T21:57:43.316+0000, op was RemoteCommand 1409 -- target:[ec2-3-82-35-209.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:57:43.316+0000 cmd:{ isMaster: 1 }
2020-05-08T21:57:43.316+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:57:43.316+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.319+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.532+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.533+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.533+0000 I  TXN      [conn94] transaction parameters:{ lsid: { id: UUID("5063000c-1f40-4a70-bd71-d7c3a2d1d285"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975061, 9) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1470649, timeInactiveMicros:348, 1470ms
2020-05-08T21:57:43.533+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5063000c-1f40-4a70-bd71-d7c3a2d1d285") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1463ms
2020-05-08T21:57:43.534+0000 I  COMMAND  [conn96] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975062, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5784e579-58c2-463f-917b-60dbecf94d46") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1467ms
2020-05-08T21:57:43.534+0000 I  COMMAND  [conn99] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975061, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("239356bc-b744-411c-9903-cfa6b8e65a98") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1703ms
2020-05-08T21:57:43.534+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.534+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.534+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.168+0000 I  NETWORK  [conn96] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:44.169+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.211+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.669+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.169+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.259+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42482 #107 (46 connections now open)
2020-05-08T21:57:45.259+0000 I  NETWORK  [conn107] received client metadata from 172.31.0.221:42482 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.296+0000 I  NETWORK  [conn97] end connection 172.31.0.221:42302 (45 connections now open)
2020-05-08T21:57:45.296+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42492 #108 (46 connections now open)
2020-05-08T21:57:45.296+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42494 #109 (47 connections now open)
2020-05-08T21:57:45.296+0000 I  NETWORK  [conn108] received client metadata from 172.31.0.221:42492 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.297+0000 I  NETWORK  [conn109] received client metadata from 172.31.0.221:42494 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.337+0000 I  NETWORK  [conn98] end connection 172.31.0.221:42316 (46 connections now open)
2020-05-08T21:57:45.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42508 #110 (47 connections now open)
2020-05-08T21:57:45.338+0000 I  NETWORK  [conn110] received client metadata from 172.31.0.221:42508 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.339+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42510 #111 (48 connections now open)
2020-05-08T21:57:45.339+0000 I  NETWORK  [conn111] received client metadata from 172.31.0.221:42510 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.669+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.669+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.670+0000 I  TXN      [conn99] transaction parameters:{ lsid: { id: UUID("239356bc-b744-411c-9903-cfa6b8e65a98"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975063, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975063, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2135426, timeInactiveMicros:0, 2135ms
2020-05-08T21:57:45.670+0000 I  TXN      [conn96] transaction parameters:{ lsid: { id: UUID("5784e579-58c2-463f-917b-60dbecf94d46"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975063, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975063, 5) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2135348, timeInactiveMicros:634, 2135ms
2020-05-08T21:57:45.670+0000 I  COMMAND  [conn99] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975063, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("239356bc-b744-411c-9903-cfa6b8e65a98") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975063, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2135ms
2020-05-08T21:57:45.670+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975063, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5784e579-58c2-463f-917b-60dbecf94d46") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2133ms
2020-05-08T21:57:45.670+0000 I  COMMAND  [conn94] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975063, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5063000c-1f40-4a70-bd71-d7c3a2d1d285") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 2135ms
2020-05-08T21:57:45.671+0000 I  NETWORK  [conn99] end connection 172.31.0.221:42318 (46 connections now open)
2020-05-08T21:57:45.671+0000 I  NETWORK  [conn96] end connection 172.31.0.221:42300 (47 connections now open)
2020-05-08T21:57:45.711+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.711+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:45.712+0000 I  NETWORK  [replSetDistLockPinger] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.712+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.211+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.426+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:57:46.711+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.063+0000 I  NETWORK  [conn95] end connection 172.31.0.221:42286 (45 connections now open)
2020-05-08T21:57:47.063+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42570 #113 (46 connections now open)
2020-05-08T21:57:47.064+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42574 #114 (47 connections now open)
2020-05-08T21:57:47.064+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:42570 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.064+0000 I  NETWORK  [conn114] received client metadata from 172.31.0.221:42574 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:47.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:47.211+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.272+0000 I  NETWORK  [conn113] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:47.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.344+0000 I  NETWORK  [conn94] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:47.344+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.518+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.711+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.211+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.272+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.272+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.273+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.273+0000 I  TXN      [conn113] transaction parameters:{ lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 14) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1207411, timeInactiveMicros:0, 1207ms
2020-05-08T21:57:48.273+0000 I  COMMAND  [conn113] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 1207ms
2020-05-08T21:57:48.273+0000 I  TXN      [conn94] transaction parameters:{ lsid: { id: UUID("5063000c-1f40-4a70-bd71-d7c3a2d1d285"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 7) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2602424, timeInactiveMicros:0, 2602ms
2020-05-08T21:57:48.273+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5063000c-1f40-4a70-bd71-d7c3a2d1d285") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 5) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 5063000c-1f40-4a70-bd71-d7c3a2d1d285:2 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975065, 7) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 2602ms
2020-05-08T21:57:48.274+0000 I  NETWORK  [conn94] end connection 172.31.0.221:42284 (46 connections now open)
2020-05-08T21:57:48.711+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.711+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.865+0000 I  COMMAND  [conn83] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 392), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("30e316dc-4b77-46fc-a166-24b8a9d5fe44") }, txnNumber: 27, autocommit: false } numYields:0 reslen:321 protocol:op_msg 13517ms
2020-05-08T21:57:48.865+0000 I  NETWORK  [conn83] end connection 172.31.0.221:42054 (45 connections now open)
2020-05-08T21:57:49.346+0000 I  NETWORK  [conn113] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:49.347+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.846+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.297+0000 I  NETWORK  [conn109] end connection 172.31.0.221:42494 (44 connections now open)
2020-05-08T21:57:50.297+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42620 #117 (45 connections now open)
2020-05-08T21:57:50.297+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42622 #118 (46 connections now open)
2020-05-08T21:57:50.297+0000 I  NETWORK  [conn117] received client metadata from 172.31.0.221:42620 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.298+0000 I  NETWORK  [conn118] received client metadata from 172.31.0.221:42622 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.299+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.321+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.339+0000 I  NETWORK  [conn110] end connection 172.31.0.221:42508 (45 connections now open)
2020-05-08T21:57:50.339+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42636 #119 (46 connections now open)
2020-05-08T21:57:50.340+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42638 #120 (47 connections now open)
2020-05-08T21:57:50.340+0000 I  NETWORK  [conn119] received client metadata from 172.31.0.221:42636 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.340+0000 I  NETWORK  [conn120] received client metadata from 172.31.0.221:42638 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.342+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.342+0000 I  -        [conn111] operation was interrupted because a client disconnected
2020-05-08T21:57:50.343+0000 I  CONNPOOL [conn111] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:57:50.343+0000 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("04f49063-ac43-4069-8cba-b20b95bf0d21"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975064, 151) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003411, timeInactiveMicros:0, 5003ms
2020-05-08T21:57:50.343+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 143 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04f49063-ac43-4069-8cba-b20b95bf0d21") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:57:50.343+0000 I  NETWORK  [conn111] end connection 172.31.0.221:42510 (46 connections now open)
2020-05-08T21:57:50.346+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.846+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.346+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.696+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42694 #121 (47 connections now open)
2020-05-08T21:57:51.696+0000 I  NETWORK  [conn121] received client metadata from 172.31.0.221:42694 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.846+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.846+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.847+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.847+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.850+0000 I  COMMAND  [conn119] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 158), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9ad8d61d-489f-4dee-83f0-ac2aebee2bfd") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1508ms
2020-05-08T21:57:51.851+0000 I  TXN      [conn113] transaction parameters:{ lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975068, 9) } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 9) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3572451, timeInactiveMicros:287, 3572ms
2020-05-08T21:57:51.851+0000 I  COMMAND  [conn113] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7053d93c-c622-4fd4-a344-462c88505759:2 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975068, 9) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 3571ms
2020-05-08T21:57:51.854+0000 I  TXN      [conn119] transaction parameters:{ lsid: { id: UUID("9ad8d61d-489f-4dee-83f0-ac2aebee2bfd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975070, 158) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1511512, timeInactiveMicros:1073, 1512ms
2020-05-08T21:57:51.856+0000 I  COMMAND  [conn117] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 190), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45d56ddb-9ec3-4bfd-9c23-d6c8c28ea4ce") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1557ms
2020-05-08T21:57:51.895+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.993+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.199+0000 I  SHARDING [conn113] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.347+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.347+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.348+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 33), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ba055d7d-9aec-45c1-b5c7-fef3c13b26fb") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 7050ms
2020-05-08T21:57:52.348+0000 I  NETWORK  [conn108] end connection 172.31.0.221:42492 (46 connections now open)
2020-05-08T21:57:52.717+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42718 #125 (47 connections now open)
2020-05-08T21:57:52.718+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:42718 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42740 #126 (48 connections now open)
2020-05-08T21:57:52.907+0000 I  NETWORK  [conn126] received client metadata from 172.31.0.221:42740 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:53.700+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 641), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759") }, txnNumber: 78, autocommit: false } numYields:0 reslen:321 protocol:op_msg 216ms
2020-05-08T21:57:53.792+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42780 #127 (49 connections now open)
2020-05-08T21:57:53.793+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:42780 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.129+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 781), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759") }, txnNumber: 102, autocommit: false } numYields:0 reslen:322 protocol:op_msg 216ms
2020-05-08T21:57:54.339+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42814 #128 (50 connections now open)
2020-05-08T21:57:54.340+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:42814 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.396+0000 I  NETWORK  [conn117] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:54.397+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:54.401+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:54.748+0000 I  TXN      [conn113] transaction parameters:{ lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 147, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975074, 250) } }, globalReadTimestamp:{ ts: Timestamp(1588975074, 251) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:213555, timeInactiveMicros:0, 213ms
2020-05-08T21:57:54.748+0000 I  COMMAND  [conn113] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975074, 251), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759") }, txnNumber: 147, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975074, 250) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 213ms
2020-05-08T21:57:54.896+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.896+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.897+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:54.897+0000 I  COMMAND  [conn119] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 589), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9ad8d61d-489f-4dee-83f0-ac2aebee2bfd") }, txnNumber: 82, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1490ms
2020-05-08T21:57:54.898+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.898+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.908+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:54.961+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42842 #129 (51 connections now open)
2020-05-08T21:57:54.961+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:42842 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:55.507+0000 I  NETWORK  [conn119] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:55.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:55.511+0000 I  TXN      [conn117] transaction parameters:{ lsid: { id: UUID("45d56ddb-9ec3-4bfd-9c23-d6c8c28ea4ce"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 562) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2120649, timeActiveMicros:2128519, timeInactiveMicros:531, 2129ms
2020-05-08T21:57:55.511+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.163+0000 I  NETWORK  [conn113] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:56.164+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.663+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.787+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42940 #130 (52 connections now open)
2020-05-08T21:57:56.788+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:42940 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.368+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:57.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.629+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43014 #131 (53 connections now open)
2020-05-08T21:57:57.630+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:43014 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.663+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.663+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.664+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7053d93c-c622-4fd4-a344-462c88505759") }, txnNumber: 192, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2509ms
2020-05-08T21:57:58.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.316+0000 I  NETWORK  [conn120] end connection 172.31.0.221:42638 (52 connections now open)
2020-05-08T21:57:58.316+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43028 #132 (53 connections now open)
2020-05-08T21:57:58.317+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:43028 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.319+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43034 #133 (54 connections now open)
2020-05-08T21:57:58.319+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:43034 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.321+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.383+0000 I  NETWORK  [conn118] end connection 172.31.0.221:42622 (53 connections now open)
2020-05-08T21:57:58.386+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43092 #134 (54 connections now open)
2020-05-08T21:57:58.386+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43094 #135 (55 connections now open)
2020-05-08T21:57:58.387+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:43092 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.387+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:43094 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.401+0000 I  CONNPOOL [conn117] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:57:58.401+0000 I  COMMAND  [conn117] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 572), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45d56ddb-9ec3-4bfd-9c23-d6c8c28ea4ce") }, txnNumber: 75, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5010ms
2020-05-08T21:57:58.401+0000 I  NETWORK  [conn117] end connection 172.31.0.221:42620 (54 connections now open)
2020-05-08T21:57:58.409+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.425+0000 I  NETWORK  [conn114] end connection 172.31.0.221:42574 (53 connections now open)
2020-05-08T21:57:58.426+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43114 #136 (54 connections now open)
2020-05-08T21:57:58.426+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43116 #137 (55 connections now open)
2020-05-08T21:57:58.426+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:43114 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.426+0000 I  NETWORK  [conn113] end connection 172.31.0.221:42570 (54 connections now open)
2020-05-08T21:57:58.428+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:43116 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.432+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.508+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.614+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43134 #138 (55 connections now open)
2020-05-08T21:57:58.615+0000 I  NETWORK  [conn138] received client metadata from 172.31.0.221:43134 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.508+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.508+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.509+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:59.509+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.510+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:59.875+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43166 #140 (56 connections now open)
2020-05-08T21:57:59.876+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:43166 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.901+0000 I  -        [conn119] operation was interrupted because a client disconnected
2020-05-08T21:57:59.902+0000 I  CONNPOOL [conn119] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:57:59.902+0000 I  TXN      [conn119] transaction parameters:{ lsid: { id: UUID("9ad8d61d-489f-4dee-83f0-ac2aebee2bfd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 83, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975074, 349) } }, globalReadTimestamp:{ ts: Timestamp(1588975074, 349) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004083, timeInactiveMicros:0, 5004ms
2020-05-08T21:57:59.902+0000 I  COMMAND  [conn119] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 254 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975074, 349), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9ad8d61d-489f-4dee-83f0-ac2aebee2bfd") }, txnNumber: 83, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975074, 349) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:57:59.902+0000 I  NETWORK  [conn119] end connection 172.31.0.221:42636 (55 connections now open)
2020-05-08T21:58:00.009+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.009+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.010+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.889+0000 I  NETWORK  [conn136] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:00.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:00.891+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.891+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.891+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.891+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:01.892+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.892+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.892+0000 I  TXN      [conn132] transaction parameters:{ lsid: { id: UUID("eac672f6-bbf6-4424-bb0d-bd86c0dc4ae9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 158) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3572237, timeInactiveMicros:0, 3572ms
2020-05-08T21:58:01.892+0000 I  TXN      [conn136] transaction parameters:{ lsid: { id: UUID("71582392-b819-4e01-9328-2162652af1f7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 214) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3462915, timeInactiveMicros:305, 3463ms
2020-05-08T21:58:01.892+0000 I  COMMAND  [conn136] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 219), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("71582392-b819-4e01-9328-2162652af1f7") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3461ms
2020-05-08T21:58:01.892+0000 I  COMMAND  [conn132] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 158), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eac672f6-bbf6-4424-bb0d-bd86c0dc4ae9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3572ms
2020-05-08T21:58:01.900+0000 I  NETWORK  [conn135] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.900+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.907+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.249+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:02.250+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.371+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.373+0000 I  NETWORK  [conn136] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:02.374+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.392+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.874+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.892+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:02.892+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.317+0000 I  NETWORK  [conn133] end connection 172.31.0.221:43034 (54 connections now open)
2020-05-08T21:58:03.317+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43284 #141 (55 connections now open)
2020-05-08T21:58:03.317+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43286 #142 (56 connections now open)
2020-05-08T21:58:03.317+0000 I  NETWORK  [conn141] received client metadata from 172.31.0.221:43284 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.318+0000 I  NETWORK  [conn142] received client metadata from 172.31.0.221:43286 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.319+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.374+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.374+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.409+0000 I  NETWORK  [conn134] end connection 172.31.0.221:43092 (55 connections now open)
2020-05-08T21:58:03.409+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43352 #143 (56 connections now open)
2020-05-08T21:58:03.409+0000 I  NETWORK  [conn143] received client metadata from 172.31.0.221:43352 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.409+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43354 #144 (57 connections now open)
2020-05-08T21:58:03.409+0000 I  NETWORK  [conn144] received client metadata from 172.31.0.221:43354 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.413+0000 I  -        [conn135] operation was interrupted because a client disconnected
2020-05-08T21:58:03.413+0000 I  TXN      [conn135] transaction parameters:{ lsid: { id: UUID("13f69cde-7e14-466b-bc7b-0013258f04d3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 205) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005047, timeInactiveMicros:0, 5005ms
2020-05-08T21:58:03.413+0000 I  COMMAND  [conn135] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 272 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 205), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("13f69cde-7e14-466b-bc7b-0013258f04d3") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:58:03.413+0000 I  NETWORK  [conn135] end connection 172.31.0.221:43094 (56 connections now open)
2020-05-08T21:58:03.413+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.426+0000 I  NETWORK  [conn137] end connection 172.31.0.221:43116 (55 connections now open)
2020-05-08T21:58:03.426+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43360 #145 (56 connections now open)
2020-05-08T21:58:03.427+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43362 #146 (57 connections now open)
2020-05-08T21:58:03.427+0000 I  NETWORK  [conn145] received client metadata from 172.31.0.221:43360 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.427+0000 I  NETWORK  [conn146] received client metadata from 172.31.0.221:43362 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.507+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.519+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("9485a517-e9a6-47b7-a627-6ea500c2e32f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 3) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:9000, timeActiveMicros:107868, timeInactiveMicros:588, 108ms
2020-05-08T21:58:03.544+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.120+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.890+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.890+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.891+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.892+0000 I  COMMAND  [conn136] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 120), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("71582392-b819-4e01-9328-2162652af1f7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 2997ms
2020-05-08T21:58:04.892+0000 I  NETWORK  [conn136] end connection 172.31.0.221:43114 (56 connections now open)
2020-05-08T21:58:04.892+0000 I  COMMAND  [conn132] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 120), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eac672f6-bbf6-4424-bb0d-bd86c0dc4ae9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2998ms
2020-05-08T21:58:04.893+0000 I  NETWORK  [conn132] end connection 172.31.0.221:43028 (55 connections now open)
2020-05-08T21:58:05.942+0000 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 278 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975082, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d710c572-196c-4ec3-9776-06a8992bacf0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2623ms
2020-05-08T21:58:05.943+0000 I  NETWORK  [conn143] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.944+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.944+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.945+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 282 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef4b6567-22d0-4002-b09e-b6586eb23c4e") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2438ms
2020-05-08T21:58:05.947+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.948+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.948+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.949+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("ef4b6567-22d0-4002-b09e-b6586eb23c4e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 3) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2520334, timeInactiveMicros:829, 2521ms
2020-05-08T21:58:05.949+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("9485a517-e9a6-47b7-a627-6ea500c2e32f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 33) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2406440, timeInactiveMicros:356, 2406ms
2020-05-08T21:58:05.949+0000 I  COMMAND  [conn143] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 33), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9485a517-e9a6-47b7-a627-6ea500c2e32f") }, txnNumber: 6, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2405ms
2020-05-08T21:58:05.956+0000 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("d710c572-196c-4ec3-9776-06a8992bacf0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975082, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2635629, timeInactiveMicros:1245, 2636ms
2020-05-08T21:58:05.976+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.980+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:06.556+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.556+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:06.969+0000 I  NETWORK  [conn143] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.972+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.056+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.469+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.556+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.556+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.970+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.970+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.970+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 54), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d710c572-196c-4ec3-9776-06a8992bacf0") }, txnNumber: 2, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1985ms
2020-05-08T21:58:08.318+0000 I  NETWORK  [conn142] end connection 172.31.0.221:43286 (54 connections now open)
2020-05-08T21:58:08.318+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43450 #151 (55 connections now open)
2020-05-08T21:58:08.318+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43452 #152 (56 connections now open)
2020-05-08T21:58:08.319+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:43450 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.319+0000 I  NETWORK  [conn152] received client metadata from 172.31.0.221:43452 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.427+0000 I  NETWORK  [conn146] end connection 172.31.0.221:43362 (55 connections now open)
2020-05-08T21:58:08.427+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43470 #153 (56 connections now open)
2020-05-08T21:58:08.427+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43472 #154 (57 connections now open)
2020-05-08T21:58:08.427+0000 I  NETWORK  [conn153] received client metadata from 172.31.0.221:43470 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.428+0000 I  NETWORK  [conn154] received client metadata from 172.31.0.221:43472 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.543+0000 I  NETWORK  [conn144] end connection 172.31.0.221:43354 (56 connections now open)
2020-05-08T21:58:08.543+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43486 #155 (57 connections now open)
2020-05-08T21:58:08.544+0000 I  NETWORK  [conn155] received client metadata from 172.31.0.221:43486 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.544+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43488 #156 (58 connections now open)
2020-05-08T21:58:08.544+0000 I  NETWORK  [conn156] received client metadata from 172.31.0.221:43488 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.563+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.937+0000 I  NETWORK  [conn155] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:09.059+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("9485a517-e9a6-47b7-a627-6ea500c2e32f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 34) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3084574, timeActiveMicros:3088339, timeInactiveMicros:995, 3089ms
2020-05-08T21:58:09.059+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 229), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d710c572-196c-4ec3-9776-06a8992bacf0") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1087ms
2020-05-08T21:58:09.059+0000 I  NETWORK  [conn141] end connection 172.31.0.221:43284 (57 connections now open)
2020-05-08T21:58:09.059+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("ef4b6567-22d0-4002-b09e-b6586eb23c4e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 34) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3082965, timeActiveMicros:3088140, timeInactiveMicros:1068, 3089ms
2020-05-08T21:58:09.352+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.437+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.937+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.937+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.938+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.938+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.938+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.938+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.938+0000 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e0cc2aab-54b9-4b29-9623-b51b8a7b81e9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 1505ms
2020-05-08T21:58:09.939+0000 I  COMMAND  [conn145] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 39), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef4b6567-22d0-4002-b09e-b6586eb23c4e") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 3963ms
2020-05-08T21:58:09.940+0000 I  NETWORK  [conn145] end connection 172.31.0.221:43360 (56 connections now open)
2020-05-08T21:58:09.943+0000 I  COMMAND  [conn143] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9485a517-e9a6-47b7-a627-6ea500c2e32f") }, txnNumber: 7, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3968ms
2020-05-08T21:58:09.943+0000 I  NETWORK  [conn143] end connection 172.31.0.221:43352 (55 connections now open)
2020-05-08T21:58:10.076+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43570 #157 (56 connections now open)
2020-05-08T21:58:10.076+0000 I  NETWORK  [conn157] received client metadata from 172.31.0.221:43570 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.388+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.438+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.938+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:11.438+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.438+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.446+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 9), t: 19 }
2020-05-08T21:58:12.286+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43622 #158 (57 connections now open)
2020-05-08T21:58:12.286+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:43622 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.319+0000 I  NETWORK  [conn152] end connection 172.31.0.221:43452 (56 connections now open)
2020-05-08T21:58:13.320+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43634 #159 (57 connections now open)
2020-05-08T21:58:13.320+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:43634 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.321+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43636 #160 (58 connections now open)
2020-05-08T21:58:13.323+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:43636 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.333+0000 I  NETWORK  [conn159] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:13.334+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.334+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.335+0000 I  CONNPOOL [conn151] Ending connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:58:13.336+0000 I  COMMAND  [conn151] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6f08b994-5884-4797-9d16-796f9990f991") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:58:13.336+0000 I  NETWORK  [conn151] end connection 172.31.0.221:43450 (57 connections now open)
2020-05-08T21:58:13.430+0000 I  NETWORK  [conn154] end connection 172.31.0.221:43472 (56 connections now open)
2020-05-08T21:58:13.430+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43650 #161 (57 connections now open)
2020-05-08T21:58:13.431+0000 I  NETWORK  [conn161] received client metadata from 172.31.0.221:43650 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.431+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43652 #162 (58 connections now open)
2020-05-08T21:58:13.431+0000 I  NETWORK  [conn162] received client metadata from 172.31.0.221:43652 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.544+0000 I  NETWORK  [conn156] end connection 172.31.0.221:43488 (57 connections now open)
2020-05-08T21:58:13.545+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43654 #163 (58 connections now open)
2020-05-08T21:58:13.545+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43656 #164 (59 connections now open)
2020-05-08T21:58:13.545+0000 I  NETWORK  [conn163] received client metadata from 172.31.0.221:43654 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.546+0000 I  NETWORK  [conn164] received client metadata from 172.31.0.221:43656 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.735+0000 I  NETWORK  [conn161] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:13.736+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.833+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.833+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.834+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 527), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58e2365b-007b-4753-8d5c-2143394e2cab") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 399ms
2020-05-08T21:58:14.759+0000 I  NETWORK  [conn161] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:14.760+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.173+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43688 #165 (60 connections now open)
2020-05-08T21:58:15.173+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:43688 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.259+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.437+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 4106 timed out, deadline was 2020-05-08T21:58:15.437+0000, op was RemoteCommand 4106 -- target:[ec2-3-82-35-209.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:15.437+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:15.437+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:15.437+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:15.437+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.759+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.759+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.760+0000 I  COMMAND  [conn161] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 672), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58e2365b-007b-4753-8d5c-2143394e2cab") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1828ms
2020-05-08T21:58:15.760+0000 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 640), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f92d090b-90c8-4a72-9b55-d51f56f4ad36") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1928ms
2020-05-08T21:58:16.766+0000 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975095, 206), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f92d090b-90c8-4a72-9b55-d51f56f4ad36") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1004ms
2020-05-08T21:58:16.767+0000 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("58e2365b-007b-4753-8d5c-2143394e2cab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975095, 205) } }, globalReadTimestamp:{ ts: Timestamp(1588975095, 206) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1006485, timeInactiveMicros:0, 1006ms
2020-05-08T21:58:16.768+0000 I  COMMAND  [conn161] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975095, 206), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58e2365b-007b-4753-8d5c-2143394e2cab") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975095, 205) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1006ms
2020-05-08T21:58:16.777+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.794+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.794+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.794+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.795+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.795+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.835+0000 I  NETWORK  [conn159] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:16.836+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.836+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.334+0000 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 215), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f92d090b-90c8-4a72-9b55-d51f56f4ad36") }, txnNumber: 10, autocommit: false } numYields:0 reslen:397 protocol:op_msg 496ms
2020-05-08T21:58:17.365+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.365+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.365+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.366+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.669+0000 I  NETWORK  [conn161] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.712+0000 I  NETWORK  [conn159] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:17.712+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.865+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:18.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.365+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.365+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.545+0000 I  NETWORK  [conn164] end connection 172.31.0.221:43656 (59 connections now open)
2020-05-08T21:58:18.546+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43838 #168 (60 connections now open)
2020-05-08T21:58:18.546+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43836 #169 (61 connections now open)
2020-05-08T21:58:18.546+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:43836 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.546+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:43838 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:19.355+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.355+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.357+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.357+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.371+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.857+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.857+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.448+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.794+0000 I  NETWORK  [conn162] end connection 172.31.0.221:43652 (60 connections now open)
2020-05-08T21:58:21.794+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43890 #170 (61 connections now open)
2020-05-08T21:58:21.794+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43892 #171 (62 connections now open)
2020-05-08T21:58:21.795+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:43890 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.795+0000 I  NETWORK  [conn171] received client metadata from 172.31.0.221:43892 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.796+0000 I  NETWORK  [conn170] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:21.796+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:21.797+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.346+0000 I  NETWORK  [conn160] end connection 172.31.0.221:43636 (61 connections now open)
2020-05-08T21:58:22.346+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43906 #172 (62 connections now open)
2020-05-08T21:58:22.346+0000 I  NETWORK  [conn172] received client metadata from 172.31.0.221:43906 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.346+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43908 #173 (63 connections now open)
2020-05-08T21:58:22.347+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:43908 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.349+0000 I  -        [conn159] operation was interrupted because a client disconnected
2020-05-08T21:58:22.349+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("f92d090b-90c8-4a72-9b55-d51f56f4ad36"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 7) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003751, timeInactiveMicros:246, 5003ms
2020-05-08T21:58:22.349+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f92d090b-90c8-4a72-9b55-d51f56f4ad36") }, txnNumber: 12, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:58:22.349+0000 I  NETWORK  [conn159] end connection 172.31.0.221:43634 (62 connections now open)
2020-05-08T21:58:22.673+0000 I  NETWORK  [conn170] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:22.673+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:22.674+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.173+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.546+0000 I  NETWORK  [conn168] end connection 172.31.0.221:43838 (61 connections now open)
2020-05-08T21:58:23.547+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 4268 timed out, deadline was 2020-05-08T21:58:23.547+0000, op was RemoteCommand 4268 -- target:[ec2-3-82-35-209.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:23.547+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:23.547+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43954 #174 (62 connections now open)
2020-05-08T21:58:23.547+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 4266 timed out, deadline was 2020-05-08T21:58:23.547+0000, op was RemoteCommand 4266 -- target:[ec2-54-226-181-14.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:23.547+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:23.547+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.548+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43956 #175 (63 connections now open)
2020-05-08T21:58:23.548+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:23.548+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:23.548+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.548+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.548+0000 I  NETWORK  [conn174] received client metadata from 172.31.0.221:43954 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.548+0000 I  NETWORK  [conn175] received client metadata from 172.31.0.221:43956 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.550+0000 I  -        [conn169] operation was interrupted because a client disconnected
2020-05-08T21:58:23.550+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("ceaff230-7cbb-48f3-bef7-1e28dbb1cdeb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002842, timeInactiveMicros:0, 5002ms
2020-05-08T21:58:23.550+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ceaff230-7cbb-48f3-bef7-1e28dbb1cdeb") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:58:23.550+0000 I  NETWORK  [conn169] end connection 172.31.0.221:43836 (62 connections now open)
2020-05-08T21:58:23.673+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.673+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.674+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.674+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 134) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1326518, timeInactiveMicros:0, 1326ms
2020-05-08T21:58:23.674+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 1326ms
2020-05-08T21:58:23.674+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:23.674+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:23.733+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.733+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:23.848+0000 I  NETWORK  [conn170] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.848+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.852+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.173+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.174+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.560+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.670+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.673+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.674+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.173+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.173+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.174+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.174+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975103, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1498ms
2020-05-08T21:58:25.260+0000 I  NETWORK  [conn170] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.261+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.264+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.670+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.673+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.674+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:26.170+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.170+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.171+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.171+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.171+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.171+0000 I  TXN      [conn161] transaction parameters:{ lsid: { id: UUID("58e2365b-007b-4753-8d5c-2143394e2cab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 197) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:9377889, timeInactiveMicros:0, 9377ms
2020-05-08T21:58:26.172+0000 I  COMMAND  [conn161] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 197), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58e2365b-007b-4753-8d5c-2143394e2cab") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 9378ms
2020-05-08T21:58:26.172+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.172+0000 I  NETWORK  [conn161] end connection 172.31.0.221:43650 (61 connections now open)
2020-05-08T21:58:26.172+0000 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 202), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e0cc2aab-54b9-4b29-9623-b51b8a7b81e9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 16232ms
2020-05-08T21:58:26.172+0000 I  NETWORK  [conn153] end connection 172.31.0.221:43470 (60 connections now open)
2020-05-08T21:58:26.173+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.173+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.174+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 92) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4378332, timeInactiveMicros:0, 4378ms
2020-05-08T21:58:26.174+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 374 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:369 protocol:op_msg 4378ms
2020-05-08T21:58:26.174+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975104, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 999ms
2020-05-08T21:58:26.377+0000 I  COMMAND  [conn170] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 201ms
2020-05-08T21:58:26.474+0000 I  COMMAND  [conn174] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 377 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 2925ms
2020-05-08T21:58:26.475+0000 I  COMMAND  [conn155] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975088, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a9928580-b3de-41a5-bfef-d5e78b384cf6") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 17930ms
2020-05-08T21:58:26.475+0000 I  NETWORK  [conn155] end connection 172.31.0.221:43486 (59 connections now open)
2020-05-08T21:58:26.489+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 374 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 111ms
2020-05-08T21:58:26.494+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 8) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:115924, timeInactiveMicros:653, 116ms
2020-05-08T21:58:26.495+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 3) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:319817, timeInactiveMicros:0, 319ms
2020-05-08T21:58:26.495+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 319ms
2020-05-08T21:58:26.834+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.897+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("2bd7b9bb-5c98-4a3c-9408-b118b8a9723c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 527) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:13350248, timeInactiveMicros:287, 13350ms
2020-05-08T21:58:26.897+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 528), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bd7b9bb-5c98-4a3c-9408-b118b8a9723c") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 2bd7b9bb-5c98-4a3c-9408-b118b8a9723c:1 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975093, 527) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:592 protocol:op_msg 13349ms
2020-05-08T21:58:26.898+0000 I  NETWORK  [conn163] end connection 172.31.0.221:43654 (58 connections now open)
2020-05-08T21:58:28.328+0000 I  NETWORK  [conn174] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:28.329+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.828+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.828+0000 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.830+0000 I  COMMAND  [conn174] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 455), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a") }, txnNumber: 41, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1470ms
2020-05-08T21:58:28.844+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 45, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 464) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 464) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1473018, timeInactiveMicros:290, 1473ms
2020-05-08T21:58:28.844+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 465), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 45, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 1471ms
2020-05-08T21:58:28.870+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 375) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 375) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1560913, timeActiveMicros:1581583, timeInactiveMicros:798, 1582ms
2020-05-08T21:58:28.871+0000 I  COMMAND  [conn170] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 406), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 38, autocommit: false } numYields:0 reslen:343 protocol:op_msg 1561ms
2020-05-08T21:58:29.725+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 633), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 80, autocommit: false } numYields:0 reslen:321 protocol:op_msg 223ms
2020-05-08T21:58:29.739+0000 I  TXN      [conn174] transaction parameters:{ lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 84, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 649) } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 651) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:219333, timeInactiveMicros:275, 219ms
2020-05-08T21:58:29.739+0000 I  COMMAND  [conn174] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975109, 652), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a") }, txnNumber: 84, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 216ms
2020-05-08T21:58:29.739+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 649) } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 651) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:220097, timeInactiveMicros:0, 220ms
2020-05-08T21:58:29.739+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975109, 651), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 68, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 649) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 220ms
2020-05-08T21:58:30.245+0000 I  NETWORK  [conn174] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.747+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.747+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.749+0000 I  COMMAND  [conn174] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 306), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a") }, txnNumber: 114, autocommit: false } numYields:0 reslen:353 protocol:op_msg 525ms
2020-05-08T21:58:31.254+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 101, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 311) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 311) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1023068, timeActiveMicros:1027413, timeInactiveMicros:1202, 1028ms
2020-05-08T21:58:31.256+0000 I  COMMAND  [conn172] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 318), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 101, autocommit: false } numYields:0 reslen:429 protocol:op_msg 1024ms
2020-05-08T21:58:31.263+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 486 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 474), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 154, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 474) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 506ms
2020-05-08T21:58:31.269+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 154, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 474) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 474) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:510395, timeInactiveMicros:1615, 512ms
2020-05-08T21:58:31.284+0000 I  TXN      [conn174] transaction parameters:{ lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 115, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 467) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 467) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:530615, timeActiveMicros:533594, timeInactiveMicros:822, 534ms
2020-05-08T21:58:31.284+0000 I  COMMAND  [conn174] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 473), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a") }, txnNumber: 115, autocommit: false } numYields:0 reslen:214 protocol:op_msg 530ms
2020-05-08T21:58:31.396+0000 I  NETWORK  [conn174] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator eae82aa8-3200-481a-a5f6-c6f854d0763a:120 stopped due to: Transaction coordinator service stepping down
2020-05-08T21:58:32.126+0000 I  COMMAND  [conn170] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 192), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 174, autocommit: false } numYields:0 reslen:322 protocol:op_msg 632ms
2020-05-08T21:58:32.240+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.396+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.396+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:33.400+0000 I  NETWORK  [conn172] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:33.401+0000 I  SHARDING [conn172] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.401+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 108, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 170) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 170) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2017074, timeInactiveMicros:0, 2017ms
2020-05-08T21:58:33.401+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 170), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 108, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 170) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:425 protocol:op_msg 2017ms
2020-05-08T21:58:33.913+0000 I  NETWORK  [conn170] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:33.914+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:34.414+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.414+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.415+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:34.415+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:34.415+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 192, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975112, 17) } }, globalReadTimestamp:{ ts: Timestamp(1588975112, 17) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2160430, timeInactiveMicros:906, 2161ms
2020-05-08T21:58:34.415+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975112, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 192, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 2158ms
2020-05-08T21:58:34.416+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:34.743+0000 I  NETWORK  [conn172] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:34.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.348+0000 I  NETWORK  [conn171] end connection 172.31.0.221:43892 (57 connections now open)
2020-05-08T21:58:35.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44150 #182 (58 connections now open)
2020-05-08T21:58:35.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44152 #183 (59 connections now open)
2020-05-08T21:58:35.349+0000 I  NETWORK  [conn182] received client metadata from 172.31.0.221:44150 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.349+0000 I  NETWORK  [conn183] received client metadata from 172.31.0.221:44152 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.172+0000 I  NETWORK  [conn170] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:36.173+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.301+0000 I  NETWORK  [conn175] end connection 172.31.0.221:43956 (58 connections now open)
2020-05-08T21:58:36.301+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44178 #184 (59 connections now open)
2020-05-08T21:58:36.301+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44180 #185 (60 connections now open)
2020-05-08T21:58:36.301+0000 I  NETWORK  [conn184] received client metadata from 172.31.0.221:44178 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.302+0000 I  NETWORK  [conn185] received client metadata from 172.31.0.221:44180 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.305+0000 I  NETWORK  [conn173] end connection 172.31.0.221:43908 (59 connections now open)
2020-05-08T21:58:36.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44186 #186 (60 connections now open)
2020-05-08T21:58:36.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44188 #187 (61 connections now open)
2020-05-08T21:58:36.306+0000 I  NETWORK  [conn186] received client metadata from 172.31.0.221:44186 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.306+0000 I  NETWORK  [conn187] received client metadata from 172.31.0.221:44188 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.375+0000 I  COMMAND  [conn174] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 148), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eae82aa8-3200-481a-a5f6-c6f854d0763a") }, txnNumber: 120, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:58:36.375+0000 I  NETWORK  [conn174] end connection 172.31.0.221:43954 (60 connections now open)
2020-05-08T21:58:36.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.743+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.743+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.744+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.744+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1806364c-6ea9-43b0-83bf-1233add26b39") }, txnNumber: 108, autocommit: false } numYields:0 reslen:517 protocol:op_msg 3342ms
2020-05-08T21:58:36.744+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.744+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.744+0000 I  NETWORK  [conn172] end connection 172.31.0.221:43906 (59 connections now open)
2020-05-08T21:58:36.745+0000 I  COMMAND  [conn186] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 506 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 437ms
2020-05-08T21:58:36.750+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 506 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 447ms
2020-05-08T21:58:36.751+0000 I  TXN      [conn182] transaction parameters:{ lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 8) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1400714, timeInactiveMicros:0, 1400ms
2020-05-08T21:58:36.751+0000 I  COMMAND  [conn182] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 506 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 2719dd5e-7b4d-4f59-abb0-0adf73637d14:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975114, 8) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 1400ms
2020-05-08T21:58:36.756+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:453142, timeInactiveMicros:400, 453ms
2020-05-08T21:58:36.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.200+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.204+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.630+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.860+0000 I  NETWORK  [conn184] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:38.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.244+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.244+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.361+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.362+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.373+0000 I  COMMAND  [conn184] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 632), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d") }, txnNumber: 87, autocommit: false } numYields:0 reslen:427 protocol:op_msg 523ms
2020-05-08T21:58:38.385+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.385+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.386+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.386+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 194, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 8) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3952565, timeInactiveMicros:766, 3953ms
2020-05-08T21:58:38.386+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d1f0ae6e-2eb3-432e-9cfd-b86225aeac60") }, txnNumber: 194, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3951ms
2020-05-08T21:58:38.386+0000 I  NETWORK  [conn170] end connection 172.31.0.221:43890 (58 connections now open)
2020-05-08T21:58:38.387+0000 I  TXN      [conn182] transaction parameters:{ lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 76) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1580655, timeInactiveMicros:697, 1581ms
2020-05-08T21:58:38.388+0000 I  COMMAND  [conn182] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 76), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 4, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1578ms
2020-05-08T21:58:38.388+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 63, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 508) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:759172, timeInactiveMicros:307, 759ms
2020-05-08T21:58:38.388+0000 I  COMMAND  [conn186] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 509), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 63, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 757ms
2020-05-08T21:58:38.514+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.514+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.515+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.519+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.519+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.860+0000 I  COMMAND  [conn182] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 4, autocommit: false } numYields:0 reslen:426 protocol:op_msg 472ms
2020-05-08T21:58:38.861+0000 I  COMMAND  [conn186] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 63, autocommit: false } numYields:0 reslen:397 protocol:op_msg 472ms
2020-05-08T21:58:38.874+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 518 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d") }, txnNumber: 89, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 488ms
2020-05-08T21:58:38.897+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 89, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 25) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:18152, timeActiveMicros:510739, timeInactiveMicros:1472, 512ms
2020-05-08T21:58:39.244+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.244+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.357+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:39.584+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:39.818+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:40.541+0000 I  NETWORK  [conn182] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.542+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.542+0000 I  NETWORK  [conn184] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:40.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.541+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.541+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.542+0000 I  COMMAND  [conn182] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1010), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 38, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1843ms
2020-05-08T21:58:41.545+0000 I  COMMAND  [conn186] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 998), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 97, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1855ms
2020-05-08T21:58:41.771+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:41.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:41.774+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.050+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 127, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975119, 988) } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 990) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2350500, timeActiveMicros:2358149, timeInactiveMicros:6368, 2364ms
2020-05-08T21:58:42.051+0000 I  NETWORK  [conn186] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:42.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.053+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.056+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.552+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.052+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.053+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.053+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.053+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 98, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975121, 10) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1507468, timeInactiveMicros:0, 1507ms
2020-05-08T21:58:43.053+0000 I  COMMAND  [conn182] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975121, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 38, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1510ms
2020-05-08T21:58:43.053+0000 I  COMMAND  [conn186] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975121, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 98, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 1507ms
2020-05-08T21:58:43.054+0000 I  COMMAND  [conn184] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1004), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d") }, txnNumber: 127, autocommit: false } numYields:0 reslen:497 protocol:op_msg 3354ms
2020-05-08T21:58:43.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.054+0000 I  COMMAND  [conn184] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d") }, txnNumber: 127, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1000ms
2020-05-08T21:58:44.056+0000 I  COMMAND  [conn182] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975123, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 39, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975123, 2) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1001ms
2020-05-08T21:58:44.058+0000 I  COMMAND  [conn186] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 98, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1003ms
2020-05-08T21:58:44.197+0000 I  TXN      [conn182] transaction parameters:{ lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 39, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975123, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975123, 3) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:136269, timeActiveMicros:1141208, timeInactiveMicros:1294, 1142ms
2020-05-08T21:58:44.197+0000 I  COMMAND  [conn182] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 39, autocommit: false } numYields:0 reslen:214 protocol:op_msg 136ms
2020-05-08T21:58:44.197+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 100, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 20) } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 20) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:111487, timeActiveMicros:118735, timeInactiveMicros:1060, 119ms
2020-05-08T21:58:44.197+0000 I  COMMAND  [conn186] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 100, autocommit: false } numYields:0 reslen:214 protocol:op_msg 111ms
2020-05-08T21:58:44.212+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:44.212+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:44.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.426+0000 I  NETWORK  [conn184] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:45.427+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.079+0000 I  NETWORK  [conn182] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 2719dd5e-7b4d-4f59-abb0-0adf73637d14:52 stopped due to: operation was interrupted
2020-05-08T21:58:46.080+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:46.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.426+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.580+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.580+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.581+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.771+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.771+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.772+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.776+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 21), t: 33 }
2020-05-08T21:58:46.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.087+0000 I  TXN      [conn182] transaction parameters:{ lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 52, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 400) } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 400) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:2661930, timeActiveMicros:2666567, timeInactiveMicros:3395, 2669ms
2020-05-08T21:58:47.087+0000 I  COMMAND  [conn182] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 408), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2719dd5e-7b4d-4f59-abb0-0adf73637d14") }, txnNumber: 52, autocommit: false } numYields:0 reslen:311 protocol:op_msg 2662ms
2020-05-08T21:58:47.088+0000 I  NETWORK  [conn182] end connection 172.31.0.221:44150 (57 connections now open)
2020-05-08T21:58:47.089+0000 I  NETWORK  [conn183] end connection 172.31.0.221:44152 (56 connections now open)
2020-05-08T21:58:47.089+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44388 #193 (57 connections now open)
2020-05-08T21:58:47.089+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44390 #194 (58 connections now open)
2020-05-08T21:58:47.089+0000 I  NETWORK  [conn193] received client metadata from 172.31.0.221:44388 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:47.089+0000 I  NETWORK  [conn194] received client metadata from 172.31.0.221:44390 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:47.091+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.271+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.271+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.426+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.426+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.426+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.467+0000 I  NETWORK  [conn184] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.467+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 113, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 372) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:4055011, timeActiveMicros:4063916, timeInactiveMicros:1978, 4065ms
2020-05-08T21:58:48.467+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.467+0000 I  NETWORK  [conn186] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:48.468+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.468+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.473+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.489+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:48.491+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:48.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.989+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:48.989+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.307+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.365+0000 I  NETWORK  [conn185] end connection 172.31.0.221:44180 (57 connections now open)
2020-05-08T21:58:49.366+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44456 #195 (58 connections now open)
2020-05-08T21:58:49.366+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44458 #196 (59 connections now open)
2020-05-08T21:58:49.366+0000 I  NETWORK  [conn195] received client metadata from 172.31.0.221:44456 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.366+0000 I  NETWORK  [conn196] received client metadata from 172.31.0.221:44458 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.367+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.367+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.368+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.368+0000 I  COMMAND  [conn186] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 388), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 113, autocommit: false } numYields:0 reslen:466 protocol:op_msg 4956ms
2020-05-08T21:58:49.368+0000 I  TXN      [conn193] transaction parameters:{ lsid: { id: UUID("7f474a39-f31f-4d3a-b34c-31b32ca40906"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975126, 26) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2278267, timeInactiveMicros:0, 2278ms
2020-05-08T21:58:49.369+0000 I  COMMAND  [conn193] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975126, 26), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f474a39-f31f-4d3a-b34c-31b32ca40906") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2278ms
2020-05-08T21:58:49.370+0000 I  NETWORK  [conn186] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.371+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.371+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.371+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.401+0000 I  NETWORK  [conn187] end connection 172.31.0.221:44188 (58 connections now open)
2020-05-08T21:58:49.401+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44476 #197 (59 connections now open)
2020-05-08T21:58:49.401+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44478 #198 (60 connections now open)
2020-05-08T21:58:49.402+0000 I  NETWORK  [conn197] received client metadata from 172.31.0.221:44476 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.402+0000 I  NETWORK  [conn198] received client metadata from 172.31.0.221:44478 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.426+0000 I  CONNPOOL [conn184] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:58:49.426+0000 I  COMMAND  [conn184] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 398), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c39e62f-1500-4f22-9607-9aa70c1ad93d") }, txnNumber: 150, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:58:49.426+0000 I  NETWORK  [conn184] end connection 172.31.0.221:44178 (59 connections now open)
2020-05-08T21:58:49.489+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.989+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.321+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.489+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.657+0000 I  CONNPOOL [conn186] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:58:50.658+0000 I  COMMAND  [conn186] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94827f95-dce6-4ac2-948a-386538b388d7") }, txnNumber: 113, autocommit: false } numYields:0 reslen:399 protocol:op_msg 1288ms
2020-05-08T21:58:50.658+0000 I  NETWORK  [conn186] end connection 172.31.0.221:44186 (58 connections now open)
2020-05-08T21:58:50.759+0000 I  NETWORK  [conn195] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:50.760+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.762+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.763+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.989+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.259+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.259+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.260+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.260+0000 I  TXN      [conn195] transaction parameters:{ lsid: { id: UUID("21695ac5-8963-4779-99e6-a91707ccb6c8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1890727, timeInactiveMicros:0, 1890ms
2020-05-08T21:58:51.261+0000 I  COMMAND  [conn195] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("21695ac5-8963-4779-99e6-a91707ccb6c8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1890ms
2020-05-08T21:58:51.261+0000 I  COMMAND  [conn193] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f474a39-f31f-4d3a-b34c-31b32ca40906") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1891ms
2020-05-08T21:58:51.489+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.489+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.490+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.873+0000 I  COMMAND  [conn197] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("61d8ef6b-1aa3-4f60-b979-d569d7d8b406") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2470ms
2020-05-08T21:58:51.876+0000 I  COMMAND  [conn193] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 45), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f474a39-f31f-4d3a-b34c-31b32ca40906") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 613ms
2020-05-08T21:58:51.877+0000 I  COMMAND  [conn195] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("21695ac5-8963-4779-99e6-a91707ccb6c8") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 615ms
2020-05-08T21:58:52.089+0000 I  NETWORK  [conn194] end connection 172.31.0.221:44390 (57 connections now open)
2020-05-08T21:58:52.090+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44620 #201 (58 connections now open)
2020-05-08T21:58:52.090+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44622 #202 (59 connections now open)
2020-05-08T21:58:52.090+0000 I  NETWORK  [conn202] received client metadata from 172.31.0.221:44622 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:52.090+0000 I  NETWORK  [conn201] received client metadata from 172.31.0.221:44620 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:52.114+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.114+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.119+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.120+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.123+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.124+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.126+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.333+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.614+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.619+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.902+0000 I  NETWORK  [conn193] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:52.902+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:53.119+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.119+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.119+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.319+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:58:53.402+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.402+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.403+0000 I  COMMAND  [conn195] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 84), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("21695ac5-8963-4779-99e6-a91707ccb6c8") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1506ms
2020-05-08T21:58:53.927+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.928+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.928+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.931+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.932+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:54.370+0000 I  NETWORK  [conn196] end connection 172.31.0.221:44458 (58 connections now open)
2020-05-08T21:58:54.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44690 #205 (59 connections now open)
2020-05-08T21:58:54.371+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:44690 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44692 #206 (60 connections now open)
2020-05-08T21:58:54.372+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:44692 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.373+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:54.428+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.428+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.432+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 4), t: 38 }
2020-05-08T21:58:54.615+0000 I  NETWORK  [conn195] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:54.615+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.115+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.115+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.116+0000 I  COMMAND  [conn195] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("21695ac5-8963-4779-99e6-a91707ccb6c8") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1711ms
2020-05-08T21:58:55.116+0000 I  NETWORK  [conn195] end connection 172.31.0.221:44456 (59 connections now open)
2020-05-08T21:58:55.615+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.875+0000 I  NETWORK  [conn198] end connection 172.31.0.221:44478 (58 connections now open)
2020-05-08T21:58:56.876+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44822 #208 (59 connections now open)
2020-05-08T21:58:56.876+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44824 #209 (60 connections now open)
2020-05-08T21:58:56.876+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:44822 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.876+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:44824 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.877+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:56.899+0000 I  CONNPOOL [conn197] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T21:58:56.900+0000 I  COMMAND  [conn197] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("61d8ef6b-1aa3-4f60-b979-d569d7d8b406") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5012ms
2020-05-08T21:58:56.900+0000 I  NETWORK  [conn197] end connection 172.31.0.221:44476 (59 connections now open)
2020-05-08T21:58:57.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.090+0000 I  NETWORK  [conn202] end connection 172.31.0.221:44622 (58 connections now open)
2020-05-08T21:58:57.091+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44874 #213 (59 connections now open)
2020-05-08T21:58:57.091+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44876 #214 (60 connections now open)
2020-05-08T21:58:57.091+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:44874 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:57.091+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:44876 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:57.094+0000 I  -        [conn201] operation was interrupted because a client disconnected
2020-05-08T21:58:57.094+0000 I  CONNPOOL [conn201] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:58:57.094+0000 I  TXN      [conn201] transaction parameters:{ lsid: { id: UUID("de66f6cf-4e03-4fb1-aeb6-a5582a5a522d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 101) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003052, timeInactiveMicros:0, 5003ms
2020-05-08T21:58:57.094+0000 I  COMMAND  [conn201] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 607 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("de66f6cf-4e03-4fb1-aeb6-a5582a5a522d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:57.094+0000 I  NETWORK  [conn201] end connection 172.31.0.221:44620 (59 connections now open)
2020-05-08T21:58:59.371+0000 I  NETWORK  [conn205] end connection 172.31.0.221:44690 (58 connections now open)
2020-05-08T21:58:59.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44982 #216 (59 connections now open)
2020-05-08T21:58:59.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44984 #217 (60 connections now open)
2020-05-08T21:58:59.372+0000 I  NETWORK  [conn216] received client metadata from 172.31.0.221:44982 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.372+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:44984 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.373+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.377+0000 I  -        [conn206] operation was interrupted because a client disconnected
2020-05-08T21:58:59.377+0000 I  CONNPOOL [conn206] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:58:59.377+0000 I  TXN      [conn206] transaction parameters:{ lsid: { id: UUID("e457432c-6cd9-44b7-b2a4-5f479f35976e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004673, timeInactiveMicros:0, 5004ms
2020-05-08T21:58:59.377+0000 I  COMMAND  [conn206] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 594 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e457432c-6cd9-44b7-b2a4-5f479f35976e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:58:59.377+0000 I  NETWORK  [conn206] end connection 172.31.0.221:44692 (59 connections now open)
2020-05-08T21:59:01.877+0000 I  NETWORK  [conn209] end connection 172.31.0.221:44824 (58 connections now open)
2020-05-08T21:59:01.878+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45086 #219 (59 connections now open)
2020-05-08T21:59:01.878+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45088 #220 (60 connections now open)
2020-05-08T21:59:01.878+0000 I  NETWORK  [conn219] received client metadata from 172.31.0.221:45086 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.878+0000 I  NETWORK  [conn220] received client metadata from 172.31.0.221:45088 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.879+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.882+0000 I  -        [conn208] operation was interrupted because a client disconnected
2020-05-08T21:59:01.882+0000 I  CONNPOOL [conn208] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:01.882+0000 I  TXN      [conn208] transaction parameters:{ lsid: { id: UUID("3ba0a931-8d60-4dca-bd41-eb0c6bbdb032"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975136, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005486, timeInactiveMicros:0, 5005ms
2020-05-08T21:59:01.883+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 613 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975136, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ba0a931-8d60-4dca-bd41-eb0c6bbdb032") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:01.883+0000 I  NETWORK  [conn208] end connection 172.31.0.221:44822 (59 connections now open)
2020-05-08T21:59:02.091+0000 I  NETWORK  [conn214] end connection 172.31.0.221:44876 (58 connections now open)
2020-05-08T21:59:02.092+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45126 #222 (59 connections now open)
2020-05-08T21:59:02.092+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45128 #223 (60 connections now open)
2020-05-08T21:59:02.092+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:45126 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:02.092+0000 I  NETWORK  [conn223] received client metadata from 172.31.0.221:45128 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:02.097+0000 I  -        [conn213] operation was interrupted because a client disconnected
2020-05-08T21:59:02.097+0000 I  CONNPOOL [conn213] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:02.097+0000 I  TXN      [conn213] transaction parameters:{ lsid: { id: UUID("b2b06950-b417-4afa-bc51-9e10016a0066"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975136, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005449, timeInactiveMicros:0, 5005ms
2020-05-08T21:59:02.097+0000 I  COMMAND  [conn213] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 617 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975136, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b2b06950-b417-4afa-bc51-9e10016a0066") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:02.097+0000 I  NETWORK  [conn213] end connection 172.31.0.221:44874 (59 connections now open)
2020-05-08T21:59:04.372+0000 I  NETWORK  [conn217] end connection 172.31.0.221:44984 (58 connections now open)
2020-05-08T21:59:04.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45238 #225 (59 connections now open)
2020-05-08T21:59:04.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45240 #226 (60 connections now open)
2020-05-08T21:59:04.372+0000 I  NETWORK  [conn225] received client metadata from 172.31.0.221:45238 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.372+0000 I  NETWORK  [conn226] received client metadata from 172.31.0.221:45240 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.374+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.894+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:59:04.895+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:05.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:06.790+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 4), t: 38 }, now { ts: Timestamp(1588975146, 1), t: 41 }
2020-05-08T21:59:06.790+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:06.791+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:06.791+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:06.879+0000 I  NETWORK  [conn220] end connection 172.31.0.221:45088 (59 connections now open)
2020-05-08T21:59:06.880+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45298 #229 (60 connections now open)
2020-05-08T21:59:06.880+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45300 #230 (61 connections now open)
2020-05-08T21:59:06.880+0000 I  NETWORK  [conn229] received client metadata from 172.31.0.221:45298 conn229: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.880+0000 I  NETWORK  [conn230] received client metadata from 172.31.0.221:45300 conn230: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.881+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:07.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:07.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:07.092+0000 I  NETWORK  [conn222] end connection 172.31.0.221:45126 (60 connections now open)
2020-05-08T21:59:07.093+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45316 #234 (61 connections now open)
2020-05-08T21:59:07.093+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45314 #235 (62 connections now open)
2020-05-08T21:59:07.093+0000 I  NETWORK  [conn234] received client metadata from 172.31.0.221:45316 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:07.093+0000 I  NETWORK  [conn235] received client metadata from 172.31.0.221:45314 conn235: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.059+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:09.377+0000 I  NETWORK  [conn226] end connection 172.31.0.221:45240 (61 connections now open)
2020-05-08T21:59:09.377+0000 I  -        [conn225] operation was interrupted because a client disconnected
2020-05-08T21:59:09.378+0000 I  CONNPOOL [conn225] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T21:59:09.378+0000 I  TXN      [conn225] transaction parameters:{ lsid: { id: UUID("7b10757f-1b0a-40b8-afdc-41a76727ef85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975136, 5) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004017, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:09.378+0000 I  COMMAND  [conn225] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 618 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975136, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7b10757f-1b0a-40b8-afdc-41a76727ef85") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:09.378+0000 I  NETWORK  [conn225] end connection 172.31.0.221:45238 (60 connections now open)
2020-05-08T21:59:09.378+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45370 #239 (61 connections now open)
2020-05-08T21:59:09.379+0000 I  NETWORK  [conn239] received client metadata from 172.31.0.221:45370 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45376 #240 (62 connections now open)
2020-05-08T21:59:09.379+0000 I  NETWORK  [conn240] received client metadata from 172.31.0.221:45376 conn240: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.384+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.385+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.612+0000 I  NETWORK  [conn239] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:09.613+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.613+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:11.202+0000 I  NETWORK  [conn239] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:11.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.703+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.881+0000 I  NETWORK  [conn230] end connection 172.31.0.221:45300 (61 connections now open)
2020-05-08T21:59:11.881+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45432 #241 (62 connections now open)
2020-05-08T21:59:11.882+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45434 #242 (63 connections now open)
2020-05-08T21:59:11.882+0000 I  NETWORK  [conn241] received client metadata from 172.31.0.221:45432 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.882+0000 I  NETWORK  [conn242] received client metadata from 172.31.0.221:45434 conn242: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.883+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.886+0000 I  -        [conn229] operation was interrupted because a client disconnected
2020-05-08T21:59:11.886+0000 I  CONNPOOL [conn229] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:11.887+0000 I  TXN      [conn229] transaction parameters:{ lsid: { id: UUID("58c3cd8a-d672-43fd-8c8e-32e874256a58"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 501) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005451, timeInactiveMicros:0, 5005ms
2020-05-08T21:59:11.887+0000 I  COMMAND  [conn229] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 668 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 501), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58c3cd8a-d672-43fd-8c8e-32e874256a58") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:11.887+0000 I  NETWORK  [conn229] end connection 172.31.0.221:45298 (62 connections now open)
2020-05-08T21:59:12.093+0000 I  NETWORK  [conn234] end connection 172.31.0.221:45316 (61 connections now open)
2020-05-08T21:59:12.094+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45448 #243 (62 connections now open)
2020-05-08T21:59:12.094+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45450 #244 (63 connections now open)
2020-05-08T21:59:12.094+0000 I  NETWORK  [conn243] received client metadata from 172.31.0.221:45448 conn243: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.094+0000 I  NETWORK  [conn244] received client metadata from 172.31.0.221:45450 conn244: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.095+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:12.097+0000 I  -        [conn235] operation was interrupted because a client disconnected
2020-05-08T21:59:12.097+0000 I  CONNPOOL [conn235] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:12.097+0000 I  TXN      [conn235] transaction parameters:{ lsid: { id: UUID("eb347a4a-8856-4cbf-9bbb-4ddd3aa0bb8b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 501) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003227, timeInactiveMicros:0, 5003ms
2020-05-08T21:59:12.097+0000 I  COMMAND  [conn235] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 670 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 501), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb347a4a-8856-4cbf-9bbb-4ddd3aa0bb8b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:12.097+0000 I  NETWORK  [conn235] end connection 172.31.0.221:45314 (62 connections now open)
2020-05-08T21:59:12.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.703+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:13.203+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.203+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.743+0000 I  NETWORK  [conn241] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:13.743+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:14.243+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.243+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.244+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:14.244+0000 I  TXN      [conn241] transaction parameters:{ lsid: { id: UUID("9404e223-3da9-4e30-9dae-f127396e58f1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 110) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2361789, timeInactiveMicros:0, 2361ms
2020-05-08T21:59:14.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:14.244+0000 I  COMMAND  [conn241] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9404e223-3da9-4e30-9dae-f127396e58f1") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2361ms
2020-05-08T21:59:14.379+0000 I  NETWORK  [conn240] end connection 172.31.0.221:45376 (61 connections now open)
2020-05-08T21:59:14.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45524 #246 (62 connections now open)
2020-05-08T21:59:14.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45526 #247 (63 connections now open)
2020-05-08T21:59:14.380+0000 I  NETWORK  [conn247] received client metadata from 172.31.0.221:45526 conn247: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.380+0000 I  NETWORK  [conn246] received client metadata from 172.31.0.221:45524 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.382+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.704+0000 I  COMMAND  [conn239] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 501), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b6acadf8-1a99-4aaa-b20f-72f71b4e2565") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 5320ms
2020-05-08T21:59:14.704+0000 I  NETWORK  [conn239] end connection 172.31.0.221:45370 (62 connections now open)
2020-05-08T21:59:14.708+0000 I  COMMAND  [conn241] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975154, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9404e223-3da9-4e30-9dae-f127396e58f1") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 462ms
2020-05-08T21:59:14.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:15.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:15.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.426+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b96b7369da8ea76060 to 5eb5d5b9883dd86ab8e095b5; invalidating user cache
2020-05-08T21:59:16.744+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.744+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.745+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 3), t: 43 }
2020-05-08T21:59:16.882+0000 I  NETWORK  [conn242] end connection 172.31.0.221:45434 (61 connections now open)
2020-05-08T21:59:16.883+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45614 #250 (62 connections now open)
2020-05-08T21:59:16.883+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45616 #251 (63 connections now open)
2020-05-08T21:59:16.883+0000 I  NETWORK  [conn250] received client metadata from 172.31.0.221:45614 conn250: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.883+0000 I  NETWORK  [conn251] received client metadata from 172.31.0.221:45616 conn251: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.885+0000 I  NETWORK  [conn250] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.886+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.094+0000 I  NETWORK  [conn244] end connection 172.31.0.221:45450 (62 connections now open)
2020-05-08T21:59:17.095+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45630 #252 (63 connections now open)
2020-05-08T21:59:17.095+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45632 #253 (64 connections now open)
2020-05-08T21:59:17.095+0000 I  NETWORK  [conn252] received client metadata from 172.31.0.221:45630 conn252: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:17.095+0000 I  NETWORK  [conn253] received client metadata from 172.31.0.221:45632 conn253: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:17.096+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.385+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.885+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.885+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.886+0000 I  TXN      [conn250] transaction parameters:{ lsid: { id: UUID("d71c5d79-92b6-425d-9a8a-a69274b04802"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975156, 8) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1001927, timeInactiveMicros:0, 1001ms
2020-05-08T21:59:17.886+0000 I  COMMAND  [conn250] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975156, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d71c5d79-92b6-425d-9a8a-a69274b04802") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1002ms
2020-05-08T21:59:17.887+0000 I  TXN      [conn252] transaction parameters:{ lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975156, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:791341, timeInactiveMicros:0, 791ms
2020-05-08T21:59:17.887+0000 I  COMMAND  [conn252] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975156, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 791ms
2020-05-08T21:59:17.901+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:18.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:18.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:18.797+0000 I  COMMAND  [conn252] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb") }, txnNumber: 3, autocommit: false } numYields:0 reslen:320 protocol:op_msg 887ms
2020-05-08T21:59:18.854+0000 I  NETWORK  [conn252] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:18.855+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.355+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.380+0000 I  NETWORK  [conn247] end connection 172.31.0.221:45526 (63 connections now open)
2020-05-08T21:59:19.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45700 #257 (64 connections now open)
2020-05-08T21:59:19.380+0000 I  NETWORK  [conn257] received client metadata from 172.31.0.221:45700 conn257: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45702 #258 (65 connections now open)
2020-05-08T21:59:19.381+0000 I  NETWORK  [conn258] received client metadata from 172.31.0.221:45702 conn258: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.383+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.855+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.855+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.856+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.856+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.856+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.857+0000 I  TXN      [conn252] transaction parameters:{ lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 51) } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 51) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1008696, timeInactiveMicros:0, 1008ms
2020-05-08T21:59:19.857+0000 I  COMMAND  [conn252] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb") }, txnNumber: 6, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 51) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1008ms
2020-05-08T21:59:19.870+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.870+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:20.283+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:22.902+0000 I  -        [conn250] operation was interrupted because a client disconnected
2020-05-08T21:59:22.902+0000 I  CONNPOOL [conn250] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 9 connections to that host remain open
2020-05-08T21:59:22.903+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45844 #261 (66 connections now open)
2020-05-08T21:59:22.903+0000 I  TXN      [conn250] transaction parameters:{ lsid: { id: UUID("d71c5d79-92b6-425d-9a8a-a69274b04802"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 105) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002814, timeInactiveMicros:255, 5003ms
2020-05-08T21:59:22.903+0000 I  COMMAND  [conn250] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 738 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 107), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d71c5d79-92b6-425d-9a8a-a69274b04802") }, txnNumber: 3, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:22.903+0000 I  NETWORK  [conn250] end connection 172.31.0.221:45614 (65 connections now open)
2020-05-08T21:59:22.903+0000 I  NETWORK  [conn261] received client metadata from 172.31.0.221:45844 conn261: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:22.904+0000 I  NETWORK  [conn261] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:22.904+0000 I  NETWORK  [conn261] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:22.904+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:22.905+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:22.905+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:22.906+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:22.906+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:23.404+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.406+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:23.904+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.904+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.905+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.905+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.446+0000 I  NETWORK  [conn261] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:24.447+0000 I  NETWORK  [conn261] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:24.447+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.447+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:24.470+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:24.868+0000 I  -        [conn252] operation was interrupted because a client disconnected
2020-05-08T21:59:24.868+0000 I  CONNPOOL [conn252] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T21:59:24.868+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45874 #262 (66 connections now open)
2020-05-08T21:59:24.869+0000 I  TXN      [conn252] transaction parameters:{ lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975159, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975159, 10) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006807, timeInactiveMicros:282, 5007ms
2020-05-08T21:59:24.869+0000 I  NETWORK  [conn262] received client metadata from 172.31.0.221:45874 conn262: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.869+0000 I  COMMAND  [conn252] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 738 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975159, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a8110cd1-9df8-4ddd-99dc-182df7f38ddb") }, txnNumber: 7, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T21:59:24.869+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:24.869+0000 I  NETWORK  [conn252] end connection 172.31.0.221:45630 (65 connections now open)
2020-05-08T21:59:24.870+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:24.946+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:24.947+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:25.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:25.947+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:26.172+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 7 connections to that host remain open
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn253] end connection 172.31.0.221:45632 (63 connections now open)
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn258] end connection 172.31.0.221:45702 (64 connections now open)
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn251] end connection 172.31.0.221:45616 (62 connections now open)
2020-05-08T21:59:26.426+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45886 #263 (63 connections now open)
2020-05-08T21:59:26.427+0000 I  NETWORK  [conn263] received client metadata from 172.31.0.221:45886 conn263: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:26.429+0000 I  NETWORK  [conn263] end connection 172.31.0.221:45886 (62 connections now open)
2020-05-08T21:59:26.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:26.848+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:26.947+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:27.044+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:27.382+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975166, 4), t: 47 }
2020-05-08T21:59:27.382+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:27.383+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:27.383+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:27.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:27.947+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:28.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:28.947+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:29.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:29.947+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:30.447+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
