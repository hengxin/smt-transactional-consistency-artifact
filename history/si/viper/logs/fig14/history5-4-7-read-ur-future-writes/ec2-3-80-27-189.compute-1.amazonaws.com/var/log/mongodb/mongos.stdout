2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.222+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.225+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.225+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-6-51:27017:1588975035:4123909040511173159 (sleeping for 30000ms)
2020-05-08T21:57:15.228+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.228+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.228+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 12), t: 1 }
2020-05-08T21:57:15.422+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.423+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.426+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.426+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.429+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("baf4a026-60fb-4c55-af65-c3ac6ac0ab4c"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.429+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.429+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.435+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52912 #10 (1 connection now open)
2020-05-08T21:57:16.435+0000 I  NETWORK  [conn10] received client metadata from 172.31.0.221:52912 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.507+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52924 #11 (2 connections now open)
2020-05-08T21:57:16.507+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:52924 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.834+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52932 #12 (3 connections now open)
2020-05-08T21:57:16.834+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:52932 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.859+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52934 #13 (4 connections now open)
2020-05-08T21:57:16.860+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:52934 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.884+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52938 #14 (5 connections now open)
2020-05-08T21:57:16.884+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:52938 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.092+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52988 #15 (6 connections now open)
2020-05-08T21:57:17.093+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:52988 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.145+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52998 #16 (7 connections now open)
2020-05-08T21:57:17.146+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:52998 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53044 #17 (8 connections now open)
2020-05-08T21:57:17.306+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:53044 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53046 #18 (9 connections now open)
2020-05-08T21:57:17.307+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:53046 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.309+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53048 #19 (10 connections now open)
2020-05-08T21:57:17.309+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:53048 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.309+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53050 #20 (11 connections now open)
2020-05-08T21:57:17.309+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:53050 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.399+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.399+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.399+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.399+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.401+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.401+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53060 #24 (12 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn24] received client metadata from 172.31.0.221:53060 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.446+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.446+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.446+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.446+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.446+0000 I  NETWORK  [conn19] end connection 172.31.0.221:53048 (11 connections now open)
2020-05-08T21:57:17.447+0000 I  NETWORK  [conn20] end connection 172.31.0.221:53050 (10 connections now open)
2020-05-08T21:57:17.448+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.448+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:17.452+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53076 #28 (11 connections now open)
2020-05-08T21:57:17.452+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53078 #29 (12 connections now open)
2020-05-08T21:57:17.452+0000 I  NETWORK  [conn29] received client metadata from 172.31.0.221:53078 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.452+0000 I  NETWORK  [conn28] received client metadata from 172.31.0.221:53076 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.516+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53110 #30 (13 connections now open)
2020-05-08T21:57:17.705+0000 I  NETWORK  [conn30] received client metadata from 172.31.0.221:53110 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.727+0000 I  COMMAND  [conn28] command jepsendb.jepsencoll command: shardCollection { shardCollection: "jepsendb.jepsencoll", key: { _id: "hashed" }, numInitialChunks: 7, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1d0a3c5e-2c15-4884-b78a-e215f8ed4393") } } numYields:0 reslen:243 protocol:op_msg 175ms
2020-05-08T21:57:17.727+0000 I  NETWORK  [conn28] end connection 172.31.0.221:53076 (12 connections now open)
2020-05-08T21:57:17.727+0000 I  NETWORK  [conn29] end connection 172.31.0.221:53078 (11 connections now open)
2020-05-08T21:57:17.780+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53120 #31 (12 connections now open)
2020-05-08T21:57:17.780+0000 I  NETWORK  [conn31] received client metadata from 172.31.0.221:53120 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.836+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53150 #32 (13 connections now open)
2020-05-08T21:57:17.836+0000 I  NETWORK  [conn32] received client metadata from 172.31.0.221:53150 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.866+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53162 #33 (14 connections now open)
2020-05-08T21:57:18.866+0000 I  NETWORK  [conn33] received client metadata from 172.31.0.221:53162 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.249+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53172 #34 (15 connections now open)
2020-05-08T21:57:19.250+0000 I  NETWORK  [conn34] received client metadata from 172.31.0.221:53172 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.466+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53178 #35 (16 connections now open)
2020-05-08T21:57:19.466+0000 I  NETWORK  [conn35] received client metadata from 172.31.0.221:53178 conn35: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.514+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53192 #36 (17 connections now open)
2020-05-08T21:57:19.514+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:53192 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53204 #37 (18 connections now open)
2020-05-08T21:57:19.561+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:53204 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.843+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53218 #38 (19 connections now open)
2020-05-08T21:57:19.843+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:53218 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.996+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53230 #39 (20 connections now open)
2020-05-08T21:57:19.996+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:53230 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.189+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53254 #40 (21 connections now open)
2020-05-08T21:57:20.190+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:53254 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.207+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53264 #41 (22 connections now open)
2020-05-08T21:57:20.207+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:53264 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.642+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53308 #42 (23 connections now open)
2020-05-08T21:57:21.642+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:53308 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.782+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53310 #43 (24 connections now open)
2020-05-08T21:57:21.783+0000 I  NETWORK  [conn43] received client metadata from 172.31.0.221:53310 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.908+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53336 #44 (25 connections now open)
2020-05-08T21:57:21.908+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:53336 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.060+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53390 #45 (26 connections now open)
2020-05-08T21:57:22.060+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53394 #46 (27 connections now open)
2020-05-08T21:57:22.060+0000 I  NETWORK  [conn45] received client metadata from 172.31.0.221:53390 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.060+0000 I  NETWORK  [conn46] received client metadata from 172.31.0.221:53394 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.072+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.076+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53452 #48 (28 connections now open)
2020-05-08T21:57:22.076+0000 I  NETWORK  [conn48] received client metadata from 172.31.0.221:53452 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.077+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53456 #49 (29 connections now open)
2020-05-08T21:57:22.077+0000 I  NETWORK  [conn49] received client metadata from 172.31.0.221:53456 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.077+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53460 #50 (30 connections now open)
2020-05-08T21:57:22.078+0000 I  NETWORK  [conn50] received client metadata from 172.31.0.221:53460 conn50: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.079+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53466 #51 (31 connections now open)
2020-05-08T21:57:22.079+0000 I  NETWORK  [conn51] received client metadata from 172.31.0.221:53466 conn51: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.324+0000 I  COMMAND  [conn48] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 220ms
2020-05-08T21:57:22.325+0000 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 216ms
2020-05-08T21:57:22.330+0000 I  TXN      [conn46] transaction parameters:{ lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 9) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 9) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:224212, timeActiveMicros:244473, timeInactiveMicros:996, 245ms
2020-05-08T21:57:22.330+0000 I  COMMAND  [conn46] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 224ms
2020-05-08T21:57:22.516+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53512 #57 (32 connections now open)
2020-05-08T21:57:22.516+0000 I  NETWORK  [conn57] received client metadata from 172.31.0.221:53512 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.102+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53552 #65 (33 connections now open)
2020-05-08T21:57:23.102+0000 I  NETWORK  [conn65] received client metadata from 172.31.0.221:53552 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.368+0000 I  COMMAND  [conn46] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 344), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6") }, txnNumber: 11, autocommit: false } numYields:0 reslen:352 protocol:op_msg 845ms
2020-05-08T21:57:23.368+0000 I  COMMAND  [conn48] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 344), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 8, autocommit: false } numYields:0 reslen:351 protocol:op_msg 845ms
2020-05-08T21:57:23.368+0000 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 336), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 10, autocommit: false } numYields:0 reslen:321 protocol:op_msg 849ms
2020-05-08T21:57:23.377+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.416+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53572 #68 (34 connections now open)
2020-05-08T21:57:23.417+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:53572 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.740+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53612 #69 (35 connections now open)
2020-05-08T21:57:23.741+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:53612 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.777+0000 I  COMMAND  [conn48] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 114), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 24, autocommit: false } numYields:0 reslen:352 protocol:op_msg 215ms
2020-05-08T21:57:24.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53664 #70 (36 connections now open)
2020-05-08T21:57:24.471+0000 I  NETWORK  [conn70] received client metadata from 172.31.0.221:53664 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.616+0000 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 12, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975043, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 1208ms
2020-05-08T21:57:25.126+0000 I  COMMAND  [conn48] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 180), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 79, autocommit: false } numYields:0 reslen:352 protocol:op_msg 847ms
2020-05-08T21:57:25.132+0000 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 188), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 13, autocommit: false } numYields:0 reslen:321 protocol:op_msg 510ms
2020-05-08T21:57:25.182+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53694 #71 (37 connections now open)
2020-05-08T21:57:25.183+0000 I  NETWORK  [conn71] received client metadata from 172.31.0.221:53694 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.420+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53728 #72 (38 connections now open)
2020-05-08T21:57:25.420+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:53728 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.509+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53754 #73 (39 connections now open)
2020-05-08T21:57:25.509+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:53754 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.549+0000 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 14, autocommit: false } numYields:0 reslen:321 protocol:op_msg 408ms
2020-05-08T21:57:25.553+0000 I  TXN      [conn46] transaction parameters:{ lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 6) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:2177547, timeActiveMicros:2184400, timeInactiveMicros:806, 2185ms
2020-05-08T21:57:25.553+0000 I  COMMAND  [conn46] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6") }, txnNumber: 12, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2177ms
2020-05-08T21:57:25.555+0000 I  TXN      [conn48] transaction parameters:{ lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 81, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 15) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:415070, timeInactiveMicros:269, 415ms
2020-05-08T21:57:25.555+0000 I  COMMAND  [conn48] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 81, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 413ms
2020-05-08T21:57:25.559+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53770 #76 (40 connections now open)
2020-05-08T21:57:25.672+0000 I  NETWORK  [conn76] received client metadata from 172.31.0.221:53770 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.130+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53800 #78 (41 connections now open)
2020-05-08T21:57:26.130+0000 I  NETWORK  [conn78] received client metadata from 172.31.0.221:53800 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53804 #79 (42 connections now open)
2020-05-08T21:57:26.364+0000 I  NETWORK  [conn79] received client metadata from 172.31.0.221:53804 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.458+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 93), t: 3 }
2020-05-08T21:57:26.945+0000 I  NETWORK  [conn46] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:26.946+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.950+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.445+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.945+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:28.445+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.445+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.446+0000 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 31, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 668) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 668) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2508486, timeInactiveMicros:264, 2508ms
2020-05-08T21:57:28.446+0000 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 668), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 31, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2507ms
2020-05-08T21:57:28.447+0000 I  TXN      [conn48] transaction parameters:{ lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 95, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 668) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 668) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2509030, timeInactiveMicros:286, 2509ms
2020-05-08T21:57:28.447+0000 I  COMMAND  [conn48] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 46 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 683), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 95, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 95 does not match any in-progress transactions. The active transaction number is 89" errName:NoSuchTransaction errCode:251 reslen:438 protocol:op_msg 2496ms
2020-05-08T21:57:28.455+0000 I  TXN      [conn46] transaction parameters:{ lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 673) }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2513436, timeInactiveMicros:0, 2513ms
2020-05-08T21:57:28.455+0000 I  COMMAND  [conn46] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 60 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 673), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6") }, txnNumber: 29, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 45f6d35d-0d0b-4970-b817-8afceaf5e4b6:29 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:627 protocol:op_msg 2513ms
2020-05-08T21:57:28.462+0000 I  NETWORK  [conn50] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:28.463+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.466+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.474+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.963+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.963+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.963+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.964+0000 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 8) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:506661, timeInactiveMicros:613, 507ms
2020-05-08T21:57:28.964+0000 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 32, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 502ms
2020-05-08T21:57:28.965+0000 I  COMMAND  [conn46] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 61 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:277 protocol:op_msg 491ms
2020-05-08T21:57:29.170+0000 I  NETWORK  [conn50] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:29.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.463+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.963+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.463+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.705+0000 I  NETWORK  [conn48] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:30.705+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:30.707+0000 I  NETWORK  [conn46] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 45f6d35d-0d0b-4970-b817-8afceaf5e4b6:31 stopped due to: operation was interrupted
2020-05-08T21:57:30.707+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:30.829+0000 I  NETWORK  [conn51] end connection 172.31.0.221:53466 (41 connections now open)
2020-05-08T21:57:30.830+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53902 #82 (42 connections now open)
2020-05-08T21:57:30.830+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53904 #83 (43 connections now open)
2020-05-08T21:57:30.830+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:53902 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.830+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:53904 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.831+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.864+0000 I  NETWORK  [conn49] end connection 172.31.0.221:53456 (42 connections now open)
2020-05-08T21:57:30.864+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53910 #84 (43 connections now open)
2020-05-08T21:57:30.865+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53912 #85 (44 connections now open)
2020-05-08T21:57:30.865+0000 I  NETWORK  [conn85] received client metadata from 172.31.0.221:53912 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.865+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:53910 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.867+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.963+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:31.205+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.205+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.206+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.463+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.463+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.463+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.464+0000 I  COMMAND  [conn50] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975048, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b5d781f9-7b1b-41ad-8c9f-d0301b80cf85") }, txnNumber: 32, autocommit: false } numYields:0 reslen:352 protocol:op_msg 2499ms
2020-05-08T21:57:31.464+0000 I  NETWORK  [conn50] end connection 172.31.0.221:53460 (43 connections now open)
2020-05-08T21:57:31.990+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1159ms
2020-05-08T21:57:31.990+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 55 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1124ms
2020-05-08T21:57:32.002+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1135372, timeInactiveMicros:691, 1136ms
2020-05-08T21:57:32.964+0000 I  NETWORK  [conn48] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:32.965+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:32.966+0000 I  TXN      [conn46] transaction parameters:{ lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 31, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 15) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:3995747, timeActiveMicros:3999072, timeInactiveMicros:1005, 4000ms
2020-05-08T21:57:32.966+0000 I  COMMAND  [conn46] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975048, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("45f6d35d-0d0b-4970-b817-8afceaf5e4b6") }, txnNumber: 31, autocommit: false } numYields:0 reslen:311 protocol:op_msg 3995ms
2020-05-08T21:57:32.967+0000 I  NETWORK  [conn46] end connection 172.31.0.221:53394 (42 connections now open)
2020-05-08T21:57:32.967+0000 I  NETWORK  [conn45] end connection 172.31.0.221:53390 (41 connections now open)
2020-05-08T21:57:32.968+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54024 #88 (42 connections now open)
2020-05-08T21:57:32.968+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54026 #89 (43 connections now open)
2020-05-08T21:57:32.968+0000 I  NETWORK  [conn88] received client metadata from 172.31.0.221:54024 conn88: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:32.968+0000 I  NETWORK  [conn89] received client metadata from 172.31.0.221:54026 conn89: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:32.969+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.204+0000 I  NETWORK  [conn84] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:33.205+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.216+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.461+0000 I  -        [conn48] operation was interrupted because a client disconnected
2020-05-08T21:57:33.462+0000 I  TXN      [conn48] transaction parameters:{ lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 96, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 8) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005267, timeInactiveMicros:0, 5005ms
2020-05-08T21:57:33.462+0000 I  COMMAND  [conn48] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 56 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("af9f6f28-db02-4bfa-bb11-8870e723089e") }, txnNumber: 96, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:57:33.462+0000 I  NETWORK  [conn48] end connection 172.31.0.221:53452 (42 connections now open)
2020-05-08T21:57:33.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.465+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.704+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.704+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.705+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:33.705+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.705+0000 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2874029, timeInactiveMicros:480, 2874ms
2020-05-08T21:57:33.705+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975051, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1715ms
2020-05-08T21:57:33.706+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.706+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975052, 44) } }, globalReadTimestamp:{ ts: Timestamp(1588975052, 44) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:1639873, timeInactiveMicros:248, 1640ms
2020-05-08T21:57:33.706+0000 I  COMMAND  [conn88] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975052, 67), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 733ms
2020-05-08T21:57:33.706+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975052, 44), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24") }, txnNumber: 6, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 6 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 1639ms
2020-05-08T21:57:33.706+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:33.724+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.965+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:34.146+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24") }, txnNumber: 7, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 430ms
2020-05-08T21:57:34.147+0000 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975053, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975053, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:432717, timeInactiveMicros:0, 432ms
2020-05-08T21:57:34.147+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975053, 12) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 432ms
2020-05-08T21:57:34.149+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975053, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975053, 12) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:433816, timeInactiveMicros:705, 434ms
2020-05-08T21:57:34.184+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.184+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.186+0000 I  TXN      [conn88] transaction parameters:{ lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975053, 13) } }, globalReadTimestamp:{ ts: Timestamp(1588975053, 13) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:464536, timeInactiveMicros:830, 465ms
2020-05-08T21:57:34.186+0000 I  COMMAND  [conn88] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 462ms
2020-05-08T21:57:34.330+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.737+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:35.048+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 44, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 819) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:230879, timeActiveMicros:250577, timeInactiveMicros:2673, 253ms
2020-05-08T21:57:35.048+0000 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 846), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24") }, txnNumber: 44, autocommit: false } numYields:0 reslen:214 protocol:op_msg 230ms
2020-05-08T21:57:35.056+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 865), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 32, autocommit: false } numYields:0 reslen:321 protocol:op_msg 217ms
2020-05-08T21:57:35.058+0000 I  COMMAND  [conn88] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 874), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff") }, txnNumber: 33, autocommit: false } numYields:0 reslen:321 protocol:op_msg 214ms
2020-05-08T21:57:35.810+0000 I  NETWORK  [conn84] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:35.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:35.870+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:35.870+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:35.871+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.176+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54122 #94 (43 connections now open)
2020-05-08T21:57:36.176+0000 I  NETWORK  [conn94] received client metadata from 172.31.0.221:54122 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.371+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.871+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.871+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.871+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.876+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 81), t: 6 }
2020-05-08T21:57:37.186+0000 I  NETWORK  [conn88] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:37.187+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:37.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.687+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.687+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.688+0000 I  COMMAND  [conn88] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975056, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff") }, txnNumber: 154, autocommit: false } numYields:0 reslen:471 protocol:op_msg 1509ms
2020-05-08T21:57:37.688+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975056, 76), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 155, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1503ms
2020-05-08T21:57:37.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.045+0000 I  NETWORK  [conn82] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.046+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:39.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.545+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.545+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.546+0000 I  SHARDING [conn82] Received reply from shard ec2-34-207-119-213.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:39.546+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975058, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 203, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1501ms
2020-05-08T21:57:39.546+0000 I  COMMAND  [conn88] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975058, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff") }, txnNumber: 203, autocommit: false } numYields:0 reslen:471 protocol:op_msg 1496ms
2020-05-08T21:57:39.554+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.810+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.810+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.814+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 127 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 204, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:383 protocol:op_msg 260ms
2020-05-08T21:57:39.815+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.057+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 59, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975055, 411) } }, globalReadTimestamp:{ ts: Timestamp(1588975055, 411) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:4681524, timeActiveMicros:4691483, timeInactiveMicros:550, 4692ms
2020-05-08T21:57:40.057+0000 I  NETWORK  [conn84] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.244+0000 I  NETWORK  [conn83] end connection 172.31.0.221:53904 (42 connections now open)
2020-05-08T21:57:40.245+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54184 #97 (43 connections now open)
2020-05-08T21:57:40.245+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54186 #98 (44 connections now open)
2020-05-08T21:57:40.245+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:54184 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.245+0000 I  NETWORK  [conn98] received client metadata from 172.31.0.221:54186 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.264+0000 I  NETWORK  [conn89] end connection 172.31.0.221:54026 (43 connections now open)
2020-05-08T21:57:40.264+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54190 #99 (44 connections now open)
2020-05-08T21:57:40.264+0000 I  NETWORK  [conn99] received client metadata from 172.31.0.221:54190 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.264+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54192 #100 (45 connections now open)
2020-05-08T21:57:40.264+0000 I  NETWORK  [conn100] received client metadata from 172.31.0.221:54192 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.265+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.294+0000 I  NETWORK  [conn85] end connection 172.31.0.221:53912 (44 connections now open)
2020-05-08T21:57:40.294+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54206 #101 (45 connections now open)
2020-05-08T21:57:40.295+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54208 #102 (46 connections now open)
2020-05-08T21:57:40.295+0000 I  NETWORK  [conn101] received client metadata from 172.31.0.221:54206 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.295+0000 I  NETWORK  [conn102] received client metadata from 172.31.0.221:54208 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.296+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.386+0000 I  COMMAND  [conn84] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 423), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("99d6b727-cb56-486d-99e3-390254295b24") }, txnNumber: 59, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5010ms
2020-05-08T21:57:40.386+0000 I  NETWORK  [conn84] end connection 172.31.0.221:53910 (45 connections now open)
2020-05-08T21:57:40.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.323+0000 I  NETWORK  [conn88] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.323+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.328+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.570+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54304 #103 (46 connections now open)
2020-05-08T21:57:41.570+0000 I  NETWORK  [conn103] received client metadata from 172.31.0.221:54304 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:41.810+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.810+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.810+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:41.823+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.823+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.823+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.824+0000 I  TXN      [conn88] transaction parameters:{ lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 246, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975059, 60) } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 60) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1991807, timeInactiveMicros:252, 1992ms
2020-05-08T21:57:41.824+0000 I  COMMAND  [conn88] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 60), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6b285b10-f8f9-4301-96d4-15841b0bbfff") }, txnNumber: 246, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1991ms
2020-05-08T21:57:41.824+0000 I  NETWORK  [conn88] end connection 172.31.0.221:54024 (45 connections now open)
2020-05-08T21:57:42.062+0000 I  COMMAND  [conn98] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1815ms
2020-05-08T21:57:42.062+0000 I  COMMAND  [conn99] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 133 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("486d8575-fbd1-4209-bb85-496f280141b6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1797ms
2020-05-08T21:57:42.062+0000 I  COMMAND  [conn101] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 133 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("845da831-b782-4856-96a8-4ffe289712e9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1766ms
2020-05-08T21:57:42.071+0000 I  TXN      [conn99] transaction parameters:{ lsid: { id: UUID("486d8575-fbd1-4209-bb85-496f280141b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:6276, timeActiveMicros:1805311, timeInactiveMicros:662, 1805ms
2020-05-08T21:57:42.071+0000 I  TXN      [conn101] transaction parameters:{ lsid: { id: UUID("845da831-b782-4856-96a8-4ffe289712e9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:7109, timeActiveMicros:1774405, timeInactiveMicros:714, 1775ms
2020-05-08T21:57:42.815+0000 I  NETWORK  [Sharding-Fixed-4] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:42.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.878+0000 I  NETWORK  [Sharding-Fixed-4] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:42.879+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.035+0000 I  NETWORK  [conn98] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:43.036+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.037+0000 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 204, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975059, 4) } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 4) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:3222198, timeActiveMicros:3484200, timeInactiveMicros:1234, 3485ms
2020-05-08T21:57:43.037+0000 I  COMMAND  [conn82] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2078de17-00ea-453b-9048-3489cee81302") }, txnNumber: 204, autocommit: false } numYields:0 reslen:311 protocol:op_msg 3222ms
2020-05-08T21:57:43.038+0000 I  NETWORK  [conn82] end connection 172.31.0.221:53902 (44 connections now open)
2020-05-08T21:57:43.134+0000 I  NETWORK  [Sharding-Fixed-4] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:43.135+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.536+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.536+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.537+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.537+0000 I  TXN      [conn98] transaction parameters:{ lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975062, 24) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1443801, timeInactiveMicros:549, 1444ms
2020-05-08T21:57:43.537+0000 I  COMMAND  [conn98] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf") }, txnNumber: 4, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1441ms
2020-05-08T21:57:43.537+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.537+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.171+0000 I  NETWORK  [conn98] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:44.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.211+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.255+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54382 #111 (45 connections now open)
2020-05-08T21:57:45.255+0000 I  NETWORK  [conn111] received client metadata from 172.31.0.221:54382 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.671+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.671+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.672+0000 I  COMMAND  [conn98] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975063, 101), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf") }, txnNumber: 4, autocommit: false } numYields:0 reslen:320 protocol:op_msg 2134ms
2020-05-08T21:57:45.794+0000 I  NETWORK  [conn101] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.795+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:45.800+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.105+0000 I  TXN      [conn98] transaction parameters:{ lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 7) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:432279, timeInactiveMicros:641, 432ms
2020-05-08T21:57:46.106+0000 I  COMMAND  [conn98] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf") }, txnNumber: 5, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 429ms
2020-05-08T21:57:46.107+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.295+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.795+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.072+0000 I  NETWORK  [conn100] end connection 172.31.0.221:54192 (44 connections now open)
2020-05-08T21:57:47.073+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54490 #112 (45 connections now open)
2020-05-08T21:57:47.073+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54492 #113 (46 connections now open)
2020-05-08T21:57:47.073+0000 I  NETWORK  [conn112] received client metadata from 172.31.0.221:54490 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.073+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:54492 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.076+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.080+0000 I  NETWORK  [conn102] end connection 172.31.0.221:54208 (45 connections now open)
2020-05-08T21:57:47.081+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54498 #114 (46 connections now open)
2020-05-08T21:57:47.081+0000 I  NETWORK  [conn114] received client metadata from 172.31.0.221:54498 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.081+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54500 #115 (47 connections now open)
2020-05-08T21:57:47.081+0000 I  NETWORK  [conn115] received client metadata from 172.31.0.221:54500 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.093+0000 I  NETWORK  [conn97] end connection 172.31.0.221:54184 (46 connections now open)
2020-05-08T21:57:47.093+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54502 #116 (47 connections now open)
2020-05-08T21:57:47.093+0000 I  NETWORK  [conn116] received client metadata from 172.31.0.221:54502 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.093+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54504 #117 (48 connections now open)
2020-05-08T21:57:47.094+0000 I  NETWORK  [conn117] received client metadata from 172.31.0.221:54504 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.295+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.390+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:47.391+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.518+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.795+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.891+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.158+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:57:48.295+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.295+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.296+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.296+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.296+0000 I  TXN      [conn101] transaction parameters:{ lsid: { id: UUID("845da831-b782-4856-96a8-4ffe289712e9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975062, 28) } }, globalReadTimestamp:{ ts: Timestamp(1588975062, 28) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6197653, timeInactiveMicros:0, 6197ms
2020-05-08T21:57:48.297+0000 I  COMMAND  [conn101] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("845da831-b782-4856-96a8-4ffe289712e9") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975062, 28) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 6197ms
2020-05-08T21:57:48.297+0000 I  NETWORK  [conn101] end connection 172.31.0.221:54206 (47 connections now open)
2020-05-08T21:57:48.297+0000 I  TXN      [conn99] transaction parameters:{ lsid: { id: UUID("486d8575-fbd1-4209-bb85-496f280141b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975062, 24) } }, globalReadTimestamp:{ ts: Timestamp(1588975062, 24) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6204380, timeInactiveMicros:0, 6204ms
2020-05-08T21:57:48.297+0000 I  COMMAND  [conn99] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("486d8575-fbd1-4209-bb85-496f280141b6") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975062, 24) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 6204ms
2020-05-08T21:57:48.297+0000 I  NETWORK  [conn99] end connection 172.31.0.221:54190 (46 connections now open)
2020-05-08T21:57:48.299+0000 I  TXN      [conn112] transaction parameters:{ lsid: { id: UUID("08482c9d-f641-4420-b426-4f4139c059bf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975066, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1223442, timeInactiveMicros:0, 1223ms
2020-05-08T21:57:48.299+0000 I  COMMAND  [conn112] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975066, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08482c9d-f641-4420-b426-4f4139c059bf") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 08482c9d-f641-4420-b426-4f4139c059bf:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975066, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:592 protocol:op_msg 1223ms
2020-05-08T21:57:48.301+0000 I  COMMAND  [conn98] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e751aa2b-a2b9-4ee9-a101-a23b211658cf") }, txnNumber: 5, autocommit: false } numYields:0 reslen:320 protocol:op_msg 2194ms
2020-05-08T21:57:48.301+0000 I  NETWORK  [conn98] end connection 172.31.0.221:54186 (45 connections now open)
2020-05-08T21:57:48.391+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.391+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.830+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:49.344+0000 I  NETWORK  [conn114] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:49.344+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.347+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.844+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.321+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.344+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.844+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.891+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54580 #119 (46 connections now open)
2020-05-08T21:57:50.891+0000 I  NETWORK  [conn119] received client metadata from 172.31.0.221:54580 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.344+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.692+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54598 #120 (47 connections now open)
2020-05-08T21:57:51.692+0000 I  NETWORK  [conn120] received client metadata from 172.31.0.221:54598 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.844+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.844+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.845+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.845+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.850+0000 I  TXN      [conn114] transaction parameters:{ lsid: { id: UUID("b4484fbf-32cc-44e9-82f5-0b0da26b6bfc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975066, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4768451, timeInactiveMicros:0, 4768ms
2020-05-08T21:57:51.851+0000 I  COMMAND  [conn114] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975066, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4484fbf-32cc-44e9-82f5-0b0da26b6bfc") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction b4484fbf-32cc-44e9-82f5-0b0da26b6bfc:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975066, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 4768ms
2020-05-08T21:57:51.855+0000 I  COMMAND  [conn116] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975066, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d89c11a6-171a-4465-a654-645323aeccbc") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 4761ms
2020-05-08T21:57:52.081+0000 I  NETWORK  [conn115] end connection 172.31.0.221:54500 (46 connections now open)
2020-05-08T21:57:52.082+0000 I  NETWORK  [conn114] end connection 172.31.0.221:54498 (45 connections now open)
2020-05-08T21:57:52.083+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54620 #121 (46 connections now open)
2020-05-08T21:57:52.083+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54622 #122 (47 connections now open)
2020-05-08T21:57:52.083+0000 I  NETWORK  [conn122] received client metadata from 172.31.0.221:54622 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.083+0000 I  NETWORK  [conn121] received client metadata from 172.31.0.221:54620 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.202+0000 I  SHARDING [conn116] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.345+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.345+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.462+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.719+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54632 #124 (48 connections now open)
2020-05-08T21:57:52.719+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:54632 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:53.711+0000 I  COMMAND  [conn112] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 644), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08482c9d-f641-4420-b426-4f4139c059bf") }, txnNumber: 548, autocommit: false } numYields:0 reslen:322 protocol:op_msg 220ms
2020-05-08T21:57:54.129+0000 I  COMMAND  [conn112] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 783), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08482c9d-f641-4420-b426-4f4139c059bf") }, txnNumber: 571, autocommit: false } numYields:0 reslen:322 protocol:op_msg 210ms
2020-05-08T21:57:54.336+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54714 #125 (49 connections now open)
2020-05-08T21:57:54.336+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:54714 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.399+0000 I  NETWORK  [conn116] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator d89c11a6-171a-4465-a654-645323aeccbc:78 stopped due to: operation was interrupted
2020-05-08T21:57:54.400+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:54.750+0000 I  COMMAND  [conn112] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 251), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08482c9d-f641-4420-b426-4f4139c059bf") }, txnNumber: 612, autocommit: false } numYields:0 reslen:322 protocol:op_msg 211ms
2020-05-08T21:57:54.900+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.900+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.901+0000 I  COMMAND  [conn122] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 563), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e56f878-926f-46ed-a46b-75e0422df20b") }, txnNumber: 63, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1517ms
2020-05-08T21:57:54.901+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:54.901+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.902+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.908+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:55.508+0000 I  TXN      [conn116] transaction parameters:{ lsid: { id: UUID("d89c11a6-171a-4465-a654-645323aeccbc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 78, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 550) } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 550) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:2127661, timeActiveMicros:2133936, timeInactiveMicros:1961, 2135ms
2020-05-08T21:57:55.508+0000 I  COMMAND  [conn116] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 560), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d89c11a6-171a-4465-a654-645323aeccbc") }, txnNumber: 78, autocommit: false } numYields:0 reslen:311 protocol:op_msg 2127ms
2020-05-08T21:57:55.509+0000 I  NETWORK  [conn116] end connection 172.31.0.221:54502 (48 connections now open)
2020-05-08T21:57:55.509+0000 I  NETWORK  [conn117] end connection 172.31.0.221:54504 (47 connections now open)
2020-05-08T21:57:55.510+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54792 #126 (48 connections now open)
2020-05-08T21:57:55.510+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54794 #127 (49 connections now open)
2020-05-08T21:57:55.510+0000 I  NETWORK  [conn126] received client metadata from 172.31.0.221:54792 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:55.510+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:54794 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:55.512+0000 I  NETWORK  [conn122] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:55.512+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:55.795+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54812 #128 (50 connections now open)
2020-05-08T21:57:55.796+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:54812 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.012+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.162+0000 I  NETWORK  [conn126] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:56.163+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.163+0000 I  NETWORK  [conn112] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:56.164+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.512+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.662+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.786+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54846 #129 (51 connections now open)
2020-05-08T21:57:56.786+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:54846 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.968+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54872 #130 (52 connections now open)
2020-05-08T21:57:56.968+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:54872 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.012+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.162+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:57.512+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.626+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54918 #131 (53 connections now open)
2020-05-08T21:57:57.627+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:54918 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.662+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.662+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.663+0000 I  COMMAND  [conn126] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 100), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b28001b9-7d1a-4a78-b401-b38f39aae41a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2149ms
2020-05-08T21:57:57.663+0000 I  COMMAND  [conn112] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 97), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08482c9d-f641-4420-b426-4f4139c059bf") }, txnNumber: 655, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2501ms
2020-05-08T21:57:58.012+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.382+0000 I  NETWORK  [conn121] end connection 172.31.0.221:54620 (52 connections now open)
2020-05-08T21:57:58.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:54996 #132 (53 connections now open)
2020-05-08T21:57:58.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55000 #133 (54 connections now open)
2020-05-08T21:57:58.384+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:54996 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.385+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:55000 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.387+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.389+0000 I  NETWORK  [conn112] end connection 172.31.0.221:54490 (53 connections now open)
2020-05-08T21:57:58.390+0000 I  NETWORK  [conn113] end connection 172.31.0.221:54492 (52 connections now open)
2020-05-08T21:57:58.390+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55016 #134 (53 connections now open)
2020-05-08T21:57:58.391+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:55016 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.391+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55018 #135 (54 connections now open)
2020-05-08T21:57:58.391+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:55018 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.512+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.602+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55032 #136 (55 connections now open)
2020-05-08T21:57:58.603+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:55032 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.012+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.512+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.512+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.513+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:59.513+0000 I  COMMAND  [conn122] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 349), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5e56f878-926f-46ed-a46b-75e0422df20b") }, txnNumber: 63, autocommit: false } numYields:0 reslen:515 protocol:op_msg 4611ms
2020-05-08T21:57:59.513+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:59.513+0000 I  NETWORK  [conn122] end connection 172.31.0.221:54622 (54 connections now open)
2020-05-08T21:57:59.862+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55070 #137 (55 connections now open)
2020-05-08T21:57:59.862+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:55070 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.013+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.013+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.013+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.403+0000 I  COMMAND  [conn126] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975079, 589), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b28001b9-7d1a-4a78-b401-b38f39aae41a") }, txnNumber: 260, autocommit: false } numYields:0 reslen:322 protocol:op_msg 417ms
2020-05-08T21:58:00.403+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975079, 592), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d11abdd7-9567-4fff-93e1-237a138918ad") }, txnNumber: 145, autocommit: false } numYields:0 reslen:353 protocol:op_msg 412ms
2020-05-08T21:58:00.511+0000 I  NETWORK  [conn127] end connection 172.31.0.221:54794 (54 connections now open)
2020-05-08T21:58:00.511+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55106 #138 (55 connections now open)
2020-05-08T21:58:00.511+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55108 #139 (56 connections now open)
2020-05-08T21:58:00.511+0000 I  NETWORK  [conn126] end connection 172.31.0.221:54792 (55 connections now open)
2020-05-08T21:58:00.511+0000 I  NETWORK  [conn138] received client metadata from 172.31.0.221:55106 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.512+0000 I  NETWORK  [conn139] received client metadata from 172.31.0.221:55108 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.892+0000 I  NETWORK  [conn132] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:00.892+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.234+0000 I  COMMAND  [conn138] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975080, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff2df10a-176a-4b1e-a693-4f0473a48e6f") }, txnNumber: 10, autocommit: false } numYields:0 reslen:321 protocol:op_msg 632ms
2020-05-08T21:58:01.238+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975080, 111), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d11abdd7-9567-4fff-93e1-237a138918ad") }, txnNumber: 164, autocommit: false } numYields:0 reslen:353 protocol:op_msg 631ms
2020-05-08T21:58:01.275+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.392+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.892+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.892+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.893+0000 I  TXN      [conn132] transaction parameters:{ lsid: { id: UUID("3f40ab12-d2c6-4c8f-8e41-a35c1dc38122"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 192) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3506480, timeInactiveMicros:0, 3506ms
2020-05-08T21:58:01.893+0000 I  COMMAND  [conn132] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 192), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f40ab12-d2c6-4c8f-8e41-a35c1dc38122") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3506ms
2020-05-08T21:58:01.901+0000 I  NETWORK  [conn138] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.902+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.907+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.373+0000 I  NETWORK  [conn134] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:02.374+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.392+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.874+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.892+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.374+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.374+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.375+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 115), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d11abdd7-9567-4fff-93e1-237a138918ad") }, txnNumber: 196, autocommit: false } numYields:0 reslen:471 protocol:op_msg 1846ms
2020-05-08T21:58:03.383+0000 I  NETWORK  [conn133] end connection 172.31.0.221:55000 (54 connections now open)
2020-05-08T21:58:03.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55246 #140 (55 connections now open)
2020-05-08T21:58:03.384+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:55246 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55248 #141 (56 connections now open)
2020-05-08T21:58:03.384+0000 I  NETWORK  [conn141] received client metadata from 172.31.0.221:55248 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.386+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.391+0000 I  NETWORK  [conn135] end connection 172.31.0.221:55018 (55 connections now open)
2020-05-08T21:58:03.391+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55254 #142 (56 connections now open)
2020-05-08T21:58:03.392+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55256 #143 (57 connections now open)
2020-05-08T21:58:03.392+0000 I  NETWORK  [conn142] received client metadata from 172.31.0.221:55254 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.392+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.392+0000 I  NETWORK  [conn143] received client metadata from 172.31.0.221:55256 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.505+0000 I  COMMAND  [conn142] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 281 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9bc30fe6-cfae-47e0-bf2e-7d1cd65124ac") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 112ms
2020-05-08T21:58:03.507+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975083, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d11abdd7-9567-4fff-93e1-237a138918ad") }, txnNumber: 196, autocommit: false } numYields:0 reslen:429 protocol:op_msg 130ms
2020-05-08T21:58:03.507+0000 I  NETWORK  [conn134] end connection 172.31.0.221:55016 (56 connections now open)
2020-05-08T21:58:03.518+0000 I  TXN      [conn142] transaction parameters:{ lsid: { id: UUID("9bc30fe6-cfae-47e0-bf2e-7d1cd65124ac"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:11167, timeActiveMicros:125000, timeInactiveMicros:629, 125ms
2020-05-08T21:58:03.520+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.892+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.120+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.392+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.892+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.892+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.893+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.893+0000 I  COMMAND  [conn132] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 124), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3f40ab12-d2c6-4c8f-8e41-a35c1dc38122") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2999ms
2020-05-08T21:58:04.894+0000 I  NETWORK  [conn132] end connection 172.31.0.221:54996 (55 connections now open)
2020-05-08T21:58:05.943+0000 I  COMMAND  [conn138] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 278 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff2df10a-176a-4b1e-a693-4f0473a48e6f") }, txnNumber: 14, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 4668ms
2020-05-08T21:58:05.945+0000 I  NETWORK  [conn138] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.946+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.946+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.947+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.947+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.947+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.948+0000 I  TXN      [conn140] transaction parameters:{ lsid: { id: UUID("ef756a23-29dd-4f3c-ba67-9ac4872a7d95"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 4) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2561856, timeInactiveMicros:0, 2561ms
2020-05-08T21:58:05.948+0000 I  COMMAND  [conn140] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef756a23-29dd-4f3c-ba67-9ac4872a7d95") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2561ms
2020-05-08T21:58:05.952+0000 I  TXN      [conn142] transaction parameters:{ lsid: { id: UUID("9bc30fe6-cfae-47e0-bf2e-7d1cd65124ac"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 16) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2432571, timeInactiveMicros:0, 2432ms
2020-05-08T21:58:05.952+0000 I  CONNPOOL [conn138] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 0 connections to that host remain open
2020-05-08T21:58:05.952+0000 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("ff2df10a-176a-4b1e-a693-4f0473a48e6f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 27) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:7379, timeActiveMicros:4677583, timeInactiveMicros:1583, 4679ms
2020-05-08T21:58:05.952+0000 I  COMMAND  [conn142] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9bc30fe6-cfae-47e0-bf2e-7d1cd65124ac") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2432ms
2020-05-08T21:58:05.952+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:06.273+0000 I  NETWORK  [conn139] end connection 172.31.0.221:55108 (54 connections now open)
2020-05-08T21:58:06.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55306 #147 (55 connections now open)
2020-05-08T21:58:06.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55308 #148 (56 connections now open)
2020-05-08T21:58:06.275+0000 I  NETWORK  [conn148] received client metadata from 172.31.0.221:55308 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:06.275+0000 I  NETWORK  [conn147] received client metadata from 172.31.0.221:55306 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:06.554+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.556+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:06.968+0000 I  NETWORK  [conn138] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.969+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:06.969+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:06.970+0000 I  NETWORK  [conn142] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:06.972+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.054+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.468+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.554+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.554+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.968+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.968+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.970+0000 I  COMMAND  [conn140] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 48), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef756a23-29dd-4f3c-ba67-9ac4872a7d95") }, txnNumber: 2, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1988ms
2020-05-08T21:58:08.386+0000 I  NETWORK  [conn141] end connection 172.31.0.221:55248 (55 connections now open)
2020-05-08T21:58:08.387+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55368 #150 (56 connections now open)
2020-05-08T21:58:08.387+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55370 #151 (57 connections now open)
2020-05-08T21:58:08.387+0000 I  NETWORK  [conn150] received client metadata from 172.31.0.221:55368 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.387+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:55370 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.520+0000 I  NETWORK  [conn143] end connection 172.31.0.221:55256 (56 connections now open)
2020-05-08T21:58:08.521+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55392 #152 (57 connections now open)
2020-05-08T21:58:08.521+0000 I  NETWORK  [conn152] received client metadata from 172.31.0.221:55392 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.521+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55394 #153 (58 connections now open)
2020-05-08T21:58:08.521+0000 I  NETWORK  [conn153] received client metadata from 172.31.0.221:55394 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.564+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.939+0000 I  NETWORK  [conn150] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:08.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.057+0000 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("ff2df10a-176a-4b1e-a693-4f0473a48e6f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 15, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 21) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 21) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3096035, timeActiveMicros:3101571, timeInactiveMicros:1148, 3102ms
2020-05-08T21:58:09.057+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("9785bc1f-22c0-4e62-90a2-adbe6acaa853"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 48) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2777992, timeActiveMicros:2780357, timeInactiveMicros:747, 2781ms
2020-05-08T21:58:09.057+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.058+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.062+0000 I  COMMAND  [conn152] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 289 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975088, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 539ms
2020-05-08T21:58:09.062+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.064+0000 I  COMMAND  [conn140] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 229), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef756a23-29dd-4f3c-ba67-9ac4872a7d95") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1093ms
2020-05-08T21:58:09.065+0000 I  NETWORK  [conn140] end connection 172.31.0.221:55246 (57 connections now open)
2020-05-08T21:58:09.067+0000 I  TXN      [conn142] transaction parameters:{ lsid: { id: UUID("9bc30fe6-cfae-47e0-bf2e-7d1cd65124ac"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 34) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:3087942, timeActiveMicros:3097470, timeInactiveMicros:1106, 3098ms
2020-05-08T21:58:09.067+0000 I  COMMAND  [conn142] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 42), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9bc30fe6-cfae-47e0-bf2e-7d1cd65124ac") }, txnNumber: 3, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3088ms
2020-05-08T21:58:09.068+0000 I  NETWORK  [conn142] end connection 172.31.0.221:55254 (56 connections now open)
2020-05-08T21:58:09.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.939+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.939+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.940+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.940+0000 I  SHARDING [conn138] Received reply from shard ec2-3-82-35-209.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.940+0000 I  COMMAND  [conn138] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ff2df10a-176a-4b1e-a693-4f0473a48e6f") }, txnNumber: 15, autocommit: false } numYields:0 reslen:397 protocol:op_msg 3979ms
2020-05-08T21:58:09.941+0000 I  COMMAND  [conn147] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975086, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9785bc1f-22c0-4e62-90a2-adbe6acaa853") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3661ms
2020-05-08T21:58:09.941+0000 I  NETWORK  [conn138] end connection 172.31.0.221:55106 (55 connections now open)
2020-05-08T21:58:09.943+0000 I  COMMAND  [conn150] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4b423ea-133e-4223-ba07-a58868741209") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1552ms
2020-05-08T21:58:09.944+0000 I  COMMAND  [conn152] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 288 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 881ms
2020-05-08T21:58:10.054+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55458 #156 (56 connections now open)
2020-05-08T21:58:10.054+0000 I  NETWORK  [conn156] received client metadata from 172.31.0.221:55458 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.180+0000 I  NETWORK  [conn147] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:10.180+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.182+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.182+0000 I  NETWORK  [conn150] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:10.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.581+0000 I  NETWORK  [conn152] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:10.581+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:10.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:11.081+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.274+0000 I  NETWORK  [conn148] end connection 172.31.0.221:55308 (55 connections now open)
2020-05-08T21:58:11.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55522 #157 (56 connections now open)
2020-05-08T21:58:11.275+0000 I  NETWORK  [conn157] received client metadata from 172.31.0.221:55522 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:11.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55524 #158 (57 connections now open)
2020-05-08T21:58:11.275+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:55524 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:11.277+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:11.439+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.439+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.441+0000 I  SHARDING [conn147] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 3), t: 19 }
2020-05-08T21:58:11.441+0000 I  COMMAND  [conn147] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 288 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9785bc1f-22c0-4e62-90a2-adbe6acaa853") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975089, 203) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1499ms
2020-05-08T21:58:11.441+0000 I  NETWORK  [conn147] end connection 172.31.0.221:55306 (56 connections now open)
2020-05-08T21:58:11.441+0000 I  COMMAND  [conn150] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 212), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4b423ea-133e-4223-ba07-a58868741209") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1498ms
2020-05-08T21:58:11.444+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975090, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:167551, timeInactiveMicros:0, 167ms
2020-05-08T21:58:11.444+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975090, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 167ms
2020-05-08T21:58:11.446+0000 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975088, 2) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:1501433, timeActiveMicros:2923309, timeInactiveMicros:934, 2924ms
2020-05-08T21:58:11.447+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.447+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.448+0000 I  COMMAND  [conn152] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 212), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1502ms
2020-05-08T21:58:12.288+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55540 #159 (57 connections now open)
2020-05-08T21:58:12.288+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:55540 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.364+0000 I  COMMAND  [conn152] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 289 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975091, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975091, 10) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 916ms
2020-05-08T21:58:12.368+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.379+0000 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975091, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975091, 10) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:11782, timeActiveMicros:930460, timeInactiveMicros:834, 931ms
2020-05-08T21:58:12.383+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975091, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975091, 12) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:926767, timeActiveMicros:930281, timeInactiveMicros:967, 931ms
2020-05-08T21:58:12.383+0000 I  COMMAND  [conn157] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 926ms
2020-05-08T21:58:12.579+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.393+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.732+0000 I  NETWORK  [conn157] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:13.732+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.733+0000 I  NETWORK  [conn152] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:13.733+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.854+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:13.855+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:13.855+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:14.232+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.232+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.756+0000 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 49, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 512) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1348125, timeActiveMicros:1351560, timeInactiveMicros:527, 1352ms
2020-05-08T21:58:14.758+0000 I  NETWORK  [conn157] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:14.759+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.782+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:15.168+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55586 #164 (58 connections now open)
2020-05-08T21:58:15.169+0000 I  NETWORK  [conn164] received client metadata from 172.31.0.221:55586 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.258+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.758+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.758+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.759+0000 I  COMMAND  [conn152] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 518), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 49, autocommit: false } numYields:0 reslen:495 protocol:op_msg 2352ms
2020-05-08T21:58:16.655+0000 I  NETWORK  [conn150] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:16.655+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:16.764+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 49, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 481) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 481) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:3374894, timeActiveMicros:3383399, timeInactiveMicros:1100, 3384ms
2020-05-08T21:58:16.764+0000 I  COMMAND  [conn157] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 492), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1") }, txnNumber: 49, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3375ms
2020-05-08T21:58:16.764+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.765+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.765+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.766+0000 I  COMMAND  [conn152] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975095, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 49, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1005ms
2020-05-08T21:58:16.766+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.766+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:17.364+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.666+0000 I  NETWORK  [conn157] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.667+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.864+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:18.167+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.218+0000 I  NETWORK  [conn151] end connection 172.31.0.221:55370 (57 connections now open)
2020-05-08T21:58:18.218+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55664 #165 (58 connections now open)
2020-05-08T21:58:18.218+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55666 #166 (59 connections now open)
2020-05-08T21:58:18.219+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:55664 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.219+0000 I  NETWORK  [conn166] received client metadata from 172.31.0.221:55666 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.220+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:18.221+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:18.221+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:18.221+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.221+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.223+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.377+0000 I  COMMAND  [conn150] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 460), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b4b423ea-133e-4223-ba07-a58868741209") }, txnNumber: 164, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:58:18.377+0000 I  NETWORK  [conn150] end connection 172.31.0.221:55368 (58 connections now open)
2020-05-08T21:58:18.404+0000 I  NETWORK  [conn153] end connection 172.31.0.221:55394 (57 connections now open)
2020-05-08T21:58:18.404+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55734 #167 (58 connections now open)
2020-05-08T21:58:18.404+0000 I  NETWORK  [conn167] received client metadata from 172.31.0.221:55734 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.405+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55736 #168 (59 connections now open)
2020-05-08T21:58:18.405+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:55736 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.406+0000 I  NETWORK  [conn167] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:18.407+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:18.407+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:18.667+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.167+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.229+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975098, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e18faa84-6580-4255-8dee-cdd594402961") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 323ms
2020-05-08T21:58:19.232+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.354+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.355+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.355+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.356+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.356+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.370+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.667+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.667+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.668+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 50, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 175) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2902171, timeInactiveMicros:0, 2902ms
2020-05-08T21:58:19.668+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 174), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1") }, txnNumber: 50, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2902ms
2020-05-08T21:58:19.668+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975098, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e18faa84-6580-4255-8dee-cdd594402961") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 437ms
2020-05-08T21:58:19.671+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 322 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975098, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43a2277a-3dcd-4963-875e-7c4d3248116b") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 1447ms
2020-05-08T21:58:19.854+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.854+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.448+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.181+0000 I  NETWORK  [conn165] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:21.181+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.185+0000 I  TXN      [conn152] transaction parameters:{ lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 50, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 176) } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 176) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:4413423, timeActiveMicros:4418040, timeInactiveMicros:550, 4418ms
2020-05-08T21:58:21.186+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.186+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.681+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.769+0000 I  NETWORK  [conn158] end connection 172.31.0.221:55524 (58 connections now open)
2020-05-08T21:58:21.771+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55794 #169 (59 connections now open)
2020-05-08T21:58:21.771+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:55794 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.772+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55798 #170 (60 connections now open)
2020-05-08T21:58:21.773+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:55798 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.775+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.783+0000 I  COMMAND  [conn152] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 179), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2393e404-4489-4edb-81d5-03cc415fd248") }, txnNumber: 50, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5011ms
2020-05-08T21:58:21.783+0000 I  NETWORK  [conn152] end connection 172.31.0.221:55392 (59 connections now open)
2020-05-08T21:58:22.181+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.681+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.681+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.681+0000 I  NETWORK  [conn167] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator e18faa84-6580-4255-8dee-cdd594402961:2 stopped due to: operation was interrupted
2020-05-08T21:58:22.682+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("43a2277a-3dcd-4963-875e-7c4d3248116b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:4461676, timeInactiveMicros:884, 4462ms
2020-05-08T21:58:22.682+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 371 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43a2277a-3dcd-4963-875e-7c4d3248116b") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 3011ms
2020-05-08T21:58:22.682+0000 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("009a6f3b-8873-46e6-b281-e90a11e759f1") }, txnNumber: 50, autocommit: false } numYields:0 reslen:515 protocol:op_msg 3013ms
2020-05-08T21:58:22.682+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:22.682+0000 I  NETWORK  [conn157] end connection 172.31.0.221:55522 (58 connections now open)
2020-05-08T21:58:22.683+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.182+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.219+0000 I  NETWORK  [conn166] end connection 172.31.0.221:55666 (57 connections now open)
2020-05-08T21:58:23.220+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55820 #171 (58 connections now open)
2020-05-08T21:58:23.220+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55822 #172 (59 connections now open)
2020-05-08T21:58:23.220+0000 I  NETWORK  [conn171] received client metadata from 172.31.0.221:55820 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.220+0000 I  NETWORK  [conn172] received client metadata from 172.31.0.221:55822 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.221+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.227+0000 I  NETWORK  [conn169] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.228+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.405+0000 I  NETWORK  [conn168] end connection 172.31.0.221:55736 (58 connections now open)
2020-05-08T21:58:23.405+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55856 #173 (59 connections now open)
2020-05-08T21:58:23.406+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:55856 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.406+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:55858 #174 (60 connections now open)
2020-05-08T21:58:23.406+0000 I  NETWORK  [conn174] received client metadata from 172.31.0.221:55858 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.408+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.682+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.682+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.683+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.846+0000 I  NETWORK  [conn172] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.846+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.847+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.848+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.848+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("e18faa84-6580-4255-8dee-cdd594402961"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975098, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975098, 5) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:4178478, timeActiveMicros:4617872, timeInactiveMicros:1342, 4619ms
2020-05-08T21:58:23.849+0000 I  COMMAND  [conn167] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e18faa84-6580-4255-8dee-cdd594402961") }, txnNumber: 2, autocommit: false } numYields:0 reslen:311 protocol:op_msg 4178ms
2020-05-08T21:58:23.849+0000 I  NETWORK  [conn167] end connection 172.31.0.221:55734 (59 connections now open)
2020-05-08T21:58:23.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.182+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.682+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.683+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.182+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.182+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.183+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1775997, timeInactiveMicros:0, 1775ms
2020-05-08T21:58:25.183+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1776ms
2020-05-08T21:58:25.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.260+0000 I  NETWORK  [conn172] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.260+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.261+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.682+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.683+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:26.182+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.182+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.183+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.183+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.183+0000 I  SHARDING [conn173] Received reply from shard ec2-34-207-119-213.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.183+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975105, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 999ms
2020-05-08T21:58:26.227+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.227+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.228+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 36) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4453529, timeInactiveMicros:0, 4453ms
2020-05-08T21:58:26.228+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 36), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 4453ms
2020-05-08T21:58:26.229+0000 I  COMMAND  [conn165] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975102, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("43a2277a-3dcd-4963-875e-7c4d3248116b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3546ms
2020-05-08T21:58:26.229+0000 I  NETWORK  [conn165] end connection 172.31.0.221:55664 (58 connections now open)
2020-05-08T21:58:26.376+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 192ms
2020-05-08T21:58:26.474+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 245ms
2020-05-08T21:58:26.501+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:124142, timeInactiveMicros:0, 124ms
2020-05-08T21:58:26.501+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 124ms
2020-05-08T21:58:26.505+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 3284ms
2020-05-08T21:58:28.328+0000 I  NETWORK  [conn173] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:28.328+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.828+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.828+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.834+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 37, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 437) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 437) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1487169, timeActiveMicros:1492565, timeInactiveMicros:780, 1493ms
2020-05-08T21:58:28.835+0000 I  COMMAND  [conn173] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 439), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 37, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1488ms
2020-05-08T21:58:28.842+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 434 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 460), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") }, txnNumber: 41, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 460) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 1478ms
2020-05-08T21:58:28.842+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 460), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 49, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 460) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1478ms
2020-05-08T21:58:28.845+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 49, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 460) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 460) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1480716, timeInactiveMicros:326, 1481ms
2020-05-08T21:58:28.845+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 41, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 460) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 460) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1481773, timeInactiveMicros:612, 1482ms
2020-05-08T21:58:28.868+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:29.736+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 652) } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 652) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:208651, timeActiveMicros:214043, timeInactiveMicros:732, 214ms
2020-05-08T21:58:29.736+0000 I  COMMAND  [conn173] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 654), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 74, autocommit: false } numYields:0 reslen:214 protocol:op_msg 208ms
2020-05-08T21:58:29.736+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 668), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") }, txnNumber: 69, autocommit: false } numYields:0 reslen:321 protocol:op_msg 204ms
2020-05-08T21:58:29.739+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 83, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 610) } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 610) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:251355, timeActiveMicros:255312, timeInactiveMicros:532, 255ms
2020-05-08T21:58:29.739+0000 I  COMMAND  [conn169] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 614), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 83, autocommit: false } numYields:0 reslen:214 protocol:op_msg 251ms
2020-05-08T21:58:30.244+0000 I  NETWORK  [conn172] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:30.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.746+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 312), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 106, autocommit: false } numYields:0 reslen:471 protocol:op_msg 519ms
2020-05-08T21:58:31.255+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 465), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 106, autocommit: false } numYields:0 reslen:353 protocol:op_msg 507ms
2020-05-08T21:58:31.282+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 93, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 252) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 253) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1085107, timeActiveMicros:1094783, timeInactiveMicros:1073, 1095ms
2020-05-08T21:58:31.282+0000 I  COMMAND  [conn172] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 270), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") }, txnNumber: 93, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1085ms
2020-05-08T21:58:31.394+0000 I  NETWORK  [conn169] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.396+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.894+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.251+0000 I  NETWORK  [conn173] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:32.251+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.251+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.252+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 99, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 319) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 319) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2019802, timeInactiveMicros:241, 2020ms
2020-05-08T21:58:32.252+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 320), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 99, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:423 protocol:op_msg 2018ms
2020-05-08T21:58:32.252+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 162), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 112, autocommit: false } numYields:0 reslen:440 protocol:op_msg 878ms
2020-05-08T21:58:32.253+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 98, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 164) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 164) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:873605, timeInactiveMicros:0, 873ms
2020-05-08T21:58:32.253+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 164), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") }, txnNumber: 98, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 164) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:425 protocol:op_msg 873ms
2020-05-08T21:58:33.388+0000 I  SHARDING [conn173] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.391+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") }, txnNumber: 98, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1137ms
2020-05-08T21:58:33.392+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 112, autocommit: false } numYields:0 reslen:399 protocol:op_msg 1138ms
2020-05-08T21:58:33.392+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 99, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1139ms
2020-05-08T21:58:33.915+0000 I  NETWORK  [conn173] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:33.916+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:34.415+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.415+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.416+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:34.416+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 100, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1021ms
2020-05-08T21:58:34.740+0000 I  NETWORK  [conn169] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.740+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.741+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.194+0000 I  NETWORK  [conn174] end connection 172.31.0.221:55858 (57 connections now open)
2020-05-08T21:58:35.195+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56046 #176 (58 connections now open)
2020-05-08T21:58:35.195+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56048 #177 (59 connections now open)
2020-05-08T21:58:35.195+0000 I  NETWORK  [conn176] received client metadata from 172.31.0.221:56046 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.195+0000 I  NETWORK  [conn177] received client metadata from 172.31.0.221:56048 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.196+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.240+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.262+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.262+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.740+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.188+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.188+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.188+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.240+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.304+0000 I  NETWORK  [conn170] end connection 172.31.0.221:55798 (58 connections now open)
2020-05-08T21:58:36.307+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56100 #178 (59 connections now open)
2020-05-08T21:58:36.307+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56102 #179 (60 connections now open)
2020-05-08T21:58:36.307+0000 I  NETWORK  [conn178] received client metadata from 172.31.0.221:56100 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.307+0000 I  NETWORK  [conn179] received client metadata from 172.31.0.221:56102 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.334+0000 I  NETWORK  [conn171] end connection 172.31.0.221:55820 (59 connections now open)
2020-05-08T21:58:36.334+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56104 #180 (60 connections now open)
2020-05-08T21:58:36.334+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56106 #181 (61 connections now open)
2020-05-08T21:58:36.335+0000 I  NETWORK  [conn180] received client metadata from 172.31.0.221:56104 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.335+0000 I  NETWORK  [conn181] received client metadata from 172.31.0.221:56106 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.336+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.740+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.740+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.741+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.741+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975114, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2bc40c0d-32b9-487e-8a53-e7114e453c7f") }, txnNumber: 101, autocommit: false } numYields:0 reslen:353 protocol:op_msg 2315ms
2020-05-08T21:58:36.741+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("05e308aa-c2bd-437e-a955-a29c612fe282") }, txnNumber: 99, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3342ms
2020-05-08T21:58:36.741+0000 I  NETWORK  [conn173] end connection 172.31.0.221:55856 (60 connections now open)
2020-05-08T21:58:36.741+0000 I  NETWORK  [conn172] end connection 172.31.0.221:55822 (59 connections now open)
2020-05-08T21:58:36.743+0000 I  COMMAND  [conn179] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 434ms
2020-05-08T21:58:36.744+0000 I  NETWORK  [conn179] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.747+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:411564, timeInactiveMicros:0, 411ms
2020-05-08T21:58:36.747+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 411ms
2020-05-08T21:58:36.748+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 113, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975113, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975113, 2) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3355832, timeInactiveMicros:0, 3355ms
2020-05-08T21:58:36.748+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 500 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975113, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("24d02f05-e7d8-4cdf-902b-943b14bfd075") }, txnNumber: 113, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975113, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 24d02f05-e7d8-4cdf-902b-943b14bfd075:113 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975113, 2) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:547 protocol:op_msg 3355ms
2020-05-08T21:58:36.749+0000 I  NETWORK  [conn169] end connection 172.31.0.221:55794 (58 connections now open)
2020-05-08T21:58:36.749+0000 I  TXN      [conn176] transaction parameters:{ lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 8) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1553095, timeInactiveMicros:0, 1553ms
2020-05-08T21:58:36.749+0000 I  COMMAND  [conn176] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7dbec9e6-175b-4951-abf1-f3bc3f7c414f:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975114, 8) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:590 protocol:op_msg 1553ms
2020-05-08T21:58:37.202+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.204+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.244+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.244+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.245+0000 I  COMMAND  [conn179] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 489 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452") }, txnNumber: 1, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:339 protocol:op_msg 501ms
2020-05-08T21:58:37.342+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.343+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.576+0000 I  NETWORK  [conn179] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.577+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.702+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.851+0000 I  NETWORK  [conn180] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T21:58:37.852+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:37.860+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:38.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.351+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.351+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.352+0000 I  COMMAND  [conn176] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 631), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 90, autocommit: false } numYields:0 reslen:439 protocol:op_msg 505ms
2020-05-08T21:58:38.358+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 6, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1528ms
2020-05-08T21:58:38.364+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.364+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.365+0000 I  TXN      [conn179] transaction parameters:{ lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 1) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2056558, timeInactiveMicros:765, 2057ms
2020-05-08T21:58:38.365+0000 I  COMMAND  [conn179] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 202), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 1120ms
2020-05-08T21:58:38.406+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.406+0000 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.407+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.515+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.519+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.519+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.702+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.856+0000 I  COMMAND  [conn179] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 490ms
2020-05-08T21:58:38.859+0000 I  TXN      [conn176] transaction parameters:{ lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 92, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 15) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:485477, timeInactiveMicros:0, 485ms
2020-05-08T21:58:38.860+0000 I  COMMAND  [conn176] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 92, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 485ms
2020-05-08T21:58:38.895+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 4) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:526796, timeActiveMicros:534957, timeInactiveMicros:1136, 536ms
2020-05-08T21:58:38.895+0000 I  COMMAND  [conn180] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950") }, txnNumber: 7, autocommit: false } numYields:0 reslen:214 protocol:op_msg 526ms
2020-05-08T21:58:39.202+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:39.359+0000 I  SHARDING [conn180] Received reply from shard ec2-35-172-222-251.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:39.702+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.702+0000 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.703+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:40.535+0000 I  NETWORK  [conn179] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:40.536+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.541+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.036+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.536+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.536+0000 I  SHARDING [Sharding-Fixed-8] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.540+0000 I  COMMAND  [conn176] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1013), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 136, autocommit: false } numYields:0 reslen:353 protocol:op_msg 1841ms
2020-05-08T21:58:41.712+0000 I  NETWORK  [conn180] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:41.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:41.771+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:42.053+0000 I  TXN      [conn179] transaction parameters:{ lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 41, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975119, 1013) } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 1013) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2346054, timeActiveMicros:2353140, timeInactiveMicros:868, 2354ms
2020-05-08T21:58:42.053+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.056+0000 I  NETWORK  [conn179] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:42.056+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.556+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.056+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.056+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:44.213+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.213+0000 I  SHARDING [Sharding-Fixed-9] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.214+0000 I  COMMAND  [conn176] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975121, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 137, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2668ms
2020-05-08T21:58:44.214+0000 I  COMMAND  [conn180] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975120, 344), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950") }, txnNumber: 170, autocommit: false } numYields:0 reslen:440 protocol:op_msg 3504ms
2020-05-08T21:58:44.215+0000 I  COMMAND  [conn179] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1019), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452") }, txnNumber: 41, autocommit: false } numYields:0 reslen:495 protocol:op_msg 4507ms
2020-05-08T21:58:45.118+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.425+0000 I  NETWORK  [conn180] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:45.426+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.428+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.428+0000 I  NETWORK  [conn179] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:45.428+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.426+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.427+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b96b7369da8ea76060 to 5eb5d5b80770106eff2e4268; invalidating user cache
2020-05-08T21:58:46.773+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.773+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.776+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 21), t: 33 }
2020-05-08T21:58:46.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.272+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.272+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.426+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.297+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:48.426+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.426+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.428+0000 I  COMMAND  [conn176] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 392), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 144, autocommit: false } numYields:0 reslen:353 protocol:op_msg 4015ms
2020-05-08T21:58:48.429+0000 I  NETWORK  [conn176] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:48.429+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.429+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.467+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 178, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 387) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:4052841, timeActiveMicros:4057670, timeInactiveMicros:1351, 4059ms
2020-05-08T21:58:48.473+0000 I  NETWORK  [conn179] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:48.474+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.474+0000 I  NETWORK  [conn180] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:48.474+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.490+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:49.105+0000 I  NETWORK  [conn176] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.105+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:49.342+0000 I  NETWORK  [conn178] end connection 172.31.0.221:56100 (57 connections now open)
2020-05-08T21:58:49.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56350 #186 (58 connections now open)
2020-05-08T21:58:49.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56352 #187 (59 connections now open)
2020-05-08T21:58:49.343+0000 I  NETWORK  [conn187] received client metadata from 172.31.0.221:56352 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.343+0000 I  NETWORK  [conn186] received client metadata from 172.31.0.221:56350 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.344+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.344+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.345+0000 I  COMMAND  [conn180] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 397), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950") }, txnNumber: 178, autocommit: false } numYields:0 reslen:497 protocol:op_msg 4930ms
2020-05-08T21:58:49.346+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.346+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.395+0000 I  CONNPOOL [conn179] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:58:49.396+0000 I  COMMAND  [conn179] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 353), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7779e5c2-8888-41ea-9f23-4acce8e0f452") }, txnNumber: 47, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:58:49.396+0000 I  NETWORK  [conn179] end connection 172.31.0.221:56102 (58 connections now open)
2020-05-08T21:58:49.405+0000 I  NETWORK  [conn177] end connection 172.31.0.221:56048 (57 connections now open)
2020-05-08T21:58:49.405+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56390 #188 (58 connections now open)
2020-05-08T21:58:49.405+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56392 #189 (59 connections now open)
2020-05-08T21:58:49.406+0000 I  NETWORK  [conn189] received client metadata from 172.31.0.221:56392 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.406+0000 I  NETWORK  [conn188] received client metadata from 172.31.0.221:56390 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.410+0000 I  NETWORK  [conn181] end connection 172.31.0.221:56106 (58 connections now open)
2020-05-08T21:58:49.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56404 #190 (59 connections now open)
2020-05-08T21:58:49.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56406 #191 (60 connections now open)
2020-05-08T21:58:49.411+0000 I  NETWORK  [conn191] received client metadata from 172.31.0.221:56406 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.411+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:56404 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:50.174+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.656+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:50.656+0000 I  COMMAND  [conn190] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1243ms
2020-05-08T21:58:50.657+0000 I  COMMAND  [conn180] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e75f5362-dace-435d-88ae-3557b1b82950") }, txnNumber: 178, autocommit: false } numYields:0 reslen:430 protocol:op_msg 1311ms
2020-05-08T21:58:50.657+0000 I  NETWORK  [conn180] end connection 172.31.0.221:56104 (59 connections now open)
2020-05-08T21:58:50.661+0000 I  TXN      [conn188] transaction parameters:{ lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1254100, timeInactiveMicros:0, 1254ms
2020-05-08T21:58:50.661+0000 I  COMMAND  [conn188] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1254ms
2020-05-08T21:58:50.663+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 2) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1249828, timeInactiveMicros:622, 1250ms
2020-05-08T21:58:50.754+0000 I  NETWORK  [conn186] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:50.754+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.761+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.990+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.254+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.254+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.255+0000 I  COMMAND  [conn190] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975130, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:351 protocol:op_msg 591ms
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn186] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1222f77c-90f9-4d67-861f-fc0b427b91dc") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2531ms
2020-05-08T21:58:51.878+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("1222f77c-90f9-4d67-861f-fc0b427b91dc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 22) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2534560, timeInactiveMicros:438, 2534ms
2020-05-08T21:58:51.879+0000 I  COMMAND  [conn176] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 603 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7dbec9e6-175b-4951-abf1-f3bc3f7c414f") }, txnNumber: 146, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 19) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 3439ms
2020-05-08T21:58:51.880+0000 I  NETWORK  [conn176] end connection 172.31.0.221:56046 (58 connections now open)
2020-05-08T21:58:51.881+0000 I  COMMAND  [conn188] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 606 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975130, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 1208ms
2020-05-08T21:58:51.895+0000 I  TXN      [conn188] transaction parameters:{ lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588975130, 15) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:12769, timeActiveMicros:1223519, timeInactiveMicros:944, 1224ms
2020-05-08T21:58:51.905+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 29) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 29) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:645693, timeActiveMicros:648317, timeInactiveMicros:1180, 649ms
2020-05-08T21:58:51.905+0000 I  COMMAND  [conn190] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 645ms
2020-05-08T21:58:52.466+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.897+0000 I  NETWORK  [conn190] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.898+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:52.901+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:52.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.990+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.990+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.991+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.397+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.397+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.399+0000 I  COMMAND  [conn186] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 91), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1222f77c-90f9-4d67-861f-fc0b427b91dc") }, txnNumber: 2, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1497ms
2020-05-08T21:58:53.399+0000 I  COMMAND  [conn188] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1499ms
2020-05-08T21:58:53.926+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.927+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.934+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.936+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.943+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.943+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:54.343+0000 I  NETWORK  [conn187] end connection 172.31.0.221:56352 (57 connections now open)
2020-05-08T21:58:54.343+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56586 #196 (58 connections now open)
2020-05-08T21:58:54.343+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56588 #197 (59 connections now open)
2020-05-08T21:58:54.343+0000 I  NETWORK  [conn196] received client metadata from 172.31.0.221:56586 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.343+0000 I  NETWORK  [conn197] received client metadata from 172.31.0.221:56588 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.426+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.426+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.427+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.427+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 2), t: 38 }
2020-05-08T21:58:54.606+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 96) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2698283, timeActiveMicros:2699926, timeInactiveMicros:487, 2700ms
2020-05-08T21:58:54.607+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:54.610+0000 I  NETWORK  [conn196] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:54.611+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.613+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.615+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.615+0000 I  NETWORK  [conn190] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:54.616+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.111+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.111+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.112+0000 I  COMMAND  [conn188] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1711ms
2020-05-08T21:58:55.112+0000 I  TXN      [conn196] transaction parameters:{ lsid: { id: UUID("3dd5b4d8-36cc-4987-af46-7e0467f04c97"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:767715, timeInactiveMicros:0, 767ms
2020-05-08T21:58:55.112+0000 I  COMMAND  [conn190] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 98), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7") }, txnNumber: 3, autocommit: false } numYields:0 reslen:493 protocol:op_msg 3203ms
2020-05-08T21:58:55.112+0000 I  COMMAND  [conn196] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3dd5b4d8-36cc-4987-af46-7e0467f04c97") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 767ms
2020-05-08T21:58:55.609+0000 I  NETWORK  [conn186] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:55.609+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.611+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.611+0000 I  NETWORK  [conn196] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:55.611+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.942+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588975134, 4), t: 38 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T21:58:56.111+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.611+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.896+0000 I  NETWORK  [conn189] end connection 172.31.0.221:56392 (58 connections now open)
2020-05-08T21:58:56.896+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56748 #201 (59 connections now open)
2020-05-08T21:58:56.897+0000 I  NETWORK  [conn201] received client metadata from 172.31.0.221:56748 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.897+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56750 #202 (60 connections now open)
2020-05-08T21:58:56.897+0000 I  NETWORK  [conn202] received client metadata from 172.31.0.221:56750 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.906+0000 I  NETWORK  [conn191] end connection 172.31.0.221:56406 (59 connections now open)
2020-05-08T21:58:56.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56756 #203 (60 connections now open)
2020-05-08T21:58:56.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56758 #204 (61 connections now open)
2020-05-08T21:58:56.907+0000 I  NETWORK  [conn203] received client metadata from 172.31.0.221:56756 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.907+0000 I  NETWORK  [conn204] received client metadata from 172.31.0.221:56758 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:57.111+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:57.611+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.611+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.612+0000 I  TXN      [conn188] transaction parameters:{ lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975134, 3) } }, globalReadTimestamp:{ ts: Timestamp(1588975134, 4) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2499004, timeInactiveMicros:0, 2499ms
2020-05-08T21:58:57.612+0000 I  COMMAND  [conn188] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975134, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("65d5a6d7-5ba1-4e34-ba03-a0f877be2445") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975134, 3) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2499ms
2020-05-08T21:58:57.612+0000 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975134, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3dd5b4d8-36cc-4987-af46-7e0467f04c97") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2499ms
2020-05-08T21:58:57.612+0000 I  NETWORK  [conn188] end connection 172.31.0.221:56390 (60 connections now open)
2020-05-08T21:58:58.110+0000 I  NETWORK  [conn190] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:58.110+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.111+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.401+0000 I  -        [conn186] operation was interrupted because a client disconnected
2020-05-08T21:58:58.401+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("1222f77c-90f9-4d67-861f-fc0b427b91dc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975133, 4) } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 4) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002035, timeInactiveMicros:0, 5002ms
2020-05-08T21:58:58.401+0000 I  COMMAND  [conn186] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1222f77c-90f9-4d67-861f-fc0b427b91dc") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975133, 4) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:58:58.401+0000 I  NETWORK  [conn186] end connection 172.31.0.221:56350 (59 connections now open)
2020-05-08T21:58:58.402+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.611+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:59.111+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.111+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.112+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 6), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.112+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:59.112+0000 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975137, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3dd5b4d8-36cc-4987-af46-7e0467f04c97") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1499ms
2020-05-08T21:58:59.112+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.112+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.343+0000 I  NETWORK  [conn197] end connection 172.31.0.221:56588 (58 connections now open)
2020-05-08T21:58:59.344+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56880 #205 (59 connections now open)
2020-05-08T21:58:59.344+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:56882 #206 (60 connections now open)
2020-05-08T21:58:59.344+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:56880 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.344+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:56882 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.822+0000 I  NETWORK  [conn196] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:59.822+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:59.822+0000 I  NETWORK  [conn190] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:59.823+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:00.123+0000 I  COMMAND  [conn190] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975134, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e23f1714-01e9-4d48-95a5-3ef7bfb116d7") }, txnNumber: 3, autocommit: false } numYields:0 reslen:493 protocol:op_msg 5010ms
2020-05-08T21:59:00.123+0000 I  NETWORK  [conn190] end connection 172.31.0.221:56404 (59 connections now open)
2020-05-08T21:59:00.322+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:00.322+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:00.323+0000 I  TXN      [conn196] transaction parameters:{ lsid: { id: UUID("3dd5b4d8-36cc-4987-af46-7e0467f04c97"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975139, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 2) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1209995, timeInactiveMicros:0, 1209ms
2020-05-08T21:59:00.323+0000 I  COMMAND  [conn196] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3dd5b4d8-36cc-4987-af46-7e0467f04c97") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975139, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1210ms
2020-05-08T21:59:00.323+0000 I  NETWORK  [conn196] end connection 172.31.0.221:56586 (58 connections now open)
2020-05-08T21:59:00.822+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:01.897+0000 I  NETWORK  [conn202] end connection 172.31.0.221:56750 (57 connections now open)
2020-05-08T21:59:01.897+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57012 #207 (58 connections now open)
2020-05-08T21:59:01.898+0000 I  NETWORK  [conn207] received client metadata from 172.31.0.221:57012 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.898+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57014 #208 (59 connections now open)
2020-05-08T21:59:01.898+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:57014 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.901+0000 I  -        [conn201] operation was interrupted because a client disconnected
2020-05-08T21:59:01.901+0000 I  CONNPOOL [conn201] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:59:01.901+0000 I  TXN      [conn201] transaction parameters:{ lsid: { id: UUID("5b858738-492e-4bcd-a9d6-560dbed26e66"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975135, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003435, timeInactiveMicros:0, 5003ms
2020-05-08T21:59:01.901+0000 I  COMMAND  [conn201] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 613 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5b858738-492e-4bcd-a9d6-560dbed26e66") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:01.901+0000 I  NETWORK  [conn201] end connection 172.31.0.221:56748 (58 connections now open)
2020-05-08T21:59:01.907+0000 I  NETWORK  [conn203] end connection 172.31.0.221:56756 (57 connections now open)
2020-05-08T21:59:01.908+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57020 #209 (58 connections now open)
2020-05-08T21:59:01.908+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57022 #210 (59 connections now open)
2020-05-08T21:59:01.908+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:57020 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.908+0000 I  NETWORK  [conn210] received client metadata from 172.31.0.221:57022 conn210: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.909+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:02.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.344+0000 I  NETWORK  [conn205] end connection 172.31.0.221:56880 (58 connections now open)
2020-05-08T21:59:04.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57136 #213 (59 connections now open)
2020-05-08T21:59:04.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57138 #214 (60 connections now open)
2020-05-08T21:59:04.345+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:57136 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.345+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:57138 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.346+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.947+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975145, 20), t: 41 }
2020-05-08T21:59:06.898+0000 I  NETWORK  [conn208] end connection 172.31.0.221:57014 (59 connections now open)
2020-05-08T21:59:06.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57216 #217 (60 connections now open)
2020-05-08T21:59:06.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57218 #218 (61 connections now open)
2020-05-08T21:59:06.900+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:57216 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.901+0000 I  NETWORK  [conn218] received client metadata from 172.31.0.221:57218 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.902+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:06.904+0000 I  -        [conn207] operation was interrupted because a client disconnected
2020-05-08T21:59:06.904+0000 I  CONNPOOL [conn207] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:06.904+0000 I  TXN      [conn207] transaction parameters:{ lsid: { id: UUID("7b3aad94-73bf-4fbb-b3c6-ad2537a153c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975140, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005016, timeInactiveMicros:0, 5005ms
2020-05-08T21:59:06.904+0000 I  COMMAND  [conn207] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 594 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975140, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7b3aad94-73bf-4fbb-b3c6-ad2537a153c5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:06.904+0000 I  NETWORK  [conn207] end connection 172.31.0.221:57012 (60 connections now open)
2020-05-08T21:59:06.908+0000 I  NETWORK  [conn210] end connection 172.31.0.221:57022 (59 connections now open)
2020-05-08T21:59:06.908+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57220 #220 (60 connections now open)
2020-05-08T21:59:06.909+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57222 #221 (61 connections now open)
2020-05-08T21:59:06.909+0000 I  NETWORK  [conn220] received client metadata from 172.31.0.221:57220 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.909+0000 I  NETWORK  [conn221] received client metadata from 172.31.0.221:57222 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.913+0000 I  -        [conn209] operation was interrupted because a client disconnected
2020-05-08T21:59:06.913+0000 I  CONNPOOL [conn209] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:06.913+0000 I  TXN      [conn209] transaction parameters:{ lsid: { id: UUID("a6ec23ca-2e60-40b0-a78b-d25aadf2baea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975140, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004524, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:06.913+0000 I  COMMAND  [conn209] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 615 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975140, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a6ec23ca-2e60-40b0-a78b-d25aadf2baea") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:06.913+0000 I  NETWORK  [conn209] end connection 172.31.0.221:57020 (60 connections now open)
2020-05-08T21:59:06.968+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:09.057+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:09.058+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:09.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57274 #223 (61 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [conn223] received client metadata from 172.31.0.221:57274 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.380+0000 I  NETWORK  [conn214] end connection 172.31.0.221:57138 (60 connections now open)
2020-05-08T21:59:09.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57292 #224 (61 connections now open)
2020-05-08T21:59:09.381+0000 I  NETWORK  [conn224] received client metadata from 172.31.0.221:57292 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57294 #225 (62 connections now open)
2020-05-08T21:59:09.381+0000 I  NETWORK  [conn225] received client metadata from 172.31.0.221:57294 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.384+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.384+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.610+0000 I  NETWORK  [conn224] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:09.611+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:09.883+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.883+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.884+0000 I  TXN      [conn224] transaction parameters:{ lsid: { id: UUID("158f971e-f397-4c84-96b7-ff8c10e816c7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975145, 427) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:500868, timeInactiveMicros:0, 500ms
2020-05-08T21:59:09.884+0000 I  COMMAND  [conn224] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975145, 427), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("158f971e-f397-4c84-96b7-ff8c10e816c7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 501ms
2020-05-08T21:59:11.207+0000 I  NETWORK  [conn224] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:11.208+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.899+0000 I  NETWORK  [conn218] end connection 172.31.0.221:57218 (61 connections now open)
2020-05-08T21:59:11.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57350 #226 (62 connections now open)
2020-05-08T21:59:11.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57352 #227 (63 connections now open)
2020-05-08T21:59:11.900+0000 I  NETWORK  [conn226] received client metadata from 172.31.0.221:57350 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.900+0000 I  NETWORK  [conn227] received client metadata from 172.31.0.221:57352 conn227: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.901+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:11.905+0000 I  -        [conn217] operation was interrupted because a client disconnected
2020-05-08T21:59:11.905+0000 I  CONNPOOL [conn217] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:11.905+0000 I  TXN      [conn217] transaction parameters:{ lsid: { id: UUID("91ede4b6-40a8-4cf9-9e7e-9f7237143767"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975145, 427) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003680, timeInactiveMicros:0, 5003ms
2020-05-08T21:59:11.905+0000 I  COMMAND  [conn217] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 670 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975145, 427), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("91ede4b6-40a8-4cf9-9e7e-9f7237143767") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:11.905+0000 I  NETWORK  [conn217] end connection 172.31.0.221:57216 (62 connections now open)
2020-05-08T21:59:11.909+0000 I  NETWORK  [conn220] end connection 172.31.0.221:57220 (61 connections now open)
2020-05-08T21:59:11.909+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57354 #229 (62 connections now open)
2020-05-08T21:59:11.909+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57356 #230 (63 connections now open)
2020-05-08T21:59:11.910+0000 I  NETWORK  [conn229] received client metadata from 172.31.0.221:57354 conn229: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.910+0000 I  NETWORK  [conn230] received client metadata from 172.31.0.221:57356 conn230: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:12.208+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.708+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:13.208+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.208+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.209+0000 I  COMMAND  [conn224] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975149, 107), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("158f971e-f397-4c84-96b7-ff8c10e816c7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3324ms
2020-05-08T21:59:13.743+0000 I  NETWORK  [conn224] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:13.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:14.243+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.243+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.244+0000 I  COMMAND  [conn224] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975153, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("158f971e-f397-4c84-96b7-ff8c10e816c7") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1033ms
2020-05-08T21:59:14.244+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:14.381+0000 I  NETWORK  [conn225] end connection 172.31.0.221:57294 (62 connections now open)
2020-05-08T21:59:14.382+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57442 #233 (63 connections now open)
2020-05-08T21:59:14.382+0000 I  NETWORK  [conn233] received client metadata from 172.31.0.221:57442 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.382+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57444 #234 (64 connections now open)
2020-05-08T21:59:14.383+0000 I  NETWORK  [conn234] received client metadata from 172.31.0.221:57444 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.385+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.708+0000 I  TXN      [conn224] transaction parameters:{ lsid: { id: UUID("158f971e-f397-4c84-96b7-ff8c10e816c7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975154, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588975154, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:462924, timeInactiveMicros:0, 462ms
2020-05-08T21:59:14.708+0000 I  COMMAND  [conn224] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975154, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("158f971e-f397-4c84-96b7-ff8c10e816c7") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975154, 1) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 463ms
2020-05-08T21:59:14.708+0000 I  NETWORK  [conn224] end connection 172.31.0.221:57292 (63 connections now open)
2020-05-08T21:59:15.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:16.427+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:59:16.900+0000 I  NETWORK  [conn227] end connection 172.31.0.221:57352 (62 connections now open)
2020-05-08T21:59:16.901+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57532 #238 (63 connections now open)
2020-05-08T21:59:16.901+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57534 #239 (64 connections now open)
2020-05-08T21:59:16.901+0000 I  NETWORK  [conn238] received client metadata from 172.31.0.221:57532 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.901+0000 I  NETWORK  [conn239] received client metadata from 172.31.0.221:57534 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.902+0000 I  SHARDING [conn238] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 3), t: 43 }
2020-05-08T21:59:16.902+0000 I  NETWORK  [conn238] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.903+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:16.910+0000 I  NETWORK  [conn230] end connection 172.31.0.221:57356 (63 connections now open)
2020-05-08T21:59:16.910+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57536 #240 (64 connections now open)
2020-05-08T21:59:16.910+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57538 #241 (65 connections now open)
2020-05-08T21:59:16.910+0000 I  NETWORK  [conn240] received client metadata from 172.31.0.221:57536 conn240: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.911+0000 I  NETWORK  [conn241] received client metadata from 172.31.0.221:57538 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.912+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:16.913+0000 I  -        [conn229] operation was interrupted because a client disconnected
2020-05-08T21:59:16.913+0000 I  CONNPOOL [conn229] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T21:59:16.913+0000 I  TXN      [conn229] transaction parameters:{ lsid: { id: UUID("62c0d84c-c565-4eba-af39-4d44e5dd4bed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 110) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002660, timeInactiveMicros:0, 5002ms
2020-05-08T21:59:16.913+0000 I  COMMAND  [conn229] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 689 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("62c0d84c-c565-4eba-af39-4d44e5dd4bed") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:16.913+0000 I  NETWORK  [conn229] end connection 172.31.0.221:57354 (64 connections now open)
2020-05-08T21:59:17.402+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.566+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:17.566+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:17.902+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.902+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.903+0000 I  TXN      [conn238] transaction parameters:{ lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975155, 525) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1001571, timeInactiveMicros:0, 1001ms
2020-05-08T21:59:17.903+0000 I  COMMAND  [conn238] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975155, 525), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1001ms
2020-05-08T21:59:17.904+0000 I  COMMAND  [conn240] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 741 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975156, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 992ms
2020-05-08T21:59:18.796+0000 I  TXN      [conn240] transaction parameters:{ lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975156, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:890778, timeActiveMicros:1884056, timeInactiveMicros:604, 1884ms
2020-05-08T21:59:18.796+0000 I  COMMAND  [conn240] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:183 protocol:op_msg 890ms
2020-05-08T21:59:18.796+0000 I  COMMAND  [conn238] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 107), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 892ms
2020-05-08T21:59:18.829+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:18.858+0000 I  NETWORK  [conn240] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:18.858+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.358+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.382+0000 I  NETWORK  [conn234] end connection 172.31.0.221:57444 (63 connections now open)
2020-05-08T21:59:19.382+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57618 #243 (64 connections now open)
2020-05-08T21:59:19.383+0000 I  NETWORK  [conn243] received client metadata from 172.31.0.221:57618 conn243: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.383+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57620 #244 (65 connections now open)
2020-05-08T21:59:19.383+0000 I  NETWORK  [conn244] received client metadata from 172.31.0.221:57620 conn244: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.605+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.605+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.606+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.606+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.606+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.858+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.858+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.859+0000 I  COMMAND  [conn240] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 47), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e") }, txnNumber: 4, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1014ms
2020-05-08T21:59:20.282+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:21.130+0000 I  COMMAND  [conn240] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975160, 279), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e") }, txnNumber: 81, autocommit: false } numYields:0 reslen:321 protocol:op_msg 626ms
2020-05-08T21:59:22.862+0000 I  NETWORK  [conn240] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:22.862+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.362+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.830+0000 I  -        [conn238] operation was interrupted because a client disconnected
2020-05-08T21:59:23.830+0000 I  CONNPOOL [conn238] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:23.831+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57760 #246 (66 connections now open)
2020-05-08T21:59:23.831+0000 I  TXN      [conn238] transaction parameters:{ lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 35) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001768, timeInactiveMicros:0, 5001ms
2020-05-08T21:59:23.831+0000 I  COMMAND  [conn238] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 742 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:23.831+0000 I  NETWORK  [conn246] received client metadata from 172.31.0.221:57760 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:23.831+0000 I  NETWORK  [conn238] end connection 172.31.0.221:57532 (65 connections now open)
2020-05-08T21:59:23.832+0000 I  NETWORK  [conn246] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:23.832+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.832+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.833+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:23.833+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.833+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.862+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.862+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.863+0000 I  COMMAND  [conn240] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975161, 372), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e") }, txnNumber: 172, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2015ms
2020-05-08T21:59:23.863+0000 I  NETWORK  [conn240] end connection 172.31.0.221:57536 (64 connections now open)
2020-05-08T21:59:23.863+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57762 #247 (65 connections now open)
2020-05-08T21:59:23.864+0000 I  NETWORK  [conn247] received client metadata from 172.31.0.221:57762 conn247: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:23.903+0000 I  NETWORK  [conn246] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:23.904+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:24.332+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.332+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.387+0000 I  -        [conn243] operation was interrupted because a client disconnected
2020-05-08T21:59:24.387+0000 I  CONNPOOL [conn243] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 6 connections to that host remain open
2020-05-08T21:59:24.387+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:57774 #248 (66 connections now open)
2020-05-08T21:59:24.387+0000 I  TXN      [conn243] transaction parameters:{ lsid: { id: UUID("d5efefb3-d0a2-4e35-9ceb-a424bbfed76b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 57) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003286, timeInactiveMicros:0, 5003ms
2020-05-08T21:59:24.388+0000 I  COMMAND  [conn243] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 735 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 57), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d5efefb3-d0a2-4e35-9ceb-a424bbfed76b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:24.388+0000 I  NETWORK  [conn248] received client metadata from 172.31.0.221:57774 conn248: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.388+0000 I  NETWORK  [conn243] end connection 172.31.0.221:57618 (65 connections now open)
2020-05-08T21:59:24.469+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:24.908+0000 I  NETWORK  [conn246] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:24.909+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.408+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.908+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:26.408+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.408+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.409+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975165, 2), t: 47 }
2020-05-08T21:59:26.409+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:26.409+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.409+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.410+0000 I  COMMAND  [conn248] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 57), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d5efefb3-d0a2-4e35-9ceb-a424bbfed76b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2021ms
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn239] end connection 172.31.0.221:57534 (64 connections now open)
2020-05-08T21:59:26.423+0000 I  NETWORK  [conn241] end connection 172.31.0.221:57538 (63 connections now open)
2020-05-08T21:59:26.424+0000 I  NETWORK  [conn244] end connection 172.31.0.221:57620 (62 connections now open)
2020-05-08T21:59:26.918+0000 I  TXN      [conn246] transaction parameters:{ lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975163, 3) } }, globalReadTimestamp:{ ts: Timestamp(1588975163, 3) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3077811, timeInactiveMicros:0, 3077ms
2020-05-08T21:59:26.918+0000 I  COMMAND  [conn246] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 742 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975163, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e038895-6602-442d-8736-06c33ce5e7cb") }, txnNumber: 4, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975163, 3) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 0e038895-6602-442d-8736-06c33ce5e7cb:4 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975163, 3) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 3077ms
2020-05-08T21:59:26.918+0000 I  COMMAND  [conn248] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975166, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d5efefb3-d0a2-4e35-9ceb-a424bbfed76b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 506ms
2020-05-08T21:59:26.918+0000 I  NETWORK  [conn246] end connection 172.31.0.221:57760 (61 connections now open)
2020-05-08T21:59:26.918+0000 I  NETWORK  [conn248] end connection 172.31.0.221:57774 (60 connections now open)
2020-05-08T21:59:28.869+0000 I  -        [conn247] operation was interrupted because a client disconnected
2020-05-08T21:59:28.869+0000 I  CONNPOOL [conn247] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:59:28.869+0000 I  TXN      [conn247] transaction parameters:{ lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 173, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975161, 372) } }, globalReadTimestamp:{ ts: Timestamp(1588975163, 3) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004937, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:28.869+0000 I  COMMAND  [conn247] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 741 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975161, 372), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6d9c085f-e669-4ba5-8c57-6aa3603ae37e") }, txnNumber: 173, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975161, 372) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:28.869+0000 I  NETWORK  [conn247] end connection 172.31.0.221:57762 (59 connections now open)
2020-05-08T21:59:29.213+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:29.357+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:30.124+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:59:30.216+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:59:30.233+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
