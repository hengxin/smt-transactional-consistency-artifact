2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.235+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.237+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.237+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.237+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.237+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.237+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.237+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.237+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.238+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-7-49:27017:1588975035:8223699253815224319 (sleeping for 30000ms)
2020-05-08T21:57:15.241+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.241+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.241+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.245+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 12), t: 1 }
2020-05-08T21:57:15.422+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.423+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.426+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.426+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.428+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("f7bf0a87-fa70-4ec1-b347-8ec39159f25d"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.428+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.428+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.428+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.443+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42218 #10 (1 connection now open)
2020-05-08T21:57:16.443+0000 I  NETWORK  [conn10] received client metadata from 172.31.0.221:42218 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.621+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42230 #11 (2 connections now open)
2020-05-08T21:57:16.621+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:42230 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.886+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42244 #12 (3 connections now open)
2020-05-08T21:57:16.887+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:42244 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.924+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42254 #13 (4 connections now open)
2020-05-08T21:57:16.924+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:42254 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.945+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42270 #14 (5 connections now open)
2020-05-08T21:57:16.945+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:42270 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.092+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42284 #15 (6 connections now open)
2020-05-08T21:57:17.093+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:42284 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.149+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42304 #16 (7 connections now open)
2020-05-08T21:57:17.149+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:42304 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.304+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42336 #17 (8 connections now open)
2020-05-08T21:57:17.305+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:42336 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.305+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42338 #18 (9 connections now open)
2020-05-08T21:57:17.305+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:42338 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42366 #19 (10 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:42366 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.457+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42396 #20 (11 connections now open)
2020-05-08T21:57:17.457+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:42396 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.469+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42402 #21 (12 connections now open)
2020-05-08T21:57:17.469+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:42402 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42418 #22 (13 connections now open)
2020-05-08T21:57:17.705+0000 I  NETWORK  [conn22] received client metadata from 172.31.0.221:42418 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.783+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42424 #23 (14 connections now open)
2020-05-08T21:57:17.784+0000 I  NETWORK  [conn23] received client metadata from 172.31.0.221:42424 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.826+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42436 #24 (15 connections now open)
2020-05-08T21:57:17.826+0000 I  NETWORK  [conn24] received client metadata from 172.31.0.221:42436 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.883+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42468 #25 (16 connections now open)
2020-05-08T21:57:18.884+0000 I  NETWORK  [conn25] received client metadata from 172.31.0.221:42468 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.490+0000 I  COMMAND  [conn20] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("52a0f66f-44dc-49ec-9432-f125c1cfcdf5") } } numYields:0 reslen:163 protocol:op_msg 2020ms
2020-05-08T21:57:19.491+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:19.492+0000 I  NETWORK  [conn20] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  NETWORK  [conn20] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.492+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.494+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.495+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.495+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.495+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.514+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42488 #32 (17 connections now open)
2020-05-08T21:57:19.514+0000 I  NETWORK  [conn32] received client metadata from 172.31.0.221:42488 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.523+0000 I  NETWORK  [conn20] end connection 172.31.0.221:42396 (16 connections now open)
2020-05-08T21:57:19.523+0000 I  NETWORK  [conn21] end connection 172.31.0.221:42402 (15 connections now open)
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42510 #33 (16 connections now open)
2020-05-08T21:57:19.562+0000 I  NETWORK  [conn33] received client metadata from 172.31.0.221:42510 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.844+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42520 #34 (17 connections now open)
2020-05-08T21:57:19.844+0000 I  NETWORK  [conn34] received client metadata from 172.31.0.221:42520 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.000+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42534 #35 (18 connections now open)
2020-05-08T21:57:20.001+0000 I  NETWORK  [conn35] received client metadata from 172.31.0.221:42534 conn35: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.188+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42548 #36 (19 connections now open)
2020-05-08T21:57:20.188+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42550 #37 (20 connections now open)
2020-05-08T21:57:20.188+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:42548 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.189+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:42550 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.272+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42574 #38 (21 connections now open)
2020-05-08T21:57:20.272+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:42574 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42584 #39 (22 connections now open)
2020-05-08T21:57:21.343+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:42584 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.553+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42600 #40 (23 connections now open)
2020-05-08T21:57:21.553+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:42600 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.917+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42638 #41 (24 connections now open)
2020-05-08T21:57:21.917+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:42638 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42688 #42 (25 connections now open)
2020-05-08T21:57:22.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42686 #43 (26 connections now open)
2020-05-08T21:57:22.060+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:42688 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.060+0000 I  NETWORK  [conn43] received client metadata from 172.31.0.221:42686 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.062+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42704 #44 (27 connections now open)
2020-05-08T21:57:22.062+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:42704 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.062+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42708 #45 (28 connections now open)
2020-05-08T21:57:22.063+0000 I  NETWORK  [conn45] received client metadata from 172.31.0.221:42708 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.072+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.078+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42764 #48 (29 connections now open)
2020-05-08T21:57:22.079+0000 I  NETWORK  [conn48] received client metadata from 172.31.0.221:42764 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.079+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42766 #49 (30 connections now open)
2020-05-08T21:57:22.079+0000 I  NETWORK  [conn49] received client metadata from 172.31.0.221:42766 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.323+0000 I  COMMAND  [conn49] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 1, autocommit: false } numYields:0 reslen:351 protocol:op_msg 214ms
2020-05-08T21:57:22.324+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 239ms
2020-05-08T21:57:22.516+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42814 #56 (31 connections now open)
2020-05-08T21:57:22.517+0000 I  NETWORK  [conn56] received client metadata from 172.31.0.221:42814 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.834+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 409), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 51, autocommit: false } numYields:0 reslen:321 protocol:op_msg 209ms
2020-05-08T21:57:23.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.085+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42846 #61 (32 connections now open)
2020-05-08T21:57:23.085+0000 I  NETWORK  [conn61] received client metadata from 172.31.0.221:42846 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.145+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42864 #62 (33 connections now open)
2020-05-08T21:57:23.145+0000 I  NETWORK  [conn62] received client metadata from 172.31.0.221:42864 conn62: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.370+0000 I  TXN      [conn44] transaction parameters:{ lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 334) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 334) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:848791, timeActiveMicros:853420, timeInactiveMicros:1154, 854ms
2020-05-08T21:57:23.370+0000 I  COMMAND  [conn44] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 340), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 848ms
2020-05-08T21:57:23.370+0000 I  COMMAND  [conn49] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 347), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 6, autocommit: false } numYields:0 reslen:320 protocol:op_msg 844ms
2020-05-08T21:57:23.421+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42882 #63 (34 connections now open)
2020-05-08T21:57:23.421+0000 I  NETWORK  [conn63] received client metadata from 172.31.0.221:42882 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.756+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42920 #64 (35 connections now open)
2020-05-08T21:57:23.756+0000 I  NETWORK  [conn64] received client metadata from 172.31.0.221:42920 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.776+0000 I  COMMAND  [conn49] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 114), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 23, autocommit: false } numYields:0 reslen:321 protocol:op_msg 215ms
2020-05-08T21:57:23.900+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 438), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 65, autocommit: false } numYields:0 reslen:321 protocol:op_msg 965ms
2020-05-08T21:57:24.197+0000 I  COMMAND  [conn44] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 5 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975043, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769") }, txnNumber: 11, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 826ms
2020-05-08T21:57:24.201+0000 I  TXN      [conn44] transaction parameters:{ lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 11, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 6) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:829770, timeInactiveMicros:402, 830ms
2020-05-08T21:57:24.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:42956 #65 (36 connections now open)
2020-05-08T21:57:24.471+0000 I  NETWORK  [conn65] received client metadata from 172.31.0.221:42956 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.618+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 66, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 44) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 197) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:714090, timeActiveMicros:716745, timeInactiveMicros:694, 717ms
2020-05-08T21:57:24.618+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 200), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 66, autocommit: false } numYields:0 reslen:214 protocol:op_msg 714ms
2020-05-08T21:57:24.619+0000 I  COMMAND  [conn44] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 131), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769") }, txnNumber: 11, autocommit: false } numYields:0 reslen:321 protocol:op_msg 417ms
2020-05-08T21:57:25.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.123+0000 I  COMMAND  [conn49] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 179), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 81, autocommit: false } numYields:0 reslen:352 protocol:op_msg 846ms
2020-05-08T21:57:25.151+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 67, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 186), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 532ms
2020-05-08T21:57:25.186+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43002 #68 (37 connections now open)
2020-05-08T21:57:25.186+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:43002 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.421+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43030 #69 (38 connections now open)
2020-05-08T21:57:25.421+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:43030 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.478+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 22) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:326118, timeInactiveMicros:0, 326ms
2020-05-08T21:57:25.478+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 68, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 326ms
2020-05-08T21:57:25.503+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43044 #70 (39 connections now open)
2020-05-08T21:57:25.503+0000 I  NETWORK  [conn70] received client metadata from 172.31.0.221:43044 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.543+0000 I  COMMAND  [conn44] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 5 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 187), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769") }, txnNumber: 12, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975044, 187) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 923ms
2020-05-08T21:57:25.546+0000 I  TXN      [conn44] transaction parameters:{ lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975044, 187) } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 187) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:925527, timeInactiveMicros:703, 926ms
2020-05-08T21:57:25.554+0000 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 82), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 111, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 201ms
2020-05-08T21:57:25.566+0000 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 111, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 82) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 82) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:9982, timeActiveMicros:213722, timeInactiveMicros:1256, 214ms
2020-05-08T21:57:25.584+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43068 #72 (40 connections now open)
2020-05-08T21:57:25.671+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:43068 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.132+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43102 #73 (41 connections now open)
2020-05-08T21:57:26.133+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:43102 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43118 #74 (42 connections now open)
2020-05-08T21:57:26.371+0000 I  NETWORK  [conn74] received client metadata from 172.31.0.221:43118 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.458+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 93), t: 3 }
2020-05-08T21:57:26.948+0000 I  NETWORK  [conn49] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:26.948+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.951+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.954+0000 I  NETWORK  [conn43] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:26.955+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.448+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.948+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:28.448+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.448+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.448+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.463+0000 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 124, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 674), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2520ms
2020-05-08T21:57:28.463+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 86, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 668) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 668) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2521706, timeActiveMicros:2524725, timeInactiveMicros:508, 2525ms
2020-05-08T21:57:28.464+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 673), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 86, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2522ms
2020-05-08T21:57:28.470+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:29.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:29.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.117+0000 I  NETWORK  [conn44] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:30.118+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.118+0000 I  NETWORK  [conn43] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:30.118+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.213+0000 I  NETWORK  [conn49] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:57:30.214+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.618+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.935+0000 I  NETWORK  [conn45] end connection 172.31.0.221:42708 (41 connections now open)
2020-05-08T21:57:30.936+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43272 #80 (42 connections now open)
2020-05-08T21:57:30.936+0000 I  NETWORK  [conn80] received client metadata from 172.31.0.221:43272 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.937+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43278 #81 (43 connections now open)
2020-05-08T21:57:30.938+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:43278 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.957+0000 I  -        [conn44] operation was interrupted because a client disconnected
2020-05-08T21:57:30.957+0000 I  TXN      [conn44] transaction parameters:{ lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 683) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 683) }, numParticipants:2, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:5006048, timeInactiveMicros:597, 5006ms
2020-05-08T21:57:30.958+0000 I  COMMAND  [conn44] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 60 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 683), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d4714cb2-07bd-404c-8ef5-36434b6c5769") }, txnNumber: 26, autocommit: false } numYields:0 ok:0 errMsg:"Transaction d4714cb2-07bd-404c-8ef5-36434b6c5769:26 was aborted on statement 2 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:627 protocol:op_msg 5003ms
2020-05-08T21:57:30.958+0000 I  NETWORK  [conn44] end connection 172.31.0.221:42704 (42 connections now open)
2020-05-08T21:57:31.118+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:31.618+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.618+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.620+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 88, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 14) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3149873, timeInactiveMicros:0, 3149ms
2020-05-08T21:57:31.620+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 88, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 3150ms
2020-05-08T21:57:31.629+0000 I  COMMAND  [conn49] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 61 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:277 protocol:op_msg 3165ms
2020-05-08T21:57:31.992+0000 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1053ms
2020-05-08T21:57:31.994+0000 I  COMMAND  [conn49] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 64 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975051, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 125, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 364ms
2020-05-08T21:57:31.999+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975051, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 88, autocommit: false } numYields:0 reslen:397 protocol:op_msg 378ms
2020-05-08T21:57:32.002+0000 I  NETWORK  [conn49] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:32.002+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.002+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.003+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:32.003+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.004+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:32.026+0000 I  TXN      [conn80] transaction parameters:{ lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 14) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:22878, timeActiveMicros:1080997, timeInactiveMicros:6891, 1087ms
2020-05-08T21:57:32.503+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:32.963+0000 I  NETWORK  [conn49] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:32.963+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.003+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.003+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.004+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:33.206+0000 I  NETWORK  [conn43] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:33.413+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.463+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.470+0000 I  NETWORK  [conn42] end connection 172.31.0.221:42688 (41 connections now open)
2020-05-08T21:57:33.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43328 #84 (42 connections now open)
2020-05-08T21:57:33.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43330 #85 (43 connections now open)
2020-05-08T21:57:33.471+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:43328 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:33.471+0000 I  NETWORK  [conn85] received client metadata from 172.31.0.221:43330 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:33.472+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.706+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.706+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.707+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 89, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975051, 7) } }, globalReadTimestamp:{ ts: Timestamp(1588975051, 7) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1708101, timeInactiveMicros:0, 1708ms
2020-05-08T21:57:33.707+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975051, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("29fdd6fe-8555-4a09-a8ba-6454d886db5c") }, txnNumber: 89, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975051, 7) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1708ms
2020-05-08T21:57:33.707+0000 I  NETWORK  [conn43] end connection 172.31.0.221:42686 (42 connections now open)
2020-05-08T21:57:33.711+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 238ms
2020-05-08T21:57:33.713+0000 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 2, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975052, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 1686ms
2020-05-08T21:57:33.721+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.963+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:34.146+0000 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa") }, txnNumber: 3, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 429ms
2020-05-08T21:57:34.146+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.147+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.147+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.147+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 65 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975053, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 426ms
2020-05-08T21:57:34.147+0000 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 125, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975051, 3) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2511184, timeInactiveMicros:6704, 2517ms
2020-05-08T21:57:34.148+0000 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975052, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 125, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2122ms
2020-05-08T21:57:34.164+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975053, 13) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:12535, timeActiveMicros:442865, timeInactiveMicros:1020, 443ms
2020-05-08T21:57:34.185+0000 I  TXN      [conn80] transaction parameters:{ lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975053, 12) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:36495, timeActiveMicros:469471, timeInactiveMicros:1080, 470ms
2020-05-08T21:57:34.272+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:35.036+0000 I  TXN      [conn80] transaction parameters:{ lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 35, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975054, 846) } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 846) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:218367, timeInactiveMicros:279, 218ms
2020-05-08T21:57:35.036+0000 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 849), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa") }, txnNumber: 35, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 214ms
2020-05-08T21:57:35.048+0000 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 862), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 165, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 214ms
2020-05-08T21:57:35.048+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975054, 857) } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 857) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:218700, timeInactiveMicros:0, 218ms
2020-05-08T21:57:35.048+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975054, 857), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3") }, txnNumber: 38, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975054, 857) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 218ms
2020-05-08T21:57:35.101+0000 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 165, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 859) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:51255, timeActiveMicros:268222, timeInactiveMicros:1663, 269ms
2020-05-08T21:57:35.816+0000 I  NETWORK  [conn80] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:35.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:35.816+0000 I  NETWORK  [conn49] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:35.817+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.283+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43428 #89 (43 connections now open)
2020-05-08T21:57:36.283+0000 I  NETWORK  [conn89] received client metadata from 172.31.0.221:43428 conn89: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.462+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:36.463+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.962+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.962+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.966+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 83), t: 6 }
2020-05-08T21:57:37.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.047+0000 I  NETWORK  [conn84] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:38.048+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:38.048+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:38.049+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:38.050+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:38.050+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:38.051+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:38.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.397+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:39.718+0000 I  NETWORK  [conn84] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.718+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.718+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.719+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.719+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 50, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975055, 410) } }, globalReadTimestamp:{ ts: Timestamp(1588975055, 411) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4355659, timeInactiveMicros:0, 4355ms
2020-05-08T21:57:39.719+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975055, 410), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3") }, txnNumber: 50, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975055, 410) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 4355ms
2020-05-08T21:57:39.719+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:39.816+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.817+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.817+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:39.818+0000 I  COMMAND  [conn80] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 417), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa") }, txnNumber: 50, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4448ms
2020-05-08T21:57:39.818+0000 I  COMMAND  [conn49] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 418), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 176, autocommit: false } numYields:0 reslen:440 protocol:op_msg 4447ms
2020-05-08T21:57:40.055+0000 I  NETWORK  [conn80] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.055+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.219+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.310+0000 I  NETWORK  [conn48] end connection 172.31.0.221:42764 (42 connections now open)
2020-05-08T21:57:40.310+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43514 #90 (43 connections now open)
2020-05-08T21:57:40.310+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43516 #91 (44 connections now open)
2020-05-08T21:57:40.311+0000 I  NETWORK  [conn90] received client metadata from 172.31.0.221:43514 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.311+0000 I  NETWORK  [conn91] received client metadata from 172.31.0.221:43516 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.337+0000 I  NETWORK  [conn85] end connection 172.31.0.221:43330 (43 connections now open)
2020-05-08T21:57:40.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43530 #92 (44 connections now open)
2020-05-08T21:57:40.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43532 #93 (45 connections now open)
2020-05-08T21:57:40.338+0000 I  NETWORK  [conn92] received client metadata from 172.31.0.221:43530 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.338+0000 I  NETWORK  [conn93] received client metadata from 172.31.0.221:43532 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.365+0000 I  NETWORK  [conn81] end connection 172.31.0.221:43278 (44 connections now open)
2020-05-08T21:57:40.367+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43566 #94 (45 connections now open)
2020-05-08T21:57:40.368+0000 I  NETWORK  [conn94] received client metadata from 172.31.0.221:43566 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.368+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43568 #95 (46 connections now open)
2020-05-08T21:57:40.368+0000 I  NETWORK  [conn95] received client metadata from 172.31.0.221:43568 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.372+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.719+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.219+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.318+0000 I  NETWORK  [conn84] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.525+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.525+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.526+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.526+0000 I  TXN      [conn84] transaction parameters:{ lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 51, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975059, 31) } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 31) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1801473, timeInactiveMicros:0, 1801ms
2020-05-08T21:57:41.527+0000 I  COMMAND  [conn84] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f908a6c-3dd6-41fe-93f7-8f2d93e6afc3") }, txnNumber: 51, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975059, 31) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1801ms
2020-05-08T21:57:41.527+0000 I  NETWORK  [conn84] end connection 172.31.0.221:43328 (45 connections now open)
2020-05-08T21:57:41.568+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43602 #96 (46 connections now open)
2020-05-08T21:57:41.569+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:43602 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:41.719+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.816+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.817+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.817+0000 I  COMMAND  [conn80] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("93cf0564-27f6-48ac-8fad-cec40ae390fa") }, txnNumber: 50, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1997ms
2020-05-08T21:57:41.817+0000 I  COMMAND  [conn49] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 51), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cbb845-17a0-4290-8a18-3cdf5e06459e") }, txnNumber: 176, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1997ms
2020-05-08T21:57:41.817+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.817+0000 I  NETWORK  [conn80] end connection 172.31.0.221:43272 (45 connections now open)
2020-05-08T21:57:41.817+0000 I  NETWORK  [conn49] end connection 172.31.0.221:42766 (44 connections now open)
2020-05-08T21:57:42.063+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40909f55-4c91-4c9c-a03a-125f9acebdbc") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1691ms
2020-05-08T21:57:42.219+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.719+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.219+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.719+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.719+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.719+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.212+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.706+0000 I  NETWORK  [conn92] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:44.707+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.206+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.258+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43690 #100 (45 connections now open)
2020-05-08T21:57:45.259+0000 I  NETWORK  [conn100] received client metadata from 172.31.0.221:43690 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.311+0000 I  NETWORK  [conn91] end connection 172.31.0.221:43516 (44 connections now open)
2020-05-08T21:57:45.311+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43706 #101 (45 connections now open)
2020-05-08T21:57:45.311+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43708 #102 (46 connections now open)
2020-05-08T21:57:45.311+0000 I  NETWORK  [conn101] received client metadata from 172.31.0.221:43706 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.311+0000 I  NETWORK  [conn102] received client metadata from 172.31.0.221:43708 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.313+0000 I  -        [conn90] operation was interrupted because a client disconnected
2020-05-08T21:57:45.313+0000 I  TXN      [conn90] transaction parameters:{ lsid: { id: UUID("b9cdd314-824b-478b-b886-c9648ddf82b5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001906, timeInactiveMicros:0, 5001ms
2020-05-08T21:57:45.313+0000 I  COMMAND  [conn90] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 137 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b9cdd314-824b-478b-b886-c9648ddf82b5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:57:45.313+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.314+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.314+0000 I  NETWORK  [conn90] end connection 172.31.0.221:43514 (45 connections now open)
2020-05-08T21:57:45.315+0000 I  TXN      [conn94] transaction parameters:{ lsid: { id: UUID("40909f55-4c91-4c9c-a03a-125f9acebdbc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4942408, timeInactiveMicros:590, 4942ms
2020-05-08T21:57:45.315+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975061, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40909f55-4c91-4c9c-a03a-125f9acebdbc") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3251ms
2020-05-08T21:57:45.338+0000 I  NETWORK  [conn93] end connection 172.31.0.221:43532 (44 connections now open)
2020-05-08T21:57:45.339+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43722 #103 (45 connections now open)
2020-05-08T21:57:45.339+0000 I  NETWORK  [conn103] received client metadata from 172.31.0.221:43722 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.340+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43724 #104 (46 connections now open)
2020-05-08T21:57:45.340+0000 I  NETWORK  [conn104] received client metadata from 172.31.0.221:43724 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.368+0000 I  NETWORK  [conn95] end connection 172.31.0.221:43568 (45 connections now open)
2020-05-08T21:57:45.368+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43754 #105 (46 connections now open)
2020-05-08T21:57:45.369+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43756 #106 (47 connections now open)
2020-05-08T21:57:45.369+0000 I  NETWORK  [conn106] received client metadata from 172.31.0.221:43756 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.369+0000 I  NETWORK  [conn105] received client metadata from 172.31.0.221:43754 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.712+0000 I  NETWORK  [replSetDistLockPinger] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:45.802+0000 I  NETWORK  [conn101] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:45.803+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:45.803+0000 I  NETWORK  [conn105] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:45.803+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.107+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.302+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.802+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.968+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.302+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.802+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.302+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.302+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.303+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.303+0000 I  COMMAND  [conn101] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5d87f95f-4430-446b-ae0b-84ba4029b718") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2988ms
2020-05-08T21:57:48.304+0000 I  COMMAND  [conn94] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("40909f55-4c91-4c9c-a03a-125f9acebdbc") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2988ms
2020-05-08T21:57:48.304+0000 I  COMMAND  [conn105] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a597bdf-a481-4522-a7db-918fc7b777af") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 2931ms
2020-05-08T21:57:48.304+0000 I  NETWORK  [conn94] end connection 172.31.0.221:43566 (46 connections now open)
2020-05-08T21:57:48.713+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.713+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:49.346+0000 I  NETWORK  [conn103] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:49.690+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43822 #107 (47 connections now open)
2020-05-08T21:57:49.690+0000 I  NETWORK  [conn107] received client metadata from 172.31.0.221:43822 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.311+0000 I  NETWORK  [conn102] end connection 172.31.0.221:43708 (46 connections now open)
2020-05-08T21:57:50.312+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43836 #108 (47 connections now open)
2020-05-08T21:57:50.312+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43834 #109 (48 connections now open)
2020-05-08T21:57:50.312+0000 I  NETWORK  [conn108] received client metadata from 172.31.0.221:43836 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.312+0000 I  NETWORK  [conn109] received client metadata from 172.31.0.221:43834 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.317+0000 I  NETWORK  [conn101] end connection 172.31.0.221:43706 (47 connections now open)
2020-05-08T21:57:50.321+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.340+0000 I  NETWORK  [conn104] end connection 172.31.0.221:43724 (46 connections now open)
2020-05-08T21:57:50.340+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43850 #110 (47 connections now open)
2020-05-08T21:57:50.340+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43852 #111 (48 connections now open)
2020-05-08T21:57:50.340+0000 I  NETWORK  [conn111] received client metadata from 172.31.0.221:43852 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.341+0000 I  NETWORK  [conn110] received client metadata from 172.31.0.221:43850 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.013+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.553+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.846+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.846+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.847+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.847+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.847+0000 I  TXN      [conn103] transaction parameters:{ lsid: { id: UUID("c094146d-1411-476e-96b8-5160243b48af"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 2) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6506004, timeInactiveMicros:571, 6506ms
2020-05-08T21:57:51.847+0000 I  COMMAND  [conn103] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c094146d-1411-476e-96b8-5160243b48af") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 6503ms
2020-05-08T21:57:51.847+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.847+0000 I  NETWORK  [conn103] end connection 172.31.0.221:43722 (47 connections now open)
2020-05-08T21:57:51.850+0000 I  TXN      [conn105] transaction parameters:{ lsid: { id: UUID("4a597bdf-a481-4522-a7db-918fc7b777af"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 52) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3501857, timeInactiveMicros:0, 3501ms
2020-05-08T21:57:51.851+0000 I  COMMAND  [conn105] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 147 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 52), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a597bdf-a481-4522-a7db-918fc7b777af") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 4a597bdf-a481-4522-a7db-918fc7b777af:5 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975068, 52) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 3501ms
2020-05-08T21:57:51.851+0000 I  TXN      [conn108] transaction parameters:{ lsid: { id: UUID("9c3b5cb0-e423-44af-94e7-dd3d701603d3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975070, 153) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1537796, timeInactiveMicros:0, 1537ms
2020-05-08T21:57:51.851+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 153), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9c3b5cb0-e423-44af-94e7-dd3d701603d3") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 1537ms
2020-05-08T21:57:51.852+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 146 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 158), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25aa461-e8a4-468b-ae1b-b63ebc59714f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1510ms
2020-05-08T21:57:51.854+0000 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("a25aa461-e8a4-468b-ae1b-b63ebc59714f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975070, 158) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1512193, timeInactiveMicros:304, 1512ms
2020-05-08T21:57:51.855+0000 I  COMMAND  [conn92] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8d84d19b-6913-4822-a557-a2e945442e22") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 11516ms
2020-05-08T21:57:51.855+0000 I  NETWORK  [conn92] end connection 172.31.0.221:43530 (46 connections now open)
2020-05-08T21:57:52.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.202+0000 I  SHARDING [conn111] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.347+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.347+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.715+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43924 #115 (47 connections now open)
2020-05-08T21:57:52.715+0000 I  NETWORK  [conn115] received client metadata from 172.31.0.221:43924 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.844+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.889+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:43942 #117 (48 connections now open)
2020-05-08T21:57:52.889+0000 I  NETWORK  [conn117] received client metadata from 172.31.0.221:43942 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.337+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44020 #118 (49 connections now open)
2020-05-08T21:57:54.338+0000 I  NETWORK  [conn118] received client metadata from 172.31.0.221:44020 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:55.794+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44110 #119 (50 connections now open)
2020-05-08T21:57:55.794+0000 I  NETWORK  [conn119] received client metadata from 172.31.0.221:44110 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.741+0000 I  NETWORK  [conn108] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:56.742+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.790+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44158 #120 (51 connections now open)
2020-05-08T21:57:56.790+0000 I  NETWORK  [conn120] received client metadata from 172.31.0.221:44158 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.967+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44170 #121 (52 connections now open)
2020-05-08T21:57:56.967+0000 I  NETWORK  [conn121] received client metadata from 172.31.0.221:44170 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.628+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44222 #122 (53 connections now open)
2020-05-08T21:57:57.628+0000 I  NETWORK  [conn122] received client metadata from 172.31.0.221:44222 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.358+0000 I  NETWORK  [conn106] end connection 172.31.0.221:43756 (52 connections now open)
2020-05-08T21:57:58.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44266 #123 (53 connections now open)
2020-05-08T21:57:58.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44268 #124 (54 connections now open)
2020-05-08T21:57:58.359+0000 I  NETWORK  [conn123] received client metadata from 172.31.0.221:44266 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.359+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:44268 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.360+0000 I  NETWORK  [conn110] end connection 172.31.0.221:43850 (53 connections now open)
2020-05-08T21:57:58.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44270 #125 (54 connections now open)
2020-05-08T21:57:58.361+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:44270 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44272 #126 (55 connections now open)
2020-05-08T21:57:58.361+0000 I  NETWORK  [conn126] received client metadata from 172.31.0.221:44272 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.400+0000 I  CONNPOOL [conn105] Ending connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:57:58.401+0000 I  COMMAND  [conn105] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 565), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4a597bdf-a481-4522-a7db-918fc7b777af") }, txnNumber: 79, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5015ms
2020-05-08T21:57:58.401+0000 I  NETWORK  [conn105] end connection 172.31.0.221:43754 (54 connections now open)
2020-05-08T21:57:58.401+0000 I  CONNPOOL [conn111] Ending connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:57:58.401+0000 I  COMMAND  [conn111] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 567), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25aa461-e8a4-468b-ae1b-b63ebc59714f") }, txnNumber: 73, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5015ms
2020-05-08T21:57:58.401+0000 I  NETWORK  [conn111] end connection 172.31.0.221:43852 (53 connections now open)
2020-05-08T21:57:58.413+0000 I  NETWORK  [conn109] end connection 172.31.0.221:43834 (52 connections now open)
2020-05-08T21:57:58.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44320 #127 (53 connections now open)
2020-05-08T21:57:58.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44322 #128 (54 connections now open)
2020-05-08T21:57:58.415+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:44322 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.415+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:44320 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.611+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44340 #129 (55 connections now open)
2020-05-08T21:57:58.611+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:44340 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.877+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44380 #130 (56 connections now open)
2020-05-08T21:57:59.877+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:44380 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.326+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.326+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:00.327+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.327+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.827+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.827+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:02.242+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 4743 timed out, deadline was 2020-05-08T21:58:02.242+0000, op was RemoteCommand 4743 -- target:[ec2-35-172-222-251.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:02.242+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:02.242+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.242+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:02.242+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:58:03.359+0000 I  NETWORK  [conn123] end connection 172.31.0.221:44266 (55 connections now open)
2020-05-08T21:58:03.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44522 #131 (56 connections now open)
2020-05-08T21:58:03.359+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:44522 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44524 #132 (57 connections now open)
2020-05-08T21:58:03.360+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:44524 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.361+0000 I  NETWORK  [conn125] end connection 172.31.0.221:44270 (56 connections now open)
2020-05-08T21:58:03.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44526 #133 (57 connections now open)
2020-05-08T21:58:03.361+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:44526 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44528 #134 (58 connections now open)
2020-05-08T21:58:03.362+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:44528 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.365+0000 I  -        [conn124] operation was interrupted because a client disconnected
2020-05-08T21:58:03.365+0000 I  TXN      [conn124] transaction parameters:{ lsid: { id: UUID("d6fb662b-cd1c-4a14-938f-73b4aa3faff7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975076, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004364, timeInactiveMicros:0, 5004ms
2020-05-08T21:58:03.365+0000 I  COMMAND  [conn124] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 264 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975076, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d6fb662b-cd1c-4a14-938f-73b4aa3faff7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:58:03.365+0000 I  NETWORK  [conn124] end connection 172.31.0.221:44268 (57 connections now open)
2020-05-08T21:58:03.415+0000 I  NETWORK  [conn128] end connection 172.31.0.221:44322 (56 connections now open)
2020-05-08T21:58:03.415+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44566 #135 (57 connections now open)
2020-05-08T21:58:03.415+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44568 #136 (58 connections now open)
2020-05-08T21:58:03.415+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:44566 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.415+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:44568 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.505+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 275 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975080, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be9e7703-45c8-4960-bbb9-0b0b43000d2a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 144ms
2020-05-08T21:58:03.505+0000 I  COMMAND  [conn133] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c960462b-3b37-4d95-95df-40810080910a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 141ms
2020-05-08T21:58:03.510+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("be9e7703-45c8-4960-bbb9-0b0b43000d2a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975080, 9) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:149652, timeInactiveMicros:396, 150ms
2020-05-08T21:58:03.518+0000 I  TXN      [conn133] transaction parameters:{ lsid: { id: UUID("c960462b-3b37-4d95-95df-40810080910a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 3) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:8016, timeActiveMicros:153818, timeInactiveMicros:1108, 154ms
2020-05-08T21:58:05.242+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.242+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.242+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.243+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:05.243+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.244+0000 I  TXN      [conn108] transaction parameters:{ lsid: { id: UUID("9c3b5cb0-e423-44af-94e7-dd3d701603d3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 72, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 595) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:11831154, timeInactiveMicros:0, 11831ms
2020-05-08T21:58:05.244+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975073, 595), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9c3b5cb0-e423-44af-94e7-dd3d701603d3") }, txnNumber: 72, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 11831ms
2020-05-08T21:58:05.244+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.245+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.245+0000 I  NETWORK  [conn108] end connection 172.31.0.221:43836 (57 connections now open)
2020-05-08T21:58:05.246+0000 I  TXN      [conn127] transaction parameters:{ lsid: { id: UUID("5afa5f0c-0a03-4e7d-b115-0e7358bbbc69"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975076, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:6830918, timeInactiveMicros:0, 6830ms
2020-05-08T21:58:05.246+0000 I  TXN      [conn126] transaction parameters:{ lsid: { id: UUID("e877d4d7-c299-4011-b410-4f0780eb5140"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975076, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:6884395, timeInactiveMicros:0, 6884ms
2020-05-08T21:58:05.246+0000 I  COMMAND  [conn127] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975076, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5afa5f0c-0a03-4e7d-b115-0e7358bbbc69") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 5afa5f0c-0a03-4e7d-b115-0e7358bbbc69:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975076, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:593 protocol:op_msg 6831ms
2020-05-08T21:58:05.246+0000 I  COMMAND  [conn126] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975076, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e877d4d7-c299-4011-b410-4f0780eb5140") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction e877d4d7-c299-4011-b410-4f0780eb5140:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975076, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:593 protocol:op_msg 6884ms
2020-05-08T21:58:05.246+0000 I  NETWORK  [conn127] end connection 172.31.0.221:44320 (56 connections now open)
2020-05-08T21:58:05.246+0000 I  NETWORK  [conn126] end connection 172.31.0.221:44272 (55 connections now open)
2020-05-08T21:58:05.743+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.743+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.947+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be9e7703-45c8-4960-bbb9-0b0b43000d2a") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2391ms
2020-05-08T21:58:05.947+0000 I  COMMAND  [conn133] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 282 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c960462b-3b37-4d95-95df-40810080910a") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2427ms
2020-05-08T21:58:05.947+0000 I  COMMAND  [conn135] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 282 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28a13812-372f-421e-9df7-36c18adacf81") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2531ms
2020-05-08T21:58:05.952+0000 I  NETWORK  [conn131] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.952+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.953+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.954+0000 I  TXN      [conn133] transaction parameters:{ lsid: { id: UUID("c960462b-3b37-4d95-95df-40810080910a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 16) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2432650, timeInactiveMicros:2450, 2435ms
2020-05-08T21:58:05.956+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("be9e7703-45c8-4960-bbb9-0b0b43000d2a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 40) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2396269, timeInactiveMicros:4374, 2400ms
2020-05-08T21:58:05.966+0000 I  TXN      [conn135] transaction parameters:{ lsid: { id: UUID("28a13812-372f-421e-9df7-36c18adacf81"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 3) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:13516, timeActiveMicros:2546663, timeInactiveMicros:3839, 2550ms
2020-05-08T21:58:06.555+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.555+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:06.972+0000 I  NETWORK  [conn133] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:07.055+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.555+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.555+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.813+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.813+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.813+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.814+0000 I  COMMAND  [conn133] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c960462b-3b37-4d95-95df-40810080910a") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1834ms
2020-05-08T21:58:07.814+0000 I  COMMAND  [conn131] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 55), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be9e7703-45c8-4960-bbb9-0b0b43000d2a") }, txnNumber: 6, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1827ms
2020-05-08T21:58:08.520+0000 I  NETWORK  [conn134] end connection 172.31.0.221:44528 (54 connections now open)
2020-05-08T21:58:08.520+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44688 #141 (55 connections now open)
2020-05-08T21:58:08.520+0000 I  NETWORK  [conn141] received client metadata from 172.31.0.221:44688 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.521+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44690 #142 (56 connections now open)
2020-05-08T21:58:08.521+0000 I  NETWORK  [conn142] received client metadata from 172.31.0.221:44690 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.556+0000 I  NETWORK  [conn132] end connection 172.31.0.221:44524 (55 connections now open)
2020-05-08T21:58:08.556+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44700 #143 (56 connections now open)
2020-05-08T21:58:08.556+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44702 #144 (57 connections now open)
2020-05-08T21:58:08.556+0000 I  NETWORK  [conn143] received client metadata from 172.31.0.221:44700 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.556+0000 I  NETWORK  [conn144] received client metadata from 172.31.0.221:44702 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.562+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.938+0000 I  NETWORK  [conn141] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:08.938+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:08.939+0000 I  NETWORK  [conn135] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:08.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.059+0000 I  COMMAND  [conn133] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 217), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c960462b-3b37-4d95-95df-40810080910a") }, txnNumber: 3, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1244ms
2020-05-08T21:58:09.059+0000 I  NETWORK  [conn133] end connection 172.31.0.221:44526 (56 connections now open)
2020-05-08T21:58:09.061+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 217), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be9e7703-45c8-4960-bbb9-0b0b43000d2a") }, txnNumber: 7, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975087, 217) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1246ms
2020-05-08T21:58:09.061+0000 I  NETWORK  [conn131] end connection 172.31.0.221:44522 (55 connections now open)
2020-05-08T21:58:09.438+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.938+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.938+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.939+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.939+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.939+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("872520a1-44dd-4c10-aff1-563078b63007") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 1413ms
2020-05-08T21:58:09.939+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.939+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.940+0000 I  COMMAND  [conn135] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 215), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28a13812-372f-421e-9df7-36c18adacf81") }, txnNumber: 174, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2537ms
2020-05-08T21:58:09.940+0000 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 1379ms
2020-05-08T21:58:10.053+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44756 #145 (56 connections now open)
2020-05-08T21:58:10.053+0000 I  NETWORK  [conn145] received client metadata from 172.31.0.221:44756 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.182+0000 I  NETWORK  [conn141] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:10.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.387+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.438+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.938+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.971+0000 I  NETWORK  [conn136] end connection 172.31.0.221:44568 (55 connections now open)
2020-05-08T21:58:10.972+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44800 #146 (56 connections now open)
2020-05-08T21:58:10.972+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44802 #147 (57 connections now open)
2020-05-08T21:58:10.972+0000 I  NETWORK  [conn146] received client metadata from 172.31.0.221:44800 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.972+0000 I  NETWORK  [conn147] received client metadata from 172.31.0.221:44802 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.973+0000 I  NETWORK  [conn146] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.974+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.438+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.438+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.439+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.439+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.439+0000 I  SHARDING [conn141] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 3), t: 19 }
2020-05-08T21:58:11.439+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("872520a1-44dd-4c10-aff1-563078b63007") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 1499ms
2020-05-08T21:58:11.440+0000 I  COMMAND  [conn135] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28a13812-372f-421e-9df7-36c18adacf81") }, txnNumber: 174, autocommit: false } numYields:0 reslen:516 protocol:op_msg 1499ms
2020-05-08T21:58:11.440+0000 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 1499ms
2020-05-08T21:58:11.440+0000 I  NETWORK  [conn135] end connection 172.31.0.221:44566 (56 connections now open)
2020-05-08T21:58:11.649+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.649+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.650+0000 I  TXN      [conn146] transaction parameters:{ lsid: { id: UUID("cb330eed-174b-4420-8b79-c3f3eb6dcfea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975089, 213) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:677119, timeInactiveMicros:0, 677ms
2020-05-08T21:58:11.650+0000 I  COMMAND  [conn146] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 213), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb330eed-174b-4420-8b79-c3f3eb6dcfea") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 677ms
2020-05-08T21:58:11.650+0000 I  COMMAND  [conn143] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 289 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975091, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 207ms
2020-05-08T21:58:11.651+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.287+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44836 #149 (57 connections now open)
2020-05-08T21:58:12.287+0000 I  NETWORK  [conn149] received client metadata from 172.31.0.221:44836 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.366+0000 I  COMMAND  [conn146] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 106), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb330eed-174b-4420-8b79-c3f3eb6dcfea") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 715ms
2020-05-08T21:58:12.372+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.379+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975091, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975091, 5) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:728826, timeActiveMicros:937993, timeInactiveMicros:796, 938ms
2020-05-08T21:58:12.379+0000 I  COMMAND  [conn143] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 106), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 728ms
2020-05-08T21:58:12.821+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.173+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44900 #154 (58 connections now open)
2020-05-08T21:58:15.173+0000 I  NETWORK  [conn154] received client metadata from 172.31.0.221:44900 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.245+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:16.427+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:58:16.648+0000 I  NETWORK  [conn143] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:16.649+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:16.656+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.149+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.149+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.150+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:17.150+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:17.150+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:17.151+0000 I  TXN      [conn143] transaction parameters:{ lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 54, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 504) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3755566, timeInactiveMicros:0, 3755ms
2020-05-08T21:58:17.151+0000 I  TXN      [conn146] transaction parameters:{ lsid: { id: UUID("cb330eed-174b-4420-8b79-c3f3eb6dcfea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 528, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 174) } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 174) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:505485, timeInactiveMicros:0, 505ms
2020-05-08T21:58:17.151+0000 I  COMMAND  [conn143] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 504), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a") }, txnNumber: 54, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 3755ms
2020-05-08T21:58:17.151+0000 I  COMMAND  [conn146] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 174), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb330eed-174b-4420-8b79-c3f3eb6dcfea") }, txnNumber: 528, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 174) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 505ms
2020-05-08T21:58:17.152+0000 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("872520a1-44dd-4c10-aff1-563078b63007"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 167, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 512) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:3746627, timeInactiveMicros:580, 3747ms
2020-05-08T21:58:17.152+0000 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 363 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 518), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("872520a1-44dd-4c10-aff1-563078b63007") }, txnNumber: 167, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 167 does not match any in-progress transactions. The active transaction number is 166" errName:NoSuchTransaction errCode:251 reslen:440 protocol:op_msg 3742ms
2020-05-08T21:58:17.363+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.364+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.650+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.670+0000 I  NETWORK  [conn143] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:17.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.671+0000 I  NETWORK  [conn146] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:17.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.150+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:18.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.374+0000 I  NETWORK  [conn147] end connection 172.31.0.221:44802 (57 connections now open)
2020-05-08T21:58:18.374+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44994 #155 (58 connections now open)
2020-05-08T21:58:18.375+0000 I  NETWORK  [conn155] received client metadata from 172.31.0.221:44994 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:44996 #156 (59 connections now open)
2020-05-08T21:58:18.375+0000 I  NETWORK  [conn156] received client metadata from 172.31.0.221:44996 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.377+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.395+0000 I  NETWORK  [conn144] end connection 172.31.0.221:44702 (58 connections now open)
2020-05-08T21:58:18.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45024 #157 (59 connections now open)
2020-05-08T21:58:18.396+0000 I  NETWORK  [conn157] received client metadata from 172.31.0.221:45024 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.397+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45028 #158 (60 connections now open)
2020-05-08T21:58:18.397+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:45028 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.398+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.405+0000 I  NETWORK  [conn142] end connection 172.31.0.221:44690 (59 connections now open)
2020-05-08T21:58:18.406+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45038 #159 (60 connections now open)
2020-05-08T21:58:18.406+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45040 #160 (61 connections now open)
2020-05-08T21:58:18.406+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:45038 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.406+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:45040 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.407+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.650+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.650+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.150+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.150+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.358+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.358+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.671+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.671+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.671+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.672+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.672+0000 I  COMMAND  [conn143] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 214), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f3fad9c6-8bd4-4acd-8573-f8c86b22730a") }, txnNumber: 54, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2520ms
2020-05-08T21:58:19.672+0000 I  NETWORK  [conn143] end connection 172.31.0.221:44700 (60 connections now open)
2020-05-08T21:58:19.672+0000 I  COMMAND  [conn141] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 214), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("872520a1-44dd-4c10-aff1-563078b63007") }, txnNumber: 167, autocommit: false } numYields:0 reslen:517 protocol:op_msg 2520ms
2020-05-08T21:58:19.673+0000 I  COMMAND  [conn146] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 214), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("cb330eed-174b-4420-8b79-c3f3eb6dcfea") }, txnNumber: 528, autocommit: false } numYields:0 reslen:516 protocol:op_msg 2521ms
2020-05-08T21:58:19.673+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b9671acd-642a-4b86-aac6-64097313d678") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1274ms
2020-05-08T21:58:19.673+0000 I  NETWORK  [conn141] end connection 172.31.0.221:44688 (59 connections now open)
2020-05-08T21:58:19.673+0000 I  NETWORK  [conn146] end connection 172.31.0.221:44800 (58 connections now open)
2020-05-08T21:58:20.097+0000 I  NETWORK  [conn157] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:58:20.098+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:20.098+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:20.099+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 374 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975099, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b9671acd-642a-4b86-aac6-64097313d678") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 425ms
2020-05-08T21:58:20.099+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:20.099+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.099+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.447+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.176+0000 I  NETWORK  [conn159] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:21.177+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.185+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.676+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.176+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.676+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.676+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.677+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("dd91d881-5625-4ac4-861e-65e8aa5045c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4270483, timeInactiveMicros:0, 4270ms
2020-05-08T21:58:22.677+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dd91d881-5625-4ac4-861e-65e8aa5045c5") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 4270ms
2020-05-08T21:58:23.226+0000 I  NETWORK  [conn157] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.229+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.231+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.375+0000 I  NETWORK  [conn156] end connection 172.31.0.221:44996 (57 connections now open)
2020-05-08T21:58:23.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45140 #163 (58 connections now open)
2020-05-08T21:58:23.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45142 #164 (59 connections now open)
2020-05-08T21:58:23.375+0000 I  NETWORK  [conn163] received client metadata from 172.31.0.221:45140 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.376+0000 I  NETWORK  [conn164] received client metadata from 172.31.0.221:45142 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.381+0000 I  -        [conn155] operation was interrupted because a client disconnected
2020-05-08T21:58:23.381+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("c7525c41-12f5-4427-bc98-694a42bdc992"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004900, timeInactiveMicros:0, 5004ms
2020-05-08T21:58:23.381+0000 I  COMMAND  [conn155] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c7525c41-12f5-4427-bc98-694a42bdc992") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:58:23.382+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.382+0000 I  NETWORK  [conn155] end connection 172.31.0.221:44994 (58 connections now open)
2020-05-08T21:58:23.406+0000 I  NETWORK  [conn160] end connection 172.31.0.221:45040 (57 connections now open)
2020-05-08T21:58:23.406+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45160 #165 (58 connections now open)
2020-05-08T21:58:23.407+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:45160 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.407+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45162 #166 (59 connections now open)
2020-05-08T21:58:23.407+0000 I  NETWORK  [conn166] received client metadata from 172.31.0.221:45162 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.408+0000 I  NETWORK  [conn165] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.409+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.585+0000 I  NETWORK  [conn163] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:58:23.586+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.908+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.100+0000 I  NETWORK  [conn158] end connection 172.31.0.221:45028 (58 connections now open)
2020-05-08T21:58:25.100+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45222 #167 (59 connections now open)
2020-05-08T21:58:25.101+0000 I  NETWORK  [conn167] received client metadata from 172.31.0.221:45222 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:25.101+0000 I  -        [conn157] operation was interrupted because a client disconnected
2020-05-08T21:58:25.101+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45224 #168 (60 connections now open)
2020-05-08T21:58:25.101+0000 I  TXN      [conn157] transaction parameters:{ lsid: { id: UUID("b9671acd-642a-4b86-aac6-64097313d678"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975099, 20) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001780, timeInactiveMicros:0, 5001ms
2020-05-08T21:58:25.101+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 375 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975099, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b9671acd-642a-4b86-aac6-64097313d678") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:58:25.102+0000 I  NETWORK  [conn157] end connection 172.31.0.221:45024 (59 connections now open)
2020-05-08T21:58:25.102+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.102+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:45224 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:25.138+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:25.138+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.638+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.908+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.908+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.909+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 379 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 2532ms
2020-05-08T21:58:25.909+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.909+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.910+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:26.152+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.227+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.227+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.229+0000 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975102, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dd91d881-5625-4ac4-861e-65e8aa5045c5") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3550ms
2020-05-08T21:58:26.229+0000 I  NETWORK  [conn159] end connection 172.31.0.221:45038 (58 connections now open)
2020-05-08T21:58:26.477+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975105, 9) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:567675, timeInactiveMicros:0, 567ms
2020-05-08T21:58:26.478+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 377 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975105, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 0039e2c9-945a-40a6-9b38-7d7228cf0f7c:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975105, 9) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 567ms
2020-05-08T21:58:26.488+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 379 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975103, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1385ms
2020-05-08T21:58:26.493+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 379 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3085ms
2020-05-08T21:58:26.497+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.498+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3090301, timeInactiveMicros:320, 3090ms
2020-05-08T21:58:26.504+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975103, 1) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:9356, timeActiveMicros:1396826, timeInactiveMicros:4978, 1401ms
2020-05-08T21:58:28.326+0000 I  NETWORK  [conn165] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:28.842+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 434 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 461), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 38, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:361 protocol:op_msg 1473ms
2020-05-08T21:58:28.844+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 460) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 460) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1477164, timeInactiveMicros:584, 1477ms
2020-05-08T21:58:29.736+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 71, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975109, 652) } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 652) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:206615, timeActiveMicros:213946, timeInactiveMicros:972, 214ms
2020-05-08T21:58:29.736+0000 I  COMMAND  [conn163] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 659), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 71, autocommit: false } numYields:0 reslen:214 protocol:op_msg 206ms
2020-05-08T21:58:29.736+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 654), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b") }, txnNumber: 211, autocommit: false } numYields:0 reslen:322 protocol:op_msg 213ms
2020-05-08T21:58:29.989+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:29.989+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:29.991+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 72, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975109, 672) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:253680, timeInactiveMicros:255, 253ms
2020-05-08T21:58:29.991+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975109, 673), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 72, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 252ms
2020-05-08T21:58:29.995+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 41, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 454) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2637286, timeActiveMicros:2640420, timeInactiveMicros:852, 2641ms
2020-05-08T21:58:29.996+0000 I  COMMAND  [conn165] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 455), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d") }, txnNumber: 41, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2637ms
2020-05-08T21:58:30.245+0000 I  NETWORK  [conn163] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.246+0000 I  NETWORK  [conn165] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:30.247+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.747+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 57, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 325) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:502295, timeInactiveMicros:267, 502ms
2020-05-08T21:58:30.747+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 325), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d") }, txnNumber: 57, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:377 protocol:op_msg 501ms
2020-05-08T21:58:31.254+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 80, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 313) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:1016598, timeActiveMicros:1025025, timeInactiveMicros:512, 1025ms
2020-05-08T21:58:31.254+0000 I  COMMAND  [conn163] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 322), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 80, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1017ms
2020-05-08T21:58:31.255+0000 I  COMMAND  [conn165] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 466), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d") }, txnNumber: 57, autocommit: false } numYields:0 reslen:352 protocol:op_msg 506ms
2020-05-08T21:58:31.255+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 438 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 313), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b") }, txnNumber: 232, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 313) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 1027ms
2020-05-08T21:58:31.259+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 232, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 313) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 313) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1029683, timeInactiveMicros:892, 1030ms
2020-05-08T21:58:31.272+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:31.395+0000 I  NETWORK  [conn167] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.395+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.895+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.395+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.395+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:33.390+0000 I  SHARDING [conn163] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.390+0000 I  COMMAND  [conn163] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 499 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 169), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 87, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 169) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:341 protocol:op_msg 2008ms
2020-05-08T21:58:33.390+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 502 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 169), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b") }, txnNumber: 238, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 169) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 2008ms
2020-05-08T21:58:33.398+0000 I  TXN      [conn163] transaction parameters:{ lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 87, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 169) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 169) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2016021, timeInactiveMicros:691, 2016ms
2020-05-08T21:58:34.746+0000 I  NETWORK  [conn163] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:34.747+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.751+0000 I  NETWORK  [conn165] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.752+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.752+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.752+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:34.753+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 65, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 176) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 176) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3360774, timeInactiveMicros:0, 3360ms
2020-05-08T21:58:34.753+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 176), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d") }, txnNumber: 65, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 176) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 3360ms
2020-05-08T21:58:34.753+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:34.753+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.077+0000 I  NETWORK  [conn167] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:35.078+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.154+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.154+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.155+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.333+0000 I  NETWORK  [conn166] end connection 172.31.0.221:45162 (57 connections now open)
2020-05-08T21:58:36.335+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45408 #171 (58 connections now open)
2020-05-08T21:58:36.336+0000 I  NETWORK  [conn171] received client metadata from 172.31.0.221:45408 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.336+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45410 #172 (59 connections now open)
2020-05-08T21:58:36.336+0000 I  NETWORK  [conn172] received client metadata from 172.31.0.221:45410 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.337+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.349+0000 I  NETWORK  [conn168] end connection 172.31.0.221:45224 (58 connections now open)
2020-05-08T21:58:36.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45420 #173 (59 connections now open)
2020-05-08T21:58:36.349+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:45420 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.350+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45422 #174 (60 connections now open)
2020-05-08T21:58:36.350+0000 I  NETWORK  [conn174] received client metadata from 172.31.0.221:45422 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.351+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.366+0000 I  NETWORK  [conn164] end connection 172.31.0.221:45142 (59 connections now open)
2020-05-08T21:58:36.367+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45432 #175 (60 connections now open)
2020-05-08T21:58:36.367+0000 I  NETWORK  [conn175] received client metadata from 172.31.0.221:45432 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.367+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45434 #176 (61 connections now open)
2020-05-08T21:58:36.368+0000 I  NETWORK  [conn176] received client metadata from 172.31.0.221:45434 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.369+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.746+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.747+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.747+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.747+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 238, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 169) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 169) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:5365383, timeInactiveMicros:340, 5365ms
2020-05-08T21:58:36.747+0000 I  COMMAND  [conn163] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0039e2c9-945a-40a6-9b38-7d7228cf0f7c") }, txnNumber: 87, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3349ms
2020-05-08T21:58:36.748+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975113, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a25bc284-cf20-4bc0-a8ac-1e161678900b") }, txnNumber: 238, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 3357ms
2020-05-08T21:58:36.748+0000 I  NETWORK  [conn163] end connection 172.31.0.221:45140 (60 connections now open)
2020-05-08T21:58:36.748+0000 I  NETWORK  [conn167] end connection 172.31.0.221:45222 (59 connections now open)
2020-05-08T21:58:36.752+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 510 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 401ms
2020-05-08T21:58:36.753+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:417039, timeInactiveMicros:0, 417ms
2020-05-08T21:58:36.754+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 417ms
2020-05-08T21:58:36.759+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:408326, timeInactiveMicros:344, 408ms
2020-05-08T21:58:36.759+0000 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:391192, timeInactiveMicros:0, 391ms
2020-05-08T21:58:36.759+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 391ms
2020-05-08T21:58:37.009+0000 I  NETWORK  [conn172] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.010+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.026+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.026+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.037+0000 I  NETWORK  [conn173] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.038+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.201+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.509+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.509+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.510+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.510+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975116, 61) } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 61) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:713826, timeInactiveMicros:257, 714ms
2020-05-08T21:58:37.510+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 68), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 3, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 708ms
2020-05-08T21:58:37.510+0000 I  TXN      [conn165] transaction parameters:{ lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 66, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 10) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2750600, timeInactiveMicros:0, 2750ms
2020-05-08T21:58:37.510+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("430562a5-2185-4752-9e13-14173957af3d") }, txnNumber: 66, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 2750ms
2020-05-08T21:58:37.510+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 99) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:681140, timeInactiveMicros:0, 681ms
2020-05-08T21:58:37.510+0000 I  NETWORK  [conn165] end connection 172.31.0.221:45160 (58 connections now open)
2020-05-08T21:58:37.511+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 681ms
2020-05-08T21:58:37.577+0000 I  NETWORK  [conn172] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.578+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.701+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.701+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.009+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.201+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.509+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.509+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.510+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.510+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.510+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 412), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 3, autocommit: false } numYields:0 reslen:351 protocol:op_msg 999ms
2020-05-08T21:58:38.510+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 412), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 5, autocommit: false } numYields:0 reslen:514 protocol:op_msg 999ms
2020-05-08T21:58:38.511+0000 I  NETWORK  [conn172] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:38.512+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.512+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.512+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.513+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.519+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.701+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.857+0000 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 71, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 556) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1156206, timeInactiveMicros:0, 1156ms
2020-05-08T21:58:38.857+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 556), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 71, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1156ms
2020-05-08T21:58:38.861+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 5, autocommit: false } numYields:0 reslen:396 protocol:op_msg 349ms
2020-05-08T21:58:38.875+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 38) } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 38) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:356808, timeInactiveMicros:250, 357ms
2020-05-08T21:58:38.875+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 5, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 356ms
2020-05-08T21:58:39.201+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:39.360+0000 I  SHARDING [conn172] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:39.701+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.701+0000 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.701+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:40.542+0000 I  NETWORK  [conn172] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.581+0000 I  NETWORK  [conn175] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.582+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.042+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:43.042+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.042+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.043+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:43.043+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 998), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 42, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3352ms
2020-05-08T21:58:43.043+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.043+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 586 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975119, 1035), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 117, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:328 protocol:op_msg 3317ms
2020-05-08T21:58:43.045+0000 I  NETWORK  [conn175] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:43.046+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.545+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:44.043+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.045+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.045+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.046+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.056+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 42, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1012ms
2020-05-08T21:58:44.060+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 42, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975119, 971) } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 971) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:4363204, timeActiveMicros:4385734, timeInactiveMicros:1447, 4387ms
2020-05-08T21:58:44.061+0000 I  COMMAND  [conn173] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1009), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 42, autocommit: false } numYields:0 reslen:428 protocol:op_msg 4363ms
2020-05-08T21:58:44.185+0000 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 117, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 1034) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1140131, timeActiveMicros:4460550, timeInactiveMicros:859, 4461ms
2020-05-08T21:58:44.185+0000 I  COMMAND  [conn175] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 117, autocommit: false } numYields:0 reslen:430 protocol:op_msg 1140ms
2020-05-08T21:58:44.185+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 44, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 20) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 107ms
2020-05-08T21:58:44.231+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 44, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 20) } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 20) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:41950, timeActiveMicros:152771, timeInactiveMicros:1019, 153ms
2020-05-08T21:58:44.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.043+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.043+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.178+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 415), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1748ms
2020-05-08T21:58:46.178+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 408), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 129, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1754ms
2020-05-08T21:58:46.179+0000 I  NETWORK  [conn175] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:46.180+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.180+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.180+0000 I  NETWORK  [conn175] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:46.181+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.181+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.543+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.680+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.043+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.043+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.086+0000 I  SHARDING [conn173] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 24), t: 33 }
2020-05-08T21:58:47.086+0000 I  NETWORK  [conn173] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:47.087+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:47.180+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.586+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:48.086+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.086+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.087+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 57, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975125, 68) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1907971, timeInactiveMicros:0, 1907ms
2020-05-08T21:58:48.087+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975125, 68), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 57, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 1908ms
2020-05-08T21:58:48.489+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:48.521+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:48.989+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:48.989+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:48.989+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.276+0000 I  NETWORK  [conn171] end connection 172.31.0.221:45408 (57 connections now open)
2020-05-08T21:58:49.276+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45638 #184 (58 connections now open)
2020-05-08T21:58:49.277+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45640 #185 (59 connections now open)
2020-05-08T21:58:49.277+0000 I  NETWORK  [conn184] received client metadata from 172.31.0.221:45638 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.277+0000 I  NETWORK  [conn185] received client metadata from 172.31.0.221:45640 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.308+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.308+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.309+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.310+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.349+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.349+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.349+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.350+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.350+0000 I  TXN      [conn175] transaction parameters:{ lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 129, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 406) } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 407) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:4928292, timeInactiveMicros:745, 4929ms
2020-05-08T21:58:49.350+0000 I  COMMAND  [conn175] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975125, 68), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 129, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 3171ms
2020-05-08T21:58:49.350+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 599 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 58, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:350 protocol:op_msg 1254ms
2020-05-08T21:58:49.351+0000 I  NETWORK  [conn175] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.352+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.352+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.352+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.396+0000 I  NETWORK  [conn176] end connection 172.31.0.221:45434 (58 connections now open)
2020-05-08T21:58:49.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45682 #187 (59 connections now open)
2020-05-08T21:58:49.396+0000 I  NETWORK  [conn187] received client metadata from 172.31.0.221:45682 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45684 #188 (60 connections now open)
2020-05-08T21:58:49.396+0000 I  NETWORK  [conn188] received client metadata from 172.31.0.221:45684 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.489+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.989+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.489+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.664+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 58, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 4) } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 4) }, numParticipants:2, coordinator:rs_shard1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1312136, timeActiveMicros:2567947, timeInactiveMicros:964, 2568ms
2020-05-08T21:58:50.664+0000 I  COMMAND  [conn173] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 58, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1312ms
2020-05-08T21:58:50.989+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.170+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 407), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fc4f9aa9-1b97-4893-afef-89c510dbf41f") }, txnNumber: 66, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 406) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 6748ms
2020-05-08T21:58:51.170+0000 I  NETWORK  [conn172] end connection 172.31.0.221:45410 (59 connections now open)
2020-05-08T21:58:51.180+0000 I  NETWORK  [conn174] end connection 172.31.0.221:45422 (58 connections now open)
2020-05-08T21:58:51.180+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45790 #189 (59 connections now open)
2020-05-08T21:58:51.180+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:45792 #190 (60 connections now open)
2020-05-08T21:58:51.180+0000 I  NETWORK  [conn189] received client metadata from 172.31.0.221:45790 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:51.180+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:45792 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:51.182+0000 I  NETWORK  [conn175] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:51.183+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.183+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.184+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.184+0000 I  COMMAND  [conn175] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d60b0361-c4f4-447c-9e1c-b4e198a48498") }, txnNumber: 129, autocommit: false } numYields:0 reslen:430 protocol:op_msg 1833ms
2020-05-08T21:58:51.184+0000 I  NETWORK  [conn175] end connection 172.31.0.221:45432 (59 connections now open)
2020-05-08T21:58:51.190+0000 I  NETWORK  [conn187] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:51.489+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.490+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.490+0000 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.850+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:51.855+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ed599ca-da08-4a34-ae59-5f4f2c73802b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2597ms
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn189] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 28), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ebea37f4-d0d5-49f8-87e5-b612a4d19381") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 684ms
2020-05-08T21:58:51.876+0000 I  COMMAND  [conn187] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 608 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b462de4b-455a-424e-b5d5-332a0ca77105") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2477ms
2020-05-08T21:58:51.880+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975130, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0189398c-fa72-4d41-9813-c31f4ac4fbed") }, txnNumber: 60, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 18) }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1203ms
2020-05-08T21:58:51.881+0000 I  NETWORK  [conn173] end connection 172.31.0.221:45420 (58 connections now open)
2020-05-08T21:58:51.887+0000 I  TXN      [conn189] transaction parameters:{ lsid: { id: UUID("ebea37f4-d0d5-49f8-87e5-b612a4d19381"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 28) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:695307, timeInactiveMicros:1334, 696ms
2020-05-08T21:58:51.891+0000 I  TXN      [conn187] transaction parameters:{ lsid: { id: UUID("b462de4b-455a-424e-b5d5-332a0ca77105"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 8) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:11520, timeActiveMicros:2491308, timeInactiveMicros:1608, 2492ms
2020-05-08T21:58:51.897+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("3ed599ca-da08-4a34-ae59-5f4f2c73802b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 22) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:9864, timeActiveMicros:2615480, timeInactiveMicros:3923, 2619ms
2020-05-08T21:58:52.114+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.116+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.119+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.124+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.125+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.614+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.859+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.898+0000 I  NETWORK  [conn189] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.013+0000 I  NETWORK  [conn184] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.014+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:53.105+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:53.114+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.114+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.115+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.302+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:58:53.398+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.398+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.399+0000 I  TXN      [conn189] transaction parameters:{ lsid: { id: UUID("ebea37f4-d0d5-49f8-87e5-b612a4d19381"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 87) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 89) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1499959, timeInactiveMicros:0, 1499ms
2020-05-08T21:58:53.399+0000 I  COMMAND  [conn189] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ebea37f4-d0d5-49f8-87e5-b612a4d19381") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 87) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1500ms
2020-05-08T21:58:53.514+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.514+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.515+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("3ed599ca-da08-4a34-ae59-5f4f2c73802b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 99) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 99) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1605969, timeInactiveMicros:0, 1605ms
2020-05-08T21:58:53.515+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ed599ca-da08-4a34-ae59-5f4f2c73802b") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 99) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 1606ms
2020-05-08T21:58:53.928+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.932+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.934+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.935+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:54.081+0000 I  NETWORK  [conn184] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:54.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:54.265+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588975126, 24), t: 33 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T21:58:54.429+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.429+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.432+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 4), t: 38 }
2020-05-08T21:58:54.581+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:55.081+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:55.581+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.581+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.582+0000 I  COMMAND  [conn184] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ed599ca-da08-4a34-ae59-5f4f2c73802b") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2065ms
2020-05-08T21:58:55.943+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: Error waiting for snapshot not less than { ts: Timestamp(1588975126, 24), t: 33 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-08T21:58:56.191+0000 I  NETWORK  [conn190] end connection 172.31.0.221:45792 (57 connections now open)
2020-05-08T21:58:56.191+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46016 #197 (58 connections now open)
2020-05-08T21:58:56.191+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46018 #198 (59 connections now open)
2020-05-08T21:58:56.191+0000 I  NETWORK  [conn197] received client metadata from 172.31.0.221:46016 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.192+0000 I  NETWORK  [conn198] received client metadata from 172.31.0.221:46018 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.893+0000 I  NETWORK  [conn188] end connection 172.31.0.221:45684 (58 connections now open)
2020-05-08T21:58:56.893+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46044 #199 (59 connections now open)
2020-05-08T21:58:56.894+0000 I  NETWORK  [conn199] received client metadata from 172.31.0.221:46044 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.894+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46046 #200 (60 connections now open)
2020-05-08T21:58:56.894+0000 I  NETWORK  [conn200] received client metadata from 172.31.0.221:46046 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.898+0000 I  NETWORK  [conn185] end connection 172.31.0.221:45640 (59 connections now open)
2020-05-08T21:58:56.899+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46052 #201 (60 connections now open)
2020-05-08T21:58:56.899+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46054 #202 (61 connections now open)
2020-05-08T21:58:56.899+0000 I  NETWORK  [conn201] received client metadata from 172.31.0.221:46052 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.899+0000 I  NETWORK  [conn202] received client metadata from 172.31.0.221:46054 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:57.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.164+0000 I  NETWORK  [conn198] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:57.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:57.221+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:57.665+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:58.146+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:58.665+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:58.665+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:58.666+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:58.666+0000 I  COMMAND  [conn184] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3ed599ca-da08-4a34-ae59-5f4f2c73802b") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3083ms
2020-05-08T21:58:58.666+0000 I  TXN      [conn201] transaction parameters:{ lsid: { id: UUID("ad5d89c0-e2e4-45dd-86f8-2ad5dff8a0b0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975135, 2) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1766599, timeInactiveMicros:0, 1766ms
2020-05-08T21:58:58.666+0000 I  NETWORK  [conn184] end connection 172.31.0.221:45638 (60 connections now open)
2020-05-08T21:58:58.666+0000 I  COMMAND  [conn201] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad5d89c0-e2e4-45dd-86f8-2ad5dff8a0b0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1766ms
2020-05-08T21:58:58.666+0000 I  TXN      [conn198] transaction parameters:{ lsid: { id: UUID("dbfbe436-612c-4aab-a40d-2b0c999c65c0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975135, 2) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2474162, timeInactiveMicros:0, 2474ms
2020-05-08T21:58:58.667+0000 I  COMMAND  [conn198] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dbfbe436-612c-4aab-a40d-2b0c999c65c0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2474ms
2020-05-08T21:58:58.667+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:58.667+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:58.853+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.869+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 6), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.406+0000 I  COMMAND  [conn198] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975138, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dbfbe436-612c-4aab-a40d-2b0c999c65c0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 738ms
2020-05-08T21:58:59.406+0000 I  COMMAND  [conn201] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975138, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad5d89c0-e2e4-45dd-86f8-2ad5dff8a0b0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 738ms
2020-05-08T21:58:59.406+0000 I  TXN      [conn199] transaction parameters:{ lsid: { id: UUID("d23911c4-408a-4018-85fb-a1fa96bc3f40"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975135, 2) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2511565, timeInactiveMicros:0, 2511ms
2020-05-08T21:58:59.406+0000 I  COMMAND  [conn199] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 615 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d23911c4-408a-4018-85fb-a1fa96bc3f40") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction d23911c4-408a-4018-85fb-a1fa96bc3f40:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975135, 2) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 2511ms
2020-05-08T21:58:59.781+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.781+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.782+0000 I  COMMAND  [conn189] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ebea37f4-d0d5-49f8-87e5-b612a4d19381") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 6382ms
2020-05-08T21:58:59.782+0000 I  NETWORK  [conn189] end connection 172.31.0.221:45790 (59 connections now open)
2020-05-08T21:59:00.669+0000 I  NETWORK  [conn201] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:00.670+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:00.670+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:00.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:00.997+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:01.169+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:01.192+0000 I  NETWORK  [conn197] end connection 172.31.0.221:46016 (58 connections now open)
2020-05-08T21:59:01.192+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46288 #204 (59 connections now open)
2020-05-08T21:59:01.192+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46290 #205 (60 connections now open)
2020-05-08T21:59:01.193+0000 I  NETWORK  [conn204] received client metadata from 172.31.0.221:46288 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.193+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:46290 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.194+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:01.669+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:01.894+0000 I  NETWORK  [conn200] end connection 172.31.0.221:46046 (59 connections now open)
2020-05-08T21:59:01.894+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46308 #206 (60 connections now open)
2020-05-08T21:59:01.895+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46310 #207 (61 connections now open)
2020-05-08T21:59:01.895+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:46308 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.895+0000 I  NETWORK  [conn207] received client metadata from 172.31.0.221:46310 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.896+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.896+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.896+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.897+0000 I  TXN      [conn201] transaction parameters:{ lsid: { id: UUID("ad5d89c0-e2e4-45dd-86f8-2ad5dff8a0b0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975138, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2490705, timeInactiveMicros:0, 2490ms
2020-05-08T21:59:01.897+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:01.897+0000 I  COMMAND  [conn201] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad5d89c0-e2e4-45dd-86f8-2ad5dff8a0b0") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975138, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2490ms
2020-05-08T21:59:01.898+0000 I  TXN      [conn198] transaction parameters:{ lsid: { id: UUID("dbfbe436-612c-4aab-a40d-2b0c999c65c0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975138, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2491330, timeInactiveMicros:0, 2491ms
2020-05-08T21:59:01.898+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:01.898+0000 I  COMMAND  [conn198] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dbfbe436-612c-4aab-a40d-2b0c999c65c0") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975138, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2491ms
2020-05-08T21:59:01.898+0000 I  NETWORK  [conn198] end connection 172.31.0.221:46018 (60 connections now open)
2020-05-08T21:59:01.899+0000 I  NETWORK  [conn202] end connection 172.31.0.221:46054 (59 connections now open)
2020-05-08T21:59:01.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46316 #208 (60 connections now open)
2020-05-08T21:59:01.900+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:46316 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46318 #209 (61 connections now open)
2020-05-08T21:59:01.900+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:46318 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:02.397+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:02.397+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:02.398+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975142, 1), t: 40 }
2020-05-08T21:59:02.685+0000 I  COMMAND  [conn201] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975141, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ad5d89c0-e2e4-45dd-86f8-2ad5dff8a0b0") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 787ms
2020-05-08T21:59:02.685+0000 I  NETWORK  [conn201] end connection 172.31.0.221:46052 (60 connections now open)
2020-05-08T21:59:04.417+0000 I  -        [conn199] operation was interrupted because a client disconnected
2020-05-08T21:59:04.417+0000 I  CONNPOOL [conn199] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:04.417+0000 I  TXN      [conn199] transaction parameters:{ lsid: { id: UUID("d23911c4-408a-4018-85fb-a1fa96bc3f40"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975139, 10) } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 10) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004249, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:04.417+0000 I  COMMAND  [conn199] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 615 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d23911c4-408a-4018-85fb-a1fa96bc3f40") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975139, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:04.417+0000 I  NETWORK  [conn199] end connection 172.31.0.221:46044 (59 connections now open)
2020-05-08T21:59:05.246+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:59:05.246+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:05.480+0000 I  SHARDING [conn206] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975142, 1), t: 40 }, now { ts: Timestamp(1588975144, 2), t: 41 }
2020-05-08T21:59:05.480+0000 I  COMMAND  [conn206] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975140, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("81806d84-17da-4b39-b915-0010d8169904") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 3584ms
2020-05-08T21:59:05.480+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975141, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 3579ms
2020-05-08T21:59:05.481+0000 I  TXN      [conn205] transaction parameters:{ lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975140, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:4287561, timeInactiveMicros:0, 4287ms
2020-05-08T21:59:05.481+0000 I  COMMAND  [conn205] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975140, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 4287ms
2020-05-08T21:59:05.491+0000 I  TXN      [conn206] transaction parameters:{ lsid: { id: UUID("81806d84-17da-4b39-b915-0010d8169904"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975140, 2) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:7682, timeActiveMicros:3594982, timeInactiveMicros:880, 3595ms
2020-05-08T21:59:05.491+0000 I  TXN      [conn208] transaction parameters:{ lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975141, 4) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:9822, timeActiveMicros:3589685, timeInactiveMicros:745, 3590ms
2020-05-08T21:59:05.493+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.493+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.494+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:05.494+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:05.494+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:05.582+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:07.302+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 403), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05") }, txnNumber: 70, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 854ms
2020-05-08T21:59:07.303+0000 I  TXN      [conn205] transaction parameters:{ lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 68, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 402) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:858606, timeInactiveMicros:308, 858ms
2020-05-08T21:59:07.303+0000 I  COMMAND  [conn205] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 403), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569") }, txnNumber: 68, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 857ms
2020-05-08T21:59:07.310+0000 I  TXN      [conn208] transaction parameters:{ lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 70, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 404) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:4442, timeActiveMicros:860609, timeInactiveMicros:1136, 861ms
2020-05-08T21:59:07.608+0000 I  NETWORK  [conn206] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:07.609+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:08.109+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:08.609+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:08.609+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:08.610+0000 I  TXN      [conn206] transaction parameters:{ lsid: { id: UUID("81806d84-17da-4b39-b915-0010d8169904"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 208, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975147, 373) } }, globalReadTimestamp:{ ts: Timestamp(1588975147, 373) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1007255, timeInactiveMicros:561, 1007ms
2020-05-08T21:59:08.610+0000 I  COMMAND  [conn206] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975147, 376), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("81806d84-17da-4b39-b915-0010d8169904") }, txnNumber: 208, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:426 protocol:op_msg 1004ms
2020-05-08T21:59:08.610+0000 I  COMMAND  [conn208] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975147, 370), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05") }, txnNumber: 90, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1011ms
2020-05-08T21:59:08.611+0000 I  COMMAND  [conn205] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975147, 375), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569") }, txnNumber: 89, autocommit: false } numYields:0 reslen:470 protocol:op_msg 1007ms
2020-05-08T21:59:09.617+0000 I  NETWORK  [conn208] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:09.618+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.618+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.619+0000 I  NETWORK  [conn205] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:09.620+0000 I  COMMAND  [conn206] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975148, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("81806d84-17da-4b39-b915-0010d8169904") }, txnNumber: 208, autocommit: false } numYields:0 reslen:548 protocol:op_msg 1008ms
2020-05-08T21:59:09.620+0000 I  COMMAND  [conn205] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975148, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569") }, txnNumber: 89, autocommit: false } numYields:0 reslen:546 protocol:op_msg 1008ms
2020-05-08T21:59:12.537+0000 I  NETWORK  [conn209] end connection 172.31.0.221:46318 (58 connections now open)
2020-05-08T21:59:12.538+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46662 #212 (59 connections now open)
2020-05-08T21:59:12.538+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46664 #213 (60 connections now open)
2020-05-08T21:59:12.538+0000 I  NETWORK  [conn212] received client metadata from 172.31.0.221:46662 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.538+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:46664 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.539+0000 I  NETWORK  [conn212] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:12.540+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:12.568+0000 I  NETWORK  [conn207] end connection 172.31.0.221:46310 (59 connections now open)
2020-05-08T21:59:12.569+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46674 #214 (60 connections now open)
2020-05-08T21:59:12.569+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46676 #215 (61 connections now open)
2020-05-08T21:59:12.569+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:46674 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.569+0000 I  NETWORK  [conn215] received client metadata from 172.31.0.221:46676 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.570+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:12.600+0000 I  NETWORK  [conn204] end connection 172.31.0.221:46288 (60 connections now open)
2020-05-08T21:59:12.601+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46690 #216 (61 connections now open)
2020-05-08T21:59:12.601+0000 I  NETWORK  [conn216] received client metadata from 172.31.0.221:46690 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.602+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46694 #217 (62 connections now open)
2020-05-08T21:59:12.602+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:46694 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:12.604+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:12.825+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:12.927+0000 I  NETWORK  [conn205] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:13.040+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:13.540+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:13.613+0000 I  -        [conn208] operation was interrupted because a client disconnected
2020-05-08T21:59:13.613+0000 I  TXN      [conn208] transaction parameters:{ lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 91, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975148, 1) } }, globalReadTimestamp:{ ts: Timestamp(1588975148, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002417, timeInactiveMicros:0, 5002ms
2020-05-08T21:59:13.613+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 682 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975148, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a376f883-c863-4a35-b9c2-69e195f3ee05") }, txnNumber: 91, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975148, 1) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:13.614+0000 I  NETWORK  [conn208] end connection 172.31.0.221:46316 (61 connections now open)
2020-05-08T21:59:14.040+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.040+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.041+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:14.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:14.429+0000 I  COMMAND  [conn206] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975149, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("81806d84-17da-4b39-b915-0010d8169904") }, txnNumber: 208, autocommit: false } numYields:0 reslen:548 protocol:op_msg 4808ms
2020-05-08T21:59:14.429+0000 I  TXN      [conn205] transaction parameters:{ lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 90, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975149, 103) } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 103) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4808174, timeInactiveMicros:0, 4808ms
2020-05-08T21:59:14.429+0000 I  COMMAND  [conn205] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("efca5072-5695-4ea4-a336-020e6c713569") }, txnNumber: 90, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975149, 103) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 4808ms
2020-05-08T21:59:14.429+0000 I  NETWORK  [conn206] end connection 172.31.0.221:46308 (60 connections now open)
2020-05-08T21:59:14.429+0000 I  NETWORK  [conn205] end connection 172.31.0.221:46290 (59 connections now open)
2020-05-08T21:59:14.541+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:14.626+0000 I  COMMAND  [conn216] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2022ms
2020-05-08T21:59:14.627+0000 I  COMMAND  [conn212] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 103), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2088ms
2020-05-08T21:59:14.628+0000 I  TXN      [conn215] transaction parameters:{ lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 110) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2057882, timeInactiveMicros:0, 2057ms
2020-05-08T21:59:14.628+0000 I  COMMAND  [conn215] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction f69bfd5f-4e21-4a67-9930-f02139b02d0e:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975149, 110) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:592 protocol:op_msg 2057ms
2020-05-08T21:59:14.919+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:15.541+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:15.575+0000 I  NETWORK  [conn215] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:15.576+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:15.953+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.076+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:16.427+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b96b7369da8ea76060 to 5eb5d5b9883dd86ab8e095b5; invalidating user cache
2020-05-08T21:59:16.541+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.541+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.576+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:16.630+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 3), t: 43 }
2020-05-08T21:59:17.076+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.076+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.077+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975155, 518), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") }, txnNumber: 60, autocommit: false } numYields:0 reslen:321 protocol:op_msg 1516ms
2020-05-08T21:59:17.077+0000 I  COMMAND  [conn215] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975155, 520), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e") }, txnNumber: 73, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1516ms
2020-05-08T21:59:17.078+0000 I  NETWORK  [conn215] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:17.079+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.578+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.585+0000 I  TXN      [conn212] transaction parameters:{ lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 58, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975155, 521) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2018307, timeActiveMicros:2021685, timeInactiveMicros:1094, 2022ms
2020-05-08T21:59:17.586+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.586+0000 I  COMMAND  [conn216] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 737 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") }, txnNumber: 61, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975157, 2) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 509ms
2020-05-08T21:59:17.587+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:18.078+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:18.078+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:18.079+0000 I  COMMAND  [conn212] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975155, 522), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6") }, txnNumber: 58, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2512ms
2020-05-08T21:59:18.081+0000 I  TXN      [conn215] transaction parameters:{ lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975157, 3) } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 3) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1003285, timeInactiveMicros:0, 1003ms
2020-05-08T21:59:18.081+0000 I  COMMAND  [conn215] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e") }, txnNumber: 74, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975157, 3) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1003ms
2020-05-08T21:59:18.081+0000 I  TXN      [conn216] transaction parameters:{ lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 61, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975157, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 3) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1003616, timeInactiveMicros:358, 1003ms
2020-05-08T21:59:18.081+0000 I  COMMAND  [conn216] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") }, txnNumber: 61, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 494ms
2020-05-08T21:59:18.797+0000 I  COMMAND  [conn215] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e") }, txnNumber: 74, autocommit: false } numYields:0 reslen:397 protocol:op_msg 714ms
2020-05-08T21:59:18.797+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") }, txnNumber: 61, autocommit: false } numYields:0 reslen:321 protocol:op_msg 715ms
2020-05-08T21:59:18.799+0000 I  TXN      [conn212] transaction parameters:{ lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 59, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 2) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:714074, timeActiveMicros:717306, timeInactiveMicros:1298, 718ms
2020-05-08T21:59:18.800+0000 I  COMMAND  [conn212] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6") }, txnNumber: 59, autocommit: false } numYields:0 reslen:214 protocol:op_msg 714ms
2020-05-08T21:59:18.853+0000 I  NETWORK  [conn216] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:19.353+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.673+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:59:19.674+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:19.853+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.853+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.854+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.854+0000 I  TXN      [conn216] transaction parameters:{ lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 63, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 39) } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 42) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1010812, timeInactiveMicros:1063, 1011ms
2020-05-08T21:59:19.854+0000 I  COMMAND  [conn216] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 52), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") }, txnNumber: 63, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:384 protocol:op_msg 1004ms
2020-05-08T21:59:19.854+0000 I  TXN      [conn215] transaction parameters:{ lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 51) } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 52) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1003693, timeInactiveMicros:0, 1003ms
2020-05-08T21:59:19.854+0000 I  COMMAND  [conn215] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 52), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e") }, txnNumber: 77, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975158, 51) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:426 protocol:op_msg 1003ms
2020-05-08T21:59:19.854+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.854+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.855+0000 I  NETWORK  [conn216] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.856+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.856+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:20.283+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:20.308+0000 I  NETWORK  [conn215] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:20.309+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:20.309+0000 I  NETWORK  [conn216] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:20.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:20.355+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:20.548+0000 I  NETWORK  [conn214] end connection 172.31.0.221:46674 (58 connections now open)
2020-05-08T21:59:20.549+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46980 #219 (59 connections now open)
2020-05-08T21:59:20.549+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46982 #220 (60 connections now open)
2020-05-08T21:59:20.549+0000 I  NETWORK  [conn219] received client metadata from 172.31.0.221:46980 conn219: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:20.549+0000 I  NETWORK  [conn220] received client metadata from 172.31.0.221:46982 conn220: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:20.557+0000 I  NETWORK  [conn217] end connection 172.31.0.221:46694 (59 connections now open)
2020-05-08T21:59:20.557+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46984 #221 (60 connections now open)
2020-05-08T21:59:20.558+0000 I  NETWORK  [conn221] received client metadata from 172.31.0.221:46984 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:20.558+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46986 #222 (61 connections now open)
2020-05-08T21:59:20.558+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:46986 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:20.855+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:21.355+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:21.418+0000 I  COMMAND  [conn221] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975160, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("82ab8062-7871-4281-be5d-c6516849ed49") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 859ms
2020-05-08T21:59:21.420+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:21.855+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:21.855+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:21.856+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:21.856+0000 I  COMMAND  [conn216] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975159, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("596557a5-d84f-4660-bc61-6123e63555aa") }, txnNumber: 63, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2001ms
2020-05-08T21:59:21.856+0000 I  TXN      [conn215] transaction parameters:{ lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 78, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975159, 9) } }, globalReadTimestamp:{ ts: Timestamp(1588975159, 9) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1995313, timeInactiveMicros:226, 1995ms
2020-05-08T21:59:21.856+0000 I  COMMAND  [conn215] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975159, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f69bfd5f-4e21-4a67-9930-f02139b02d0e") }, txnNumber: 78, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 1993ms
2020-05-08T21:59:21.856+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:21.856+0000 I  NETWORK  [conn216] end connection 172.31.0.221:46690 (60 connections now open)
2020-05-08T21:59:21.856+0000 I  NETWORK  [conn215] end connection 172.31.0.221:46676 (59 connections now open)
2020-05-08T21:59:22.356+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:22.856+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:23.356+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:23.813+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47058 #223 (60 connections now open)
2020-05-08T21:59:23.814+0000 I  NETWORK  [conn223] received client metadata from 172.31.0.221:47058 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:23.825+0000 I  CONNPOOL [conn212] Ending connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:59:23.825+0000 I  COMMAND  [conn212] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 32), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6") }, txnNumber: 61, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5014ms
2020-05-08T21:59:23.825+0000 I  NETWORK  [conn212] end connection 172.31.0.221:46662 (59 connections now open)
2020-05-08T21:59:23.856+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.856+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.903+0000 I  NETWORK  [conn221] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:23.903+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:24.403+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.403+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.470+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:24.907+0000 I  NETWORK  [conn221] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:24.908+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.408+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.553+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47090 #224 (60 connections now open)
2020-05-08T21:59:25.553+0000 I  NETWORK  [conn224] received client metadata from 172.31.0.221:47090 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:25.908+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:26.408+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.408+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.409+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975165, 2), t: 47 }
2020-05-08T21:59:26.409+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:26.410+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.410+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.419+0000 I  NETWORK  [conn213] end connection 172.31.0.221:46664 (59 connections now open)
2020-05-08T21:59:26.421+0000 I  -        [conn221] operation was interrupted because a client disconnected
2020-05-08T21:59:26.421+0000 I  CONNPOOL [conn221] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:59:26.421+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47094 #225 (60 connections now open)
2020-05-08T21:59:26.421+0000 I  TXN      [conn221] transaction parameters:{ lsid: { id: UUID("82ab8062-7871-4281-be5d-c6516849ed49"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975161, 155) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002237, timeInactiveMicros:0, 5002ms
2020-05-08T21:59:26.421+0000 I  COMMAND  [conn221] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 742 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975161, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("82ab8062-7871-4281-be5d-c6516849ed49") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:26.421+0000 I  NETWORK  [conn222] end connection 172.31.0.221:46986 (59 connections now open)
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn221] end connection 172.31.0.221:46984 (58 connections now open)
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn225] received client metadata from 172.31.0.221:47094 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn225] end connection 172.31.0.221:47094 (57 connections now open)
2020-05-08T21:59:26.424+0000 I  NETWORK  [conn220] end connection 172.31.0.221:46982 (56 connections now open)
2020-05-08T21:59:26.429+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47108 #226 (57 connections now open)
2020-05-08T21:59:26.429+0000 I  NETWORK  [conn226] end connection 172.31.0.221:47108 (56 connections now open)
2020-05-08T21:59:28.829+0000 I  CONNPOOL [conn223] Ending connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:59:28.829+0000 I  COMMAND  [conn223] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975161, 155), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("772d2eb3-8f90-45e8-85f2-e12222d69fb6") }, txnNumber: 61, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5014ms
2020-05-08T21:59:28.829+0000 I  NETWORK  [conn223] end connection 172.31.0.221:47058 (55 connections now open)
