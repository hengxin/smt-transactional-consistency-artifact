2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.223+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.224+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.224+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.224+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.225+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.225+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.225+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.226+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-7-45:27017:1588975035:-6576501800400173510 (sleeping for 30000ms)
2020-05-08T21:57:15.228+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.228+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.228+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.232+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 10), t: 1 }
2020-05-08T21:57:15.422+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.424+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.424+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.425+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("55747517-3153-4de1-8d0d-dfb5c9e786c0"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.425+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.426+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.426+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.435+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48640 #10 (1 connection now open)
2020-05-08T21:57:16.435+0000 I  NETWORK  [conn10] received client metadata from 172.31.0.221:48640 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.446+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48658 #11 (2 connections now open)
2020-05-08T21:57:16.446+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:48658 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.896+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48688 #12 (3 connections now open)
2020-05-08T21:57:16.897+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:48688 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.930+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48696 #13 (4 connections now open)
2020-05-08T21:57:16.930+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:48696 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.950+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48712 #14 (5 connections now open)
2020-05-08T21:57:16.950+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:48712 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.144+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48730 #15 (6 connections now open)
2020-05-08T21:57:17.145+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:48730 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.304+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48766 #16 (7 connections now open)
2020-05-08T21:57:17.304+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48768 #17 (8 connections now open)
2020-05-08T21:57:17.304+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:48766 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.304+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:48768 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48790 #18 (9 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:48790 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.454+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48818 #19 (10 connections now open)
2020-05-08T21:57:17.454+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:48818 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.457+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48828 #20 (11 connections now open)
2020-05-08T21:57:17.457+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:48828 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48848 #21 (12 connections now open)
2020-05-08T21:57:17.705+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:48848 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.786+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48866 #22 (13 connections now open)
2020-05-08T21:57:17.786+0000 I  NETWORK  [conn22] received client metadata from 172.31.0.221:48866 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.826+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48872 #23 (14 connections now open)
2020-05-08T21:57:17.826+0000 I  NETWORK  [conn23] received client metadata from 172.31.0.221:48872 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.866+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48894 #24 (15 connections now open)
2020-05-08T21:57:18.866+0000 I  NETWORK  [conn24] received client metadata from 172.31.0.221:48894 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.985+0000 I  COMMAND  [conn19] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("85a650ed-2e51-480c-9ecc-11ddfd9c30bf") } } numYields:0 reslen:163 protocol:op_msg 1526ms
2020-05-08T21:57:18.986+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:18.987+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.987+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.989+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.989+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.992+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:18.992+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:19.021+0000 I  NETWORK  [conn19] end connection 172.31.0.221:48818 (14 connections now open)
2020-05-08T21:57:19.021+0000 I  NETWORK  [conn20] end connection 172.31.0.221:48828 (13 connections now open)
2020-05-08T21:57:19.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48912 #31 (14 connections now open)
2020-05-08T21:57:19.350+0000 I  NETWORK  [conn31] received client metadata from 172.31.0.221:48912 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.515+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48932 #32 (15 connections now open)
2020-05-08T21:57:19.515+0000 I  NETWORK  [conn32] received client metadata from 172.31.0.221:48932 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48934 #33 (16 connections now open)
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48938 #34 (17 connections now open)
2020-05-08T21:57:19.561+0000 I  NETWORK  [conn33] received client metadata from 172.31.0.221:48934 conn33: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.561+0000 I  NETWORK  [conn34] received client metadata from 172.31.0.221:48938 conn34: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.909+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48964 #35 (18 connections now open)
2020-05-08T21:57:19.910+0000 I  NETWORK  [conn35] received client metadata from 172.31.0.221:48964 conn35: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.080+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48972 #36 (19 connections now open)
2020-05-08T21:57:20.080+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:48972 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.188+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48982 #37 (20 connections now open)
2020-05-08T21:57:20.188+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:48982 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.791+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49056 #38 (21 connections now open)
2020-05-08T21:57:21.791+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:49056 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.856+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49066 #39 (22 connections now open)
2020-05-08T21:57:21.856+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:49066 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.009+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49092 #40 (23 connections now open)
2020-05-08T21:57:22.010+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:49092 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.072+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49170 #41 (24 connections now open)
2020-05-08T21:57:22.072+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:49170 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.073+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49172 #42 (25 connections now open)
2020-05-08T21:57:22.073+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:49172 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.074+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49178 #43 (26 connections now open)
2020-05-08T21:57:22.074+0000 I  NETWORK  [conn43] received client metadata from 172.31.0.221:49178 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.074+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49180 #44 (27 connections now open)
2020-05-08T21:57:22.074+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:49180 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.080+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49206 #45 (28 connections now open)
2020-05-08T21:57:22.082+0000 I  NETWORK  [conn45] received client metadata from 172.31.0.221:49206 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.082+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49208 #46 (29 connections now open)
2020-05-08T21:57:22.083+0000 I  NETWORK  [conn46] received client metadata from 172.31.0.221:49208 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.087+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.306+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 10 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 217ms
2020-05-08T21:57:22.306+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975039, 4) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:220777, timeInactiveMicros:0, 220ms
2020-05-08T21:57:22.307+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975039, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 220ms
2020-05-08T21:57:22.308+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 4) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:219288, timeInactiveMicros:616, 219ms
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn41] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975039, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 236ms
2020-05-08T21:57:22.454+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.515+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49242 #55 (30 connections now open)
2020-05-08T21:57:22.516+0000 I  NETWORK  [conn55] received client metadata from 172.31.0.221:49242 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.082+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49280 #56 (31 connections now open)
2020-05-08T21:57:23.082+0000 I  NETWORK  [conn56] received client metadata from 172.31.0.221:49280 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.125+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49292 #63 (32 connections now open)
2020-05-08T21:57:23.125+0000 I  NETWORK  [conn63] received client metadata from 172.31.0.221:49292 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.364+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 8 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 347), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 10, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:341 protocol:op_msg 837ms
2020-05-08T21:57:23.364+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 327) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 328) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:848271, timeInactiveMicros:5713, 853ms
2020-05-08T21:57:23.364+0000 I  COMMAND  [conn41] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 332), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1") }, txnNumber: 7, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 844ms
2020-05-08T21:57:23.366+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 338) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 339) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:844282, timeInactiveMicros:1479, 845ms
2020-05-08T21:57:23.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49306 #64 (33 connections now open)
2020-05-08T21:57:23.415+0000 I  NETWORK  [conn64] received client metadata from 172.31.0.221:49306 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.426+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 394) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:838463, timeInactiveMicros:0, 838ms
2020-05-08T21:57:23.426+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 394), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c") }, txnNumber: 14, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 838ms
2020-05-08T21:57:23.454+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.454+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.740+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49350 #67 (34 connections now open)
2020-05-08T21:57:23.741+0000 I  NETWORK  [conn67] received client metadata from 172.31.0.221:49350 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.776+0000 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 23, autocommit: false } numYields:0 reslen:321 protocol:op_msg 217ms
2020-05-08T21:57:23.777+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 114), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c") }, txnNumber: 26, autocommit: false } numYields:0 reslen:321 protocol:op_msg 215ms
2020-05-08T21:57:24.485+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49408 #68 (35 connections now open)
2020-05-08T21:57:24.485+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:49408 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.821+0000 I  COMMAND  [conn41] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 394), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1") }, txnNumber: 7, autocommit: false } numYields:0 reslen:351 protocol:op_msg 1456ms
2020-05-08T21:57:25.082+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49424 #69 (36 connections now open)
2020-05-08T21:57:25.083+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:49424 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.122+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 67, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975044, 177) } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 177) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:851705, timeInactiveMicros:621, 852ms
2020-05-08T21:57:25.122+0000 I  COMMAND  [conn45] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 180), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 67, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 843ms
2020-05-08T21:57:25.122+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c") }, txnNumber: 82, autocommit: false } numYields:0 reslen:321 protocol:op_msg 851ms
2020-05-08T21:57:25.156+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.183+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49434 #72 (37 connections now open)
2020-05-08T21:57:25.184+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:49434 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.426+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49476 #73 (38 connections now open)
2020-05-08T21:57:25.427+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:49476 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.503+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49478 #74 (39 connections now open)
2020-05-08T21:57:25.503+0000 I  NETWORK  [conn74] received client metadata from 172.31.0.221:49478 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.547+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 69, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 22) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:391349, timeActiveMicros:393671, timeInactiveMicros:535, 394ms
2020-05-08T21:57:25.547+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 69, autocommit: false } numYields:0 reslen:214 protocol:op_msg 391ms
2020-05-08T21:57:25.554+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 85, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 22) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 22) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:396764, timeActiveMicros:398796, timeInactiveMicros:818, 399ms
2020-05-08T21:57:25.554+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c") }, txnNumber: 85, autocommit: false } numYields:0 reslen:214 protocol:op_msg 396ms
2020-05-08T21:57:25.588+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975044, 193) } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 193) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:762909, timeActiveMicros:765253, timeInactiveMicros:965, 766ms
2020-05-08T21:57:25.588+0000 I  COMMAND  [conn41] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 204), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1") }, txnNumber: 8, autocommit: false } numYields:0 reslen:214 protocol:op_msg 762ms
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49512 #76 (40 connections now open)
2020-05-08T21:57:25.672+0000 I  NETWORK  [conn76] received client metadata from 172.31.0.221:49512 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.120+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49534 #77 (41 connections now open)
2020-05-08T21:57:26.121+0000 I  NETWORK  [conn77] received client metadata from 172.31.0.221:49534 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.370+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49552 #78 (42 connections now open)
2020-05-08T21:57:26.370+0000 I  NETWORK  [conn78] received client metadata from 172.31.0.221:49552 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.458+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 93), t: 3 }
2020-05-08T21:57:27.475+0000 I  NETWORK  [conn45] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:27.476+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:27.476+0000 I  NETWORK  [conn43] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:57:27.477+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:27.975+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.475+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.975+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.975+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.976+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.976+0000 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975046, 98), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 186, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2500ms
2020-05-08T21:57:29.170+0000 I  NETWORK  [conn43] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:57:29.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.475+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.975+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.475+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.892+0000 I  NETWORK  [conn44] end connection 172.31.0.221:49180 (41 connections now open)
2020-05-08T21:57:30.892+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49662 #81 (42 connections now open)
2020-05-08T21:57:30.892+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49664 #82 (43 connections now open)
2020-05-08T21:57:30.893+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:49662 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.893+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:49664 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.894+0000 I  NETWORK  [conn81] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:30.895+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.895+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.919+0000 I  NETWORK  [conn42] end connection 172.31.0.221:49172 (42 connections now open)
2020-05-08T21:57:30.920+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49688 #83 (43 connections now open)
2020-05-08T21:57:30.920+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:49688 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.921+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49690 #84 (44 connections now open)
2020-05-08T21:57:30.921+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:49690 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.927+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 638), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7efffaf1-b0cf-489e-943e-f800cb8e880c") }, txnNumber: 102, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5012ms
2020-05-08T21:57:30.927+0000 I  NETWORK  [conn43] end connection 172.31.0.221:49178 (43 connections now open)
2020-05-08T21:57:30.941+0000 I  COMMAND  [conn41] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 658), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e25df045-1689-4dd7-8182-488725ed0bd1") }, txnNumber: 25, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:57:30.941+0000 I  NETWORK  [conn41] end connection 172.31.0.221:49170 (42 connections now open)
2020-05-08T21:57:30.955+0000 I  NETWORK  [conn46] end connection 172.31.0.221:49208 (41 connections now open)
2020-05-08T21:57:30.955+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49720 #85 (42 connections now open)
2020-05-08T21:57:30.955+0000 I  NETWORK  [conn85] received client metadata from 172.31.0.221:49720 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.955+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49722 #86 (43 connections now open)
2020-05-08T21:57:30.955+0000 I  NETWORK  [conn86] received client metadata from 172.31.0.221:49722 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.957+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.975+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:31.475+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.475+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.475+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.476+0000 I  COMMAND  [conn45] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975048, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aa24b785-9aa0-4c59-ae43-fb5cb5c7e307") }, txnNumber: 186, autocommit: false } numYields:0 reslen:516 protocol:op_msg 2499ms
2020-05-08T21:57:31.476+0000 I  NETWORK  [conn45] end connection 172.31.0.221:49206 (42 connections now open)
2020-05-08T21:57:31.992+0000 I  COMMAND  [conn85] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1035ms
2020-05-08T21:57:31.994+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.640+0000 I  NETWORK  [conn83] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:34.641+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.641+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.642+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:34.642+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.642+0000 I  SHARDING [conn81] Received reply from shard ec2-3-82-35-209.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:34.642+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975050, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4de0f467-5514-4a38-8dbc-0eb74b15939a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3249ms
2020-05-08T21:57:34.642+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:34.646+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("1cd3d129-68d6-4e0c-b09f-b27fb5e6123b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 3) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3723848, timeInactiveMicros:0, 3723ms
2020-05-08T21:57:34.646+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 60 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1cd3d129-68d6-4e0c-b09f-b27fb5e6123b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 1cd3d129-68d6-4e0c-b09f-b27fb5e6123b:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975050, 3) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 3723ms
2020-05-08T21:57:34.654+0000 I  NETWORK  [conn81] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:34.654+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.654+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.655+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:34.656+0000 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 3) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2662039, timeActiveMicros:3698950, timeInactiveMicros:586, 3699ms
2020-05-08T21:57:34.656+0000 I  COMMAND  [conn85] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975051, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 2662ms
2020-05-08T21:57:35.059+0000 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 878), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097") }, txnNumber: 12, autocommit: false } numYields:0 reslen:352 protocol:op_msg 209ms
2020-05-08T21:57:35.060+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("1cd3d129-68d6-4e0c-b09f-b27fb5e6123b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975054, 815) } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 816) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:257620, timeActiveMicros:265969, timeInactiveMicros:1848, 267ms
2020-05-08T21:57:35.060+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 827), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1cd3d129-68d6-4e0c-b09f-b27fb5e6123b") }, txnNumber: 8, autocommit: false } numYields:0 reslen:214 protocol:op_msg 257ms
2020-05-08T21:57:35.142+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:35.142+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:35.142+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:35.511+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:35.511+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:35.642+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:35.812+0000 I  NETWORK  [conn83] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:35.812+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:35.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.110+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49842 #92 (43 connections now open)
2020-05-08T21:57:36.110+0000 I  NETWORK  [conn92] received client metadata from 172.31.0.221:49842 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.142+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.642+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.642+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.642+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.645+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 78), t: 6 }
2020-05-08T21:57:37.186+0000 I  NETWORK  [conn85] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:37.186+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:37.686+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.686+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.687+0000 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975056, 74), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097") }, txnNumber: 131, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1507ms
2020-05-08T21:57:37.985+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.563+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49904 #95 (44 connections now open)
2020-05-08T21:57:39.563+0000 I  NETWORK  [conn95] received client metadata from 172.31.0.221:49904 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.275+0000 I  NETWORK  [conn86] end connection 172.31.0.221:49722 (43 connections now open)
2020-05-08T21:57:40.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49934 #96 (44 connections now open)
2020-05-08T21:57:40.275+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49936 #97 (45 connections now open)
2020-05-08T21:57:40.276+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:49934 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.276+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:49936 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.323+0000 I  NETWORK  [conn84] end connection 172.31.0.221:49690 (44 connections now open)
2020-05-08T21:57:40.324+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49954 #98 (45 connections now open)
2020-05-08T21:57:40.324+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49956 #99 (46 connections now open)
2020-05-08T21:57:40.324+0000 I  NETWORK  [conn98] received client metadata from 172.31.0.221:49954 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.324+0000 I  NETWORK  [conn99] received client metadata from 172.31.0.221:49956 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.325+0000 I  SHARDING [conn98] Received reply from shard ec2-35-172-222-251.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:40.325+0000 I  NETWORK  [conn98] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:57:40.325+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.326+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:40.326+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.327+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.361+0000 I  NETWORK  [conn82] end connection 172.31.0.221:49664 (45 connections now open)
2020-05-08T21:57:40.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49990 #100 (46 connections now open)
2020-05-08T21:57:40.361+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49992 #101 (47 connections now open)
2020-05-08T21:57:40.361+0000 I  NETWORK  [conn100] received client metadata from 172.31.0.221:49990 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.361+0000 I  NETWORK  [conn101] received client metadata from 172.31.0.221:49992 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.398+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 431), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1cd3d129-68d6-4e0c-b09f-b27fb5e6123b") }, txnNumber: 23, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5014ms
2020-05-08T21:57:40.398+0000 I  NETWORK  [conn83] end connection 172.31.0.221:49688 (46 connections now open)
2020-05-08T21:57:40.826+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.318+0000 I  NETWORK  [conn98] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.319+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.326+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.819+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.819+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.820+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.820+0000 I  TXN      [conn98] transaction parameters:{ lsid: { id: UUID("26279b8c-3d28-43ea-a583-030ad40e078f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975060, 1) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:1491852, timeInactiveMicros:240, 1492ms
2020-05-08T21:57:41.821+0000 I  COMMAND  [conn98] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 137 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26279b8c-3d28-43ea-a583-030ad40e078f") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 1491ms
2020-05-08T21:57:41.826+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.326+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.826+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.038+0000 I  NETWORK  [conn98] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:43.039+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.312+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 2354 timed out, deadline was 2020-05-08T21:57:43.312+0000, op was RemoteCommand 2354 -- target:[ec2-54-226-181-14.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:57:43.312+0000 cmd:{ isMaster: 1 }
2020-05-08T21:57:43.312+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 2356 timed out, deadline was 2020-05-08T21:57:43.312+0000, op was RemoteCommand 2356 -- target:[ec2-54-159-37-160.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:57:43.312+0000 cmd:{ isMaster: 1 }
2020-05-08T21:57:43.312+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:43.312+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.312+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.312+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:57:43.312+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:57:43.326+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.538+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.538+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.539+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.539+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.539+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.539+0000 I  COMMAND  [conn98] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975061, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26279b8c-3d28-43ea-a583-030ad40e078f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 1718ms
2020-05-08T21:57:44.171+0000 I  NETWORK  [conn98] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:44.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.211+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.255+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50122 #103 (47 connections now open)
2020-05-08T21:57:45.255+0000 I  NETWORK  [conn103] received client metadata from 172.31.0.221:50122 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.276+0000 I  NETWORK  [conn97] end connection 172.31.0.221:49936 (46 connections now open)
2020-05-08T21:57:45.276+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50134 #104 (47 connections now open)
2020-05-08T21:57:45.276+0000 I  NETWORK  [conn104] received client metadata from 172.31.0.221:50134 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.276+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50136 #105 (48 connections now open)
2020-05-08T21:57:45.277+0000 I  NETWORK  [conn105] received client metadata from 172.31.0.221:50136 conn105: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.281+0000 I  -        [conn96] operation was interrupted because a client disconnected
2020-05-08T21:57:45.281+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 136 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975057, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("07f6a7ba-feed-43e0-af45-cad763efaf30") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:57:45.281+0000 I  NETWORK  [conn96] end connection 172.31.0.221:49934 (47 connections now open)
2020-05-08T21:57:45.329+0000 I  NETWORK  [conn99] end connection 172.31.0.221:49956 (46 connections now open)
2020-05-08T21:57:45.329+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50146 #106 (47 connections now open)
2020-05-08T21:57:45.329+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50148 #107 (48 connections now open)
2020-05-08T21:57:45.329+0000 I  NETWORK  [conn106] received client metadata from 172.31.0.221:50146 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.330+0000 I  NETWORK  [conn107] received client metadata from 172.31.0.221:50148 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.362+0000 I  NETWORK  [conn101] end connection 172.31.0.221:49992 (47 connections now open)
2020-05-08T21:57:45.362+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50182 #108 (48 connections now open)
2020-05-08T21:57:45.362+0000 I  NETWORK  [conn108] received client metadata from 172.31.0.221:50182 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.362+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50184 #109 (49 connections now open)
2020-05-08T21:57:45.363+0000 I  NETWORK  [conn109] received client metadata from 172.31.0.221:50184 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.368+0000 I  -        [conn100] operation was interrupted because a client disconnected
2020-05-08T21:57:45.368+0000 I  TXN      [conn100] transaction parameters:{ lsid: { id: UUID("672ec4b3-777a-4774-b560-9ff63d6174a6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975060, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004321, timeInactiveMicros:0, 5004ms
2020-05-08T21:57:45.368+0000 I  COMMAND  [conn100] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 133 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672ec4b3-777a-4774-b560-9ff63d6174a6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:57:45.368+0000 I  NETWORK  [conn100] end connection 172.31.0.221:49990 (48 connections now open)
2020-05-08T21:57:45.671+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.671+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.672+0000 I  COMMAND  [conn98] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975063, 102), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("26279b8c-3d28-43ea-a583-030ad40e078f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 2132ms
2020-05-08T21:57:45.672+0000 I  NETWORK  [conn98] end connection 172.31.0.221:49954 (47 connections now open)
2020-05-08T21:57:45.710+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.711+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:45.712+0000 I  NETWORK  [replSetDistLockPinger] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.210+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.710+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.210+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.517+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.710+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.210+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.312+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.710+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.710+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:50.277+0000 I  NETWORK  [conn105] end connection 172.31.0.221:50136 (46 connections now open)
2020-05-08T21:57:50.277+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50262 #111 (47 connections now open)
2020-05-08T21:57:50.278+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50264 #112 (48 connections now open)
2020-05-08T21:57:50.278+0000 I  NETWORK  [conn111] received client metadata from 172.31.0.221:50262 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.278+0000 I  NETWORK  [conn112] received client metadata from 172.31.0.221:50264 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.279+0000 I  NETWORK  [conn111] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:50.280+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.320+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.330+0000 I  NETWORK  [conn107] end connection 172.31.0.221:50148 (47 connections now open)
2020-05-08T21:57:50.330+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50274 #113 (48 connections now open)
2020-05-08T21:57:50.330+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50276 #114 (49 connections now open)
2020-05-08T21:57:50.330+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:50274 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.330+0000 I  NETWORK  [conn114] received client metadata from 172.31.0.221:50276 conn114: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50292 #115 (50 connections now open)
2020-05-08T21:57:50.375+0000 I  NETWORK  [conn115] end connection 172.31.0.221:50292 (49 connections now open)
2020-05-08T21:57:50.378+0000 I  NETWORK  [conn109] end connection 172.31.0.221:50184 (48 connections now open)
2020-05-08T21:57:50.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50304 #116 (49 connections now open)
2020-05-08T21:57:50.379+0000 I  NETWORK  [conn116] received client metadata from 172.31.0.221:50304 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50306 #117 (50 connections now open)
2020-05-08T21:57:50.380+0000 I  NETWORK  [conn117] received client metadata from 172.31.0.221:50306 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.402+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:50.402+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:50.402+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:50.403+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 431), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4de0f467-5514-4a38-8dbc-0eb74b15939a") }, txnNumber: 9, autocommit: false } numYields:0 reslen:438 protocol:op_msg 15019ms
2020-05-08T21:57:50.403+0000 I  NETWORK  [conn81] end connection 172.31.0.221:49662 (49 connections now open)
2020-05-08T21:57:50.406+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.406+0000 I  TXN      [conn106] transaction parameters:{ lsid: { id: UUID("b77f75ac-ddef-47a3-b08e-f67d94c240e3"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975064, 151) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:5075497, timeInactiveMicros:0, 5075ms
2020-05-08T21:57:50.406+0000 I  COMMAND  [conn106] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b77f75ac-ddef-47a3-b08e-f67d94c240e3") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction b77f75ac-ddef-47a3-b08e-f67d94c240e3:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975064, 151) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:594 protocol:op_msg 5075ms
2020-05-08T21:57:50.406+0000 I  NETWORK  [conn106] end connection 172.31.0.221:50146 (48 connections now open)
2020-05-08T21:57:50.406+0000 I  COMMAND  [conn108] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 151), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bf882aa4-06e4-4d5c-b9a8-e05837709a2e") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 5042ms
2020-05-08T21:57:50.407+0000 I  NETWORK  [conn108] end connection 172.31.0.221:50182 (47 connections now open)
2020-05-08T21:57:50.407+0000 I  TXN      [conn104] transaction parameters:{ lsid: { id: UUID("1f1d2fb9-e84d-4f7f-a591-55df5fea2573"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975064, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:5129318, timeInactiveMicros:0, 5129ms
2020-05-08T21:57:50.407+0000 I  COMMAND  [conn104] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1f1d2fb9-e84d-4f7f-a591-55df5fea2573") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 1f1d2fb9-e84d-4f7f-a591-55df5fea2573:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975064, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:592 protocol:op_msg 5129ms
2020-05-08T21:57:50.407+0000 I  NETWORK  [conn104] end connection 172.31.0.221:50134 (46 connections now open)
2020-05-08T21:57:50.414+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.779+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.279+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.694+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50338 #122 (47 connections now open)
2020-05-08T21:57:51.694+0000 I  NETWORK  [conn122] received client metadata from 172.31.0.221:50338 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.779+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.779+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.780+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.780+0000 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("68ff4881-038d-439f-8679-5ae1819f88a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975066, 1) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1501307, timeInactiveMicros:0, 1501ms
2020-05-08T21:57:51.780+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975066, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("68ff4881-038d-439f-8679-5ae1819f88a0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 1501ms
2020-05-08T21:57:51.780+0000 I  COMMAND  [conn116] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 147 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 184), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8e5a8c4e-95ce-4547-8189-d889a3015c5e") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 1366ms
2020-05-08T21:57:51.780+0000 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 132, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975057, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975057, 5) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:14088202, timeInactiveMicros:273, 14088ms
2020-05-08T21:57:51.780+0000 I  COMMAND  [conn85] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975057, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2066d4cf-f844-44fa-97f9-c87698808097") }, txnNumber: 132, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 2066d4cf-f844-44fa-97f9-c87698808097:132 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975057, 5) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:594 protocol:op_msg 14086ms
2020-05-08T21:57:51.781+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.781+0000 I  NETWORK  [conn85] end connection 172.31.0.221:49720 (46 connections now open)
2020-05-08T21:57:51.790+0000 I  TXN      [conn116] transaction parameters:{ lsid: { id: UUID("8e5a8c4e-95ce-4547-8189-d889a3015c5e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975070, 184) } }, globalReadTimestamp:{ ts: Timestamp(1588975070, 184) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:8370, timeActiveMicros:1377180, timeInactiveMicros:1138, 1378ms
2020-05-08T21:57:52.200+0000 I  SHARDING [conn111] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.280+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.280+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.716+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50362 #123 (47 connections now open)
2020-05-08T21:57:52.716+0000 I  NETWORK  [conn123] received client metadata from 172.31.0.221:50362 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.907+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50388 #124 (48 connections now open)
2020-05-08T21:57:52.907+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:50388 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:53.700+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 641), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584") }, txnNumber: 273, autocommit: false } numYields:0 reslen:322 protocol:op_msg 214ms
2020-05-08T21:57:54.120+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 779), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584") }, txnNumber: 297, autocommit: false } numYields:0 reslen:322 protocol:op_msg 212ms
2020-05-08T21:57:54.334+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50448 #125 (49 connections now open)
2020-05-08T21:57:54.335+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:50448 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.398+0000 I  NETWORK  [conn116] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:54.398+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:54.749+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 247), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584") }, txnNumber: 342, autocommit: false } numYields:0 reslen:322 protocol:op_msg 216ms
2020-05-08T21:57:54.898+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.898+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.899+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:54.899+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.899+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:54.899+0000 I  COMMAND  [conn116] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 264 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975073, 611), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8e5a8c4e-95ce-4547-8189-d889a3015c5e") }, txnNumber: 76, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 1462ms
2020-05-08T21:57:54.900+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:54.908+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:54.960+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50486 #127 (50 connections now open)
2020-05-08T21:57:54.960+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:50486 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:55.505+0000 I  NETWORK  [conn116] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:55.505+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:55.798+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50552 #128 (51 connections now open)
2020-05-08T21:57:55.798+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:50552 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.005+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.159+0000 I  NETWORK  [conn111] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:56.159+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.161+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.505+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:56.659+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.789+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50590 #129 (52 connections now open)
2020-05-08T21:57:56.789+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:50590 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.005+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.365+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.365+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.366+0000 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("68ff4881-038d-439f-8679-5ae1819f88a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 75, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 585) } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 585) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3964654, timeInactiveMicros:509, 3965ms
2020-05-08T21:57:57.366+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975073, 587), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("68ff4881-038d-439f-8679-5ae1819f88a0") }, txnNumber: 75, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 3961ms
2020-05-08T21:57:57.366+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584") }, txnNumber: 388, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2211ms
2020-05-08T21:57:57.396+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.505+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:57.630+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50662 #130 (53 connections now open)
2020-05-08T21:57:57.631+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:50662 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.005+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.369+0000 I  NETWORK  [conn112] end connection 172.31.0.221:50264 (52 connections now open)
2020-05-08T21:57:58.369+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50718 #131 (53 connections now open)
2020-05-08T21:57:58.370+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:50718 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.370+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50720 #132 (54 connections now open)
2020-05-08T21:57:58.370+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:50720 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.378+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.436+0000 I  NETWORK  [conn117] end connection 172.31.0.221:50306 (53 connections now open)
2020-05-08T21:57:58.436+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50764 #133 (54 connections now open)
2020-05-08T21:57:58.437+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50766 #134 (55 connections now open)
2020-05-08T21:57:58.437+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:50764 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.437+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:50766 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.505+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.614+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50782 #135 (56 connections now open)
2020-05-08T21:57:58.614+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:50782 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.005+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.505+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.505+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.506+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.506+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:59.507+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:59.779+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50792 #137 (57 connections now open)
2020-05-08T21:57:59.779+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:50792 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.909+0000 I  CONNPOOL [conn116] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:57:59.909+0000 I  COMMAND  [conn116] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 349), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8e5a8c4e-95ce-4547-8189-d889a3015c5e") }, txnNumber: 76, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5009ms
2020-05-08T21:57:59.909+0000 I  NETWORK  [conn116] end connection 172.31.0.221:50304 (56 connections now open)
2020-05-08T21:58:00.006+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.006+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.007+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.403+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975079, 589), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa") }, txnNumber: 149, autocommit: false } numYields:0 reslen:322 protocol:op_msg 417ms
2020-05-08T21:58:00.888+0000 I  NETWORK  [conn113] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:00.888+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:00.890+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.235+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975080, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa") }, txnNumber: 169, autocommit: false } numYields:0 reslen:322 protocol:op_msg 633ms
2020-05-08T21:58:01.243+0000 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("68ff4881-038d-439f-8679-5ae1819f88a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975077, 7) } }, globalReadTimestamp:{ ts: Timestamp(1588975077, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3862051, timeInactiveMicros:558, 3862ms
2020-05-08T21:58:01.243+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975077, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("68ff4881-038d-439f-8679-5ae1819f88a0") }, txnNumber: 77, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 3859ms
2020-05-08T21:58:01.243+0000 I  NETWORK  [conn111] end connection 172.31.0.221:50262 (55 connections now open)
2020-05-08T21:58:01.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.889+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.889+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.890+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:01.891+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.891+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.891+0000 I  TXN      [conn131] transaction parameters:{ lsid: { id: UUID("7d20d725-4a99-4c79-8232-ad5dd394b61c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975077, 10) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3518961, timeInactiveMicros:909, 3519ms
2020-05-08T21:58:01.891+0000 I  COMMAND  [conn131] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 190), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7d20d725-4a99-4c79-8232-ad5dd394b61c") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3513ms
2020-05-08T21:58:02.250+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:02.250+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.313+0000 I  TXN      [conn113] transaction parameters:{ lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 391, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975077, 10) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:4918633, timeInactiveMicros:249, 4918ms
2020-05-08T21:58:02.313+0000 I  COMMAND  [conn113] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 270 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975077, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584") }, txnNumber: 391, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 831704fc-3b84-4c8e-8d14-aafcb60de584:391 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975077, 10) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:548 protocol:op_msg 4918ms
2020-05-08T21:58:02.315+0000 I  NETWORK  [conn113] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:02.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.372+0000 I  NETWORK  [conn134] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:02.373+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.395+0000 I  NETWORK  [conn114] end connection 172.31.0.221:50276 (54 connections now open)
2020-05-08T21:58:02.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50906 #138 (55 connections now open)
2020-05-08T21:58:02.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50908 #139 (56 connections now open)
2020-05-08T21:58:02.396+0000 I  NETWORK  [conn138] received client metadata from 172.31.0.221:50906 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:02.396+0000 I  NETWORK  [conn139] received client metadata from 172.31.0.221:50908 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:02.397+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.529+0000 I  NETWORK  [conn131] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:02.530+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.872+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:02.888+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.890+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:02.890+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.370+0000 I  NETWORK  [conn132] end connection 172.31.0.221:50720 (55 connections now open)
2020-05-08T21:58:03.370+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50970 #140 (56 connections now open)
2020-05-08T21:58:03.371+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:50970 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50972 #141 (57 connections now open)
2020-05-08T21:58:03.371+0000 I  NETWORK  [conn141] received client metadata from 172.31.0.221:50972 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.785+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.785+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.786+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 116), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa") }, txnNumber: 202, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2254ms
2020-05-08T21:58:03.787+0000 I  TXN      [conn140] transaction parameters:{ lsid: { id: UUID("8546b0be-1868-4b86-b600-81d4ea535d5a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975082, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:415738, timeInactiveMicros:0, 415ms
2020-05-08T21:58:03.787+0000 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("ed3dd7d2-9c91-4447-94c2-0ceff7b5bbe4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975082, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1390376, timeInactiveMicros:0, 1390ms
2020-05-08T21:58:03.787+0000 I  COMMAND  [conn140] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975082, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8546b0be-1868-4b86-b600-81d4ea535d5a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 415ms
2020-05-08T21:58:03.788+0000 I  COMMAND  [conn138] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975082, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ed3dd7d2-9c91-4447-94c2-0ceff7b5bbe4") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1390ms
2020-05-08T21:58:03.791+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.796+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.801+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.803+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.811+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.888+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.120+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.889+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.889+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.890+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.894+0000 I  COMMAND  [conn131] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 118), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7d20d725-4a99-4c79-8232-ad5dd394b61c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:545 protocol:op_msg 3002ms
2020-05-08T21:58:04.894+0000 I  NETWORK  [conn131] end connection 172.31.0.221:50718 (56 connections now open)
2020-05-08T21:58:05.454+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.941+0000 I  COMMAND  [conn140] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8546b0be-1868-4b86-b600-81d4ea535d5a") }, txnNumber: 3, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2138ms
2020-05-08T21:58:05.942+0000 I  NETWORK  [conn140] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.943+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.943+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.944+0000 I  TXN      [conn134] transaction parameters:{ lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 204, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 63) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2142813, timeInactiveMicros:0, 2142ms
2020-05-08T21:58:05.944+0000 I  COMMAND  [conn134] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 63), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa") }, txnNumber: 204, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2142ms
2020-05-08T21:58:05.944+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.944+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.944+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.949+0000 I  TXN      [conn140] transaction parameters:{ lsid: { id: UUID("8546b0be-1868-4b86-b600-81d4ea535d5a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 63) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2146248, timeInactiveMicros:677, 2146ms
2020-05-08T21:58:05.953+0000 I  TXN      [conn138] transaction parameters:{ lsid: { id: UUID("ed3dd7d2-9c91-4447-94c2-0ceff7b5bbe4"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 64) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2142873, timeInactiveMicros:307, 2143ms
2020-05-08T21:58:05.953+0000 I  COMMAND  [conn138] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 64), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ed3dd7d2-9c91-4447-94c2-0ceff7b5bbe4") }, txnNumber: 4, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2142ms
2020-05-08T21:58:06.555+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.556+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:06.561+0000 I  NETWORK  [conn113] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:06.562+0000 I  COMMAND  [conn113] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("831704fc-3b84-4c8e-8d14-aafcb60de584") }, txnNumber: 391, autocommit: false } numYields:0 reslen:471 protocol:op_msg 4247ms
2020-05-08T21:58:06.562+0000 I  NETWORK  [conn113] end connection 172.31.0.221:50274 (55 connections now open)
2020-05-08T21:58:06.968+0000 I  NETWORK  [conn140] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.968+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:06.971+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.055+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.468+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.555+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.555+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.968+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.968+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.969+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 42), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa") }, txnNumber: 205, autocommit: false } numYields:0 reslen:440 protocol:op_msg 1991ms
2020-05-08T21:58:08.562+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.802+0000 I  NETWORK  [conn133] end connection 172.31.0.221:50764 (54 connections now open)
2020-05-08T21:58:08.802+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51152 #147 (55 connections now open)
2020-05-08T21:58:08.802+0000 I  NETWORK  [conn147] received client metadata from 172.31.0.221:51152 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.806+0000 I  NETWORK  [conn141] end connection 172.31.0.221:50972 (54 connections now open)
2020-05-08T21:58:08.806+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51154 #148 (55 connections now open)
2020-05-08T21:58:08.806+0000 I  NETWORK  [conn148] received client metadata from 172.31.0.221:51154 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.808+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51156 #149 (56 connections now open)
2020-05-08T21:58:08.809+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51158 #150 (57 connections now open)
2020-05-08T21:58:08.809+0000 I  NETWORK  [conn149] received client metadata from 172.31.0.221:51156 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.809+0000 I  NETWORK  [conn150] received client metadata from 172.31.0.221:51158 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.810+0000 I  NETWORK  [conn139] end connection 172.31.0.221:50908 (56 connections now open)
2020-05-08T21:58:08.810+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51160 #151 (57 connections now open)
2020-05-08T21:58:08.810+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:51160 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.811+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51162 #152 (58 connections now open)
2020-05-08T21:58:08.811+0000 I  NETWORK  [conn152] received client metadata from 172.31.0.221:51162 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:09.060+0000 I  TXN      [conn140] transaction parameters:{ lsid: { id: UUID("8546b0be-1868-4b86-b600-81d4ea535d5a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 33) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 33) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:3083640, timeActiveMicros:3090134, timeInactiveMicros:1081, 3091ms
2020-05-08T21:58:09.060+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.064+0000 I  COMMAND  [conn151] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 226), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("09eca2e6-f82c-4420-8d8a-479c3f2286b9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 252ms
2020-05-08T21:58:09.064+0000 I  COMMAND  [conn134] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 226), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2c034fe2-0018-49c7-bccc-8c4b69934daa") }, txnNumber: 205, autocommit: false } numYields:0 reslen:398 protocol:op_msg 1094ms
2020-05-08T21:58:09.064+0000 I  NETWORK  [conn134] end connection 172.31.0.221:50766 (57 connections now open)
2020-05-08T21:58:09.065+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.066+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975087, 226) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:259001, timeInactiveMicros:0, 259ms
2020-05-08T21:58:09.066+0000 I  COMMAND  [conn147] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 226), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 259ms
2020-05-08T21:58:09.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.265+0000 I  SHARDING [conn140] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.265+0000 I  NETWORK  [conn140] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.266+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.266+0000 I  NETWORK  [conn151] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.266+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.348+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.665+0000 I  NETWORK  [conn149] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:58:09.666+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.765+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.055+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51196 #155 (58 connections now open)
2020-05-08T21:58:10.055+0000 I  NETWORK  [conn155] received client metadata from 172.31.0.221:51196 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.335+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.336+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.582+0000 I  NETWORK  [conn147] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:10.582+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:10.835+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.988+0000 I  COMMAND  [conn140] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 39), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8546b0be-1868-4b86-b600-81d4ea535d5a") }, txnNumber: 4, autocommit: false } numYields:0 reslen:396 protocol:op_msg 5012ms
2020-05-08T21:58:10.988+0000 I  NETWORK  [conn140] end connection 172.31.0.221:50970 (57 connections now open)
2020-05-08T21:58:11.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.335+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.335+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.339+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 2), t: 19 }
2020-05-08T21:58:11.582+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.582+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.583+0000 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 199), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 57, autocommit: false } numYields:0 reslen:470 protocol:op_msg 2001ms
2020-05-08T21:58:12.284+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51264 #156 (58 connections now open)
2020-05-08T21:58:12.285+0000 I  NETWORK  [conn156] received client metadata from 172.31.0.221:51264 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.365+0000 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 57, autocommit: false } numYields:0 reslen:428 protocol:op_msg 780ms
2020-05-08T21:58:13.809+0000 I  NETWORK  [conn150] end connection 172.31.0.221:51158 (57 connections now open)
2020-05-08T21:58:13.810+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51304 #157 (58 connections now open)
2020-05-08T21:58:13.810+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51306 #158 (59 connections now open)
2020-05-08T21:58:13.810+0000 I  NETWORK  [conn157] received client metadata from 172.31.0.221:51304 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.810+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:51306 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.811+0000 I  NETWORK  [conn152] end connection 172.31.0.221:51162 (58 connections now open)
2020-05-08T21:58:13.811+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51308 #159 (59 connections now open)
2020-05-08T21:58:13.812+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:51308 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.812+0000 I  NETWORK  [conn157] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:13.812+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51310 #160 (60 connections now open)
2020-05-08T21:58:13.812+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:51310 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:13.812+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.813+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.815+0000 I  -        [conn149] operation was interrupted because a client disconnected
2020-05-08T21:58:13.815+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 286 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 226), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fb1b32ba-b768-4eee-9f07-757c9d09d999") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:58:13.815+0000 I  NETWORK  [conn149] end connection 172.31.0.221:51156 (59 connections now open)
2020-05-08T21:58:14.312+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.312+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.754+0000 I  NETWORK  [conn157] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Exec error resulting in state FAILURE :: caused by :: operation was interrupted
2020-05-08T21:58:14.755+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.757+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.812+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.170+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51326 #161 (60 connections now open)
2020-05-08T21:58:15.170+0000 I  NETWORK  [conn161] received client metadata from 172.31.0.221:51326 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.233+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:15.265+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 7389 timed out, deadline was 2020-05-08T21:58:15.265+0000, op was RemoteCommand 7389 -- target:[ec2-54-226-181-14.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:15.265+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:15.265+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 7387 timed out, deadline was 2020-05-08T21:58:15.265+0000, op was RemoteCommand 7387 -- target:[ec2-54-159-37-160.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:15.265+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:15.265+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:15.265+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.265+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.265+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:58:15.265+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:58:15.313+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.812+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.812+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.290+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.290+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.290+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.291+0000 I  TXN      [conn151] transaction parameters:{ lsid: { id: UUID("09eca2e6-f82c-4420-8d8a-479c3f2286b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975087, 226) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:7478461, timeInactiveMicros:608, 7479ms
2020-05-08T21:58:16.291+0000 I  COMMAND  [conn151] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("09eca2e6-f82c-4420-8d8a-479c3f2286b9") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 7225ms
2020-05-08T21:58:16.291+0000 I  COMMAND  [conn138] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 213), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ed3dd7d2-9c91-4447-94c2-0ceff7b5bbe4") }, txnNumber: 175, autocommit: false } numYields:0 reslen:440 protocol:op_msg 8890ms
2020-05-08T21:58:16.291+0000 I  NETWORK  [conn151] end connection 172.31.0.221:51160 (59 connections now open)
2020-05-08T21:58:16.291+0000 I  COMMAND  [conn147] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 298 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975092, 295), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:354 protocol:op_msg 3836ms
2020-05-08T21:58:16.291+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.291+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.291+0000 I  NETWORK  [conn138] end connection 172.31.0.221:50906 (58 connections now open)
2020-05-08T21:58:16.763+0000 I  COMMAND  [conn157] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975092, 295), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c1318b86-9271-4c27-a8df-3d7f4b77396b") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 2952ms
2020-05-08T21:58:16.765+0000 I  NETWORK  [conn157] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.765+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.765+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.767+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 370 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 640), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2954ms
2020-05-08T21:58:16.768+0000 I  COMMAND  [conn147] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 79), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 64, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 475ms
2020-05-08T21:58:16.771+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 64, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 79) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:478274, timeInactiveMicros:334, 478ms
2020-05-08T21:58:16.773+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 640) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2959766, timeInactiveMicros:464, 2960ms
2020-05-08T21:58:16.837+0000 I  NETWORK  [conn159] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:16.837+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.837+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.334+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 370 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 211), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea") }, txnNumber: 8, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 211) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 505ms
2020-05-08T21:58:17.334+0000 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 216), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 71, autocommit: false } numYields:0 reslen:428 protocol:op_msg 495ms
2020-05-08T21:58:17.343+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 211) } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 211) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:5754, timeActiveMicros:513642, timeInactiveMicros:1186, 514ms
2020-05-08T21:58:17.363+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.364+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.365+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.671+0000 I  NETWORK  [conn157] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:17.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.761+0000 I  NETWORK  [conn159] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:17.762+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.863+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:18.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.363+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.363+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.354+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.355+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.355+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.355+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.356+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.370+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.667+0000 I  COMMAND  [conn147] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 73, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 2319ms
2020-05-08T21:58:19.668+0000 I  NETWORK  [conn147] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:19.669+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.669+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.671+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.671+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.672+0000 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 176), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c1318b86-9271-4c27-a8df-3d7f4b77396b") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2903ms
2020-05-08T21:58:19.672+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 9, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 7) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2327341, timeInactiveMicros:255, 2327ms
2020-05-08T21:58:19.672+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea") }, txnNumber: 9, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 2325ms
2020-05-08T21:58:19.676+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 73, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975097, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 7) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:7961, timeActiveMicros:2330784, timeInactiveMicros:807, 2331ms
2020-05-08T21:58:19.855+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.855+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.448+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.191+0000 I  NETWORK  [conn159] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:21.293+0000 I  NETWORK  [conn148] end connection 172.31.0.221:51154 (57 connections now open)
2020-05-08T21:58:21.293+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51492 #165 (58 connections now open)
2020-05-08T21:58:21.293+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51494 #166 (59 connections now open)
2020-05-08T21:58:21.294+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:51492 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.294+0000 I  NETWORK  [conn166] received client metadata from 172.31.0.221:51494 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.765+0000 I  NETWORK  [conn158] end connection 172.31.0.221:51306 (58 connections now open)
2020-05-08T21:58:21.766+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51508 #167 (59 connections now open)
2020-05-08T21:58:21.766+0000 I  NETWORK  [conn167] received client metadata from 172.31.0.221:51508 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:21.766+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51510 #168 (60 connections now open)
2020-05-08T21:58:21.766+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:51510 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.344+0000 I  NETWORK  [conn160] end connection 172.31.0.221:51310 (59 connections now open)
2020-05-08T21:58:22.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51548 #169 (60 connections now open)
2020-05-08T21:58:22.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51550 #170 (61 connections now open)
2020-05-08T21:58:22.345+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:51548 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.345+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:51550 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.675+0000 I  NETWORK  [conn167] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:22.675+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:22.676+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:22.680+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:22.681+0000 I  NETWORK  [conn147] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 0e735c5e-80a3-4150-8eae-2f996988a7fc:74 stopped due to: operation was interrupted
2020-05-08T21:58:22.682+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:22.692+0000 I  COMMAND  [conn157] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c1318b86-9271-4c27-a8df-3d7f4b77396b") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3018ms
2020-05-08T21:58:22.692+0000 I  COMMAND  [conn159] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("132f8d84-0a21-47d6-8bcd-00c276915bea") }, txnNumber: 9, autocommit: false } numYields:0 reslen:395 protocol:op_msg 3018ms
2020-05-08T21:58:22.692+0000 I  NETWORK  [conn157] end connection 172.31.0.221:51304 (59 connections now open)
2020-05-08T21:58:22.692+0000 I  NETWORK  [conn159] end connection 172.31.0.221:51308 (60 connections now open)
2020-05-08T21:58:23.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.671+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 7654 timed out, deadline was 2020-05-08T21:58:23.671+0000, op was RemoteCommand 7654 -- target:[ec2-54-159-37-160.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:23.671+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:23.671+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:23.671+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.675+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.675+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.675+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.676+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:23.676+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:23.676+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 134) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1329819, timeInactiveMicros:283, 1330ms
2020-05-08T21:58:23.676+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 1329ms
2020-05-08T21:58:23.677+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 58) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:1909270, timeInactiveMicros:300, 1909ms
2020-05-08T21:58:23.677+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 374 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 134), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 1 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 1908ms
2020-05-08T21:58:23.732+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.733+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:23.847+0000 I  NETWORK  [conn165] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.848+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.848+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975099, 11) } }, globalReadTimestamp:{ ts: Timestamp(1588975099, 16) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:4168960, timeActiveMicros:4171436, timeInactiveMicros:663, 4172ms
2020-05-08T21:58:23.848+0000 I  COMMAND  [conn147] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0e735c5e-80a3-4150-8eae-2f996988a7fc") }, txnNumber: 74, autocommit: false } numYields:0 reslen:311 protocol:op_msg 4169ms
2020-05-08T21:58:23.848+0000 I  NETWORK  [conn147] end connection 172.31.0.221:51152 (58 connections now open)
2020-05-08T21:58:23.849+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.176+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.675+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.676+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.137+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.175+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.175+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.176+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975103, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1498ms
2020-05-08T21:58:25.176+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975103, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1498ms
2020-05-08T21:58:25.176+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.261+0000 I  NETWORK  [conn167] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:25.262+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.263+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.265+0000 I  NETWORK  [conn165] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.265+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.675+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.676+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:26.175+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.175+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.176+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.176+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.176+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.176+0000 I  SHARDING [conn167] Received reply from shard ec2-34-207-119-213.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.176+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975105, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 999ms
2020-05-08T21:58:26.176+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975105, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 999ms
2020-05-08T21:58:26.296+0000 I  NETWORK  [conn166] end connection 172.31.0.221:51494 (57 connections now open)
2020-05-08T21:58:26.297+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51662 #173 (58 connections now open)
2020-05-08T21:58:26.297+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51664 #174 (59 connections now open)
2020-05-08T21:58:26.297+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:51662 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:26.297+0000 I  NETWORK  [conn174] received client metadata from 172.31.0.221:51664 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:26.372+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 370 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 4) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 195ms
2020-05-08T21:58:26.374+0000 I  NETWORK  [conn173] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:26.374+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 370 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 4) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 197ms
2020-05-08T21:58:26.374+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.374+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.488+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 374 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 115ms
2020-05-08T21:58:26.491+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 4) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 4) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:313295, timeInactiveMicros:814, 314ms
2020-05-08T21:58:26.496+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 4) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 4) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:318199, timeInactiveMicros:611, 318ms
2020-05-08T21:58:26.496+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 121ms
2020-05-08T21:58:26.505+0000 I  COMMAND  [conn165] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 58), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("470b1f88-554e-433a-8aeb-50610628a61f") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 5209ms
2020-05-08T21:58:26.505+0000 I  NETWORK  [conn165] end connection 172.31.0.221:51492 (58 connections now open)
2020-05-08T21:58:26.573+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.327+0000 I  NETWORK  [conn173] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:28.328+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.328+0000 I  NETWORK  [conn169] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:28.328+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.828+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.828+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.829+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 418), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 42, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1504ms
2020-05-08T21:58:28.830+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 425), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 38, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1499ms
2020-05-08T21:58:28.834+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 27, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 470) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1447746, timeActiveMicros:1451896, timeInactiveMicros:1032, 1452ms
2020-05-08T21:58:28.834+0000 I  COMMAND  [conn173] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 474), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 27, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1447ms
2020-05-08T21:58:29.735+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 646), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 64, autocommit: false } numYields:0 reslen:352 protocol:op_msg 221ms
2020-05-08T21:58:29.741+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 652), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 59, autocommit: false } numYields:0 reslen:352 protocol:op_msg 219ms
2020-05-08T21:58:29.744+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 658), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 53, autocommit: false } numYields:0 reslen:321 protocol:op_msg 215ms
2020-05-08T21:58:30.237+0000 I  NETWORK  [conn167] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:30.238+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.239+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.242+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.737+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.737+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.738+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 74, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 310) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:512827, timeInactiveMicros:0, 512ms
2020-05-08T21:58:30.738+0000 I  COMMAND  [conn173] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 310), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 74, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 512ms
2020-05-08T21:58:30.738+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 81, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 315) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 315) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:506983, timeInactiveMicros:1875, 508ms
2020-05-08T21:58:30.738+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 320), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 81, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 503ms
2020-05-08T21:58:31.252+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 81, autocommit: false } numYields:0 reslen:352 protocol:op_msg 512ms
2020-05-08T21:58:31.255+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 443), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 74, autocommit: false } numYields:0 reslen:397 protocol:op_msg 516ms
2020-05-08T21:58:31.269+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 79, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 290), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1057ms
2020-05-08T21:58:31.277+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.240+0000 I  NETWORK  [conn169] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:32.240+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.241+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.740+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.740+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.741+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 157), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 80, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1368ms
2020-05-08T21:58:33.388+0000 I  SHARDING [conn167] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.388+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 85, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 153) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2015642, timeActiveMicros:2019140, timeInactiveMicros:1180, 2020ms
2020-05-08T21:58:33.388+0000 I  COMMAND  [conn167] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 156), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 85, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2015ms
2020-05-08T21:58:33.390+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 503 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 168), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 85, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2008ms
2020-05-08T21:58:33.393+0000 I  COMMAND  [conn173] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 80, autocommit: false } numYields:0 reslen:397 protocol:op_msg 650ms
2020-05-08T21:58:34.737+0000 I  NETWORK  [conn173] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.737+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.743+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.746+0000 I  NETWORK  [conn169] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.382+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:36.369+0000 I  NETWORK  [conn174] end connection 172.31.0.221:51664 (57 connections now open)
2020-05-08T21:58:36.369+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51872 #178 (58 connections now open)
2020-05-08T21:58:36.369+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51874 #179 (59 connections now open)
2020-05-08T21:58:36.369+0000 I  NETWORK  [conn178] received client metadata from 172.31.0.221:51872 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.369+0000 I  NETWORK  [conn179] received client metadata from 172.31.0.221:51874 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.382+0000 I  NETWORK  [conn170] end connection 172.31.0.221:51550 (58 connections now open)
2020-05-08T21:58:36.383+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51884 #180 (59 connections now open)
2020-05-08T21:58:36.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51886 #181 (60 connections now open)
2020-05-08T21:58:36.384+0000 I  NETWORK  [conn180] received client metadata from 172.31.0.221:51884 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.384+0000 I  NETWORK  [conn181] received client metadata from 172.31.0.221:51886 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.645+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-107-21-173-199.compute-1.amazonaws.com:27019 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:36.737+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.737+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.738+0000 I  TXN      [conn173] transaction parameters:{ lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 81, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975113, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975113, 2) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:3339699, timeActiveMicros:3343999, timeInactiveMicros:477, 3344ms
2020-05-08T21:58:36.738+0000 I  COMMAND  [conn173] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1907b9b5-d8ec-4e21-b047-91a8aab8570f") }, txnNumber: 81, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3339ms
2020-05-08T21:58:36.739+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 86, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3339ms
2020-05-08T21:58:36.739+0000 I  NETWORK  [conn173] end connection 172.31.0.221:51662 (59 connections now open)
2020-05-08T21:58:36.740+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 8) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:355704, timeInactiveMicros:0, 355ms
2020-05-08T21:58:36.740+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 2d5be4d7-eeb3-411c-aa00-02c5ee2e6067:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975114, 8) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:590 protocol:op_msg 355ms
2020-05-08T21:58:36.743+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 8) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:372703, timeInactiveMicros:0, 372ms
2020-05-08T21:58:36.743+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975114, 8) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:590 protocol:op_msg 372ms
2020-05-08T21:58:36.751+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 85, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 168) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3359706, timeActiveMicros:5369705, timeInactiveMicros:598, 5370ms
2020-05-08T21:58:36.753+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.754+0000 I  COMMAND  [conn169] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("be1e5be6-bbd0-4430-b11a-0605801093d9") }, txnNumber: 85, autocommit: false } numYields:0 reslen:397 protocol:op_msg 3361ms
2020-05-08T21:58:36.756+0000 I  NETWORK  [conn169] end connection 172.31.0.221:51548 (58 connections now open)
2020-05-08T21:58:37.202+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.202+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.204+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.608+0000 I  NETWORK  [conn167] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.609+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.702+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.857+0000 I  NETWORK  [conn180] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.860+0000 I  NETWORK  [conn178] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f:36 stopped due to: operation was interrupted
2020-05-08T21:58:38.109+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.202+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.358+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.358+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.358+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.358+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.359+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 35, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 243) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 243) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1071295, timeInactiveMicros:0, 1071ms
2020-05-08T21:58:38.359+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 243), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067") }, txnNumber: 35, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 243) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1071ms
2020-05-08T21:58:38.513+0000 I  NETWORK  [Uptime-reporter] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.514+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.519+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.609+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.609+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.610+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.610+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 133, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 490) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1002460, timeInactiveMicros:0, 1002ms
2020-05-08T21:58:38.610+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 490), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 133, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1002ms
2020-05-08T21:58:38.702+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.859+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 44), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 133, autocommit: false } numYields:0 reslen:398 protocol:op_msg 248ms
2020-05-08T21:58:38.863+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 11) } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:496338, timeInactiveMicros:0, 496ms
2020-05-08T21:58:38.863+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067") }, txnNumber: 36, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 496ms
2020-05-08T21:58:38.880+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 36, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 225) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 225) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1603801, timeActiveMicros:1612532, timeInactiveMicros:2338, 1614ms
2020-05-08T21:58:38.880+0000 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 230), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 36, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1603ms
2020-05-08T21:58:38.979+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:39.202+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:39.360+0000 I  SHARDING [conn167] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:39.702+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.702+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:40.540+0000 I  NETWORK  [conn180] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:40.541+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.541+0000 I  NETWORK  [conn178] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.542+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.541+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.541+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.543+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 997), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 78, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1853ms
2020-05-08T21:58:41.772+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:41.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.051+0000 I  NETWORK  [conn178] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:42.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.056+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 77, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 1018) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:2348832, timeActiveMicros:2352711, timeInactiveMicros:809, 2353ms
2020-05-08T21:58:42.056+0000 I  COMMAND  [conn180] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1020), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2d5be4d7-eeb3-411c-aa00-02c5ee2e6067") }, txnNumber: 77, autocommit: false } numYields:0 reslen:311 protocol:op_msg 2348ms
2020-05-08T21:58:42.058+0000 I  NETWORK  [conn180] end connection 172.31.0.221:51884 (57 connections now open)
2020-05-08T21:58:42.058+0000 I  NETWORK  [conn181] end connection 172.31.0.221:51886 (56 connections now open)
2020-05-08T21:58:42.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52010 #184 (57 connections now open)
2020-05-08T21:58:42.058+0000 I  NETWORK  [conn184] received client metadata from 172.31.0.221:52010 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:42.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52012 #185 (58 connections now open)
2020-05-08T21:58:42.059+0000 I  NETWORK  [conn185] received client metadata from 172.31.0.221:52012 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:42.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.551+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.051+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.051+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.052+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 79, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975121, 6) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1509254, timeInactiveMicros:0, 1509ms
2020-05-08T21:58:43.052+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975121, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 79, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975121, 6) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 1509ms
2020-05-08T21:58:43.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.746+0000 I  NETWORK  [conn184] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:43.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.047+0000 I  TXN      [conn167] transaction parameters:{ lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 297, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975120, 344) } }, globalReadTimestamp:{ ts: Timestamp(1588975120, 344) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3340493, timeInactiveMicros:0, 3340ms
2020-05-08T21:58:44.048+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975120, 344), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 297, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975120, 344) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 3340ms
2020-05-08T21:58:44.049+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.049+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.049+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.049+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("3674c25b-00be-4bca-a1ac-cbcc768efdf8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975121, 10) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1989469, timeInactiveMicros:0, 1989ms
2020-05-08T21:58:44.050+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975121, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3674c25b-00be-4bca-a1ac-cbcc768efdf8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 1989ms
2020-05-08T21:58:44.057+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 79, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1004ms
2020-05-08T21:58:44.177+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 297, autocommit: false } numYields:0 reslen:399 protocol:op_msg 129ms
2020-05-08T21:58:44.179+0000 I  COMMAND  [conn184] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975123, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3674c25b-00be-4bca-a1ac-cbcc768efdf8") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 129ms
2020-05-08T21:58:44.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.429+0000 I  NETWORK  [conn167] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:45.429+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.430+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.078+0000 I  NETWORK  [conn178] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:46.079+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:46.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.425+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:58:46.429+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.579+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.579+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.580+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.580+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 105, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 416) } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 416) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2149725, timeInactiveMicros:0, 2149ms
2020-05-08T21:58:46.580+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 416), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 105, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975124, 416) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2149ms
2020-05-08T21:58:46.772+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.772+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.773+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.776+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 21), t: 33 }
2020-05-08T21:58:46.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.088+0000 I  NETWORK  [conn178] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:47.088+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:47.272+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.272+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.429+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.588+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:47.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.088+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.088+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.089+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975126, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 105, autocommit: false } numYields:0 reslen:516 protocol:op_msg 1507ms
2020-05-08T21:58:48.429+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.429+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.430+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 410), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 309, autocommit: false } numYields:0 reslen:322 protocol:op_msg 4005ms
2020-05-08T21:58:48.430+0000 I  COMMAND  [conn184] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 407), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3674c25b-00be-4bca-a1ac-cbcc768efdf8") }, txnNumber: 17, autocommit: false } numYields:0 reslen:470 protocol:op_msg 4009ms
2020-05-08T21:58:48.474+0000 I  NETWORK  [conn167] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:48.474+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.490+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:48.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.990+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:48.990+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.105+0000 I  NETWORK  [conn178] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.106+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:49.292+0000 I  NETWORK  [conn179] end connection 172.31.0.221:51874 (57 connections now open)
2020-05-08T21:58:49.292+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52078 #188 (58 connections now open)
2020-05-08T21:58:49.292+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52080 #189 (59 connections now open)
2020-05-08T21:58:49.293+0000 I  NETWORK  [conn188] received client metadata from 172.31.0.221:52078 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.293+0000 I  NETWORK  [conn189] received client metadata from 172.31.0.221:52080 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.294+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.294+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.295+0000 I  COMMAND  [conn167] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975128, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 310, autocommit: false } numYields:0 reslen:322 protocol:op_msg 858ms
2020-05-08T21:58:49.295+0000 I  COMMAND  [conn184] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975128, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3674c25b-00be-4bca-a1ac-cbcc768efdf8") }, txnNumber: 17, autocommit: false } numYields:0 reslen:545 protocol:op_msg 863ms
2020-05-08T21:58:49.296+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.296+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.297+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 106, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 6) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1198959, timeInactiveMicros:0, 1198ms
2020-05-08T21:58:49.297+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("15a7eac9-67a5-4b4f-ad47-f947e0c3ec4f") }, txnNumber: 106, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 5) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1199ms
2020-05-08T21:58:49.297+0000 I  NETWORK  [conn178] end connection 172.31.0.221:51872 (58 connections now open)
2020-05-08T21:58:49.307+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.309+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.357+0000 I  NETWORK  [conn185] end connection 172.31.0.221:52012 (57 connections now open)
2020-05-08T21:58:49.357+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52090 #190 (58 connections now open)
2020-05-08T21:58:49.357+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52092 #191 (59 connections now open)
2020-05-08T21:58:49.357+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:52090 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.357+0000 I  NETWORK  [conn191] received client metadata from 172.31.0.221:52092 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.419+0000 I  NETWORK  [conn168] end connection 172.31.0.221:51510 (58 connections now open)
2020-05-08T21:58:49.419+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52156 #192 (59 connections now open)
2020-05-08T21:58:49.419+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52158 #193 (60 connections now open)
2020-05-08T21:58:49.419+0000 I  NETWORK  [conn192] received client metadata from 172.31.0.221:52156 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.419+0000 I  NETWORK  [conn193] received client metadata from 172.31.0.221:52158 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.706+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.990+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.406+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T21:58:50.406+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.490+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.657+0000 I  COMMAND  [conn167] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 594 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9f604685-21f5-4c75-a8f0-1e884ccd03a0") }, txnNumber: 311, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975129, 2) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1361ms
2020-05-08T21:58:50.658+0000 I  NETWORK  [conn167] end connection 172.31.0.221:51508 (59 connections now open)
2020-05-08T21:58:50.659+0000 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("d434131c-2973-45c0-a9cb-b260ec8e50b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1238840, timeInactiveMicros:0, 1238ms
2020-05-08T21:58:50.659+0000 I  COMMAND  [conn192] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d434131c-2973-45c0-a9cb-b260ec8e50b6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1238ms
2020-05-08T21:58:50.680+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:50.754+0000 I  NETWORK  [conn192] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:50.755+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.760+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.764+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.770+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.990+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.255+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.255+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.256+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.257+0000 I  TXN      [conn188] transaction parameters:{ lsid: { id: UUID("5b461da7-3402-4e45-9110-0a1bfa03ccee"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 22) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1963335, timeInactiveMicros:0, 1963ms
2020-05-08T21:58:51.257+0000 I  COMMAND  [conn188] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5b461da7-3402-4e45-9110-0a1bfa03ccee") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1963ms
2020-05-08T21:58:51.490+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.491+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.491+0000 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn190] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d93b6367-458a-4c99-b75f-413ac0eea16c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2516ms
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn192] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 610 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975130, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d434131c-2973-45c0-a9cb-b260ec8e50b6") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1195ms
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 598 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3674c25b-00be-4bca-a1ac-cbcc768efdf8") }, txnNumber: 18, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975129, 2) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:363 protocol:op_msg 2579ms
2020-05-08T21:58:51.876+0000 I  NETWORK  [conn184] end connection 172.31.0.221:52010 (58 connections now open)
2020-05-08T21:58:51.877+0000 I  COMMAND  [conn188] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5b461da7-3402-4e45-9110-0a1bfa03ccee") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 619ms
2020-05-08T21:58:51.887+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("d93b6367-458a-4c99-b75f-413ac0eea16c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2527386, timeInactiveMicros:787, 2528ms
2020-05-08T21:58:51.889+0000 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("d434131c-2973-45c0-a9cb-b260ec8e50b6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975130, 18) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:11132, timeActiveMicros:1208501, timeInactiveMicros:1086, 1209ms
2020-05-08T21:58:52.096+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.115+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.118+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.120+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.124+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.615+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.901+0000 I  NETWORK  [conn192] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:52.902+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:52.903+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:53.115+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.115+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.116+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.402+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.402+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.403+0000 I  COMMAND  [conn190] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 95), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d93b6367-458a-4c99-b75f-413ac0eea16c") }, txnNumber: 2, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1497ms
2020-05-08T21:58:53.404+0000 I  COMMAND  [conn188] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5b461da7-3402-4e45-9110-0a1bfa03ccee") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1504ms
2020-05-08T21:58:53.928+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.928+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.928+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.930+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.934+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.934+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:54.293+0000 I  NETWORK  [conn189] end connection 172.31.0.221:52080 (57 connections now open)
2020-05-08T21:58:54.293+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52314 #200 (58 connections now open)
2020-05-08T21:58:54.294+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52316 #201 (59 connections now open)
2020-05-08T21:58:54.294+0000 I  NETWORK  [conn200] received client metadata from 172.31.0.221:52314 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.294+0000 I  NETWORK  [conn201] received client metadata from 172.31.0.221:52316 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.358+0000 I  NETWORK  [conn191] end connection 172.31.0.221:52092 (58 connections now open)
2020-05-08T21:58:54.358+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52326 #202 (59 connections now open)
2020-05-08T21:58:54.358+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52328 #203 (60 connections now open)
2020-05-08T21:58:54.358+0000 I  NETWORK  [conn202] received client metadata from 172.31.0.221:52326 conn202: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.358+0000 I  NETWORK  [conn203] received client metadata from 172.31.0.221:52328 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.428+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.428+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.432+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 4), t: 38 }
2020-05-08T21:58:54.606+0000 I  NETWORK  [conn202] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:54.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.607+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.610+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.106+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.106+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.107+0000 I  COMMAND  [conn190] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d93b6367-458a-4c99-b75f-413ac0eea16c") }, txnNumber: 2, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1703ms
2020-05-08T21:58:55.108+0000 I  NETWORK  [conn190] end connection 172.31.0.221:52090 (59 connections now open)
2020-05-08T21:58:55.108+0000 I  COMMAND  [conn188] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5b461da7-3402-4e45-9110-0a1bfa03ccee") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1703ms
2020-05-08T21:58:55.108+0000 I  NETWORK  [conn188] end connection 172.31.0.221:52078 (58 connections now open)
2020-05-08T21:58:55.604+0000 I  NETWORK  [conn202] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:55.604+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.106+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.891+0000 I  NETWORK  [conn193] end connection 172.31.0.221:52158 (57 connections now open)
2020-05-08T21:58:56.892+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52476 #204 (58 connections now open)
2020-05-08T21:58:56.892+0000 I  NETWORK  [conn204] received client metadata from 172.31.0.221:52476 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:56.893+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52478 #205 (59 connections now open)
2020-05-08T21:58:56.893+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:52478 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:57.106+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:57.606+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.606+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:58.109+0000 I  NETWORK  [conn200] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:58.110+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.111+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.609+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:59.109+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.109+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.110+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 6), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.110+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:59.110+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.110+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.294+0000 I  NETWORK  [conn201] end connection 172.31.0.221:52316 (58 connections now open)
2020-05-08T21:58:59.294+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52608 #206 (59 connections now open)
2020-05-08T21:58:59.295+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52606 #207 (60 connections now open)
2020-05-08T21:58:59.295+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:52608 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.295+0000 I  NETWORK  [conn207] received client metadata from 172.31.0.221:52606 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.297+0000 I  -        [conn200] operation was interrupted because a client disconnected
2020-05-08T21:58:59.297+0000 I  CONNPOOL [conn200] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:58:59.298+0000 I  TXN      [conn200] transaction parameters:{ lsid: { id: UUID("378d3230-ec31-4130-b7bd-a3bbcc855a62"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003366, timeInactiveMicros:0, 5003ms
2020-05-08T21:58:59.298+0000 I  COMMAND  [conn200] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 610 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("378d3230-ec31-4130-b7bd-a3bbcc855a62") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:59.298+0000 I  NETWORK  [conn200] end connection 172.31.0.221:52314 (59 connections now open)
2020-05-08T21:58:59.358+0000 I  NETWORK  [conn203] end connection 172.31.0.221:52328 (58 connections now open)
2020-05-08T21:58:59.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52620 #208 (59 connections now open)
2020-05-08T21:58:59.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52622 #209 (60 connections now open)
2020-05-08T21:58:59.359+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:52620 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.359+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:52622 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.361+0000 I  -        [conn202] operation was interrupted because a client disconnected
2020-05-08T21:58:59.361+0000 I  CONNPOOL [conn202] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:58:59.361+0000 I  TXN      [conn202] transaction parameters:{ lsid: { id: UUID("2b0173ac-2ebd-42d7-97d9-b72755661392"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001986, timeInactiveMicros:0, 5001ms
2020-05-08T21:58:59.361+0000 I  COMMAND  [conn202] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 612 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2b0173ac-2ebd-42d7-97d9-b72755661392") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:58:59.361+0000 I  NETWORK  [conn202] end connection 172.31.0.221:52326 (59 connections now open)
2020-05-08T21:59:01.893+0000 I  NETWORK  [conn205] end connection 172.31.0.221:52478 (58 connections now open)
2020-05-08T21:59:01.893+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52740 #210 (59 connections now open)
2020-05-08T21:59:01.893+0000 I  NETWORK  [conn210] received client metadata from 172.31.0.221:52740 conn210: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.893+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52742 #211 (60 connections now open)
2020-05-08T21:59:01.893+0000 I  NETWORK  [conn211] received client metadata from 172.31.0.221:52742 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:01.895+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.899+0000 I  -        [conn204] operation was interrupted because a client disconnected
2020-05-08T21:59:01.899+0000 I  CONNPOOL [conn204] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:01.899+0000 I  TXN      [conn204] transaction parameters:{ lsid: { id: UUID("e52e74fb-0f65-4765-bbd3-c9f816dbfc65"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975135, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004909, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:01.899+0000 I  COMMAND  [conn204] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 607 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975135, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e52e74fb-0f65-4765-bbd3-c9f816dbfc65") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:01.899+0000 I  NETWORK  [conn204] end connection 172.31.0.221:52476 (59 connections now open)
2020-05-08T21:59:03.799+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:04.295+0000 I  NETWORK  [conn206] end connection 172.31.0.221:52608 (58 connections now open)
2020-05-08T21:59:04.296+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52864 #213 (59 connections now open)
2020-05-08T21:59:04.296+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52866 #214 (60 connections now open)
2020-05-08T21:59:04.296+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:52864 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.296+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:52866 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.297+0000 I  -        [conn207] operation was interrupted because a client disconnected
2020-05-08T21:59:04.297+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.297+0000 I  CONNPOOL [conn207] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:04.297+0000 I  TXN      [conn207] transaction parameters:{ lsid: { id: UUID("3b365645-5750-433e-a86d-78191d9efb1a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975138, 6) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001781, timeInactiveMicros:0, 5001ms
2020-05-08T21:59:04.297+0000 I  COMMAND  [conn207] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 617 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3b365645-5750-433e-a86d-78191d9efb1a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:04.297+0000 I  NETWORK  [conn207] end connection 172.31.0.221:52606 (59 connections now open)
2020-05-08T21:59:04.359+0000 I  NETWORK  [conn209] end connection 172.31.0.221:52622 (58 connections now open)
2020-05-08T21:59:04.359+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52876 #215 (59 connections now open)
2020-05-08T21:59:04.360+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52878 #216 (60 connections now open)
2020-05-08T21:59:04.360+0000 I  NETWORK  [conn215] received client metadata from 172.31.0.221:52876 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.360+0000 I  NETWORK  [conn216] received client metadata from 172.31.0.221:52878 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.365+0000 I  -        [conn208] operation was interrupted because a client disconnected
2020-05-08T21:59:04.365+0000 I  CONNPOOL [conn208] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:04.365+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 617 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("08e5e585-f3b0-45ff-b76e-ad89e32ead20") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:04.365+0000 I  NETWORK  [conn208] end connection 172.31.0.221:52620 (59 connections now open)
2020-05-08T21:59:04.438+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975144, 2), t: 41 }
2020-05-08T21:59:04.896+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:59:06.893+0000 I  NETWORK  [conn211] end connection 172.31.0.221:52742 (58 connections now open)
2020-05-08T21:59:06.894+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52948 #217 (59 connections now open)
2020-05-08T21:59:06.894+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52950 #218 (60 connections now open)
2020-05-08T21:59:06.894+0000 I  NETWORK  [conn218] received client metadata from 172.31.0.221:52950 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.894+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:52948 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:06.897+0000 I  -        [conn210] operation was interrupted because a client disconnected
2020-05-08T21:59:06.897+0000 I  CONNPOOL [conn210] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:59:06.897+0000 I  COMMAND  [conn210] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 594 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b1b57edf-937f-4948-9ba3-6b24e0c08207") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:06.897+0000 I  NETWORK  [conn210] end connection 172.31.0.221:52740 (59 connections now open)
2020-05-08T21:59:07.330+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.065+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:59:09.296+0000 I  NETWORK  [conn213] end connection 172.31.0.221:52864 (58 connections now open)
2020-05-08T21:59:09.297+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52998 #222 (59 connections now open)
2020-05-08T21:59:09.297+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53000 #223 (60 connections now open)
2020-05-08T21:59:09.297+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:52998 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.297+0000 I  NETWORK  [conn223] received client metadata from 172.31.0.221:53000 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.298+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.301+0000 I  -        [conn214] operation was interrupted because a client disconnected
2020-05-08T21:59:09.301+0000 I  CONNPOOL [conn214] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:59:09.301+0000 I  TXN      [conn214] transaction parameters:{ lsid: { id: UUID("4f884b81-9dbb-4f4f-a3cd-74dd73449568"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975138, 6) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004388, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:09.301+0000 I  COMMAND  [conn214] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 622 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975138, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f884b81-9dbb-4f4f-a3cd-74dd73449568") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:09.301+0000 I  NETWORK  [conn214] end connection 172.31.0.221:52866 (59 connections now open)
2020-05-08T21:59:09.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53008 #225 (60 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [conn225] end connection 172.31.0.221:53008 (59 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53012 #226 (60 connections now open)
2020-05-08T21:59:09.376+0000 I  NETWORK  [conn226] received client metadata from 172.31.0.221:53012 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.379+0000 I  NETWORK  [conn216] end connection 172.31.0.221:52878 (59 connections now open)
2020-05-08T21:59:09.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53024 #227 (60 connections now open)
2020-05-08T21:59:09.380+0000 I  NETWORK  [conn227] received client metadata from 172.31.0.221:53024 conn227: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53026 #228 (61 connections now open)
2020-05-08T21:59:09.380+0000 I  NETWORK  [conn228] received client metadata from 172.31.0.221:53026 conn228: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.382+0000 I  NETWORK  [conn227] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:59:09.382+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.382+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.882+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.882+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:10.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:10.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:11.894+0000 I  NETWORK  [conn217] end connection 172.31.0.221:52948 (60 connections now open)
2020-05-08T21:59:11.894+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53082 #232 (61 connections now open)
2020-05-08T21:59:11.895+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53084 #233 (62 connections now open)
2020-05-08T21:59:11.895+0000 I  NETWORK  [conn232] received client metadata from 172.31.0.221:53082 conn232: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.895+0000 I  NETWORK  [conn233] received client metadata from 172.31.0.221:53084 conn233: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:11.896+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:11.899+0000 I  -        [conn218] operation was interrupted because a client disconnected
2020-05-08T21:59:11.899+0000 I  CONNPOOL [conn218] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:11.899+0000 I  TXN      [conn218] transaction parameters:{ lsid: { id: UUID("28a7f8da-eedb-4f1b-aabd-32903792e182"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975145, 19) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003615, timeInactiveMicros:0, 5003ms
2020-05-08T21:59:11.899+0000 I  COMMAND  [conn218] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 668 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975145, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28a7f8da-eedb-4f1b-aabd-32903792e182") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:11.899+0000 I  NETWORK  [conn218] end connection 172.31.0.221:52950 (61 connections now open)
2020-05-08T21:59:14.297+0000 I  NETWORK  [conn223] end connection 172.31.0.221:53000 (60 connections now open)
2020-05-08T21:59:14.298+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53164 #234 (61 connections now open)
2020-05-08T21:59:14.298+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53162 #235 (62 connections now open)
2020-05-08T21:59:14.298+0000 I  NETWORK  [conn234] received client metadata from 172.31.0.221:53164 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.298+0000 I  NETWORK  [conn235] received client metadata from 172.31.0.221:53162 conn235: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.299+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.385+0000 I  NETWORK  [conn228] end connection 172.31.0.221:53026 (61 connections now open)
2020-05-08T21:59:14.385+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53190 #237 (62 connections now open)
2020-05-08T21:59:14.386+0000 I  -        [conn227] operation was interrupted because a client disconnected
2020-05-08T21:59:14.386+0000 I  NETWORK  [conn237] received client metadata from 172.31.0.221:53190 conn237: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.386+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53192 #238 (63 connections now open)
2020-05-08T21:59:14.386+0000 I  CONNPOOL [conn227] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 5 connections to that host remain open
2020-05-08T21:59:14.386+0000 I  NETWORK  [conn238] received client metadata from 172.31.0.221:53192 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.386+0000 I  TXN      [conn227] transaction parameters:{ lsid: { id: UUID("4402a569-a3b5-4985-82ac-dd7c8863bd85"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 21) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002487, timeInactiveMicros:0, 5002ms
2020-05-08T21:59:14.386+0000 I  COMMAND  [conn227] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 686 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975149, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4402a569-a3b5-4985-82ac-dd7c8863bd85") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:14.386+0000 I  NETWORK  [conn227] end connection 172.31.0.221:53024 (62 connections now open)
2020-05-08T21:59:15.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.540+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:15.541+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.041+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.425+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b96b7369da8ea76060 to 5eb5d5b80770106eff2e4268; invalidating user cache
2020-05-08T21:59:16.541+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.541+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.631+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 3), t: 43 }
2020-05-08T21:59:16.895+0000 I  NETWORK  [conn233] end connection 172.31.0.221:53084 (61 connections now open)
2020-05-08T21:59:16.895+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53264 #243 (62 connections now open)
2020-05-08T21:59:16.895+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53266 #244 (63 connections now open)
2020-05-08T21:59:16.896+0000 I  NETWORK  [conn243] received client metadata from 172.31.0.221:53264 conn243: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.896+0000 I  NETWORK  [conn244] received client metadata from 172.31.0.221:53266 conn244: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.897+0000 I  NETWORK  [conn243] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.897+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.397+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:17.897+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.897+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:17.898+0000 I  TXN      [conn243] transaction parameters:{ lsid: { id: UUID("b98c143d-dbb6-4062-ab95-e44f1d41cc3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975156, 3) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1001766, timeInactiveMicros:0, 1001ms
2020-05-08T21:59:17.898+0000 I  COMMAND  [conn243] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975156, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b98c143d-dbb6-4062-ab95-e44f1d41cc3d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1001ms
2020-05-08T21:59:18.794+0000 I  TXN      [conn243] transaction parameters:{ lsid: { id: UUID("b98c143d-dbb6-4062-ab95-e44f1d41cc3d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975157, 107) } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 108) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:882663, timeActiveMicros:887786, timeInactiveMicros:1044, 888ms
2020-05-08T21:59:18.794+0000 I  COMMAND  [conn243] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b98c143d-dbb6-4062-ab95-e44f1d41cc3d") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 882ms
2020-05-08T21:59:18.798+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.087+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.298+0000 I  NETWORK  [conn234] end connection 172.31.0.221:53164 (62 connections now open)
2020-05-08T21:59:19.299+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53336 #248 (63 connections now open)
2020-05-08T21:59:19.299+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53338 #249 (64 connections now open)
2020-05-08T21:59:19.299+0000 I  NETWORK  [conn248] received client metadata from 172.31.0.221:53336 conn248: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.299+0000 I  NETWORK  [conn249] received client metadata from 172.31.0.221:53338 conn249: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.386+0000 I  NETWORK  [conn238] end connection 172.31.0.221:53192 (63 connections now open)
2020-05-08T21:59:19.387+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53366 #251 (64 connections now open)
2020-05-08T21:59:19.387+0000 I  NETWORK  [conn251] received client metadata from 172.31.0.221:53366 conn251: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.388+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53368 #252 (65 connections now open)
2020-05-08T21:59:19.388+0000 I  NETWORK  [conn252] received client metadata from 172.31.0.221:53368 conn252: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.606+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.606+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.607+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.607+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.607+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:20.282+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:23.799+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53492 #254 (66 connections now open)
2020-05-08T21:59:23.799+0000 I  NETWORK  [conn254] received client metadata from 172.31.0.221:53492 conn254: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.305+0000 I  -        [conn248] operation was interrupted because a client disconnected
2020-05-08T21:59:24.305+0000 I  CONNPOOL [conn248] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T21:59:24.305+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53506 #255 (67 connections now open)
2020-05-08T21:59:24.306+0000 I  TXN      [conn248] transaction parameters:{ lsid: { id: UUID("5d82efed-7d6f-4e98-8cac-83bf940d4e8a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 19) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005898, timeInactiveMicros:0, 5005ms
2020-05-08T21:59:24.306+0000 I  NETWORK  [conn255] received client metadata from 172.31.0.221:53506 conn255: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.306+0000 I  COMMAND  [conn248] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 743 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5d82efed-7d6f-4e98-8cac-83bf940d4e8a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T21:59:24.306+0000 I  NETWORK  [conn248] end connection 172.31.0.221:53336 (66 connections now open)
2020-05-08T21:59:24.393+0000 I  -        [conn251] operation was interrupted because a client disconnected
2020-05-08T21:59:24.393+0000 I  CONNPOOL [conn251] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:24.393+0000 I  TXN      [conn251] transaction parameters:{ lsid: { id: UUID("982e05b2-e817-4a1e-9447-f7cd6b5b4e5f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975158, 19) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004889, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:24.393+0000 I  COMMAND  [conn251] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 742 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975158, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("982e05b2-e817-4a1e-9447-f7cd6b5b4e5f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:24.393+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53516 #256 (67 connections now open)
2020-05-08T21:59:24.394+0000 I  NETWORK  [conn251] end connection 172.31.0.221:53366 (66 connections now open)
2020-05-08T21:59:24.394+0000 I  NETWORK  [conn256] received client metadata from 172.31.0.221:53516 conn256: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.433+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:24.434+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.434+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.471+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:24.909+0000 I  NETWORK  [conn255] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:24.910+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:24.910+0000 I  NETWORK  [conn256] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:24.910+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.409+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.909+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:26.409+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.409+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.410+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975165, 2), t: 47 }
2020-05-08T21:59:26.410+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:26.410+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.411+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.411+0000 I  COMMAND  [conn256] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("982e05b2-e817-4a1e-9447-f7cd6b5b4e5f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2016ms
2020-05-08T21:59:26.411+0000 I  COMMAND  [conn255] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975158, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5d82efed-7d6f-4e98-8cac-83bf940d4e8a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2104ms
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn252] end connection 172.31.0.221:53368 (65 connections now open)
2020-05-08T21:59:26.423+0000 I  NETWORK  [conn249] end connection 172.31.0.221:53338 (64 connections now open)
2020-05-08T21:59:26.423+0000 I  NETWORK  [conn244] end connection 172.31.0.221:53266 (63 connections now open)
2020-05-08T21:59:26.428+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53540 #257 (64 connections now open)
2020-05-08T21:59:26.428+0000 I  NETWORK  [conn257] end connection 172.31.0.221:53540 (63 connections now open)
2020-05-08T21:59:26.916+0000 I  COMMAND  [conn255] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975166, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5d82efed-7d6f-4e98-8cac-83bf940d4e8a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 504ms
2020-05-08T21:59:26.917+0000 I  NETWORK  [conn255] end connection 172.31.0.221:53506 (62 connections now open)
2020-05-08T21:59:26.917+0000 I  COMMAND  [conn256] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975166, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("982e05b2-e817-4a1e-9447-f7cd6b5b4e5f") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 506ms
2020-05-08T21:59:26.918+0000 I  NETWORK  [conn256] end connection 172.31.0.221:53516 (61 connections now open)
2020-05-08T21:59:27.012+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:59:30.159+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
