2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.225+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.228+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.228+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.229+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.229+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.229+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.229+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.229+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-6-164:27017:1588975035:1078644234032991027 (sleeping for 30000ms)
2020-05-08T21:57:15.232+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.232+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.232+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.240+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 12), t: 1 }
2020-05-08T21:57:15.421+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.423+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.423+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.424+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("a41ad862-b6a1-4ebe-b88e-82fa1d59ea9c"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.425+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.425+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.425+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.425+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.425+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.446+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46724 #9 (1 connection now open)
2020-05-08T21:57:16.446+0000 I  NETWORK  [conn9] received client metadata from 172.31.0.221:46724 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.453+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:16.507+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46728 #11 (2 connections now open)
2020-05-08T21:57:16.507+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:46728 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.887+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46750 #12 (3 connections now open)
2020-05-08T21:57:16.887+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:46750 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.933+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46768 #13 (4 connections now open)
2020-05-08T21:57:16.933+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:46768 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.956+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46786 #14 (5 connections now open)
2020-05-08T21:57:16.956+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:46786 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.147+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46806 #15 (6 connections now open)
2020-05-08T21:57:17.148+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:46806 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.303+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46828 #16 (7 connections now open)
2020-05-08T21:57:17.303+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:46828 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.304+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46838 #17 (8 connections now open)
2020-05-08T21:57:17.305+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:46838 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46860 #18 (9 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:46860 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.455+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46894 #19 (10 connections now open)
2020-05-08T21:57:17.455+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:46894 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.456+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46898 #20 (11 connections now open)
2020-05-08T21:57:17.456+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:46898 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.705+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46910 #21 (12 connections now open)
2020-05-08T21:57:17.705+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:46910 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.781+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46926 #22 (13 connections now open)
2020-05-08T21:57:17.781+0000 I  NETWORK  [conn22] received client metadata from 172.31.0.221:46926 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.829+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46948 #23 (14 connections now open)
2020-05-08T21:57:17.830+0000 I  NETWORK  [conn23] received client metadata from 172.31.0.221:46948 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.866+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46958 #24 (15 connections now open)
2020-05-08T21:57:18.866+0000 I  NETWORK  [conn24] received client metadata from 172.31.0.221:46958 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.893+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46974 #25 (16 connections now open)
2020-05-08T21:57:18.893+0000 I  NETWORK  [conn25] received client metadata from 172.31.0.221:46974 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.511+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:46990 #26 (17 connections now open)
2020-05-08T21:57:19.512+0000 I  NETWORK  [conn26] received client metadata from 172.31.0.221:46990 conn26: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.561+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47002 #27 (18 connections now open)
2020-05-08T21:57:19.561+0000 I  NETWORK  [conn27] received client metadata from 172.31.0.221:47002 conn27: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.854+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47028 #28 (19 connections now open)
2020-05-08T21:57:19.854+0000 I  NETWORK  [conn28] received client metadata from 172.31.0.221:47028 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.909+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47030 #29 (20 connections now open)
2020-05-08T21:57:19.909+0000 I  NETWORK  [conn29] received client metadata from 172.31.0.221:47030 conn29: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.996+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47034 #30 (21 connections now open)
2020-05-08T21:57:19.996+0000 I  NETWORK  [conn30] received client metadata from 172.31.0.221:47034 conn30: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.115+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47048 #31 (22 connections now open)
2020-05-08T21:57:20.115+0000 I  NETWORK  [conn31] received client metadata from 172.31.0.221:47048 conn31: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.191+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47060 #32 (23 connections now open)
2020-05-08T21:57:20.191+0000 I  NETWORK  [conn32] received client metadata from 172.31.0.221:47060 conn32: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.503+0000 I  COMMAND  [conn19] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("077c4206-d367-4178-b5ec-1e3ec1734df7") } } numYields:0 reslen:163 protocol:op_msg 3044ms
2020-05-08T21:57:20.504+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 0 ms
2020-05-08T21:57:20.505+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.505+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.507+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.507+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.508+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.508+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:20.534+0000 I  NETWORK  [conn19] end connection 172.31.0.221:46894 (22 connections now open)
2020-05-08T21:57:20.534+0000 I  NETWORK  [conn20] end connection 172.31.0.221:46898 (21 connections now open)
2020-05-08T21:57:20.956+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47080 #39 (22 connections now open)
2020-05-08T21:57:20.956+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:47080 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47086 #40 (23 connections now open)
2020-05-08T21:57:21.342+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:47086 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.542+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47100 #41 (24 connections now open)
2020-05-08T21:57:21.542+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:47100 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.785+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47122 #42 (25 connections now open)
2020-05-08T21:57:21.786+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:47122 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.056+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47162 #43 (26 connections now open)
2020-05-08T21:57:22.056+0000 I  NETWORK  [conn43] received client metadata from 172.31.0.221:47162 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47170 #44 (27 connections now open)
2020-05-08T21:57:22.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47172 #45 (28 connections now open)
2020-05-08T21:57:22.057+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:47170 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.057+0000 I  NETWORK  [conn45] received client metadata from 172.31.0.221:47172 conn45: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47178 #46 (29 connections now open)
2020-05-08T21:57:22.058+0000 I  NETWORK  [conn46] received client metadata from 172.31.0.221:47178 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47180 #47 (30 connections now open)
2020-05-08T21:57:22.058+0000 I  NETWORK  [conn47] received client metadata from 172.31.0.221:47180 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.061+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47202 #48 (31 connections now open)
2020-05-08T21:57:22.061+0000 I  NETWORK  [conn48] received client metadata from 172.31.0.221:47202 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.071+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.322+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 14) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:216849, timeActiveMicros:227176, timeInactiveMicros:496, 227ms
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95") }, txnNumber: 1, autocommit: false } numYields:0 reslen:183 protocol:op_msg 216ms
2020-05-08T21:57:22.324+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("64cad716-75ca-4f4d-ab23-4756dd41399d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975040, 17) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:244242, timeActiveMicros:253509, timeInactiveMicros:942, 254ms
2020-05-08T21:57:22.324+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("64cad716-75ca-4f4d-ab23-4756dd41399d") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 244ms
2020-05-08T21:57:22.326+0000 I  COMMAND  [conn46] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158") }, txnNumber: 2, autocommit: false } numYields:0 reslen:351 protocol:op_msg 219ms
2020-05-08T21:57:22.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.516+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47320 #55 (32 connections now open)
2020-05-08T21:57:22.519+0000 I  NETWORK  [conn55] received client metadata from 172.31.0.221:47320 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.133+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47370 #61 (33 connections now open)
2020-05-08T21:57:23.133+0000 I  NETWORK  [conn61] received client metadata from 172.31.0.221:47370 conn61: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.365+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 329), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95") }, txnNumber: 9, autocommit: false } numYields:0 reslen:320 protocol:op_msg 854ms
2020-05-08T21:57:23.370+0000 I  COMMAND  [conn46] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 351), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158") }, txnNumber: 12, autocommit: false } numYields:0 reslen:352 protocol:op_msg 837ms
2020-05-08T21:57:23.420+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47384 #63 (34 connections now open)
2020-05-08T21:57:23.420+0000 I  NETWORK  [conn63] received client metadata from 172.31.0.221:47384 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.751+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47422 #64 (35 connections now open)
2020-05-08T21:57:23.751+0000 I  NETWORK  [conn64] received client metadata from 172.31.0.221:47422 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.774+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95") }, txnNumber: 25, autocommit: false } numYields:0 reslen:321 protocol:op_msg 216ms
2020-05-08T21:57:24.471+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47464 #65 (36 connections now open)
2020-05-08T21:57:24.471+0000 I  NETWORK  [conn65] received client metadata from 172.31.0.221:47464 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.122+0000 I  COMMAND  [conn43] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975044, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95") }, txnNumber: 85, autocommit: false } numYields:0 reslen:321 protocol:op_msg 851ms
2020-05-08T21:57:25.126+0000 I  TXN      [conn46] transaction parameters:{ lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 6) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:1752067, timeActiveMicros:1755555, timeInactiveMicros:854, 1756ms
2020-05-08T21:57:25.127+0000 I  COMMAND  [conn46] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158") }, txnNumber: 13, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1752ms
2020-05-08T21:57:25.199+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47512 #66 (37 connections now open)
2020-05-08T21:57:25.199+0000 I  NETWORK  [conn66] received client metadata from 172.31.0.221:47512 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.417+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47528 #67 (38 connections now open)
2020-05-08T21:57:25.418+0000 I  NETWORK  [conn67] received client metadata from 172.31.0.221:47528 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.503+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47554 #68 (39 connections now open)
2020-05-08T21:57:25.503+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:47554 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.543+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("64cad716-75ca-4f4d-ab23-4756dd41399d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 11, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 340) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 340) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:3015223, timeActiveMicros:3020826, timeInactiveMicros:1934, 3022ms
2020-05-08T21:57:25.543+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 348), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("64cad716-75ca-4f4d-ab23-4756dd41399d") }, txnNumber: 11, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3015ms
2020-05-08T21:57:25.544+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.548+0000 I  COMMAND  [conn46] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 14, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 420ms
2020-05-08T21:57:25.555+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 87, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 11) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 11) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:418569, timeInactiveMicros:0, 418ms
2020-05-08T21:57:25.556+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95") }, txnNumber: 87, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 418ms
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47570 #71 (40 connections now open)
2020-05-08T21:57:25.672+0000 I  NETWORK  [conn71] received client metadata from 172.31.0.221:47570 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.120+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47598 #72 (41 connections now open)
2020-05-08T21:57:26.121+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:47598 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.368+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47618 #73 (42 connections now open)
2020-05-08T21:57:26.369+0000 I  NETWORK  [conn73] received client metadata from 172.31.0.221:47618 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.462+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 95), t: 3 }
2020-05-08T21:57:26.945+0000 I  NETWORK  [conn45] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:26.946+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.950+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.446+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.946+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:28.446+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.446+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.447+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.447+0000 I  COMMAND  [conn46] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 668), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158") }, txnNumber: 35, autocommit: false } numYields:0 reslen:321 protocol:op_msg 2508ms
2020-05-08T21:57:28.448+0000 I  NETWORK  [conn46] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:28.459+0000 I  TXN      [conn45] transaction parameters:{ lsid: { id: UUID("64cad716-75ca-4f4d-ab23-4756dd41399d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 666) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:2512404, timeActiveMicros:2521552, timeInactiveMicros:1634, 2523ms
2020-05-08T21:57:28.465+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 101, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 634) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 634) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2547102, timeActiveMicros:2554399, timeInactiveMicros:1271, 2555ms
2020-05-08T21:57:30.111+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.448+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.820+0000 I  NETWORK  [conn48] end connection 172.31.0.221:47202 (41 connections now open)
2020-05-08T21:57:30.820+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47698 #78 (42 connections now open)
2020-05-08T21:57:30.821+0000 I  NETWORK  [conn78] received client metadata from 172.31.0.221:47698 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.821+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47700 #79 (43 connections now open)
2020-05-08T21:57:30.821+0000 I  NETWORK  [conn79] received client metadata from 172.31.0.221:47700 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.823+0000 I  NETWORK  [conn78] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:30.823+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.823+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:30.931+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 643), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9de0c4e0-55b4-4415-99bf-a71be4ebcc95") }, txnNumber: 101, autocommit: false } numYields:0 reslen:429 protocol:op_msg 5012ms
2020-05-08T21:57:30.931+0000 I  NETWORK  [conn43] end connection 172.31.0.221:47162 (42 connections now open)
2020-05-08T21:57:30.932+0000 I  NETWORK  [conn47] end connection 172.31.0.221:47180 (41 connections now open)
2020-05-08T21:57:30.933+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47772 #80 (42 connections now open)
2020-05-08T21:57:30.933+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47774 #81 (43 connections now open)
2020-05-08T21:57:30.933+0000 I  NETWORK  [conn80] received client metadata from 172.31.0.221:47772 conn80: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.933+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:47774 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.934+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.936+0000 I  NETWORK  [conn44] end connection 172.31.0.221:47170 (42 connections now open)
2020-05-08T21:57:30.936+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47778 #82 (43 connections now open)
2020-05-08T21:57:30.937+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:47778 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.937+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47780 #83 (44 connections now open)
2020-05-08T21:57:30.937+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:47780 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.948+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.959+0000 I  COMMAND  [conn45] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 679), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("64cad716-75ca-4f4d-ab23-4756dd41399d") }, txnNumber: 28, autocommit: false } numYields:0 reslen:397 protocol:op_msg 5012ms
2020-05-08T21:57:30.959+0000 I  NETWORK  [conn45] end connection 172.31.0.221:47172 (43 connections now open)
2020-05-08T21:57:31.448+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.448+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.448+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.994+0000 I  COMMAND  [conn46] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 61 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975047, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("33c55da3-9cbe-4b38-b842-3bd58c4e2158") }, txnNumber: 36, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975047, 2) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 3546ms
2020-05-08T21:57:31.994+0000 I  NETWORK  [conn46] end connection 172.31.0.221:47178 (42 connections now open)
2020-05-08T21:57:31.997+0000 I  TXN      [conn80] transaction parameters:{ lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1062848, timeInactiveMicros:0, 1062ms
2020-05-08T21:57:31.997+0000 I  COMMAND  [conn80] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1062ms
2020-05-08T21:57:32.039+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:32.962+0000 I  NETWORK  [conn80] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:32.962+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:32.964+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:32.965+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.962+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:34.462+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.462+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.463+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:34.463+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:34.464+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:34.464+0000 I  SHARDING [conn78] Received reply from shard ec2-3-82-35-209.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:34.465+0000 I  TXN      [conn78] transaction parameters:{ lsid: { id: UUID("58bd45cb-808b-4c2e-9dab-314f24ef388f"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 12) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3642897, timeInactiveMicros:0, 3642ms
2020-05-08T21:57:34.465+0000 I  COMMAND  [conn78] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 58 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58bd45cb-808b-4c2e-9dab-314f24ef388f") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 58bd45cb-808b-4c2e-9dab-314f24ef388f:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975048, 12) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 3643ms
2020-05-08T21:57:34.465+0000 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 2) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3527363, timeInactiveMicros:0, 3527ms
2020-05-08T21:57:34.466+0000 I  COMMAND  [conn82] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 65 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975050, 2) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 3527ms
2020-05-08T21:57:34.471+0000 I  TXN      [conn80] transaction parameters:{ lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975052, 26) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:2429907, timeActiveMicros:2432323, timeInactiveMicros:493, 2432ms
2020-05-08T21:57:34.471+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.471+0000 I  NETWORK  [conn80] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:34.472+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.472+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.475+0000 I  COMMAND  [conn80] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975052, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77") }, txnNumber: 4, autocommit: false } numYields:0 reslen:396 protocol:op_msg 2434ms
2020-05-08T21:57:34.963+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:34.963+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:35.058+0000 I  TXN      [conn80] transaction parameters:{ lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 22, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 859) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:214682, timeActiveMicros:224030, timeInactiveMicros:2962, 226ms
2020-05-08T21:57:35.058+0000 I  COMMAND  [conn80] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 869), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77") }, txnNumber: 22, autocommit: false } numYields:0 reslen:183 protocol:op_msg 214ms
2020-05-08T21:57:35.058+0000 I  COMMAND  [conn78] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 875), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58bd45cb-808b-4c2e-9dab-314f24ef388f") }, txnNumber: 21, autocommit: false } numYields:0 reslen:321 protocol:op_msg 213ms
2020-05-08T21:57:35.059+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 873), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9") }, txnNumber: 16, autocommit: false } numYields:0 reslen:321 protocol:op_msg 214ms
2020-05-08T21:57:35.114+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:35.815+0000 I  NETWORK  [conn82] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:35.817+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.159+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47912 #90 (43 connections now open)
2020-05-08T21:57:36.160+0000 I  NETWORK  [conn90] received client metadata from 172.31.0.221:47912 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.465+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:36.465+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:36.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.965+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.965+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:36.970+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 85), t: 6 }
2020-05-08T21:57:37.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.563+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:47974 #91 (44 connections now open)
2020-05-08T21:57:39.563+0000 I  NETWORK  [conn91] received client metadata from 172.31.0.221:47974 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:39.815+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.815+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.816+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.816+0000 I  SHARDING [conn80] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:39.816+0000 I  COMMAND  [conn80] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 423), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77") }, txnNumber: 38, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4440ms
2020-05-08T21:57:39.816+0000 I  COMMAND  [conn82] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 423), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9") }, txnNumber: 30, autocommit: false } numYields:0 reslen:352 protocol:op_msg 4441ms
2020-05-08T21:57:39.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:39.817+0000 I  COMMAND  [conn78] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 422), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58bd45cb-808b-4c2e-9dab-314f24ef388f") }, txnNumber: 33, autocommit: false } numYields:0 reslen:439 protocol:op_msg 4443ms
2020-05-08T21:57:39.817+0000 I  NETWORK  [conn82] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.818+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.818+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.056+0000 I  NETWORK  [conn78] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.056+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:40.348+0000 I  NETWORK  [conn83] end connection 172.31.0.221:47780 (43 connections now open)
2020-05-08T21:57:40.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48042 #92 (44 connections now open)
2020-05-08T21:57:40.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48044 #93 (45 connections now open)
2020-05-08T21:57:40.349+0000 I  NETWORK  [conn92] received client metadata from 172.31.0.221:48042 conn92: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.349+0000 I  NETWORK  [conn93] received client metadata from 172.31.0.221:48044 conn93: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.350+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.368+0000 I  NETWORK  [conn81] end connection 172.31.0.221:47774 (44 connections now open)
2020-05-08T21:57:40.369+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48074 #94 (45 connections now open)
2020-05-08T21:57:40.369+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48076 #95 (46 connections now open)
2020-05-08T21:57:40.369+0000 I  NETWORK  [conn94] received client metadata from 172.31.0.221:48074 conn94: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.370+0000 I  NETWORK  [conn95] received client metadata from 172.31.0.221:48076 conn95: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.371+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.375+0000 I  NETWORK  [conn79] end connection 172.31.0.221:47700 (45 connections now open)
2020-05-08T21:57:40.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48082 #96 (46 connections now open)
2020-05-08T21:57:40.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48084 #97 (47 connections now open)
2020-05-08T21:57:40.376+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:48084 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.376+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:48082 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.537+0000 I  NETWORK  [conn82] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9:32 stopped due to: operation was interrupted
2020-05-08T21:57:41.538+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.538+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.538+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.538+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.541+0000 I  NETWORK  [conn96] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.542+0000 I  TXN      [conn96] transaction parameters:{ lsid: { id: UUID("1b7d201b-f463-4116-8023-c711490a41b9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1164954, timeInactiveMicros:0, 1164ms
2020-05-08T21:57:41.542+0000 I  COMMAND  [conn96] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b7d201b-f463-4116-8023-c711490a41b9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1165ms
2020-05-08T21:57:41.815+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.815+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.815+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.816+0000 I  COMMAND  [conn80] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7290829-866c-4995-987c-7242a87a3b77") }, txnNumber: 38, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1999ms
2020-05-08T21:57:41.816+0000 I  NETWORK  [conn80] end connection 172.31.0.221:47772 (46 connections now open)
2020-05-08T21:57:41.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:41.816+0000 I  COMMAND  [conn78] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("58bd45cb-808b-4c2e-9dab-314f24ef388f") }, txnNumber: 33, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1998ms
2020-05-08T21:57:41.817+0000 I  NETWORK  [conn78] end connection 172.31.0.221:47698 (45 connections now open)
2020-05-08T21:57:42.061+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b70df57d-2355-4827-b1aa-5d7e57c27449") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1690ms
2020-05-08T21:57:42.061+0000 I  COMMAND  [conn93] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 135 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8c5df9b7-189c-401f-b1a3-90397537628e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1711ms
2020-05-08T21:57:42.067+0000 I  TXN      [conn93] transaction parameters:{ lsid: { id: UUID("8c5df9b7-189c-401f-b1a3-90397537628e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1716510, timeInactiveMicros:363, 1716ms
2020-05-08T21:57:42.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:42.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:42.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.316+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.816+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.816+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.817+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.213+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.706+0000 I  NETWORK  [conn93] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:44.707+0000 I  TXN      [conn82] transaction parameters:{ lsid: { id: UUID("d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975059, 53) } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 53) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:4878343, timeActiveMicros:4880185, timeInactiveMicros:944, 4881ms
2020-05-08T21:57:44.707+0000 I  COMMAND  [conn82] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 59), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d8b94bb2-2ca9-4db2-99ac-2c41b45b66a9") }, txnNumber: 32, autocommit: false } numYields:0 reslen:311 protocol:op_msg 4878ms
2020-05-08T21:57:44.707+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.707+0000 I  NETWORK  [conn82] end connection 172.31.0.221:47778 (44 connections now open)
2020-05-08T21:57:45.207+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.266+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48200 #106 (45 connections now open)
2020-05-08T21:57:45.266+0000 I  NETWORK  [conn106] received client metadata from 172.31.0.221:48200 conn106: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.349+0000 I  NETWORK  [conn92] end connection 172.31.0.221:48042 (44 connections now open)
2020-05-08T21:57:45.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48234 #107 (45 connections now open)
2020-05-08T21:57:45.349+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48236 #108 (46 connections now open)
2020-05-08T21:57:45.349+0000 I  NETWORK  [conn107] received client metadata from 172.31.0.221:48234 conn107: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.350+0000 I  NETWORK  [conn108] received client metadata from 172.31.0.221:48236 conn108: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.376+0000 I  NETWORK  [conn97] end connection 172.31.0.221:48084 (45 connections now open)
2020-05-08T21:57:45.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48262 #109 (46 connections now open)
2020-05-08T21:57:45.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48264 #110 (47 connections now open)
2020-05-08T21:57:45.376+0000 I  NETWORK  [conn109] received client metadata from 172.31.0.221:48262 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.377+0000 I  NETWORK  [conn110] received client metadata from 172.31.0.221:48264 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.378+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.378+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.378+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.379+0000 I  COMMAND  [conn96] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975061, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1b7d201b-f463-4116-8023-c711490a41b9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3836ms
2020-05-08T21:57:45.379+0000 I  NETWORK  [conn96] end connection 172.31.0.221:48082 (46 connections now open)
2020-05-08T21:57:45.713+0000 I  NETWORK  [replSetDistLockPinger] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.714+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:45.802+0000 I  NETWORK  [conn107] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:45.803+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.303+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.424+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:57:46.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:46.802+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.062+0000 I  NETWORK  [conn95] end connection 172.31.0.221:48076 (45 connections now open)
2020-05-08T21:57:47.063+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48282 #112 (46 connections now open)
2020-05-08T21:57:47.063+0000 I  NETWORK  [conn112] received client metadata from 172.31.0.221:48282 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.063+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48284 #113 (47 connections now open)
2020-05-08T21:57:47.064+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:48284 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:47.065+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.097+0000 I  -        [conn93] operation was interrupted because a client disconnected
2020-05-08T21:57:47.097+0000 I  CONNPOOL [conn93] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:57:47.097+0000 I  TXN      [conn93] transaction parameters:{ lsid: { id: UUID("8c5df9b7-189c-401f-b1a3-90397537628e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975062, 23) } }, globalReadTimestamp:{ ts: Timestamp(1588975062, 23) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5007213, timeInactiveMicros:533, 5007ms
2020-05-08T21:57:47.097+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.098+0000 I  COMMAND  [conn93] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 138 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975062, 24), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8c5df9b7-189c-401f-b1a3-90397537628e") }, txnNumber: 3, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:57:47.098+0000 I  NETWORK  [conn93] end connection 172.31.0.221:48044 (46 connections now open)
2020-05-08T21:57:47.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.302+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.517+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.802+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.302+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.302+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.303+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.303+0000 I  COMMAND  [conn107] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e4af6bc-8eb0-4c4e-b24b-567712a27eeb") }, txnNumber: 1, autocommit: false } numYields:0 reslen:469 protocol:op_msg 2949ms
2020-05-08T21:57:48.306+0000 I  TXN      [conn112] transaction parameters:{ lsid: { id: UUID("51ffb6e9-aaea-4248-8c93-e2005670317e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 14) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1241056, timeInactiveMicros:0, 1241ms
2020-05-08T21:57:48.306+0000 I  COMMAND  [conn112] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 144 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("51ffb6e9-aaea-4248-8c93-e2005670317e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 51ffb6e9-aaea-4248-8c93-e2005670317e:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975065, 14) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 1241ms
2020-05-08T21:57:48.327+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.713+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.713+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:50.321+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.377+0000 I  NETWORK  [conn109] end connection 172.31.0.221:48262 (45 connections now open)
2020-05-08T21:57:50.378+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48368 #117 (46 connections now open)
2020-05-08T21:57:50.378+0000 I  NETWORK  [conn117] received client metadata from 172.31.0.221:48368 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48370 #118 (47 connections now open)
2020-05-08T21:57:50.379+0000 I  NETWORK  [conn118] received client metadata from 172.31.0.221:48370 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.380+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:50.382+0000 I  NETWORK  [conn117] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:50.382+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.712+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48382 #120 (48 connections now open)
2020-05-08T21:57:50.713+0000 I  NETWORK  [conn120] received client metadata from 172.31.0.221:48382 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.853+0000 I  NETWORK  [conn110] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:50.854+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.882+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.013+0000 I  NETWORK  [conn112] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:51.014+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.014+0000 I  NETWORK  [conn107] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:51.014+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.077+0000 I  NETWORK  [conn94] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:51.078+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.587+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.696+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48412 #121 (49 connections now open)
2020-05-08T21:57:51.696+0000 I  NETWORK  [conn121] received client metadata from 172.31.0.221:48412 conn121: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:51.882+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.883+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.883+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.884+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.884+0000 I  TXN      [conn110] transaction parameters:{ lsid: { id: UUID("0fa7d61e-571d-49fd-bd85-628305ac7f31"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 4) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6506644, timeInactiveMicros:0, 6506ms
2020-05-08T21:57:51.884+0000 I  COMMAND  [conn110] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0fa7d61e-571d-49fd-bd85-628305ac7f31") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 6506ms
2020-05-08T21:57:51.885+0000 I  NETWORK  [conn110] end connection 172.31.0.221:48264 (48 connections now open)
2020-05-08T21:57:51.885+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.886+0000 I  COMMAND  [conn117] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 147 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 158), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672970c1-b7f9-42cf-82dc-36ed385e8363") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1505ms
2020-05-08T21:57:51.887+0000 I  TXN      [conn107] transaction parameters:{ lsid: { id: UUID("9e4af6bc-8eb0-4c4e-b24b-567712a27eeb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 39) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3559835, timeInactiveMicros:0, 3559ms
2020-05-08T21:57:51.887+0000 I  COMMAND  [conn107] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 148 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 39), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e4af6bc-8eb0-4c4e-b24b-567712a27eeb") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 9e4af6bc-8eb0-4c4e-b24b-567712a27eeb:3 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975068, 39) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 3559ms
2020-05-08T21:57:51.887+0000 I  TXN      [conn112] transaction parameters:{ lsid: { id: UUID("51ffb6e9-aaea-4248-8c93-e2005670317e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975068, 29) } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 29) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3571287, timeInactiveMicros:258, 3571ms
2020-05-08T21:57:51.887+0000 I  COMMAND  [conn112] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 141 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 29), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("51ffb6e9-aaea-4248-8c93-e2005670317e") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 51ffb6e9-aaea-4248-8c93-e2005670317e:2 was aborted on statement 1 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975068, 29) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:546 protocol:op_msg 3570ms
2020-05-08T21:57:51.890+0000 I  TXN      [conn117] transaction parameters:{ lsid: { id: UUID("672970c1-b7f9-42cf-82dc-36ed385e8363"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975070, 158) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1509170, timeInactiveMicros:745, 1509ms
2020-05-08T21:57:51.893+0000 I  COMMAND  [conn94] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975061, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b70df57d-2355-4827-b1aa-5d7e57c27449") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 9830ms
2020-05-08T21:57:51.893+0000 I  NETWORK  [conn94] end connection 172.31.0.221:48074 (47 connections now open)
2020-05-08T21:57:52.064+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48414 #123 (48 connections now open)
2020-05-08T21:57:52.064+0000 I  NETWORK  [conn113] end connection 172.31.0.221:48284 (47 connections now open)
2020-05-08T21:57:52.066+0000 I  NETWORK  [conn112] end connection 172.31.0.221:48282 (46 connections now open)
2020-05-08T21:57:52.066+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48416 #124 (47 connections now open)
2020-05-08T21:57:52.068+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:48416 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.070+0000 I  NETWORK  [conn123] received client metadata from 172.31.0.221:48414 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.070+0000 I  NETWORK  [conn123] end connection 172.31.0.221:48414 (46 connections now open)
2020-05-08T21:57:52.071+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48418 #125 (47 connections now open)
2020-05-08T21:57:52.073+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:48418 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.200+0000 I  SHARDING [conn124] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.225+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:52.385+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.385+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.900+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48450 #127 (48 connections now open)
2020-05-08T21:57:52.904+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:48450 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:53.715+0000 I  COMMAND  [conn124] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 646), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80") }, txnNumber: 56, autocommit: false } numYields:0 reslen:321 protocol:op_msg 221ms
2020-05-08T21:57:54.129+0000 I  COMMAND  [conn124] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 780), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80") }, txnNumber: 78, autocommit: false } numYields:0 reslen:321 protocol:op_msg 219ms
2020-05-08T21:57:54.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48514 #128 (49 connections now open)
2020-05-08T21:57:54.333+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:48514 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.400+0000 I  NETWORK  [conn117] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:54.749+0000 I  COMMAND  [conn124] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 247), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80") }, txnNumber: 121, autocommit: false } numYields:0 reslen:322 protocol:op_msg 217ms
2020-05-08T21:57:54.916+0000 I  SHARDING [conn124] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:55.798+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48622 #129 (50 connections now open)
2020-05-08T21:57:55.798+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:48622 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.159+0000 I  NETWORK  [conn107] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:56.160+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.163+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.659+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.791+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48664 #130 (51 connections now open)
2020-05-08T21:57:56.791+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:48664 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.159+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:57.632+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48736 #131 (52 connections now open)
2020-05-08T21:57:57.632+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:48736 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.659+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.659+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.660+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:57.660+0000 I  COMMAND  [conn124] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 94), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80") }, txnNumber: 165, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2506ms
2020-05-08T21:57:57.660+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:57.660+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:58.332+0000 I  NETWORK  [conn108] end connection 172.31.0.221:48236 (51 connections now open)
2020-05-08T21:57:58.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48758 #132 (52 connections now open)
2020-05-08T21:57:58.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48760 #133 (53 connections now open)
2020-05-08T21:57:58.333+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:48758 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.333+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:48760 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.367+0000 I  NETWORK  [conn118] end connection 172.31.0.221:48370 (52 connections now open)
2020-05-08T21:57:58.367+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48778 #134 (53 connections now open)
2020-05-08T21:57:58.367+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48780 #135 (54 connections now open)
2020-05-08T21:57:58.368+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:48778 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.368+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:48780 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.413+0000 I  -        [conn107] operation was interrupted because a client disconnected
2020-05-08T21:57:58.413+0000 I  CONNPOOL [conn107] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:57:58.414+0000 I  TXN      [conn107] transaction parameters:{ lsid: { id: UUID("9e4af6bc-8eb0-4c4e-b24b-567712a27eeb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 60, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 595) } }, globalReadTimestamp:{ ts: Timestamp(1588975073, 595) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004776, timeInactiveMicros:0, 5004ms
2020-05-08T21:57:58.414+0000 I  COMMAND  [conn107] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 260 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975073, 595), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("9e4af6bc-8eb0-4c4e-b24b-567712a27eeb") }, txnNumber: 60, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975073, 595) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:57:58.414+0000 I  NETWORK  [conn107] end connection 172.31.0.221:48234 (53 connections now open)
2020-05-08T21:57:58.612+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48846 #136 (54 connections now open)
2020-05-08T21:57:58.612+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:48846 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.787+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48854 #137 (55 connections now open)
2020-05-08T21:57:58.787+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:48854 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:59.400+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 2855 timed out, deadline was 2020-05-08T21:57:59.400+0000, op was RemoteCommand 2855 -- target:[ec2-34-207-119-213.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:57:59.400+0000 cmd:{ isMaster: 1 }
2020-05-08T21:57:59.400+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.400+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.400+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:57:59.866+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48876 #138 (56 connections now open)
2020-05-08T21:57:59.866+0000 I  NETWORK  [conn138] received client metadata from 172.31.0.221:48876 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.107+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:00.108+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:00.108+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:00.108+0000 I  COMMAND  [conn117] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 578), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("672970c1-b7f9-42cf-82dc-36ed385e8363") }, txnNumber: 52, autocommit: false } numYields:0 reslen:321 protocol:op_msg 6711ms
2020-05-08T21:58:00.109+0000 I  NETWORK  [conn117] end connection 172.31.0.221:48368 (55 connections now open)
2020-05-08T21:58:00.109+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.109+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.109+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.608+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.608+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.886+0000 I  NETWORK  [conn124] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.387+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.887+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.887+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.888+0000 I  TXN      [conn124] transaction parameters:{ lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 167, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975077, 22) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4210505, timeInactiveMicros:0, 4210ms
2020-05-08T21:58:01.888+0000 I  COMMAND  [conn124] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975077, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80") }, txnNumber: 167, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 4210ms
2020-05-08T21:58:01.889+0000 I  TXN      [conn132] transaction parameters:{ lsid: { id: UUID("ca9027af-8aec-492d-ba1c-8976d1d20c50"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975077, 22) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3555282, timeInactiveMicros:0, 3555ms
2020-05-08T21:58:01.889+0000 I  COMMAND  [conn132] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975077, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ca9027af-8aec-492d-ba1c-8976d1d20c50") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3555ms
2020-05-08T21:58:01.897+0000 I  NETWORK  [conn134] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.898+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.899+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.250+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:02.250+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:02.678+0000 I  NETWORK  [conn125] end connection 172.31.0.221:48418 (54 connections now open)
2020-05-08T21:58:02.679+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48980 #140 (55 connections now open)
2020-05-08T21:58:02.679+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48978 #141 (56 connections now open)
2020-05-08T21:58:02.679+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:48980 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:02.679+0000 I  NETWORK  [conn141] received client metadata from 172.31.0.221:48978 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:02.750+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:02.750+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.333+0000 I  NETWORK  [conn133] end connection 172.31.0.221:48760 (55 connections now open)
2020-05-08T21:58:03.334+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49014 #142 (56 connections now open)
2020-05-08T21:58:03.334+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49016 #143 (57 connections now open)
2020-05-08T21:58:03.334+0000 I  NETWORK  [conn142] received client metadata from 172.31.0.221:49014 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.334+0000 I  NETWORK  [conn143] received client metadata from 172.31.0.221:49016 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.367+0000 I  NETWORK  [conn135] end connection 172.31.0.221:48780 (56 connections now open)
2020-05-08T21:58:03.368+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49036 #144 (57 connections now open)
2020-05-08T21:58:03.368+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49034 #145 (58 connections now open)
2020-05-08T21:58:03.368+0000 I  NETWORK  [conn145] received client metadata from 172.31.0.221:49034 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.368+0000 I  NETWORK  [conn144] received client metadata from 172.31.0.221:49036 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.370+0000 I  NETWORK  [conn145] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:03.370+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.370+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.370+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.373+0000 I  -        [conn134] operation was interrupted because a client disconnected
2020-05-08T21:58:03.373+0000 I  TXN      [conn134] transaction parameters:{ lsid: { id: UUID("dcfdc9ca-8193-43b9-ac48-02a535532e14"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975077, 22) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004112, timeInactiveMicros:0, 5004ms
2020-05-08T21:58:03.373+0000 I  COMMAND  [conn134] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 264 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975077, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("dcfdc9ca-8193-43b9-ac48-02a535532e14") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:58:03.373+0000 I  NETWORK  [conn134] end connection 172.31.0.221:48778 (57 connections now open)
2020-05-08T21:58:03.505+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 279 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 136ms
2020-05-08T21:58:03.510+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 127) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:140275, timeInactiveMicros:370, 140ms
2020-05-08T21:58:04.063+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.119+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.387+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.887+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.887+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.888+0000 I  COMMAND  [conn124] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f32a7be0-8406-4ba3-aa2f-a703ee794f80") }, txnNumber: 167, autocommit: false } numYields:0 reslen:516 protocol:op_msg 2998ms
2020-05-08T21:58:04.888+0000 I  NETWORK  [conn124] end connection 172.31.0.221:48416 (56 connections now open)
2020-05-08T21:58:04.889+0000 I  COMMAND  [conn142] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1e398809-5194-4731-a73a-2a92718e03e7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:352 protocol:op_msg 1553ms
2020-05-08T21:58:04.889+0000 I  COMMAND  [conn132] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ca9027af-8aec-492d-ba1c-8976d1d20c50") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2996ms
2020-05-08T21:58:04.889+0000 I  NETWORK  [conn132] end connection 172.31.0.221:48758 (55 connections now open)
2020-05-08T21:58:05.941+0000 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 278 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5924d3ec-91d6-4ec0-89a2-7097e13e9155") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3260ms
2020-05-08T21:58:05.941+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 55), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce") }, txnNumber: 7, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 2365ms
2020-05-08T21:58:05.941+0000 I  COMMAND  [conn142] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975084, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1e398809-5194-4731-a73a-2a92718e03e7") }, txnNumber: 1, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 1052ms
2020-05-08T21:58:05.942+0000 I  NETWORK  [conn145] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.944+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.944+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.945+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.945+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.945+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 7, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975083, 53) } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 54) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:2370922, timeInactiveMicros:886, 2371ms
2020-05-08T21:58:05.945+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.954+0000 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("5924d3ec-91d6-4ec0-89a2-7097e13e9155"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 127) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3272942, timeInactiveMicros:1472, 3274ms
2020-05-08T21:58:05.967+0000 I  TXN      [conn142] transaction parameters:{ lsid: { id: UUID("1e398809-5194-4731-a73a-2a92718e03e7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 127) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:24253, timeActiveMicros:2630706, timeInactiveMicros:1325, 2632ms
2020-05-08T21:58:06.554+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.555+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.055+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.555+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.555+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.653+0000 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 278 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975085, 34), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5924d3ec-91d6-4ec0-89a2-7097e13e9155") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 1683ms
2020-05-08T21:58:07.654+0000 I  NETWORK  [conn141] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:07.655+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.679+0000 I  NETWORK  [conn140] end connection 172.31.0.221:48980 (54 connections now open)
2020-05-08T21:58:07.680+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49126 #147 (55 connections now open)
2020-05-08T21:58:07.680+0000 I  NETWORK  [conn147] received client metadata from 172.31.0.221:49126 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:07.680+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49128 #148 (56 connections now open)
2020-05-08T21:58:07.680+0000 I  NETWORK  [conn148] received client metadata from 172.31.0.221:49128 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:07.683+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.685+0000 I  COMMAND  [conn145] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce") }, txnNumber: 7, autocommit: false } numYields:0 reslen:426 protocol:op_msg 1738ms
2020-05-08T21:58:07.687+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:08.154+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:08.154+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:08.156+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 218), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce") }, txnNumber: 8, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 469ms
2020-05-08T21:58:08.156+0000 I  COMMAND  [conn147] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 218), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198") }, txnNumber: 1, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 473ms
2020-05-08T21:58:08.156+0000 I  TXN      [conn141] transaction parameters:{ lsid: { id: UUID("5924d3ec-91d6-4ec0-89a2-7097e13e9155"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 34) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:2186174, timeInactiveMicros:500, 2186ms
2020-05-08T21:58:08.156+0000 I  COMMAND  [conn141] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 278 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 212), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5924d3ec-91d6-4ec0-89a2-7097e13e9155") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: Given transaction number 2 does not match any in-progress transactions. The active transaction number is -1" errName:NoSuchTransaction errCode:251 reslen:437 protocol:op_msg 502ms
2020-05-08T21:58:08.156+0000 I  NETWORK  [conn141] end connection 172.31.0.221:48978 (55 connections now open)
2020-05-08T21:58:08.562+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.566+0000 I  NETWORK  [conn144] end connection 172.31.0.221:49036 (54 connections now open)
2020-05-08T21:58:08.567+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49208 #149 (55 connections now open)
2020-05-08T21:58:08.568+0000 I  NETWORK  [conn149] received client metadata from 172.31.0.221:49208 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.568+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49210 #150 (56 connections now open)
2020-05-08T21:58:08.569+0000 I  NETWORK  [conn150] received client metadata from 172.31.0.221:49210 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.934+0000 I  NETWORK  [conn147] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:08.935+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:08.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.061+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 8, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975087, 218) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1375230, timeInactiveMicros:805, 1376ms
2020-05-08T21:58:09.062+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975087, 236), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("79ec8e94-1bca-4c27-a141-bbd56301b2ce") }, txnNumber: 8, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 905ms
2020-05-08T21:58:09.062+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 290 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975088, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 492ms
2020-05-08T21:58:09.065+0000 I  NETWORK  [conn145] end connection 172.31.0.221:49034 (55 connections now open)
2020-05-08T21:58:09.068+0000 I  TXN      [conn149] transaction parameters:{ lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975088, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:496778, timeInactiveMicros:1574, 498ms
2020-05-08T21:58:09.273+0000 I  SHARDING [conn149] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.273+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 6, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 163ms
2020-05-08T21:58:09.435+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.935+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.935+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.936+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.936+0000 I  COMMAND  [conn142] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 212), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1e398809-5194-4731-a73a-2a92718e03e7") }, txnNumber: 174, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2539ms
2020-05-08T21:58:09.936+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.936+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:09.976+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49256 #151 (56 connections now open)
2020-05-08T21:58:09.976+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:49256 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.179+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975087, 212) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2022758, timeActiveMicros:2497323, timeInactiveMicros:626, 2497ms
2020-05-08T21:58:10.182+0000 I  NETWORK  [conn147] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:10.182+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.387+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.388+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.435+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.436+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.582+0000 I  NETWORK  [conn149] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:10.787+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:10.935+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.936+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:10.969+0000 I  NETWORK  [conn143] end connection 172.31.0.221:49016 (55 connections now open)
2020-05-08T21:58:10.970+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49300 #152 (56 connections now open)
2020-05-08T21:58:10.970+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49302 #153 (57 connections now open)
2020-05-08T21:58:10.970+0000 I  NETWORK  [conn152] received client metadata from 172.31.0.221:49300 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.970+0000 I  NETWORK  [conn153] received client metadata from 172.31.0.221:49302 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.971+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:11.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.435+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.435+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.436+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.436+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.436+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.436+0000 I  COMMAND  [conn142] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 199), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("1e398809-5194-4731-a73a-2a92718e03e7") }, txnNumber: 174, autocommit: false } numYields:0 reslen:516 protocol:op_msg 1499ms
2020-05-08T21:58:11.436+0000 I  COMMAND  [conn147] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 236), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198") }, txnNumber: 1, autocommit: false } numYields:0 reslen:494 protocol:op_msg 3280ms
2020-05-08T21:58:11.436+0000 I  NETWORK  [conn142] end connection 172.31.0.221:49014 (56 connections now open)
2020-05-08T21:58:11.437+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 3), t: 19 }
2020-05-08T21:58:11.443+0000 I  COMMAND  [conn153] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975090, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 472ms
2020-05-08T21:58:11.655+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.656+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.656+0000 I  COMMAND  [conn147] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 219ms
2020-05-08T21:58:11.657+0000 I  COMMAND  [conn149] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 199), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 36, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2074ms
2020-05-08T21:58:12.284+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49332 #155 (57 connections now open)
2020-05-08T21:58:12.285+0000 I  NETWORK  [conn155] received client metadata from 172.31.0.221:49332 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.363+0000 I  COMMAND  [conn153] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 292 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975091, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 917ms
2020-05-08T21:58:12.365+0000 I  COMMAND  [conn149] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 113), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 36, autocommit: false } numYields:0 reslen:396 protocol:op_msg 706ms
2020-05-08T21:58:12.366+0000 I  COMMAND  [conn147] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 114), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198") }, txnNumber: 2, autocommit: false } numYields:0 reslen:320 protocol:op_msg 705ms
2020-05-08T21:58:12.368+0000 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975091, 9) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:921587, timeInactiveMicros:341, 921ms
2020-05-08T21:58:12.456+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.458+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.734+0000 I  NETWORK  [conn147] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198:55 stopped due to: operation was interrupted
2020-05-08T21:58:13.735+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.806+0000 I  TXN      [conn149] transaction parameters:{ lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 90, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 490) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 491) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:416915, timeInactiveMicros:1562, 418ms
2020-05-08T21:58:13.806+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 499), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 90, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 413ms
2020-05-08T21:58:13.807+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:13.814+0000 I  COMMAND  [conn153] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 365 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 473), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e") }, txnNumber: 55, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 471) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:363 protocol:op_msg 436ms
2020-05-08T21:58:13.815+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.815+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.816+0000 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 55, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 471) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 475) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:438186, timeInactiveMicros:361, 438ms
2020-05-08T21:58:14.757+0000 I  NETWORK  [conn153] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:14.757+0000 I  TXN      [conn147] transaction parameters:{ lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 55, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 481) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 481) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:1372641, timeActiveMicros:1376064, timeInactiveMicros:1211, 1377ms
2020-05-08T21:58:14.757+0000 I  COMMAND  [conn147] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 487), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4b5f7ba2-dfc5-4eb7-ad30-d726ac1b4198") }, txnNumber: 55, autocommit: false } numYields:0 reslen:311 protocol:op_msg 1372ms
2020-05-08T21:58:14.758+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.758+0000 I  NETWORK  [conn149] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:14.759+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.759+0000 I  NETWORK  [conn147] end connection 172.31.0.221:49126 (56 connections now open)
2020-05-08T21:58:14.760+0000 I  NETWORK  [conn148] end connection 172.31.0.221:49128 (55 connections now open)
2020-05-08T21:58:14.760+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49384 #159 (56 connections now open)
2020-05-08T21:58:14.760+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49386 #160 (57 connections now open)
2020-05-08T21:58:14.761+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:49386 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:14.761+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:49384 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:14.762+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.172+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49400 #161 (58 connections now open)
2020-05-08T21:58:15.172+0000 I  NETWORK  [conn161] received client metadata from 172.31.0.221:49400 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.240+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:15.257+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.757+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.757+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.758+0000 I  COMMAND  [conn149] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 528), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 90, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1951ms
2020-05-08T21:58:15.758+0000 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 670), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e") }, txnNumber: 55, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1941ms
2020-05-08T21:58:16.765+0000 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975095, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e") }, txnNumber: 55, autocommit: false } numYields:0 reslen:397 protocol:op_msg 1006ms
2020-05-08T21:58:16.766+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975095, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 91, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975095, 82) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1007ms
2020-05-08T21:58:16.767+0000 I  NETWORK  [conn149] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.768+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.768+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.768+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.769+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.769+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.772+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("2dcaf104-f900-4c1f-8f43-3bc630b9fb90"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975094, 286) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2010239, timeInactiveMicros:0, 2010ms
2020-05-08T21:58:16.772+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975094, 286), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2dcaf104-f900-4c1f-8f43-3bc630b9fb90") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2010ms
2020-05-08T21:58:16.831+0000 I  NETWORK  [conn159] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:16.832+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:17.331+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.331+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:17.337+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 4, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 196), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2dcaf104-f900-4c1f-8f43-3bc630b9fb90") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 544ms
2020-05-08T21:58:17.366+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.366+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.366+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.367+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.659+0000 I  NETWORK  [conn159] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.660+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.661+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.666+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.866+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:18.160+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.346+0000 I  NETWORK  [conn152] end connection 172.31.0.221:49300 (57 connections now open)
2020-05-08T21:58:18.347+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49490 #162 (58 connections now open)
2020-05-08T21:58:18.347+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49492 #163 (59 connections now open)
2020-05-08T21:58:18.347+0000 I  NETWORK  [conn162] received client metadata from 172.31.0.221:49490 conn162: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.347+0000 I  NETWORK  [conn163] received client metadata from 172.31.0.221:49492 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.348+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.366+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.366+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:18.375+0000 I  NETWORK  [conn150] end connection 172.31.0.221:49210 (58 connections now open)
2020-05-08T21:58:18.377+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49510 #164 (59 connections now open)
2020-05-08T21:58:18.378+0000 I  NETWORK  [conn164] received client metadata from 172.31.0.221:49510 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49512 #165 (60 connections now open)
2020-05-08T21:58:18.379+0000 I  NETWORK  [conn165] received client metadata from 172.31.0.221:49512 conn165: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.380+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.660+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.160+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.355+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.355+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:19.357+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.357+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.371+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.660+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.661+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.662+0000 I  COMMAND  [conn164] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94f73290-3a75-4f26-8bbe-22bfb0188f3e") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 1281ms
2020-05-08T21:58:19.662+0000 I  TXN      [conn149] transaction parameters:{ lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 91, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975095, 82) } }, globalReadTimestamp:{ ts: Timestamp(1588975095, 203) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3902434, timeInactiveMicros:1036, 3903ms
2020-05-08T21:58:19.662+0000 I  COMMAND  [conn149] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 179), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d17bbdc3-dd93-4c71-b048-2abde4739875") }, txnNumber: 91, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2890ms
2020-05-08T21:58:19.662+0000 I  NETWORK  [conn149] end connection 172.31.0.221:49208 (59 connections now open)
2020-05-08T21:58:19.857+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.857+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.448+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.177+0000 I  NETWORK  [conn164] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:21.178+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.183+0000 I  TXN      [conn153] transaction parameters:{ lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 56, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 80) } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 174) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:4408110, timeActiveMicros:4416121, timeInactiveMicros:775, 4416ms
2020-05-08T21:58:21.183+0000 I  NETWORK  [conn153] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:21.184+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:21.184+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:21.184+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.188+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.677+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.785+0000 I  COMMAND  [conn153] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 184), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ea822c0f-8408-4ab4-a72c-3a7340f1631e") }, txnNumber: 56, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5010ms
2020-05-08T21:58:21.785+0000 I  NETWORK  [conn153] end connection 172.31.0.221:49302 (58 connections now open)
2020-05-08T21:58:22.177+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.338+0000 I  NETWORK  [conn160] end connection 172.31.0.221:49386 (57 connections now open)
2020-05-08T21:58:22.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49612 #166 (58 connections now open)
2020-05-08T21:58:22.338+0000 I  NETWORK  [conn166] received client metadata from 172.31.0.221:49612 conn166: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49614 #167 (59 connections now open)
2020-05-08T21:58:22.338+0000 I  NETWORK  [conn167] received client metadata from 172.31.0.221:49614 conn167: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:22.340+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.341+0000 I  -        [conn159] operation was interrupted because a client disconnected
2020-05-08T21:58:22.341+0000 I  TXN      [conn159] transaction parameters:{ lsid: { id: UUID("2dcaf104-f900-4c1f-8f43-3bc630b9fb90"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003984, timeInactiveMicros:0, 5003ms
2020-05-08T21:58:22.341+0000 I  COMMAND  [conn159] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 342 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2dcaf104-f900-4c1f-8f43-3bc630b9fb90") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:58:22.341+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.341+0000 I  NETWORK  [conn159] end connection 172.31.0.221:49384 (58 connections now open)
2020-05-08T21:58:22.678+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.678+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.227+0000 I  NETWORK  [conn162] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.229+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.237+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.347+0000 I  NETWORK  [conn163] end connection 172.31.0.221:49492 (57 connections now open)
2020-05-08T21:58:23.347+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49636 #168 (58 connections now open)
2020-05-08T21:58:23.348+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49638 #169 (59 connections now open)
2020-05-08T21:58:23.348+0000 I  NETWORK  [conn168] received client metadata from 172.31.0.221:49636 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.348+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:49638 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.349+0000 I  NETWORK  [conn169] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.353+0000 I  -        [conn162] operation was interrupted because a client disconnected
2020-05-08T21:58:23.353+0000 I  TXN      [conn162] transaction parameters:{ lsid: { id: UUID("0a834719-08b5-40bd-8e92-350f064ca17d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005293, timeInactiveMicros:0, 5005ms
2020-05-08T21:58:23.353+0000 I  COMMAND  [conn162] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0a834719-08b5-40bd-8e92-350f064ca17d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:58:23.353+0000 I  NETWORK  [conn162] end connection 172.31.0.221:49490 (58 connections now open)
2020-05-08T21:58:23.354+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.663+0000 I  NETWORK  [conn165] end connection 172.31.0.221:49512 (57 connections now open)
2020-05-08T21:58:24.664+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49710 #170 (58 connections now open)
2020-05-08T21:58:24.664+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49712 #171 (59 connections now open)
2020-05-08T21:58:24.664+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:49710 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:24.664+0000 I  NETWORK  [conn171] received client metadata from 172.31.0.221:49712 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:24.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.227+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.727+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:26.227+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.227+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.228+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975106, 5), t: 26 }
2020-05-08T21:58:26.228+0000 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975101, 38) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3888858, timeInactiveMicros:0, 3888ms
2020-05-08T21:58:26.228+0000 I  COMMAND  [conn166] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975101, 38), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 3889ms
2020-05-08T21:58:26.474+0000 I  COMMAND  [conn164] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975099, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("94f73290-3a75-4f26-8bbe-22bfb0188f3e") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 6811ms
2020-05-08T21:58:26.474+0000 I  NETWORK  [conn164] end connection 172.31.0.221:49510 (58 connections now open)
2020-05-08T21:58:26.476+0000 I  COMMAND  [conn166] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 247ms
2020-05-08T21:58:26.683+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5389 timed out, deadline was 2020-05-08T21:58:26.683+0000, op was RemoteCommand 5389 -- target:[ec2-34-207-119-213.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:26.683+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:26.683+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5390 timed out, deadline was 2020-05-08T21:58:26.683+0000, op was RemoteCommand 5390 -- target:[ec2-35-172-222-251.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:26.683+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:26.683+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:26.683+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:26.683+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.683+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.849+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.849+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.851+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3502376, timeInactiveMicros:0, 3502ms
2020-05-08T21:58:26.851+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 3502ms
2020-05-08T21:58:26.852+0000 I  COMMAND  [conn166] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 380 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 3, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 363ms
2020-05-08T21:58:26.852+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2187416, timeInactiveMicros:0, 2187ms
2020-05-08T21:58:26.852+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2187ms
2020-05-08T21:58:26.870+0000 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 17) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:17481, timeActiveMicros:383466, timeInactiveMicros:2275, 385ms
2020-05-08T21:58:27.220+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.848+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 455), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 26, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 455) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 1492ms
2020-05-08T21:58:28.851+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 455) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 455) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1494745, timeInactiveMicros:396, 1495ms
2020-05-08T21:58:29.740+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 651), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 49, autocommit: false } numYields:0 reslen:352 protocol:op_msg 220ms
2020-05-08T21:58:29.862+0000 I  NETWORK  [conn169] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:29.863+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:29.863+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.245+0000 I  NETWORK  [conn169] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.245+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.656+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.657+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.657+0000 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 24, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 404) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 404) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3347751, timeInactiveMicros:264, 3348ms
2020-05-08T21:58:30.657+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 305), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 71, autocommit: false } numYields:0 reslen:352 protocol:op_msg 434ms
2020-05-08T21:58:30.658+0000 I  COMMAND  [conn166] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 431), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 24, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 3325ms
2020-05-08T21:58:30.688+0000 I  NETWORK  [conn170] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:30.688+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 439 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975107, 455), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 26, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 3330ms
2020-05-08T21:58:30.690+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 26, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 455) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, timeActiveMicros:3332003, timeInactiveMicros:672, 3332ms
2020-05-08T21:58:31.252+0000 I  COMMAND  [conn166] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 428), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 24, autocommit: false } numYields:0 reslen:397 protocol:op_msg 593ms
2020-05-08T21:58:31.252+0000 I  COMMAND  [conn170] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 441), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 26, autocommit: false } numYields:0 reslen:352 protocol:op_msg 562ms
2020-05-08T21:58:31.260+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 473), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 84, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 473) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 507ms
2020-05-08T21:58:31.267+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 84, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 473) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 473) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:513363, timeInactiveMicros:1520, 514ms
2020-05-08T21:58:31.394+0000 I  NETWORK  [conn170] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.395+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.396+0000 I  NETWORK  [conn169] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.396+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.401+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.895+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.395+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.395+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.396+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 89, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 166) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 166) }, numParticipants:2, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1016104, timeInactiveMicros:622, 1016ms
2020-05-08T21:58:32.396+0000 I  COMMAND  [conn170] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 156), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 31, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1023ms
2020-05-08T21:58:32.396+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 175), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 89, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:425 protocol:op_msg 1006ms
2020-05-08T21:58:33.388+0000 I  SHARDING [conn166] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.388+0000 I  TXN      [conn166] transaction parameters:{ lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 150) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1998278, timeActiveMicros:2021955, timeInactiveMicros:1029, 2022ms
2020-05-08T21:58:33.389+0000 I  COMMAND  [conn166] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 175), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 28, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1999ms
2020-05-08T21:58:33.391+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975112, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 32, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975112, 21) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 993ms
2020-05-08T21:58:33.392+0000 I  COMMAND  [conn169] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 21), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 89, autocommit: false } numYields:0 reslen:352 protocol:op_msg 994ms
2020-05-08T21:58:33.908+0000 I  NETWORK  [conn170] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.744+0000 I  NETWORK  [conn166] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:34.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.751+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.752+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.752+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:34.753+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 32, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975112, 21) } }, globalReadTimestamp:{ ts: Timestamp(1588975112, 21) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2355302, timeInactiveMicros:622, 2355ms
2020-05-08T21:58:34.753+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975113, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 32, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 1360ms
2020-05-08T21:58:34.753+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:34.753+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:34.756+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 90, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975113, 2) } }, globalReadTimestamp:{ ts: Timestamp(1588975113, 2) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1337811, timeActiveMicros:1362633, timeInactiveMicros:1384, 1364ms
2020-05-08T21:58:34.756+0000 I  COMMAND  [conn169] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 90, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1337ms
2020-05-08T21:58:34.759+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.130+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:35.166+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.205+0000 I  NETWORK  [conn168] end connection 172.31.0.221:49636 (57 connections now open)
2020-05-08T21:58:35.206+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49856 #176 (58 connections now open)
2020-05-08T21:58:35.206+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49858 #177 (59 connections now open)
2020-05-08T21:58:35.206+0000 I  NETWORK  [conn176] received client metadata from 172.31.0.221:49856 conn176: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.206+0000 I  NETWORK  [conn177] received client metadata from 172.31.0.221:49858 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:35.207+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.244+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.344+0000 I  NETWORK  [conn171] end connection 172.31.0.221:49712 (58 connections now open)
2020-05-08T21:58:36.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49916 #178 (59 connections now open)
2020-05-08T21:58:36.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49918 #179 (60 connections now open)
2020-05-08T21:58:36.345+0000 I  NETWORK  [conn178] received client metadata from 172.31.0.221:49916 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.345+0000 I  NETWORK  [conn179] received client metadata from 172.31.0.221:49918 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.346+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.365+0000 I  NETWORK  [conn167] end connection 172.31.0.221:49614 (59 connections now open)
2020-05-08T21:58:36.366+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49932 #180 (60 connections now open)
2020-05-08T21:58:36.366+0000 I  NETWORK  [conn180] received client metadata from 172.31.0.221:49932 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.366+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49934 #181 (61 connections now open)
2020-05-08T21:58:36.367+0000 I  NETWORK  [conn181] received client metadata from 172.31.0.221:49934 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.368+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.745+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.746+0000 I  COMMAND  [conn166] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ccf3af0f-9f45-4dbe-83df-68c7605dc62d") }, txnNumber: 29, autocommit: false } numYields:0 reslen:439 protocol:op_msg 3347ms
2020-05-08T21:58:36.746+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.746+0000 I  NETWORK  [conn166] end connection 172.31.0.221:49612 (60 connections now open)
2020-05-08T21:58:36.746+0000 I  COMMAND  [conn177] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 503 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975115, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a55489bd-14ee-41d4-b052-4910ef26a207") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:277 protocol:op_msg 1539ms
2020-05-08T21:58:36.746+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.747+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.757+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975115, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:410997, timeInactiveMicros:0, 410ms
2020-05-08T21:58:36.757+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 510 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975115, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975115, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 411ms
2020-05-08T21:58:36.759+0000 I  TXN      [conn181] transaction parameters:{ lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975115, 1) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:391640, timeInactiveMicros:0, 391ms
2020-05-08T21:58:36.759+0000 I  COMMAND  [conn181] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975115, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 072b15ab-faad-4885-a62e-cc2c7c7796cd:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975115, 1) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:590 protocol:op_msg 391ms
2020-05-08T21:58:36.968+0000 I  NETWORK  [conn169] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.968+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.007+0000 I  NETWORK  [conn170] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.008+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.039+0000 I  NETWORK  [conn178] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:37.040+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.201+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.201+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.468+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.468+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:37.469+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.469+0000 I  TXN      [conn169] transaction parameters:{ lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 91, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 9) } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 10) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2712080, timeInactiveMicros:508, 2712ms
2020-05-08T21:58:37.469+0000 I  COMMAND  [conn169] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7ea30ea6-51a8-4c4e-ae72-40a90f145207") }, txnNumber: 91, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7ea30ea6-51a8-4c4e-ae72-40a90f145207:91 was aborted on statement 2 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975114, 10) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:592 protocol:op_msg 2711ms
2020-05-08T21:58:37.469+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 6, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 99) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:641060, timeInactiveMicros:0, 641ms
2020-05-08T21:58:37.469+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 99), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353") }, txnNumber: 6, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 641ms
2020-05-08T21:58:37.469+0000 I  NETWORK  [conn169] end connection 172.31.0.221:49638 (59 connections now open)
2020-05-08T21:58:37.469+0000 I  COMMAND  [conn170] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975114, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("aedfbf52-2885-41a4-95c0-1b850fdae93c") }, txnNumber: 32, autocommit: false } numYields:0 reslen:428 protocol:op_msg 2303ms
2020-05-08T21:58:37.470+0000 I  NETWORK  [conn170] end connection 172.31.0.221:49710 (58 connections now open)
2020-05-08T21:58:37.577+0000 I  NETWORK  [conn178] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:37.578+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.860+0000 I  NETWORK  [conn181] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:37.860+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:37.861+0000 I  NETWORK  [conn177] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:37.861+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:37.968+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.246+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.246+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.360+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.360+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.361+0000 I  TXN      [conn181] transaction parameters:{ lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 81, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 632) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 632) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:511650, timeInactiveMicros:0, 511ms
2020-05-08T21:58:38.361+0000 I  COMMAND  [conn181] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 632), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd") }, txnNumber: 81, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 632) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:423 protocol:op_msg 511ms
2020-05-08T21:58:38.362+0000 I  COMMAND  [conn177] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 514 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 632), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a55489bd-14ee-41d4-b052-4910ef26a207") }, txnNumber: 79, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 632) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 512ms
2020-05-08T21:58:38.364+0000 I  TXN      [conn177] transaction parameters:{ lsid: { id: UUID("a55489bd-14ee-41d4-b052-4910ef26a207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 79, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 632) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 632) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:514481, timeInactiveMicros:579, 515ms
2020-05-08T21:58:38.400+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.400+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.401+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975117, 382), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353") }, txnNumber: 6, autocommit: false } numYields:0 reslen:514 protocol:op_msg 930ms
2020-05-08T21:58:38.514+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.515+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.516+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.517+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.517+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.519+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.746+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.859+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975118, 33), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353") }, txnNumber: 6, autocommit: false } numYields:0 reslen:396 protocol:op_msg 458ms
2020-05-08T21:58:38.872+0000 I  COMMAND  [conn181] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd") }, txnNumber: 83, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 22) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 492ms
2020-05-08T21:58:38.874+0000 I  TXN      [conn181] transaction parameters:{ lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 83, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 22) } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 22) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:494156, timeInactiveMicros:377, 494ms
2020-05-08T21:58:38.883+0000 I  COMMAND  [conn177] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 83, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a55489bd-14ee-41d4-b052-4910ef26a207") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 473ms
2020-05-08T21:58:39.246+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.246+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.357+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:40.543+0000 I  NETWORK  [conn177] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:40.544+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.546+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975119, 988), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353") }, txnNumber: 46, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 862ms
2020-05-08T21:58:40.554+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.044+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.544+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.544+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.713+0000 I  NETWORK  [conn181] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:41.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:41.771+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:41.772+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:41.774+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.050+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 46, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 991) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1501905, timeActiveMicros:2363935, timeInactiveMicros:609, 2364ms
2020-05-08T21:58:42.051+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.052+0000 I  NETWORK  [conn177] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:42.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:42.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:43.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.213+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.213+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.214+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.215+0000 I  COMMAND  [conn181] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975120, 346), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd") }, txnNumber: 240, autocommit: false } numYields:0 reslen:440 protocol:op_msg 3501ms
2020-05-08T21:58:44.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.684+0000 I  NETWORK  [conn179] end connection 172.31.0.221:49918 (57 connections now open)
2020-05-08T21:58:44.685+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50094 #184 (58 connections now open)
2020-05-08T21:58:44.685+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50096 #185 (59 connections now open)
2020-05-08T21:58:44.685+0000 I  NETWORK  [conn184] received client metadata from 172.31.0.221:50094 conn184: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:44.685+0000 I  NETWORK  [conn185] received client metadata from 172.31.0.221:50096 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:44.699+0000 I  NETWORK  [conn176] end connection 172.31.0.221:49856 (58 connections now open)
2020-05-08T21:58:44.699+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50098 #186 (59 connections now open)
2020-05-08T21:58:44.699+0000 I  NETWORK  [conn186] received client metadata from 172.31.0.221:50098 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:44.699+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50100 #187 (60 connections now open)
2020-05-08T21:58:44.700+0000 I  NETWORK  [conn187] received client metadata from 172.31.0.221:50100 conn187: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:44.701+0000 I  -        [conn177] operation was interrupted because a client disconnected
2020-05-08T21:58:44.701+0000 I  TXN      [conn177] transaction parameters:{ lsid: { id: UUID("a55489bd-14ee-41d4-b052-4910ef26a207"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 121, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 1012) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5002917, timeInactiveMicros:0, 5002ms
2020-05-08T21:58:44.701+0000 I  COMMAND  [conn177] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 565 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975119, 1012), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a55489bd-14ee-41d4-b052-4910ef26a207") }, txnNumber: 121, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:44.701+0000 I  NETWORK  [conn177] end connection 172.31.0.221:49858 (59 connections now open)
2020-05-08T21:58:44.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.560+0000 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975120, 265), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("997eb76e-fb9d-4a2d-8ac5-0ef3bfb5e353") }, txnNumber: 46, autocommit: false } numYields:0 reslen:495 protocol:op_msg 5011ms
2020-05-08T21:58:45.560+0000 I  NETWORK  [conn178] end connection 172.31.0.221:49916 (58 connections now open)
2020-05-08T21:58:45.771+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.271+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.424+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b96b7369da8ea76060 to 5eb5d5b80770106eff2e4268; invalidating user cache
2020-05-08T21:58:46.544+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 8490 timed out, deadline was 2020-05-08T21:58:46.544+0000, op was RemoteCommand 8490 -- target:[ec2-35-172-222-251.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:58:46.544+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:46.544+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:46.544+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.552+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.771+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.771+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.772+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.772+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 17), t: 33 }
2020-05-08T21:58:47.052+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.271+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.271+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.052+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.052+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.053+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.053+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 269), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("71948062-ba64-4169-ab01-badf087e9f16") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:233 protocol:op_msg 4367ms
2020-05-08T21:58:49.053+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.053+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:49.054+0000 I  NETWORK  [conn184] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMasterNoSlaveOk: not master and slaveOk=false
2020-05-08T21:58:49.054+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.054+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.308+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.309+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:49.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.326+0000 I  NETWORK  [conn180] end connection 172.31.0.221:49932 (57 connections now open)
2020-05-08T21:58:49.326+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50150 #190 (58 connections now open)
2020-05-08T21:58:49.326+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50152 #191 (59 connections now open)
2020-05-08T21:58:49.326+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:50150 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.326+0000 I  NETWORK  [conn191] received client metadata from 172.31.0.221:50152 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.328+0000 I  NETWORK  [conn190] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.328+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.328+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.329+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.553+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.700+0000 I  NETWORK  [conn187] end connection 172.31.0.221:50100 (58 connections now open)
2020-05-08T21:58:49.700+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50232 #192 (59 connections now open)
2020-05-08T21:58:49.701+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50234 #193 (60 connections now open)
2020-05-08T21:58:49.701+0000 I  NETWORK  [conn192] received client metadata from 172.31.0.221:50232 conn192: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.701+0000 I  NETWORK  [conn193] received client metadata from 172.31.0.221:50234 conn193: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:50.053+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.553+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.654+0000 I  COMMAND  [conn190] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 606 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c57e9892-63be-4bba-960f-b98873f18a8d") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1327ms
2020-05-08T21:58:50.661+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("c57e9892-63be-4bba-960f-b98873f18a8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1333174, timeInactiveMicros:757, 1333ms
2020-05-08T21:58:51.053+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.170+0000 I  NETWORK  [conn192] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:51.171+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:51.174+0000 I  NETWORK  [conn181] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:51.174+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.174+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.175+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.175+0000 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("a7d9e61f-24bb-4872-ae34-1b93427388d9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 2) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1473458, timeInactiveMicros:0, 1473ms
2020-05-08T21:58:51.175+0000 I  COMMAND  [conn192] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7d9e61f-24bb-4872-ae34-1b93427388d9") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1473ms
2020-05-08T21:58:51.178+0000 I  NETWORK  [conn184] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:51.199+0000 I  TXN      [conn186] transaction parameters:{ lsid: { id: UUID("082a8ded-04e0-46e0-8fe7-f610e66d57f7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 269) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6498243, timeInactiveMicros:0, 6498ms
2020-05-08T21:58:51.199+0000 I  COMMAND  [conn186] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 269), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("082a8ded-04e0-46e0-8fe7-f610e66d57f7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 6498ms
2020-05-08T21:58:51.199+0000 I  NETWORK  [conn186] end connection 172.31.0.221:50098 (59 connections now open)
2020-05-08T21:58:51.553+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.553+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.554+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.874+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 605 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 22), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("71948062-ba64-4169-ab01-badf087e9f16") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2818ms
2020-05-08T21:58:51.875+0000 I  COMMAND  [conn181] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 245, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975124, 269), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("072b15ab-faad-4885-a62e-cc2c7c7796cd") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 7550ms
2020-05-08T21:58:51.875+0000 I  NETWORK  [conn181] end connection 172.31.0.221:49934 (58 connections now open)
2020-05-08T21:58:51.876+0000 I  COMMAND  [conn192] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7d9e61f-24bb-4872-ae34-1b93427388d9") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 700ms
2020-05-08T21:58:51.879+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("71948062-ba64-4169-ab01-badf087e9f16"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 22) }, numParticipants:2, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:2822538, timeInactiveMicros:365, 2822ms
2020-05-08T21:58:51.880+0000 I  COMMAND  [conn190] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 606 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975130, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c57e9892-63be-4bba-960f-b98873f18a8d") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 15) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1208ms
2020-05-08T21:58:51.882+0000 I  TXN      [conn190] transaction parameters:{ lsid: { id: UUID("c57e9892-63be-4bba-960f-b98873f18a8d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975130, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588975130, 15) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1210550, timeInactiveMicros:599, 1211ms
2020-05-08T21:58:51.890+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:51.892+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:52.117+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.117+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.118+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.124+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.125+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.617+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:52.845+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:53.117+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.117+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.118+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.292+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:58:53.352+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:58:53.574+0000 I  NETWORK  [conn192] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:53.574+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.574+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.575+0000 I  COMMAND  [conn192] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 70), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7d9e61f-24bb-4872-ae34-1b93427388d9") }, txnNumber: 2, autocommit: false } numYields:0 reslen:320 protocol:op_msg 1688ms
2020-05-08T21:58:53.605+0000 I  TXN      [conn184] transaction parameters:{ lsid: { id: UUID("71948062-ba64-4169-ab01-badf087e9f16"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 80) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 80) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1712816, timeInactiveMicros:302, 1713ms
2020-05-08T21:58:53.605+0000 I  COMMAND  [conn184] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975131, 80), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("71948062-ba64-4169-ab01-badf087e9f16") }, txnNumber: 2, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1711ms
2020-05-08T21:58:53.926+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.926+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.931+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.941+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.941+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.942+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:54.056+0000 I  NETWORK  [conn185] end connection 172.31.0.221:50096 (57 connections now open)
2020-05-08T21:58:54.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50366 #198 (58 connections now open)
2020-05-08T21:58:54.057+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50368 #199 (59 connections now open)
2020-05-08T21:58:54.057+0000 I  NETWORK  [conn198] received client metadata from 172.31.0.221:50366 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.057+0000 I  NETWORK  [conn199] received client metadata from 172.31.0.221:50368 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.326+0000 I  NETWORK  [conn191] end connection 172.31.0.221:50152 (58 connections now open)
2020-05-08T21:58:54.327+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50386 #200 (59 connections now open)
2020-05-08T21:58:54.327+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50388 #201 (60 connections now open)
2020-05-08T21:58:54.327+0000 I  NETWORK  [conn200] received client metadata from 172.31.0.221:50386 conn200: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.327+0000 I  NETWORK  [conn201] received client metadata from 172.31.0.221:50388 conn201: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.426+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.426+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.427+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 2), t: 38 }
2020-05-08T21:58:54.444+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:54.701+0000 I  NETWORK  [conn193] end connection 172.31.0.221:50234 (59 connections now open)
2020-05-08T21:58:54.701+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50446 #203 (60 connections now open)
2020-05-08T21:58:54.701+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50448 #204 (61 connections now open)
2020-05-08T21:58:54.701+0000 I  NETWORK  [conn203] received client metadata from 172.31.0.221:50446 conn203: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.702+0000 I  NETWORK  [conn204] received client metadata from 172.31.0.221:50448 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:57.407+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:57.408+0000 I  NETWORK  [conn198] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:57.408+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.408+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.409+0000 I  TXN      [conn198] transaction parameters:{ lsid: { id: UUID("28351096-e7ac-469b-bfbd-41a66fe7adb8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3351272, timeInactiveMicros:0, 3351ms
2020-05-08T21:58:57.409+0000 I  COMMAND  [conn198] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28351096-e7ac-469b-bfbd-41a66fe7adb8") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:380 protocol:op_msg 3351ms
2020-05-08T21:58:57.760+0000 I  NETWORK  [conn200] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:58.019+0000 I  TXN      [conn192] transaction parameters:{ lsid: { id: UUID("a7d9e61f-24bb-4872-ae34-1b93427388d9"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975133, 15) } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4443314, timeInactiveMicros:0, 4443ms
2020-05-08T21:58:58.019+0000 I  COMMAND  [conn192] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a7d9e61f-24bb-4872-ae34-1b93427388d9") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975133, 15) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 4443ms
2020-05-08T21:58:58.019+0000 I  NETWORK  [conn192] end connection 172.31.0.221:50232 (60 connections now open)
2020-05-08T21:58:58.115+0000 I  NETWORK  [conn198] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:58.116+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.272+0000 I  NETWORK  [conn200] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:58.272+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:59.057+0000 I  NETWORK  [conn199] end connection 172.31.0.221:50368 (59 connections now open)
2020-05-08T21:58:59.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50658 #205 (60 connections now open)
2020-05-08T21:58:59.058+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50660 #206 (61 connections now open)
2020-05-08T21:58:59.058+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:50658 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.058+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:50660 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.115+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.115+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.116+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 6), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.116+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:59.116+0000 I  COMMAND  [conn198] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975137, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("28351096-e7ac-469b-bfbd-41a66fe7adb8") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1705ms
2020-05-08T21:58:59.116+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.116+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.117+0000 I  NETWORK  [conn198] end connection 172.31.0.221:50366 (60 connections now open)
2020-05-08T21:58:59.327+0000 I  NETWORK  [conn201] end connection 172.31.0.221:50388 (59 connections now open)
2020-05-08T21:58:59.328+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50680 #208 (60 connections now open)
2020-05-08T21:58:59.328+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:50680 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.328+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50682 #209 (61 connections now open)
2020-05-08T21:58:59.328+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:50682 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.329+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.702+0000 I  NETWORK  [conn204] end connection 172.31.0.221:50448 (60 connections now open)
2020-05-08T21:58:59.702+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50746 #211 (61 connections now open)
2020-05-08T21:58:59.702+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50748 #212 (62 connections now open)
2020-05-08T21:58:59.703+0000 I  NETWORK  [conn211] received client metadata from 172.31.0.221:50746 conn211: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.703+0000 I  NETWORK  [conn212] received client metadata from 172.31.0.221:50748 conn212: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.815+0000 I  NETWORK  [conn200] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:59.819+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:00.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:01.152+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:01.315+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:01.815+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:03.315+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:03.315+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:03.316+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975142, 1), t: 40 }
2020-05-08T21:59:03.316+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:03.316+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:03.316+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:03.428+0000 I  NETWORK  [conn200] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:03.428+0000 I  COMMAND  [conn200] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef04f5c4-4a03-42b3-aeeb-a4ea7bd37e05") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:316 protocol:op_msg 9100ms
2020-05-08T21:59:03.429+0000 I  NETWORK  [conn200] end connection 172.31.0.221:50386 (61 connections now open)
2020-05-08T21:59:03.816+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:04.058+0000 I  NETWORK  [conn206] end connection 172.31.0.221:50660 (60 connections now open)
2020-05-08T21:59:04.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50906 #217 (61 connections now open)
2020-05-08T21:59:04.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50908 #218 (62 connections now open)
2020-05-08T21:59:04.059+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:50906 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.059+0000 I  NETWORK  [conn218] received client metadata from 172.31.0.221:50908 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.060+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.328+0000 I  NETWORK  [conn209] end connection 172.31.0.221:50682 (61 connections now open)
2020-05-08T21:59:04.329+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50936 #222 (62 connections now open)
2020-05-08T21:59:04.329+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50938 #223 (63 connections now open)
2020-05-08T21:59:04.329+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:50936 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.329+0000 I  NETWORK  [conn223] received client metadata from 172.31.0.221:50938 conn223: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.333+0000 I  -        [conn208] operation was interrupted because a client disconnected
2020-05-08T21:59:04.333+0000 I  CONNPOOL [conn208] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:04.333+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 617 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eab87861-0e60-423e-8cb3-031d4f05f1e3") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:04.333+0000 I  NETWORK  [conn208] end connection 172.31.0.221:50680 (62 connections now open)
2020-05-08T21:59:04.703+0000 I  NETWORK  [conn211] end connection 172.31.0.221:50746 (61 connections now open)
2020-05-08T21:59:04.703+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50980 #225 (62 connections now open)
2020-05-08T21:59:04.703+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50982 #226 (63 connections now open)
2020-05-08T21:59:04.704+0000 I  NETWORK  [conn225] received client metadata from 172.31.0.221:50980 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.704+0000 I  NETWORK  [conn226] received client metadata from 172.31.0.221:50982 conn226: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.705+0000 I  -        [conn212] operation was interrupted because a client disconnected
2020-05-08T21:59:04.705+0000 I  CONNPOOL [conn212] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:04.705+0000 I  TXN      [conn212] transaction parameters:{ lsid: { id: UUID("3dd26bbe-c65d-4cab-b94e-a72c02211ebc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975139, 3) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001956, timeInactiveMicros:0, 5001ms
2020-05-08T21:59:04.705+0000 I  COMMAND  [conn212] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 615 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975139, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3dd26bbe-c65d-4cab-b94e-a72c02211ebc") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5002ms
2020-05-08T21:59:04.705+0000 I  NETWORK  [conn212] end connection 172.31.0.221:50748 (62 connections now open)
2020-05-08T21:59:04.888+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:59:06.785+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:06.785+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:06.789+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975142, 1), t: 40 }, now { ts: Timestamp(1588975146, 1), t: 41 }
2020-05-08T21:59:09.059+0000 I  NETWORK  [conn218] end connection 172.31.0.221:50908 (61 connections now open)
2020-05-08T21:59:09.060+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51062 #228 (62 connections now open)
2020-05-08T21:59:09.060+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51064 #229 (63 connections now open)
2020-05-08T21:59:09.060+0000 I  NETWORK  [conn228] received client metadata from 172.31.0.221:51062 conn228: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.060+0000 I  NETWORK  [conn229] received client metadata from 172.31.0.221:51064 conn229: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.061+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.065+0000 I  -        [conn217] operation was interrupted because a client disconnected
2020-05-08T21:59:09.065+0000 I  CONNPOOL [conn217] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:09.065+0000 I  COMMAND  [conn217] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 618 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975143, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e56ef644-17c8-4e4d-bb24-b11c7020e53d") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:09.065+0000 I  NETWORK  [conn217] end connection 172.31.0.221:50906 (62 connections now open)
2020-05-08T21:59:09.329+0000 I  NETWORK  [conn223] end connection 172.31.0.221:50938 (61 connections now open)
2020-05-08T21:59:09.329+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51070 #231 (62 connections now open)
2020-05-08T21:59:09.330+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51072 #232 (63 connections now open)
2020-05-08T21:59:09.330+0000 I  NETWORK  [conn231] received client metadata from 172.31.0.221:51070 conn231: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.330+0000 I  NETWORK  [conn232] received client metadata from 172.31.0.221:51072 conn232: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.333+0000 I  -        [conn222] operation was interrupted because a client disconnected
2020-05-08T21:59:09.333+0000 I  CONNPOOL [conn222] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:09.333+0000 I  COMMAND  [conn222] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 622 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975143, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("795f3a32-0bdb-4d83-bc7c-bea3493684ee") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:59:09.333+0000 I  NETWORK  [conn222] end connection 172.31.0.221:50936 (62 connections now open)
2020-05-08T21:59:09.704+0000 I  NETWORK  [conn226] end connection 172.31.0.221:50982 (61 connections now open)
2020-05-08T21:59:09.704+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51116 #234 (62 connections now open)
2020-05-08T21:59:09.704+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51118 #235 (63 connections now open)
2020-05-08T21:59:09.705+0000 I  NETWORK  [conn234] received client metadata from 172.31.0.221:51116 conn234: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.705+0000 I  NETWORK  [conn235] received client metadata from 172.31.0.221:51118 conn235: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.709+0000 I  -        [conn225] operation was interrupted because a client disconnected
2020-05-08T21:59:09.709+0000 I  CONNPOOL [conn225] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:09.709+0000 I  TXN      [conn225] transaction parameters:{ lsid: { id: UUID("d0e280a5-c536-424b-8264-90da8130b420"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975143, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004772, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:09.709+0000 I  COMMAND  [conn225] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 616 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975143, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d0e280a5-c536-424b-8264-90da8130b420") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:09.709+0000 I  NETWORK  [conn225] end connection 172.31.0.221:50980 (62 connections now open)
2020-05-08T21:59:14.060+0000 I  NETWORK  [conn229] end connection 172.31.0.221:51064 (61 connections now open)
2020-05-08T21:59:14.061+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51222 #237 (62 connections now open)
2020-05-08T21:59:14.061+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51224 #238 (63 connections now open)
2020-05-08T21:59:14.061+0000 I  NETWORK  [conn237] received client metadata from 172.31.0.221:51222 conn237: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.061+0000 I  NETWORK  [conn238] received client metadata from 172.31.0.221:51224 conn238: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.062+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.071+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.330+0000 I  NETWORK  [conn232] end connection 172.31.0.221:51072 (62 connections now open)
2020-05-08T21:59:14.330+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51234 #242 (63 connections now open)
2020-05-08T21:59:14.331+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51236 #243 (64 connections now open)
2020-05-08T21:59:14.331+0000 I  NETWORK  [conn242] received client metadata from 172.31.0.221:51234 conn242: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.331+0000 I  NETWORK  [conn243] received client metadata from 172.31.0.221:51236 conn243: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.705+0000 I  NETWORK  [conn235] end connection 172.31.0.221:51118 (63 connections now open)
2020-05-08T21:59:14.706+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51274 #245 (64 connections now open)
2020-05-08T21:59:14.706+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51276 #246 (65 connections now open)
2020-05-08T21:59:14.709+0000 I  -        [conn234] operation was interrupted because a client disconnected
2020-05-08T21:59:14.709+0000 I  NETWORK  [conn245] received client metadata from 172.31.0.221:51274 conn245: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.709+0000 I  CONNPOOL [conn234] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T21:59:14.710+0000 I  TXN      [conn234] transaction parameters:{ lsid: { id: UUID("db8705a1-b710-40e6-b420-2034e49630cb"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004125, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:14.710+0000 I  COMMAND  [conn234] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 688 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("db8705a1-b710-40e6-b420-2034e49630cb") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:14.710+0000 I  NETWORK  [conn234] end connection 172.31.0.221:51116 (64 connections now open)
2020-05-08T21:59:14.710+0000 I  NETWORK  [conn246] received client metadata from 172.31.0.221:51276 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:16.791+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.792+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.792+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.795+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 4), t: 43 }
2020-05-08T21:59:19.061+0000 I  NETWORK  [conn238] end connection 172.31.0.221:51224 (63 connections now open)
2020-05-08T21:59:19.062+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51400 #250 (64 connections now open)
2020-05-08T21:59:19.062+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51402 #251 (65 connections now open)
2020-05-08T21:59:19.062+0000 I  NETWORK  [conn250] received client metadata from 172.31.0.221:51400 conn250: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.062+0000 I  NETWORK  [conn251] received client metadata from 172.31.0.221:51402 conn251: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.064+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.331+0000 I  NETWORK  [conn243] end connection 172.31.0.221:51236 (64 connections now open)
2020-05-08T21:59:19.331+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51410 #252 (65 connections now open)
2020-05-08T21:59:19.332+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51408 #253 (66 connections now open)
2020-05-08T21:59:19.332+0000 I  NETWORK  [conn252] received client metadata from 172.31.0.221:51410 conn252: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.332+0000 I  NETWORK  [conn253] received client metadata from 172.31.0.221:51408 conn253: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.333+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.336+0000 I  -        [conn242] operation was interrupted because a client disconnected
2020-05-08T21:59:19.337+0000 I  CONNPOOL [conn242] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 9 connections to that host remain open
2020-05-08T21:59:19.337+0000 I  TXN      [conn242] transaction parameters:{ lsid: { id: UUID("37388f4f-420e-44ca-843d-2dc747f20ada"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005208, timeInactiveMicros:0, 5005ms
2020-05-08T21:59:19.337+0000 I  COMMAND  [conn242] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 692 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("37388f4f-420e-44ca-843d-2dc747f20ada") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:59:19.337+0000 I  NETWORK  [conn242] end connection 172.31.0.221:51234 (65 connections now open)
2020-05-08T21:59:19.554+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.554+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.555+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.555+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.555+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.706+0000 I  NETWORK  [conn246] end connection 172.31.0.221:51276 (64 connections now open)
2020-05-08T21:59:19.706+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51470 #255 (65 connections now open)
2020-05-08T21:59:19.707+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51472 #256 (66 connections now open)
2020-05-08T21:59:19.707+0000 I  NETWORK  [conn255] received client metadata from 172.31.0.221:51470 conn255: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.707+0000 I  NETWORK  [conn256] received client metadata from 172.31.0.221:51472 conn256: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.712+0000 I  -        [conn245] operation was interrupted because a client disconnected
2020-05-08T21:59:19.712+0000 I  CONNPOOL [conn245] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T21:59:19.712+0000 I  TXN      [conn245] transaction parameters:{ lsid: { id: UUID("2174ee2b-79dd-4158-adea-ed0ae57c115e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 2) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001262, timeInactiveMicros:0, 5001ms
2020-05-08T21:59:19.712+0000 I  COMMAND  [conn245] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 694 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2174ee2b-79dd-4158-adea-ed0ae57c115e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:19.712+0000 I  NETWORK  [conn245] end connection 172.31.0.221:51274 (65 connections now open)
2020-05-08T21:59:19.767+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:20.063+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:20.063+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:20.065+0000 I  TXN      [conn250] transaction parameters:{ lsid: { id: UUID("d78c5c57-d949-4ecb-91fd-805e0ba43d86"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 4) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:1002162, timeInactiveMicros:0, 1002ms
2020-05-08T21:59:20.065+0000 I  COMMAND  [conn250] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 744 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d78c5c57-d949-4ecb-91fd-805e0ba43d86") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction d78c5c57-d949-4ecb-91fd-805e0ba43d86:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered non-retryable error during query :: caused by :: Read timestamp Timestamp(1588975157, 4) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:545 protocol:op_msg 1002ms
2020-05-08T21:59:20.282+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:20.308+0000 I  NETWORK  [conn255] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:20.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:20.808+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:21.308+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:21.808+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:21.808+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:21.809+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:21.809+0000 I  TXN      [conn255] transaction parameters:{ lsid: { id: UUID("8798562f-5a08-47ae-9d28-422a92b43519"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975159, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2101558, timeInactiveMicros:0, 2101ms
2020-05-08T21:59:21.809+0000 I  COMMAND  [conn255] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975159, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8798562f-5a08-47ae-9d28-422a92b43519") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2101ms
2020-05-08T21:59:21.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:22.309+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:22.316+0000 I  COMMAND  [conn255] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975161, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8798562f-5a08-47ae-9d28-422a92b43519") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 506ms
2020-05-08T21:59:22.809+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:22.853+0000 I  NETWORK  [conn255] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:23.309+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:23.809+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.809+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.333+0000 I  -        [conn252] operation was interrupted because a client disconnected
2020-05-08T21:59:24.333+0000 I  CONNPOOL [conn252] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 7 connections to that host remain open
2020-05-08T21:59:24.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51576 #257 (66 connections now open)
2020-05-08T21:59:24.333+0000 I  TXN      [conn252] transaction parameters:{ lsid: { id: UUID("a75fb851-b825-4cbd-a103-ee21c58aee88"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975157, 4) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5000579, timeInactiveMicros:0, 5000ms
2020-05-08T21:59:24.333+0000 I  COMMAND  [conn252] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 743 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975157, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a75fb851-b825-4cbd-a103-ee21c58aee88") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5000ms
2020-05-08T21:59:24.333+0000 I  NETWORK  [conn252] end connection 172.31.0.221:51410 (65 connections now open)
2020-05-08T21:59:24.333+0000 I  NETWORK  [conn257] received client metadata from 172.31.0.221:51576 conn257: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.334+0000 I  NETWORK  [conn257] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:24.335+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.335+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:24.469+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:24.909+0000 I  NETWORK  [conn257] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:59:24.910+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.072+0000 I  -        [conn250] operation was interrupted because a client disconnected
2020-05-08T21:59:25.072+0000 I  TXN      [conn250] transaction parameters:{ lsid: { id: UUID("d78c5c57-d949-4ecb-91fd-805e0ba43d86"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975160, 35) } }, globalReadTimestamp:{ ts: Timestamp(1588975160, 35) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5001319, timeInactiveMicros:0, 5001ms
2020-05-08T21:59:25.072+0000 I  COMMAND  [conn250] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 744 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975160, 35), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d78c5c57-d949-4ecb-91fd-805e0ba43d86") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975160, 35) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:25.072+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51590 #258 (66 connections now open)
2020-05-08T21:59:25.073+0000 I  NETWORK  [conn250] end connection 172.31.0.221:51400 (65 connections now open)
2020-05-08T21:59:25.073+0000 I  NETWORK  [conn258] received client metadata from 172.31.0.221:51590 conn258: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:25.410+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:25.910+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:59:26.410+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.410+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:26.411+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975165, 2), t: 47 }
2020-05-08T21:59:26.411+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:26.411+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.411+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.411+0000 I  COMMAND  [conn257] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975157, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a75fb851-b825-4cbd-a103-ee21c58aee88") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2077ms
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn256] end connection 172.31.0.221:51472 (64 connections now open)
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn251] end connection 172.31.0.221:51402 (63 connections now open)
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn253] end connection 172.31.0.221:51408 (62 connections now open)
2020-05-08T21:59:26.429+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51610 #259 (63 connections now open)
2020-05-08T21:59:26.429+0000 I  NETWORK  [conn259] end connection 172.31.0.221:51610 (62 connections now open)
2020-05-08T21:59:26.917+0000 I  COMMAND  [conn257] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975166, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a75fb851-b825-4cbd-a103-ee21c58aee88") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 505ms
2020-05-08T21:59:26.917+0000 I  NETWORK  [conn257] end connection 172.31.0.221:51576 (61 connections now open)
2020-05-08T21:59:27.115+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
2020-05-08T21:59:27.223+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-3-82-35-209.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:27.854+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 9035 timed out, deadline was 2020-05-08T21:59:27.854+0000, op was RemoteCommand 9035 -- target:[ec2-34-207-119-213.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:59:27.854+0000 cmd:{ isMaster: 1 }
2020-05-08T21:59:27.854+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 9036 timed out, deadline was 2020-05-08T21:59:27.854+0000, op was RemoteCommand 9036 -- target:[ec2-35-172-222-251.compute-1.amazonaws.com:27018] db:admin expDate:2020-05-08T21:59:27.854+0000 cmd:{ isMaster: 1 }
2020-05-08T21:59:27.854+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:27.854+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:59:27.854+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:59:27.854+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-08T21:59:27.854+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
