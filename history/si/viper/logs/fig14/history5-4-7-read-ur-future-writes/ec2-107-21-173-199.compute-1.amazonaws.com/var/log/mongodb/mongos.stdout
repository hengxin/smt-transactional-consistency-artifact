2020-05-08 21:57:15 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-08T21:57:15.228+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-08T21:57:15.230+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.230+0000 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-08T21:57:15.230+0000 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-08T21:57:15.230+0000 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-08T21:57:15.230+0000 I  CONTROL  [main] 
2020-05-08T21:57:15.230+0000 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-08T21:57:15.230+0000 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-08T21:57:15.231+0000 I  CONTROL  [mongosMain] modules: none
2020-05-08T21:57:15.231+0000 I  CONTROL  [mongosMain] build environment:
2020-05-08T21:57:15.231+0000 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-08T21:57:15.231+0000 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-08T21:57:15.231+0000 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-08T21:57:15.231+0000 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019" } }
2020-05-08T21:57:15.231+0000 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.232+0000 I  SHARDING [thread1] creating distributed lock ping thread for process ip-172-31-13-225:27017:1588975035:6221165245416396937 (sleeping for 30000ms)
2020-05-08T21:57:15.232+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.232+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.232+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.238+0000 I  SHARDING [Sharding-Fixed-0] Updating ShardRegistry connection string for shard config from: rs_config/ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019,ec2-107-21-173-199.compute-1.amazonaws.com:27019 to: rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:15.244+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1588975033, 12), t: 1 }
2020-05-08T21:57:15.422+0000 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-08T21:57:15.425+0000 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-08T21:57:16.424+0000 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-08T21:57:16.424+0000 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-08T21:57:16.426+0000 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-08T21:57:16.426+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("021267a0-a2a3-4b0c-b19e-8ddf6d5270d1"), lastMod: 0 } took 0 ms
2020-05-08T21:57:16.427+0000 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.427+0000 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-08T21:57:16.435+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48572 #9 (1 connection now open)
2020-05-08T21:57:16.435+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48582 #10 (2 connections now open)
2020-05-08T21:57:16.435+0000 I  NETWORK  [conn9] received client metadata from 172.31.0.221:48572 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.435+0000 I  NETWORK  [conn10] received client metadata from 172.31.0.221:48582 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.886+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48610 #11 (3 connections now open)
2020-05-08T21:57:16.886+0000 I  NETWORK  [conn11] received client metadata from 172.31.0.221:48610 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.925+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48624 #12 (4 connections now open)
2020-05-08T21:57:16.925+0000 I  NETWORK  [conn12] received client metadata from 172.31.0.221:48624 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:16.947+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48640 #13 (5 connections now open)
2020-05-08T21:57:16.947+0000 I  NETWORK  [conn13] received client metadata from 172.31.0.221:48640 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.092+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48658 #14 (6 connections now open)
2020-05-08T21:57:17.093+0000 I  NETWORK  [conn14] received client metadata from 172.31.0.221:48658 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.152+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48676 #15 (7 connections now open)
2020-05-08T21:57:17.153+0000 I  NETWORK  [conn15] received client metadata from 172.31.0.221:48676 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.302+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48688 #16 (8 connections now open)
2020-05-08T21:57:17.302+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48690 #17 (9 connections now open)
2020-05-08T21:57:17.302+0000 I  NETWORK  [conn16] received client metadata from 172.31.0.221:48688 conn16: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.303+0000 I  NETWORK  [conn17] received client metadata from 172.31.0.221:48690 conn17: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48726 #18 (10 connections now open)
2020-05-08T21:57:17.414+0000 I  NETWORK  [conn18] received client metadata from 172.31.0.221:48726 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.451+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48740 #19 (11 connections now open)
2020-05-08T21:57:17.452+0000 I  NETWORK  [conn19] received client metadata from 172.31.0.221:48740 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.472+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48748 #20 (12 connections now open)
2020-05-08T21:57:17.472+0000 I  NETWORK  [conn20] received client metadata from 172.31.0.221:48748 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.785+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48796 #21 (13 connections now open)
2020-05-08T21:57:17.786+0000 I  NETWORK  [conn21] received client metadata from 172.31.0.221:48796 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:17.829+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48808 #22 (14 connections now open)
2020-05-08T21:57:17.829+0000 I  NETWORK  [conn22] received client metadata from 172.31.0.221:48808 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:18.866+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48822 #23 (15 connections now open)
2020-05-08T21:57:18.866+0000 I  NETWORK  [conn23] received client metadata from 172.31.0.221:48822 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.514+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48862 #24 (16 connections now open)
2020-05-08T21:57:19.515+0000 I  NETWORK  [conn24] received client metadata from 172.31.0.221:48862 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:19.568+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48882 #25 (17 connections now open)
2020-05-08T21:57:19.568+0000 I  NETWORK  [conn25] received client metadata from 172.31.0.221:48882 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.208+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48934 #26 (18 connections now open)
2020-05-08T21:57:20.208+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48936 #27 (19 connections now open)
2020-05-08T21:57:20.208+0000 I  NETWORK  [conn26] received client metadata from 172.31.0.221:48934 conn26: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.209+0000 I  NETWORK  [conn27] received client metadata from 172.31.0.221:48936 conn27: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:20.270+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48940 #28 (20 connections now open)
2020-05-08T21:57:20.270+0000 I  NETWORK  [conn28] received client metadata from 172.31.0.221:48940 conn28: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.017+0000 I  COMMAND  [conn19] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975037, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04d05a0c-64e8-40a6-af8c-047220182983") } } numYields:0 reslen:163 protocol:op_msg 3545ms
2020-05-08T21:57:21.018+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:21.020+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("581932e5-9f09-463d-9e4f-6ce29bfb98d7"), lastMod: 1 } took 1 ms
2020-05-08T21:57:21.021+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  NETWORK  [conn19] Starting new replica set monitor for rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.021+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.026+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.026+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.028+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.028+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:21.345+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48956 #36 (21 connections now open)
2020-05-08T21:57:21.346+0000 I  NETWORK  [conn36] received client metadata from 172.31.0.221:48956 conn36: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.544+0000 I  COMMAND  [conn19] command jepsendb.jepsencoll command: create { create: "jepsencoll", capped: false, writeConcern: { w: "majority" }, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975041, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("04d05a0c-64e8-40a6-af8c-047220182983") } } numYields:0 reslen:163 protocol:op_msg 526ms
2020-05-08T21:57:21.560+0000 I  NETWORK  [conn19] end connection 172.31.0.221:48740 (20 connections now open)
2020-05-08T21:57:21.561+0000 I  NETWORK  [conn20] end connection 172.31.0.221:48748 (19 connections now open)
2020-05-08T21:57:21.562+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48972 #37 (20 connections now open)
2020-05-08T21:57:21.562+0000 I  NETWORK  [conn37] received client metadata from 172.31.0.221:48972 conn37: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.849+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:48994 #38 (21 connections now open)
2020-05-08T21:57:21.849+0000 I  NETWORK  [conn38] received client metadata from 172.31.0.221:48994 conn38: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.932+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49010 #39 (22 connections now open)
2020-05-08T21:57:21.932+0000 I  NETWORK  [conn39] received client metadata from 172.31.0.221:49010 conn39: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:21.957+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49016 #40 (23 connections now open)
2020-05-08T21:57:21.958+0000 I  NETWORK  [conn40] received client metadata from 172.31.0.221:49016 conn40: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49050 #41 (24 connections now open)
2020-05-08T21:57:22.059+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49052 #42 (25 connections now open)
2020-05-08T21:57:22.059+0000 I  NETWORK  [conn41] received client metadata from 172.31.0.221:49050 conn41: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.059+0000 I  NETWORK  [conn42] received client metadata from 172.31.0.221:49052 conn42: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.062+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49074 #43 (26 connections now open)
2020-05-08T21:57:22.062+0000 I  NETWORK  [conn43] received client metadata from 172.31.0.221:49074 conn43: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.063+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49078 #44 (27 connections now open)
2020-05-08T21:57:22.063+0000 I  NETWORK  [conn44] received client metadata from 172.31.0.221:49078 conn44: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.072+0000 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb5d5bdaa21895c8b24d0bd took 1 ms
2020-05-08T21:57:22.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:22.075+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49114 #47 (28 connections now open)
2020-05-08T21:57:22.075+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49116 #48 (29 connections now open)
2020-05-08T21:57:22.076+0000 I  NETWORK  [conn48] received client metadata from 172.31.0.221:49116 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.076+0000 I  NETWORK  [conn47] received client metadata from 172.31.0.221:49114 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:22.321+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 2, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975042, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 232ms
2020-05-08T21:57:22.322+0000 I  TXN      [conn47] transaction parameters:{ lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 5) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:217706, timeActiveMicros:233901, timeInactiveMicros:739, 234ms
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn47] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 217ms
2020-05-08T21:57:22.322+0000 I  COMMAND  [conn41] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:320 protocol:op_msg 216ms
2020-05-08T21:57:22.516+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49176 #53 (30 connections now open)
2020-05-08T21:57:22.516+0000 I  NETWORK  [conn53] received client metadata from 172.31.0.221:49176 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.086+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49218 #59 (31 connections now open)
2020-05-08T21:57:23.086+0000 I  NETWORK  [conn59] received client metadata from 172.31.0.221:49218 conn59: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.101+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49222 #60 (32 connections now open)
2020-05-08T21:57:23.101+0000 I  NETWORK  [conn60] received client metadata from 172.31.0.221:49222 conn60: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.367+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 10, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975042, 299) } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 299) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:849446, timeActiveMicros:877868, timeInactiveMicros:1168, 879ms
2020-05-08T21:57:23.367+0000 I  COMMAND  [conn41] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 336), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c") }, txnNumber: 10, autocommit: false } numYields:0 reslen:214 protocol:op_msg 849ms
2020-05-08T21:57:23.368+0000 I  COMMAND  [conn47] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 337), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 12, autocommit: false } numYields:0 reslen:321 protocol:op_msg 850ms
2020-05-08T21:57:23.369+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 12, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975042, 337) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:843692, timeActiveMicros:848982, timeInactiveMicros:588, 849ms
2020-05-08T21:57:23.369+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975042, 347), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5") }, txnNumber: 12, autocommit: false } numYields:0 reslen:183 protocol:op_msg 843ms
2020-05-08T21:57:23.374+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:23.436+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49240 #63 (33 connections now open)
2020-05-08T21:57:23.436+0000 I  NETWORK  [conn63] received client metadata from 172.31.0.221:49240 conn63: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:23.740+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49276 #64 (34 connections now open)
2020-05-08T21:57:23.741+0000 I  NETWORK  [conn64] received client metadata from 172.31.0.221:49276 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.070+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49292 #65 (35 connections now open)
2020-05-08T21:57:24.070+0000 I  NETWORK  [conn65] received client metadata from 172.31.0.221:49292 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.485+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49342 #66 (36 connections now open)
2020-05-08T21:57:24.485+0000 I  NETWORK  [conn66] received client metadata from 172.31.0.221:49342 conn66: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:24.616+0000 I  TXN      [conn47] transaction parameters:{ lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 6) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 6) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:1239926, timeActiveMicros:1246528, timeInactiveMicros:982, 1247ms
2020-05-08T21:57:24.616+0000 I  COMMAND  [conn47] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 13, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1240ms
2020-05-08T21:57:25.134+0000 I  COMMAND  [conn41] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 27 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975043, 40), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c") }, txnNumber: 13, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:339 protocol:op_msg 1712ms
2020-05-08T21:57:25.135+0000 I  COMMAND  [conn47] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 16 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975044, 180), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 14, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:341 protocol:op_msg 517ms
2020-05-08T21:57:25.136+0000 I  TXN      [conn41] transaction parameters:{ lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975043, 36) } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 38) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1717054, timeInactiveMicros:1039, 1718ms
2020-05-08T21:57:25.182+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49362 #67 (37 connections now open)
2020-05-08T21:57:25.183+0000 I  NETWORK  [conn67] received client metadata from 172.31.0.221:49362 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.425+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49404 #68 (38 connections now open)
2020-05-08T21:57:25.426+0000 I  NETWORK  [conn68] received client metadata from 172.31.0.221:49404 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.515+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49424 #69 (39 connections now open)
2020-05-08T21:57:25.515+0000 I  NETWORK  [conn69] received client metadata from 172.31.0.221:49424 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.548+0000 I  TXN      [conn47] transaction parameters:{ lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 14, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975044, 180) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:411672, timeActiveMicros:929815, timeInactiveMicros:612, 930ms
2020-05-08T21:57:25.548+0000 I  COMMAND  [conn47] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 14, autocommit: false } numYields:0 reslen:183 protocol:op_msg 411ms
2020-05-08T21:57:25.568+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 13, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975043, 6) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:2186401, timeActiveMicros:2196569, timeInactiveMicros:719, 2197ms
2020-05-08T21:57:25.568+0000 I  COMMAND  [conn43] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975043, 17), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5") }, txnNumber: 13, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2186ms
2020-05-08T21:57:25.646+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:25.671+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49432 #71 (40 connections now open)
2020-05-08T21:57:25.671+0000 I  NETWORK  [conn71] received client metadata from 172.31.0.221:49432 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:25.697+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49446 #72 (41 connections now open)
2020-05-08T21:57:25.697+0000 I  NETWORK  [conn72] received client metadata from 172.31.0.221:49446 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:26.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:26.368+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49480 #78 (42 connections now open)
2020-05-08T21:57:26.369+0000 I  NETWORK  [conn78] received client metadata from 172.31.0.221:49480 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:26.462+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975042, 4), t: 1 }, now { ts: Timestamp(1588975046, 95), t: 3 }
2020-05-08T21:57:26.950+0000 I  NETWORK  [conn43] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:26.951+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.953+0000 I  NETWORK  [conn47] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:26.954+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:26.955+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.450+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:27.950+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:28.450+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.450+0000 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.451+0000 I  COMMAND  [conn47] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 677), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 29, autocommit: false } numYields:0 reslen:439 protocol:op_msg 2506ms
2020-05-08T21:57:28.451+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 27, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975045, 668) } }, globalReadTimestamp:{ ts: Timestamp(1588975045, 668) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2513092, timeInactiveMicros:768, 2513ms
2020-05-08T21:57:28.451+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975045, 683), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5") }, txnNumber: 27, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2499ms
2020-05-08T21:57:28.453+0000 I  COMMAND  [conn41] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975045, 663), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c") }, txnNumber: 96, autocommit: false } numYields:0 reslen:321 protocol:op_msg 2519ms
2020-05-08T21:57:28.453+0000 I  NETWORK  [conn41] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:28.454+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.462+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:28.953+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.953+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.953+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:28.960+0000 I  TXN      [conn47] transaction parameters:{ lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 30, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 12) }, numParticipants:2, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:500048, timeInactiveMicros:492, 500ms
2020-05-08T21:57:28.960+0000 I  COMMAND  [conn47] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 61 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 30, autocommit: false } numYields:0 ok:0 errMsg:"Transaction b811240e-d515-4994-b417-924f73a3ddee:30 was aborted on statement 2 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:627 protocol:op_msg 497ms
2020-05-08T21:57:29.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:29.168+0000 I  NETWORK  [conn41] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:29.169+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.170+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.453+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:29.953+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.453+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.704+0000 I  NETWORK  [conn43] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:30.705+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:30.875+0000 I  NETWORK  [conn44] end connection 172.31.0.221:49078 (41 connections now open)
2020-05-08T21:57:30.876+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49582 #81 (42 connections now open)
2020-05-08T21:57:30.876+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49584 #82 (43 connections now open)
2020-05-08T21:57:30.876+0000 I  NETWORK  [conn81] received client metadata from 172.31.0.221:49582 conn81: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.876+0000 I  NETWORK  [conn82] received client metadata from 172.31.0.221:49584 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.879+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.920+0000 I  NETWORK  [conn42] end connection 172.31.0.221:49052 (42 connections now open)
2020-05-08T21:57:30.921+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49624 #83 (43 connections now open)
2020-05-08T21:57:30.921+0000 I  NETWORK  [conn83] received client metadata from 172.31.0.221:49624 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.921+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49626 #84 (44 connections now open)
2020-05-08T21:57:30.921+0000 I  NETWORK  [conn84] received client metadata from 172.31.0.221:49626 conn84: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.923+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.940+0000 I  NETWORK  [conn48] end connection 172.31.0.221:49116 (43 connections now open)
2020-05-08T21:57:30.940+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49648 #85 (44 connections now open)
2020-05-08T21:57:30.940+0000 I  NETWORK  [conn85] received client metadata from 172.31.0.221:49648 conn85: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.941+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49650 #86 (45 connections now open)
2020-05-08T21:57:30.941+0000 I  NETWORK  [conn86] received client metadata from 172.31.0.221:49650 conn86: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:30.942+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:30.953+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:31.204+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.204+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.205+0000 I  TXN      [conn43] transaction parameters:{ lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 28, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 12) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2741521, timeInactiveMicros:0, 2741ms
2020-05-08T21:57:31.205+0000 I  COMMAND  [conn43] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("35d9d382-3db4-4885-b735-e78b1d3886c5") }, txnNumber: 28, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 12) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 2741ms
2020-05-08T21:57:31.206+0000 I  NETWORK  [conn43] end connection 172.31.0.221:49074 (44 connections now open)
2020-05-08T21:57:31.453+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.453+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.454+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.456+0000 I  COMMAND  [conn47] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975048, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b811240e-d515-4994-b417-924f73a3ddee") }, txnNumber: 30, autocommit: false } numYields:0 reslen:352 protocol:op_msg 2495ms
2020-05-08T21:57:31.456+0000 I  NETWORK  [conn47] end connection 172.31.0.221:49114 (43 connections now open)
2020-05-08T21:57:31.991+0000 I  COMMAND  [conn81] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 62 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e4754ac2-1dc2-4b07-b0a4-66bfa2b70c41") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1114ms
2020-05-08T21:57:31.992+0000 I  COMMAND  [conn41] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 4 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975048, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c72b1bc8-9c6a-4838-8e7e-57de8791dd4c") }, txnNumber: 97, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975048, 2) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:363 protocol:op_msg 3538ms
2020-05-08T21:57:31.992+0000 I  NETWORK  [conn41] end connection 172.31.0.221:49050 (42 connections now open)
2020-05-08T21:57:31.993+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:31.997+0000 I  TXN      [conn85] transaction parameters:{ lsid: { id: UUID("6aa08de7-15f5-4197-ba28-820dda1debd1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1055157, timeInactiveMicros:0, 1055ms
2020-05-08T21:57:31.997+0000 I  COMMAND  [conn85] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6aa08de7-15f5-4197-ba28-820dda1debd1") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1055ms
2020-05-08T21:57:31.999+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("a80b7529-a714-4921-b63e-f6f689cd563a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975050, 2) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1076992, timeInactiveMicros:0, 1076ms
2020-05-08T21:57:31.999+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975050, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a80b7529-a714-4921-b63e-f6f689cd563a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1077ms
2020-05-08T21:57:32.320+0000 I  NETWORK  [Sharding-Fixed-2] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:32.321+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:32.820+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:32.928+0000 I  NETWORK  [Sharding-Fixed-2] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:32.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:32.963+0000 I  NETWORK  [conn81] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:32.964+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:32.966+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.215+0000 I  NETWORK  [conn85] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:33.216+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:33.320+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.320+0000 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.320+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:57:33.321+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975047, 1), t: 3 }, now { ts: Timestamp(1588975052, 43), t: 4 }
2020-05-08T21:57:33.463+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:33.716+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.716+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:33.717+0000 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975052, 66), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6aa08de7-15f5-4197-ba28-820dda1debd1") }, txnNumber: 29, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1511ms
2020-05-08T21:57:33.963+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:34.268+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.268+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.268+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:57:34.269+0000 I  COMMAND  [conn83] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975052, 27), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a80b7529-a714-4921-b63e-f6f689cd563a") }, txnNumber: 4, autocommit: false } numYields:0 reslen:351 protocol:op_msg 2228ms
2020-05-08T21:57:34.278+0000 I  TXN      [conn81] transaction parameters:{ lsid: { id: UUID("e4754ac2-1dc2-4b07-b0a4-66bfa2b70c41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975048, 20) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:2285134, timeActiveMicros:3400438, timeInactiveMicros:586, 3401ms
2020-05-08T21:57:34.279+0000 I  COMMAND  [conn81] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975051, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e4754ac2-1dc2-4b07-b0a4-66bfa2b70c41") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 2285ms
2020-05-08T21:57:35.056+0000 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 863), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6aa08de7-15f5-4197-ba28-820dda1debd1") }, txnNumber: 112, autocommit: false } numYields:0 reslen:322 protocol:op_msg 219ms
2020-05-08T21:57:35.058+0000 I  COMMAND  [conn81] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 869), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e4754ac2-1dc2-4b07-b0a4-66bfa2b70c41") }, txnNumber: 30, autocommit: false } numYields:0 reslen:321 protocol:op_msg 217ms
2020-05-08T21:57:35.091+0000 I  TXN      [conn83] transaction parameters:{ lsid: { id: UUID("a80b7529-a714-4921-b63e-f6f689cd563a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 29, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975054, 860) } }, globalReadTimestamp:{ ts: Timestamp(1588975054, 860) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:254418, timeActiveMicros:258996, timeInactiveMicros:1096, 260ms
2020-05-08T21:57:35.091+0000 I  COMMAND  [conn83] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975054, 863), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a80b7529-a714-4921-b63e-f6f689cd563a") }, txnNumber: 29, autocommit: false } numYields:0 reslen:214 protocol:op_msg 254ms
2020-05-08T21:57:35.809+0000 I  NETWORK  [conn83] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:35.812+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.104+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49770 #96 (43 connections now open)
2020-05-08T21:57:36.104+0000 I  NETWORK  [conn96] received client metadata from 172.31.0.221:49770 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:36.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.464+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:36.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:36.970+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975052, 43), t: 4 }, now { ts: Timestamp(1588975056, 85), t: 6 }
2020-05-08T21:57:37.185+0000 I  NETWORK  [conn81] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:37.186+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:37.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:37.685+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.685+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:37.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:38.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.045+0000 I  NETWORK  [conn81] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:39.046+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:39.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:39.545+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.545+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.546+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:39.810+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.810+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:39.811+0000 I  SHARDING [conn85] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 1), t: 6 }, now { ts: Timestamp(1588975057, 3), t: 7 }
2020-05-08T21:57:39.811+0000 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975055, 422), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6aa08de7-15f5-4197-ba28-820dda1debd1") }, txnNumber: 127, autocommit: false } numYields:0 reslen:440 protocol:op_msg 4437ms
2020-05-08T21:57:40.053+0000 I  NETWORK  [conn85] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:40.056+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:40.341+0000 I  NETWORK  [conn82] end connection 172.31.0.221:49584 (42 connections now open)
2020-05-08T21:57:40.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49902 #97 (43 connections now open)
2020-05-08T21:57:40.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49904 #98 (44 connections now open)
2020-05-08T21:57:40.342+0000 I  NETWORK  [conn97] received client metadata from 172.31.0.221:49902 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.342+0000 I  NETWORK  [conn98] received client metadata from 172.31.0.221:49904 conn98: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.362+0000 I  NETWORK  [conn86] end connection 172.31.0.221:49650 (43 connections now open)
2020-05-08T21:57:40.363+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49926 #99 (44 connections now open)
2020-05-08T21:57:40.363+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49928 #100 (45 connections now open)
2020-05-08T21:57:40.363+0000 I  NETWORK  [conn100] received client metadata from 172.31.0.221:49928 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.363+0000 I  NETWORK  [conn84] end connection 172.31.0.221:49626 (44 connections now open)
2020-05-08T21:57:40.364+0000 I  NETWORK  [conn99] received client metadata from 172.31.0.221:49926 conn99: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49930 #101 (45 connections now open)
2020-05-08T21:57:40.364+0000 I  NETWORK  [conn101] received client metadata from 172.31.0.221:49930 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49932 #102 (46 connections now open)
2020-05-08T21:57:40.364+0000 I  NETWORK  [conn102] received client metadata from 172.31.0.221:49932 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:40.370+0000 I  -        [conn81] operation was interrupted because a client disconnected
2020-05-08T21:57:40.370+0000 I  CONNPOOL [conn81] Ending connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:57:40.370+0000 I  TXN      [conn81] transaction parameters:{ lsid: { id: UUID("e4754ac2-1dc2-4b07-b0a4-66bfa2b70c41"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 44, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975055, 410) } }, globalReadTimestamp:{ ts: Timestamp(1588975055, 410) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006231, timeInactiveMicros:0, 5006ms
2020-05-08T21:57:40.370+0000 I  COMMAND  [conn81] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 121 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975055, 410), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e4754ac2-1dc2-4b07-b0a4-66bfa2b70c41") }, txnNumber: 44, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975055, 410) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-08T21:57:40.370+0000 I  NETWORK  [conn81] end connection 172.31.0.221:49582 (45 connections now open)
2020-05-08T21:57:40.810+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.310+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:41.317+0000 I  NETWORK  [conn99] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:41.318+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.322+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:41.565+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:49962 #104 (46 connections now open)
2020-05-08T21:57:41.566+0000 I  NETWORK  [conn104] received client metadata from 172.31.0.221:49962 conn104: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:41.810+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.810+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.812+0000 I  COMMAND  [conn85] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975059, 44), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6aa08de7-15f5-4197-ba28-820dda1debd1") }, txnNumber: 127, autocommit: false } numYields:0 reslen:517 protocol:op_msg 1999ms
2020-05-08T21:57:41.812+0000 I  NETWORK  [conn85] end connection 172.31.0.221:49648 (45 connections now open)
2020-05-08T21:57:41.818+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.818+0000 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:41.819+0000 I  TXN      [conn101] transaction parameters:{ lsid: { id: UUID("bb78825f-02d2-42f3-a0b9-e04faa28ac34"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975060, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1443136, timeInactiveMicros:0, 1443ms
2020-05-08T21:57:41.819+0000 I  COMMAND  [conn101] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975060, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bb78825f-02d2-42f3-a0b9-e04faa28ac34") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1443ms
2020-05-08T21:57:41.819+0000 I  TXN      [conn99] transaction parameters:{ lsid: { id: UUID("d9872c4e-cafc-49ad-befa-b1899f68488b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975059, 61) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1454864, timeInactiveMicros:0, 1454ms
2020-05-08T21:57:41.820+0000 I  COMMAND  [conn99] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d9872c4e-cafc-49ad-befa-b1899f68488b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1455ms
2020-05-08T21:57:42.063+0000 I  COMMAND  [conn83] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 46, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975055, 410), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a80b7529-a714-4921-b63e-f6f689cd563a") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 6697ms
2020-05-08T21:57:42.063+0000 I  NETWORK  [conn83] end connection 172.31.0.221:49624 (44 connections now open)
2020-05-08T21:57:42.880+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.030+0000 I  NETWORK  [conn97] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:43.031+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.031+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.039+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:43.046+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:43.531+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.531+0000 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:43.532+0000 I  COMMAND  [conn101] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975061, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bb78825f-02d2-42f3-a0b9-e04faa28ac34") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1712ms
2020-05-08T21:57:43.532+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.532+0000 I  COMMAND  [conn99] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975061, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d9872c4e-cafc-49ad-befa-b1899f68488b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1712ms
2020-05-08T21:57:43.532+0000 I  SHARDING [Sharding-Fixed-5] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:43.533+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:44.171+0000 I  NETWORK  [conn99] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:57:44.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.173+0000 I  NETWORK  [conn97] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:44.173+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:44.211+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975057, 3), t: 7 }, now { ts: Timestamp(1588975063, 7), t: 8 }
2020-05-08T21:57:44.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:45.261+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50062 #109 (45 connections now open)
2020-05-08T21:57:45.262+0000 I  NETWORK  [conn109] received client metadata from 172.31.0.221:50062 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.342+0000 I  NETWORK  [conn98] end connection 172.31.0.221:49904 (44 connections now open)
2020-05-08T21:57:45.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50094 #110 (45 connections now open)
2020-05-08T21:57:45.342+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50096 #111 (46 connections now open)
2020-05-08T21:57:45.343+0000 I  NETWORK  [conn110] received client metadata from 172.31.0.221:50094 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.343+0000 I  NETWORK  [conn111] received client metadata from 172.31.0.221:50096 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.344+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.344+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.345+0000 I  COMMAND  [conn99] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975063, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d9872c4e-cafc-49ad-befa-b1899f68488b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1811ms
2020-05-08T21:57:45.345+0000 I  COMMAND  [conn101] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975063, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bb78825f-02d2-42f3-a0b9-e04faa28ac34") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1811ms
2020-05-08T21:57:45.363+0000 I  NETWORK  [conn100] end connection 172.31.0.221:49928 (45 connections now open)
2020-05-08T21:57:45.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50118 #112 (46 connections now open)
2020-05-08T21:57:45.364+0000 I  NETWORK  [conn112] received client metadata from 172.31.0.221:50118 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.364+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50120 #113 (47 connections now open)
2020-05-08T21:57:45.364+0000 I  NETWORK  [conn113] received client metadata from 172.31.0.221:50120 conn113: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.366+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:45.376+0000 I  NETWORK  [conn102] end connection 172.31.0.221:49932 (46 connections now open)
2020-05-08T21:57:45.377+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50130 #115 (47 connections now open)
2020-05-08T21:57:45.377+0000 I  NETWORK  [conn115] received client metadata from 172.31.0.221:50130 conn115: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.377+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50132 #116 (48 connections now open)
2020-05-08T21:57:45.377+0000 I  NETWORK  [conn116] received client metadata from 172.31.0.221:50132 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:45.794+0000 I  NETWORK  [conn115] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:45.795+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:46.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:46.295+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:46.795+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.295+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:47.518+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:47.518+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:47.795+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:48.018+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.160+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b80770106eff2e4268 to 5eb5d5b96b7369da8ea76060; invalidating user cache
2020-05-08T21:57:48.295+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.295+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.296+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:48.299+0000 I  TXN      [conn115] transaction parameters:{ lsid: { id: UUID("ead86487-69ca-43e0-8dc0-32da435b30cc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 7) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2918664, timeActiveMicros:2920372, timeInactiveMicros:503, 2920ms
2020-05-08T21:57:48.299+0000 I  COMMAND  [conn115] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ead86487-69ca-43e0-8dc0-32da435b30cc") }, txnNumber: 1, autocommit: false } numYields:0 reslen:214 protocol:op_msg 2918ms
2020-05-08T21:57:48.300+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:57:48.518+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.518+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:48.768+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:49.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:49.073+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:57:49.342+0000 I  NETWORK  [conn111] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:57:49.343+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.344+0000 I  COMMAND  [conn97] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975059, 61), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4913347a-b7ca-473d-ba4f-4a2e78a64d08") } } nShards:1 nMatched:0 nModified:0 numYields:0 reslen:316 protocol:op_msg 9001ms
2020-05-08T21:57:49.344+0000 I  NETWORK  [conn97] end connection 172.31.0.221:49902 (47 connections now open)
2020-05-08T21:57:49.344+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.345+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.346+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:49.692+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50192 #124 (48 connections now open)
2020-05-08T21:57:49.692+0000 I  NETWORK  [conn124] received client metadata from 172.31.0.221:50192 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:49.842+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.320+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975063, 7), t: 8 }, now { ts: Timestamp(1588975068, 297), t: 10 }
2020-05-08T21:57:50.342+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.343+0000 I  NETWORK  [conn110] end connection 172.31.0.221:50094 (47 connections now open)
2020-05-08T21:57:50.374+0000 I  -        [conn112] operation was interrupted because a client disconnected
2020-05-08T21:57:50.375+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50222 #125 (48 connections now open)
2020-05-08T21:57:50.375+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.375+0000 I  TXN      [conn112] transaction parameters:{ lsid: { id: UUID("f33b28ff-c8b0-449b-a495-2964fcf2c8ea"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 4) }, numParticipants:2, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5009649, timeInactiveMicros:238, 5009ms
2020-05-08T21:57:50.375+0000 I  NETWORK  [conn125] received client metadata from 172.31.0.221:50222 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.375+0000 I  COMMAND  [conn112] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 141 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f33b28ff-c8b0-449b-a495-2964fcf2c8ea") }, txnNumber: 1, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5009ms
2020-05-08T21:57:50.375+0000 I  NETWORK  [conn112] end connection 172.31.0.221:50118 (47 connections now open)
2020-05-08T21:57:50.375+0000 I  NETWORK  [conn125] end connection 172.31.0.221:50222 (46 connections now open)
2020-05-08T21:57:50.376+0000 I  -        [conn111] operation was interrupted because a client disconnected
2020-05-08T21:57:50.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50226 #126 (47 connections now open)
2020-05-08T21:57:50.376+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.376+0000 I  TXN      [conn111] transaction parameters:{ lsid: { id: UUID("c98ae4f9-48fd-4ef9-9cc3-e91f3860c77b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975064, 1) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5032964, timeInactiveMicros:0, 5032ms
2020-05-08T21:57:50.376+0000 I  COMMAND  [conn111] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 141 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975064, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c98ae4f9-48fd-4ef9-9cc3-e91f3860c77b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5033ms
2020-05-08T21:57:50.376+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50228 #127 (48 connections now open)
2020-05-08T21:57:50.377+0000 I  NETWORK  [conn111] end connection 172.31.0.221:50096 (47 connections now open)
2020-05-08T21:57:50.377+0000 I  NETWORK  [conn127] received client metadata from 172.31.0.221:50228 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.377+0000 I  NETWORK  [conn126] received client metadata from 172.31.0.221:50226 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.377+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50230 #128 (48 connections now open)
2020-05-08T21:57:50.377+0000 I  NETWORK  [conn128] received client metadata from 172.31.0.221:50230 conn128: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.378+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.379+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.379+0000 I  NETWORK  [conn113] end connection 172.31.0.221:50120 (47 connections now open)
2020-05-08T21:57:50.380+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50240 #129 (48 connections now open)
2020-05-08T21:57:50.380+0000 I  NETWORK  [conn129] received client metadata from 172.31.0.221:50240 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50242 #130 (49 connections now open)
2020-05-08T21:57:50.381+0000 I  NETWORK  [conn130] received client metadata from 172.31.0.221:50242 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:50.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:50.842+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.342+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:51.842+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.842+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:51.843+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:51.843+0000 I  TXN      [conn101] transaction parameters:{ lsid: { id: UUID("bb78825f-02d2-42f3-a0b9-e04faa28ac34"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 3) } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 4) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6497241, timeInactiveMicros:0, 6497ms
2020-05-08T21:57:51.843+0000 I  COMMAND  [conn101] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bb78825f-02d2-42f3-a0b9-e04faa28ac34") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 3) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 6497ms
2020-05-08T21:57:51.844+0000 I  NETWORK  [conn101] end connection 172.31.0.221:49930 (48 connections now open)
2020-05-08T21:57:51.844+0000 I  TXN      [conn115] transaction parameters:{ lsid: { id: UUID("ead86487-69ca-43e0-8dc0-32da435b30cc"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975068, 15) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3543869, timeInactiveMicros:0, 3543ms
2020-05-08T21:57:51.844+0000 I  COMMAND  [conn115] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975068, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ead86487-69ca-43e0-8dc0-32da435b30cc") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3543ms
2020-05-08T21:57:51.844+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:57:51.844+0000 I  TXN      [conn128] transaction parameters:{ lsid: { id: UUID("32370e70-0c28-42ad-97da-1b6a7b6f406c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975070, 157) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1465382, timeInactiveMicros:0, 1465ms
2020-05-08T21:57:51.844+0000 I  COMMAND  [conn128] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 157), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("32370e70-0c28-42ad-97da-1b6a7b6f406c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:385 protocol:op_msg 1465ms
2020-05-08T21:57:51.844+0000 I  TXN      [conn99] transaction parameters:{ lsid: { id: UUID("d9872c4e-cafc-49ad-befa-b1899f68488b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 3) } }, globalReadTimestamp:{ ts: Timestamp(1588975065, 4) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:6498967, timeInactiveMicros:0, 6498ms
2020-05-08T21:57:51.844+0000 I  COMMAND  [conn99] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975065, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d9872c4e-cafc-49ad-befa-b1899f68488b") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975065, 3) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 6499ms
2020-05-08T21:57:51.844+0000 I  NETWORK  [conn99] end connection 172.31.0.221:49926 (47 connections now open)
2020-05-08T21:57:51.845+0000 I  COMMAND  [conn130] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 147 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975070, 172), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fdb0020e-877f-4fb1-952e-8388dde96a08") } } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:299 protocol:op_msg 1454ms
2020-05-08T21:57:51.854+0000 I  COMMAND  [conn126] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975065, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f33b28ff-c8b0-449b-a495-2964fcf2c8ea") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 1476ms
2020-05-08T21:57:51.854+0000 I  NETWORK  [conn126] end connection 172.31.0.221:50226 (46 connections now open)
2020-05-08T21:57:52.199+0000 I  SHARDING [conn115] Received reply from shard ec2-54-236-6-178.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975068, 297), t: 10 }, now { ts: Timestamp(1588975071, 384), t: 11 }
2020-05-08T21:57:52.343+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.343+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:57:52.726+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50302 #131 (47 connections now open)
2020-05-08T21:57:52.726+0000 I  NETWORK  [conn131] received client metadata from 172.31.0.221:50302 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:52.888+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50306 #132 (48 connections now open)
2020-05-08T21:57:52.888+0000 I  NETWORK  [conn132] received client metadata from 172.31.0.221:50306 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:53.711+0000 I  COMMAND  [conn128] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 644), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("32370e70-0c28-42ad-97da-1b6a7b6f406c") }, txnNumber: 90, autocommit: false } numYields:0 reslen:321 protocol:op_msg 219ms
2020-05-08T21:57:53.794+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50362 #133 (49 connections now open)
2020-05-08T21:57:53.795+0000 I  NETWORK  [conn133] received client metadata from 172.31.0.221:50362 conn133: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.129+0000 I  COMMAND  [conn128] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 783), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("32370e70-0c28-42ad-97da-1b6a7b6f406c") }, txnNumber: 114, autocommit: false } numYields:0 reslen:322 protocol:op_msg 210ms
2020-05-08T21:57:54.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50390 #134 (50 connections now open)
2020-05-08T21:57:54.338+0000 I  NETWORK  [conn134] received client metadata from 172.31.0.221:50390 conn134: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:54.750+0000 I  COMMAND  [conn128] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975074, 248), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("32370e70-0c28-42ad-97da-1b6a7b6f406c") }, txnNumber: 157, autocommit: false } numYields:0 reslen:322 protocol:op_msg 216ms
2020-05-08T21:57:54.913+0000 I  SHARDING [conn128] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975071, 384), t: 11 }, now { ts: Timestamp(1588975073, 2), t: 12 }
2020-05-08T21:57:55.626+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50464 #135 (51 connections now open)
2020-05-08T21:57:55.626+0000 I  NETWORK  [conn135] received client metadata from 172.31.0.221:50464 conn135: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.164+0000 I  NETWORK  [conn130] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:57:56.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.664+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:56.787+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50516 #136 (52 connections now open)
2020-05-08T21:57:56.787+0000 I  NETWORK  [conn136] received client metadata from 172.31.0.221:50516 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:56.965+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50534 #137 (53 connections now open)
2020-05-08T21:57:56.965+0000 I  NETWORK  [conn137] received client metadata from 172.31.0.221:50534 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:57.164+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:57:57.664+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.664+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.664+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:57:57.665+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:57.665+0000 I  COMMAND  [conn128] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975075, 97), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("32370e70-0c28-42ad-97da-1b6a7b6f406c") }, txnNumber: 200, autocommit: false } numYields:0 reslen:440 protocol:op_msg 2504ms
2020-05-08T21:57:58.318+0000 I  NETWORK  [conn129] end connection 172.31.0.221:50240 (52 connections now open)
2020-05-08T21:57:58.319+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50614 #139 (53 connections now open)
2020-05-08T21:57:58.319+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50616 #140 (54 connections now open)
2020-05-08T21:57:58.320+0000 I  NETWORK  [conn140] received client metadata from 172.31.0.221:50616 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.320+0000 I  NETWORK  [conn139] received client metadata from 172.31.0.221:50614 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.332+0000 I  NETWORK  [conn140] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:57:58.333+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.372+0000 I  CONNPOOL [conn130] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:57:58.372+0000 I  COMMAND  [conn130] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 532), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("fdb0020e-877f-4fb1-952e-8388dde96a08") }, txnNumber: 74, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:57:58.372+0000 I  NETWORK  [conn130] end connection 172.31.0.221:50242 (53 connections now open)
2020-05-08T21:57:58.378+0000 I  NETWORK  [conn116] end connection 172.31.0.221:50132 (52 connections now open)
2020-05-08T21:57:58.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50654 #142 (53 connections now open)
2020-05-08T21:57:58.379+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50656 #143 (54 connections now open)
2020-05-08T21:57:58.379+0000 I  NETWORK  [conn142] received client metadata from 172.31.0.221:50654 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.379+0000 I  NETWORK  [conn143] received client metadata from 172.31.0.221:50656 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.381+0000 I  NETWORK  [conn127] end connection 172.31.0.221:50228 (53 connections now open)
2020-05-08T21:57:58.382+0000 I  NETWORK  [conn128] end connection 172.31.0.221:50230 (52 connections now open)
2020-05-08T21:57:58.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50662 #144 (53 connections now open)
2020-05-08T21:57:58.384+0000 I  NETWORK  [conn144] received client metadata from 172.31.0.221:50662 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50666 #145 (54 connections now open)
2020-05-08T21:57:58.384+0000 I  NETWORK  [conn145] received client metadata from 172.31.0.221:50666 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.387+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:58.394+0000 I  CONNPOOL [conn115] Ending connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 1 connections to that host remain open
2020-05-08T21:57:58.394+0000 I  COMMAND  [conn115] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975073, 563), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ead86487-69ca-43e0-8dc0-32da435b30cc") }, txnNumber: 77, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5011ms
2020-05-08T21:57:58.394+0000 I  NETWORK  [conn115] end connection 172.31.0.221:50130 (53 connections now open)
2020-05-08T21:57:58.614+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50716 #146 (54 connections now open)
2020-05-08T21:57:58.615+0000 I  NETWORK  [conn146] received client metadata from 172.31.0.221:50716 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:57:58.833+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.333+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:57:59.833+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.833+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:57:59.834+0000 I  TXN      [conn140] transaction parameters:{ lsid: { id: UUID("6a4a9410-a4b5-40ab-8d80-35dc5a1ba2c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 165) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1502303, timeInactiveMicros:0, 1502ms
2020-05-08T21:57:59.834+0000 I  COMMAND  [conn140] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 165), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6a4a9410-a4b5-40ab-8d80-35dc5a1ba2c2") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 1502ms
2020-05-08T21:57:59.876+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50746 #147 (55 connections now open)
2020-05-08T21:57:59.877+0000 I  NETWORK  [conn147] received client metadata from 172.31.0.221:50746 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:00.165+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.165+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.166+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975073, 2), t: 12 }, now { ts: Timestamp(1588975079, 310), t: 13 }
2020-05-08T21:58:00.828+0000 I  COMMAND  [conn140] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975079, 309), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6a4a9410-a4b5-40ab-8d80-35dc5a1ba2c2") }, txnNumber: 2, autocommit: false } numYields:0 reslen:396 protocol:op_msg 992ms
2020-05-08T21:58:00.889+0000 I  NETWORK  [conn145] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:00.889+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:00.893+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:00.992+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:00.992+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:01.242+0000 I  COMMAND  [conn142] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 191), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f01af62-dadf-4ddc-8007-e4323f553f86") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 2861ms
2020-05-08T21:58:01.269+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.389+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:01.889+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.889+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:01.890+0000 I  TXN      [conn140] transaction parameters:{ lsid: { id: UUID("6a4a9410-a4b5-40ab-8d80-35dc5a1ba2c2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975079, 310) } }, globalReadTimestamp:{ ts: Timestamp(1588975080, 9) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1061897, timeInactiveMicros:0, 1061ms
2020-05-08T21:58:01.891+0000 I  COMMAND  [conn140] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975080, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6a4a9410-a4b5-40ab-8d80-35dc5a1ba2c2") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975079, 310) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1062ms
2020-05-08T21:58:01.901+0000 I  NETWORK  [conn142] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:01.901+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.389+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:02.889+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.332+0000 I  NETWORK  [conn139] end connection 172.31.0.221:50614 (54 connections now open)
2020-05-08T21:58:03.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50874 #148 (55 connections now open)
2020-05-08T21:58:03.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50876 #149 (56 connections now open)
2020-05-08T21:58:03.333+0000 I  NETWORK  [conn148] received client metadata from 172.31.0.221:50874 conn148: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.333+0000 I  NETWORK  [conn149] received client metadata from 172.31.0.221:50876 conn149: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.335+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.382+0000 I  NETWORK  [conn144] end connection 172.31.0.221:50662 (55 connections now open)
2020-05-08T21:58:03.383+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50910 #150 (56 connections now open)
2020-05-08T21:58:03.383+0000 I  NETWORK  [conn150] received client metadata from 172.31.0.221:50910 conn150: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.383+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50912 #151 (57 connections now open)
2020-05-08T21:58:03.384+0000 I  NETWORK  [conn151] received client metadata from 172.31.0.221:50912 conn151: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:03.385+0000 I  NETWORK  [conn151] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:03.385+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.385+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:03.386+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:03.386+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.387+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:03.389+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.390+0000 I  -        [conn145] operation was interrupted because a client disconnected
2020-05-08T21:58:03.391+0000 I  TXN      [conn145] transaction parameters:{ lsid: { id: UUID("6151aaf1-5943-4bad-a9aa-9674f40c7f2b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975078, 191) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003849, timeInactiveMicros:0, 5003ms
2020-05-08T21:58:03.391+0000 I  COMMAND  [conn145] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 272 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975078, 191), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6151aaf1-5943-4bad-a9aa-9674f40c7f2b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5003ms
2020-05-08T21:58:03.391+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.391+0000 I  NETWORK  [conn145] end connection 172.31.0.221:50666 (56 connections now open)
2020-05-08T21:58:03.552+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:03.889+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:03.898+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.119+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975080, 9), t: 13 }, now { ts: Timestamp(1588975082, 1), t: 15 }
2020-05-08T21:58:04.389+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:04.889+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.889+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:04.890+0000 I  COMMAND  [conn140] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975081, 117), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6a4a9410-a4b5-40ab-8d80-35dc5a1ba2c2") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 2998ms
2020-05-08T21:58:04.891+0000 I  NETWORK  [conn140] end connection 172.31.0.221:50616 (55 connections now open)
2020-05-08T21:58:04.891+0000 I  TXN      [conn142] transaction parameters:{ lsid: { id: UUID("4f01af62-dadf-4ddc-8007-e4323f553f86"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 24) }, numParticipants:2, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3623242, timeInactiveMicros:267, 3623ms
2020-05-08T21:58:04.891+0000 I  COMMAND  [conn142] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 25), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f01af62-dadf-4ddc-8007-e4323f553f86") }, txnNumber: 4, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 3622ms
2020-05-08T21:58:04.899+0000 I  NETWORK  [conn142] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:04.899+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:05.399+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:05.899+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:05.944+0000 I  COMMAND  [conn151] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 284 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975083, 67), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c81f99a8-102b-4570-856a-3c6d6d4140d2") }, txnNumber: 3, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 2046ms
2020-05-08T21:58:05.945+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.946+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:05.946+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:05.946+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.947+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:05.947+0000 I  COMMAND  [conn142] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975084, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f01af62-dadf-4ddc-8007-e4323f553f86") }, txnNumber: 4, autocommit: false } numYields:0 reslen:544 protocol:op_msg 1054ms
2020-05-08T21:58:05.952+0000 I  TXN      [conn148] transaction parameters:{ lsid: { id: UUID("f5fe904f-5d2f-4bf9-8c0a-068c41acba47"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975081, 127) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:2618298, timeInactiveMicros:0, 2618ms
2020-05-08T21:58:05.953+0000 I  COMMAND  [conn148] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975081, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f5fe904f-5d2f-4bf9-8c0a-068c41acba47") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 2618ms
2020-05-08T21:58:05.967+0000 I  TXN      [conn151] transaction parameters:{ lsid: { id: UUID("c81f99a8-102b-4570-856a-3c6d6d4140d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975083, 67) }, numParticipants:2, terminationCause:committed, commitType:readOnly, commitDurationMicros:19125, timeActiveMicros:2068561, timeInactiveMicros:868, 2069ms
2020-05-08T21:58:05.979+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:06.268+0000 I  NETWORK  [conn143] end connection 172.31.0.221:50656 (54 connections now open)
2020-05-08T21:58:06.269+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50966 #153 (55 connections now open)
2020-05-08T21:58:06.269+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:50968 #154 (56 connections now open)
2020-05-08T21:58:06.269+0000 I  NETWORK  [conn153] received client metadata from 172.31.0.221:50966 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:06.269+0000 I  NETWORK  [conn154] received client metadata from 172.31.0.221:50968 conn154: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:06.554+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.555+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:06.966+0000 I  NETWORK  [conn148] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:06.967+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:06.968+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:06.972+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.054+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:07.466+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:07.554+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.554+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:07.966+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.966+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:07.967+0000 I  COMMAND  [conn142] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 42), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("4f01af62-dadf-4ddc-8007-e4323f553f86") }, txnNumber: 5, autocommit: false } numYields:0 reslen:351 protocol:op_msg 1988ms
2020-05-08T21:58:07.967+0000 I  NETWORK  [conn142] end connection 172.31.0.221:50654 (55 connections now open)
2020-05-08T21:58:08.333+0000 I  NETWORK  [conn149] end connection 172.31.0.221:50876 (54 connections now open)
2020-05-08T21:58:08.333+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51032 #155 (55 connections now open)
2020-05-08T21:58:08.334+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51034 #156 (56 connections now open)
2020-05-08T21:58:08.334+0000 I  NETWORK  [conn155] received client metadata from 172.31.0.221:51032 conn155: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.334+0000 I  NETWORK  [conn156] received client metadata from 172.31.0.221:51034 conn156: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:08.563+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975082, 1), t: 15 }, now { ts: Timestamp(1588975087, 1), t: 17 }
2020-05-08T21:58:08.939+0000 I  NETWORK  [conn153] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:08.940+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.058+0000 I  TXN      [conn151] transaction parameters:{ lsid: { id: UUID("c81f99a8-102b-4570-856a-3c6d6d4140d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 4, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 33) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3083070, timeActiveMicros:3088707, timeInactiveMicros:1374, 3090ms
2020-05-08T21:58:09.059+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.061+0000 I  TXN      [conn148] transaction parameters:{ lsid: { id: UUID("f5fe904f-5d2f-4bf9-8c0a-068c41acba47"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975085, 34) } }, globalReadTimestamp:{ ts: Timestamp(1588975085, 34) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:3081522, timeActiveMicros:3091069, timeInactiveMicros:666, 3091ms
2020-05-08T21:58:09.061+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.064+0000 I  COMMAND  [conn148] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f5fe904f-5d2f-4bf9-8c0a-068c41acba47") }, txnNumber: 2, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3084ms
2020-05-08T21:58:09.064+0000 I  NETWORK  [conn148] end connection 172.31.0.221:50874 (55 connections now open)
2020-05-08T21:58:09.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:09.939+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.939+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:09.940+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975087, 1), t: 17 }, now { ts: Timestamp(1588975088, 2), t: 18 }
2020-05-08T21:58:09.940+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:09.940+0000 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975087, 217), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("617fdb10-5ebc-4d52-9689-d1255f9b35d9") }, txnNumber: 119, autocommit: false } numYields:0 reslen:471 protocol:op_msg 2533ms
2020-05-08T21:58:09.941+0000 I  COMMAND  [conn155] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975088, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6") }, txnNumber: 1, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1603ms
2020-05-08T21:58:09.941+0000 I  COMMAND  [conn151] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975085, 39), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c81f99a8-102b-4570-856a-3c6d6d4140d2") }, txnNumber: 4, autocommit: false } numYields:0 reslen:427 protocol:op_msg 3966ms
2020-05-08T21:58:10.055+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51130 #157 (56 connections now open)
2020-05-08T21:58:10.055+0000 I  NETWORK  [conn157] received client metadata from 172.31.0.221:51130 conn157: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.180+0000 I  NETWORK  [conn151] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:10.180+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.183+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.439+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.581+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.582+0000 I  NETWORK  [conn155] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:10.582+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:10.939+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:10.969+0000 I  NETWORK  [conn150] end connection 172.31.0.221:50910 (55 connections now open)
2020-05-08T21:58:10.969+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51160 #158 (56 connections now open)
2020-05-08T21:58:10.969+0000 I  NETWORK  [conn158] received client metadata from 172.31.0.221:51160 conn158: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.970+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51162 #159 (57 connections now open)
2020-05-08T21:58:10.970+0000 I  NETWORK  [conn159] received client metadata from 172.31.0.221:51162 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:10.971+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.082+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.270+0000 I  NETWORK  [conn154] end connection 172.31.0.221:50968 (56 connections now open)
2020-05-08T21:58:11.270+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51176 #160 (57 connections now open)
2020-05-08T21:58:11.271+0000 I  NETWORK  [conn160] received client metadata from 172.31.0.221:51176 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:11.272+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51184 #161 (58 connections now open)
2020-05-08T21:58:11.272+0000 I  NETWORK  [conn161] received client metadata from 172.31.0.221:51184 conn161: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:11.275+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:11.439+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.439+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.440+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.440+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:11.441+0000 I  SHARDING [conn153] Received reply from shard ec2-54-159-37-160.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975088, 2), t: 18 }, now { ts: Timestamp(1588975091, 3), t: 19 }
2020-05-08T21:58:11.441+0000 I  COMMAND  [conn153] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("617fdb10-5ebc-4d52-9689-d1255f9b35d9") }, txnNumber: 119, autocommit: false } numYields:0 reslen:547 protocol:op_msg 1498ms
2020-05-08T21:58:11.441+0000 I  NETWORK  [conn153] end connection 172.31.0.221:50966 (57 connections now open)
2020-05-08T21:58:11.443+0000 I  TXN      [conn151] transaction parameters:{ lsid: { id: UUID("c81f99a8-102b-4570-856a-3c6d6d4140d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 5, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975089, 203) } }, globalReadTimestamp:{ ts: Timestamp(1588975089, 203) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1501134, timeInactiveMicros:0, 1501ms
2020-05-08T21:58:11.443+0000 I  COMMAND  [conn151] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c81f99a8-102b-4570-856a-3c6d6d4140d2") }, txnNumber: 5, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975089, 203) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1501ms
2020-05-08T21:58:11.443+0000 I  NETWORK  [conn151] end connection 172.31.0.221:50912 (56 connections now open)
2020-05-08T21:58:11.582+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.582+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:11.583+0000 I  COMMAND  [conn155] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975089, 203), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1641ms
2020-05-08T21:58:11.593+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-35-172-222-251.compute-1.amazonaws.com:27018
2020-05-08T21:58:12.288+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51206 #163 (57 connections now open)
2020-05-08T21:58:12.288+0000 I  NETWORK  [conn163] received client metadata from 172.31.0.221:51206 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:12.366+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("510e29bf-1dfb-4c81-8354-171b2428bcd0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975090, 1) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1091850, timeInactiveMicros:0, 1091ms
2020-05-08T21:58:12.366+0000 I  COMMAND  [conn160] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975090, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("510e29bf-1dfb-4c81-8354-171b2428bcd0") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:387 protocol:op_msg 1091ms
2020-05-08T21:58:12.372+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975091, 23) } }, globalReadTimestamp:{ ts: Timestamp(1588975091, 23) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:784283, timeActiveMicros:787203, timeInactiveMicros:464, 787ms
2020-05-08T21:58:12.372+0000 I  COMMAND  [conn155] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975091, 77), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6") }, txnNumber: 2, autocommit: false } numYields:0 reslen:214 protocol:op_msg 784ms
2020-05-08T21:58:12.380+0000 I  COMMAND  [conn158] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975090, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 1409ms
2020-05-08T21:58:12.452+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:13.735+0000 I  NETWORK  [conn158] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:13.736+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.236+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.236+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:14.237+0000 I  COMMAND  [conn158] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975093, 510), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70") }, txnNumber: 52, autocommit: false } numYields:0 reslen:352 protocol:op_msg 836ms
2020-05-08T21:58:14.752+0000 I  NETWORK  [conn158] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:14.752+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:14.941+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 5310 timed out, deadline was 2020-05-08T21:58:14.941+0000, op was RemoteCommand 5310 -- target:[ec2-3-80-27-189.compute-1.amazonaws.com:27019] db:admin expDate:2020-05-08T21:58:14.941+0000 cmd:{ isMaster: 1 }
2020-05-08T21:58:14.941+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host ec2-3-80-27-189.compute-1.amazonaws.com:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-08T21:58:14.941+0000 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:15.169+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51256 #169 (58 connections now open)
2020-05-08T21:58:15.170+0000 I  NETWORK  [conn169] received client metadata from 172.31.0.221:51256 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:15.252+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:15.752+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.752+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:15.753+0000 I  TXN      [conn158] transaction parameters:{ lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 53, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975094, 92) } }, globalReadTimestamp:{ ts: Timestamp(1588975094, 92) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1515268, timeInactiveMicros:485, 1515ms
2020-05-08T21:58:15.753+0000 I  COMMAND  [conn158] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975094, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70") }, txnNumber: 53, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 1514ms
2020-05-08T21:58:16.647+0000 I  NETWORK  [conn160] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:16.648+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:16.653+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:16.764+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.764+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:16.765+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:16.765+0000 I  TXN      [conn155] transaction parameters:{ lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 58, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 508) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 508) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3367888, timeInactiveMicros:0, 3367ms
2020-05-08T21:58:16.766+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.766+0000 I  COMMAND  [conn155] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 508), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6") }, txnNumber: 58, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 508) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 3368ms
2020-05-08T21:58:16.766+0000 I  TXN      [conn160] transaction parameters:{ lsid: { id: UUID("510e29bf-1dfb-4c81-8354-171b2428bcd0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 54, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 512) } }, globalReadTimestamp:{ ts: Timestamp(1588975093, 512) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3364008, timeInactiveMicros:0, 3364ms
2020-05-08T21:58:16.766+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:16.766+0000 I  COMMAND  [conn160] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975093, 512), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("510e29bf-1dfb-4c81-8354-171b2428bcd0") }, txnNumber: 54, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975093, 512) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 3364ms
2020-05-08T21:58:16.766+0000 I  COMMAND  [conn158] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975095, 81), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70") }, txnNumber: 53, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1012ms
2020-05-08T21:58:17.366+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.472+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:17.665+0000 I  NETWORK  [conn158] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:17.665+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:17.671+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.337+0000 I  NETWORK  [conn161] end connection 172.31.0.221:51184 (57 connections now open)
2020-05-08T21:58:18.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51350 #170 (58 connections now open)
2020-05-08T21:58:18.338+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51352 #171 (59 connections now open)
2020-05-08T21:58:18.338+0000 I  NETWORK  [conn170] received client metadata from 172.31.0.221:51350 conn170: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.338+0000 I  NETWORK  [conn171] received client metadata from 172.31.0.221:51352 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.339+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.387+0000 I  NETWORK  [conn156] end connection 172.31.0.221:51034 (58 connections now open)
2020-05-08T21:58:18.388+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51386 #172 (59 connections now open)
2020-05-08T21:58:18.388+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51388 #173 (60 connections now open)
2020-05-08T21:58:18.388+0000 I  NETWORK  [conn172] received client metadata from 172.31.0.221:51386 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.388+0000 I  NETWORK  [conn173] received client metadata from 172.31.0.221:51388 conn173: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.390+0000 I  NETWORK  [conn172] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:18.390+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:18.390+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:18.396+0000 I  NETWORK  [conn159] end connection 172.31.0.221:51162 (59 connections now open)
2020-05-08T21:58:18.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51390 #174 (60 connections now open)
2020-05-08T21:58:18.396+0000 I  NETWORK  [conn174] received client metadata from 172.31.0.221:51390 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.396+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51394 #175 (61 connections now open)
2020-05-08T21:58:18.397+0000 I  NETWORK  [conn175] received client metadata from 172.31.0.221:51394 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:18.398+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:18.665+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.165+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.230+0000 I  COMMAND  [conn172] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975098, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("599de82a-8932-4233-bc73-c023756bd6ab") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 340ms
2020-05-08T21:58:19.232+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:19.366+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.366+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.371+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975093, 671), t: 19 }, now { ts: Timestamp(1588975098, 3), t: 22 }
2020-05-08T21:58:19.665+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.665+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.666+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:19.666+0000 I  COMMAND  [conn155] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 176), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ce733fab-3e4f-44bf-a14d-f8a2040242a6") }, txnNumber: 58, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2898ms
2020-05-08T21:58:19.666+0000 I  TXN      [conn158] transaction parameters:{ lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 54, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 176) } }, globalReadTimestamp:{ ts: Timestamp(1588975096, 176) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2899220, timeInactiveMicros:0, 2899ms
2020-05-08T21:58:19.666+0000 I  COMMAND  [conn158] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975096, 176), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8536ca4b-19a2-46cc-b321-844de3cada70") }, txnNumber: 54, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975096, 176) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 2899ms
2020-05-08T21:58:19.666+0000 I  NETWORK  [conn155] end connection 172.31.0.221:51032 (60 connections now open)
2020-05-08T21:58:19.667+0000 I  NETWORK  [conn158] end connection 172.31.0.221:51160 (59 connections now open)
2020-05-08T21:58:19.667+0000 I  COMMAND  [conn160] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975096, 176), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("510e29bf-1dfb-4c81-8354-171b2428bcd0") }, txnNumber: 54, autocommit: false } numYields:0 reslen:515 protocol:op_msg 2900ms
2020-05-08T21:58:19.667+0000 I  NETWORK  [conn160] end connection 172.31.0.221:51176 (58 connections now open)
2020-05-08T21:58:19.669+0000 I  COMMAND  [conn172] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 373 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975098, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("599de82a-8932-4233-bc73-c023756bd6ab") }, txnNumber: 2, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:284 protocol:op_msg 437ms
2020-05-08T21:58:19.866+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:19.866+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:20.447+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975098, 3), t: 22 }, now { ts: Timestamp(1588975100, 57), t: 23 }
2020-05-08T21:58:21.176+0000 I  NETWORK  [conn170] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:21.176+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.182+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.190+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:21.676+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.176+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:22.676+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.676+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:22.677+0000 I  TXN      [conn170] transaction parameters:{ lsid: { id: UUID("f88484a4-9b47-4f07-bed7-b0af2f1c5902"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975097, 8) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4338394, timeInactiveMicros:0, 4338ms
2020-05-08T21:58:22.677+0000 I  COMMAND  [conn170] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975097, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f88484a4-9b47-4f07-bed7-b0af2f1c5902") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 4338ms
2020-05-08T21:58:22.678+0000 I  TXN      [conn174] transaction parameters:{ lsid: { id: UUID("bab9d81f-3088-4322-8ca0-3fbfc155241a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975098, 3) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4280028, timeInactiveMicros:0, 4280ms
2020-05-08T21:58:22.678+0000 I  COMMAND  [conn174] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975098, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bab9d81f-3088-4322-8ca0-3fbfc155241a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-226-181-14.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:416 protocol:op_msg 4280ms
2020-05-08T21:58:23.229+0000 I  TXN      [conn172] transaction parameters:{ lsid: { id: UUID("599de82a-8932-4233-bc73-c023756bd6ab"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975098, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975098, 5) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:3558647, timeActiveMicros:3998204, timeInactiveMicros:1009, 3999ms
2020-05-08T21:58:23.230+0000 I  NETWORK  [conn172] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.230+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.235+0000 I  NETWORK  [conn174] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:23.236+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.236+0000 I  NETWORK  [conn170] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:23.236+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.338+0000 I  NETWORK  [conn171] end connection 172.31.0.221:51352 (57 connections now open)
2020-05-08T21:58:23.339+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51496 #178 (58 connections now open)
2020-05-08T21:58:23.339+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51498 #179 (59 connections now open)
2020-05-08T21:58:23.339+0000 I  NETWORK  [conn178] received client metadata from 172.31.0.221:51496 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.339+0000 I  NETWORK  [conn179] received client metadata from 172.31.0.221:51498 conn179: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.340+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.388+0000 I  NETWORK  [conn173] end connection 172.31.0.221:51388 (58 connections now open)
2020-05-08T21:58:23.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51512 #180 (59 connections now open)
2020-05-08T21:58:23.389+0000 I  NETWORK  [conn180] received client metadata from 172.31.0.221:51512 conn180: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.389+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51514 #181 (60 connections now open)
2020-05-08T21:58:23.389+0000 I  NETWORK  [conn181] received client metadata from 172.31.0.221:51514 conn181: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.390+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.397+0000 I  NETWORK  [conn175] end connection 172.31.0.221:51394 (59 connections now open)
2020-05-08T21:58:23.397+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51516 #182 (60 connections now open)
2020-05-08T21:58:23.397+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51518 #183 (61 connections now open)
2020-05-08T21:58:23.397+0000 I  NETWORK  [conn182] received client metadata from 172.31.0.221:51516 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.397+0000 I  NETWORK  [conn183] received client metadata from 172.31.0.221:51518 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:23.398+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.730+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.730+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:23.736+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:23.846+0000 I  NETWORK  [conn183] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:23.847+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:23.940+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:23.941+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.230+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.236+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.384+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:24.385+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.440+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:24.682+0000 I  COMMAND  [conn172] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975099, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("599de82a-8932-4233-bc73-c023756bd6ab") }, txnNumber: 2, autocommit: false } numYields:0 reslen:494 protocol:op_msg 5011ms
2020-05-08T21:58:24.682+0000 I  NETWORK  [conn172] end connection 172.31.0.221:51386 (60 connections now open)
2020-05-08T21:58:24.730+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:24.736+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:24.940+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:24.940+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.069+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.070+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.230+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.230+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:25.231+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.231+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1832969, timeInactiveMicros:0, 1832ms
2020-05-08T21:58:25.231+0000 I  COMMAND  [conn183] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1833ms
2020-05-08T21:58:25.236+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.259+0000 I  NETWORK  [conn178] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:25.259+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.264+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.440+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:25.730+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:25.736+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:25.940+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:25.940+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:26.152+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975101, 92), t: 23 }, now { ts: Timestamp(1588975105, 10), t: 26 }
2020-05-08T21:58:26.230+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.230+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.231+0000 I  COMMAND  [conn183] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975105, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 999ms
2020-05-08T21:58:26.236+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.236+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:26.237+0000 I  COMMAND  [conn174] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975102, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("bab9d81f-3088-4322-8ca0-3fbfc155241a") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3558ms
2020-05-08T21:58:26.237+0000 I  COMMAND  [conn170] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975102, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f88484a4-9b47-4f07-bed7-b0af2f1c5902") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3558ms
2020-05-08T21:58:26.237+0000 I  NETWORK  [conn174] end connection 172.31.0.221:51390 (59 connections now open)
2020-05-08T21:58:26.237+0000 I  NETWORK  [conn170] end connection 172.31.0.221:51350 (58 connections now open)
2020-05-08T21:58:26.376+0000 I  COMMAND  [conn183] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975106, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 144ms
2020-05-08T21:58:26.478+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:SnapshotTooOld, timeActiveMicros:3087863, timeInactiveMicros:0, 3087ms
2020-05-08T21:58:26.478+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction b97b7ce8-0d6a-4e27-91c5-e714d794626a:1 was aborted on statement 0 due to: a non-retryable snapshot error :: caused by :: Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Read timestamp Timestamp(1588975102, 8) is older than the oldest available timestamp." errName:SnapshotTooOld errCode:239 reslen:590 protocol:op_msg 3087ms
2020-05-08T21:58:26.490+0000 I  COMMAND  [conn178] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 378 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975102, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 3150ms
2020-05-08T21:58:26.496+0000 I  COMMAND  [conn183] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975106, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 120ms
2020-05-08T21:58:26.498+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975102, 8) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:3157799, timeInactiveMicros:525, 3158ms
2020-05-08T21:58:26.505+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975106, 8) } }, globalReadTimestamp:{ ts: Timestamp(1588975106, 8) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:7298, timeActiveMicros:128579, timeInactiveMicros:791, 129ms
2020-05-08T21:58:26.830+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.325+0000 I  NETWORK  [conn178] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:28.326+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.330+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:28.826+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.826+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:28.828+0000 I  COMMAND  [conn180] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 457), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 43, autocommit: false } numYields:0 reslen:352 protocol:op_msg 1467ms
2020-05-08T21:58:28.832+0000 I  TXN      [conn178] transaction parameters:{ lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 33, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 354) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 354) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1554558, timeActiveMicros:1556862, timeInactiveMicros:629, 1557ms
2020-05-08T21:58:28.832+0000 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 362), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1") }, txnNumber: 33, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1554ms
2020-05-08T21:58:28.833+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 37, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975107, 418) } }, globalReadTimestamp:{ ts: Timestamp(1588975107, 418) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:twoPhaseCommit, commitDurationMicros:1504192, timeActiveMicros:1511455, timeInactiveMicros:698, 1512ms
2020-05-08T21:58:28.833+0000 I  COMMAND  [conn183] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975107, 424), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 37, autocommit: false } numYields:0 reslen:428 protocol:op_msg 1504ms
2020-05-08T21:58:29.737+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 654), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1") }, txnNumber: 65, autocommit: false } numYields:0 reslen:321 protocol:op_msg 209ms
2020-05-08T21:58:29.738+0000 I  COMMAND  [conn180] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 659), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 74, autocommit: false } numYields:0 reslen:352 protocol:op_msg 209ms
2020-05-08T21:58:29.740+0000 I  COMMAND  [conn183] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975109, 659), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 76, autocommit: false } numYields:0 reslen:321 protocol:op_msg 211ms
2020-05-08T21:58:30.245+0000 I  NETWORK  [conn180] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.246+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.247+0000 I  NETWORK  [conn178] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:30.247+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:30.745+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.745+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:30.746+0000 I  COMMAND  [conn180] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 311), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 100, autocommit: false } numYields:0 reslen:322 protocol:op_msg 520ms
2020-05-08T21:58:30.747+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 311), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1") }, txnNumber: 95, autocommit: false } numYields:0 reslen:439 protocol:op_msg 520ms
2020-05-08T21:58:31.255+0000 I  COMMAND  [conn178] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 466), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1") }, txnNumber: 95, autocommit: false } numYields:0 reslen:397 protocol:op_msg 507ms
2020-05-08T21:58:31.260+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 491 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975110, 465), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 101, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 465) }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:341 protocol:op_msg 513ms
2020-05-08T21:58:31.264+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 101, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975110, 465) } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 465) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:517438, timeInactiveMicros:626, 518ms
2020-05-08T21:58:31.277+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 103, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975110, 289) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:1064763, timeActiveMicros:1067230, timeInactiveMicros:1545, 1068ms
2020-05-08T21:58:31.277+0000 I  COMMAND  [conn183] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975110, 295), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 103, autocommit: false } numYields:0 reslen:214 protocol:op_msg 1064ms
2020-05-08T21:58:31.394+0000 I  NETWORK  [conn178] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:31.396+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.396+0000 I  NETWORK  [conn180] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:31.397+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:31.894+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:32.394+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.394+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:32.395+0000 I  COMMAND  [conn180] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 503 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 175), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 106, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1005ms
2020-05-08T21:58:33.834+0000 I  NETWORK  [conn179] end connection 172.31.0.221:51498 (57 connections now open)
2020-05-08T21:58:33.835+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51692 #185 (58 connections now open)
2020-05-08T21:58:33.835+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51694 #186 (59 connections now open)
2020-05-08T21:58:33.835+0000 I  NETWORK  [conn185] received client metadata from 172.31.0.221:51692 conn185: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:33.835+0000 I  NETWORK  [conn186] received client metadata from 172.31.0.221:51694 conn186: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:33.836+0000 I  SHARDING [conn185] Received reply from shard ec2-54-226-181-14.compute-1.amazonaws.com:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975111, 187), t: 26 }, now { ts: Timestamp(1588975113, 1), t: 27 }
2020-05-08T21:58:33.840+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:33.914+0000 I  NETWORK  [conn183] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:33.915+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:34.415+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.415+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:34.416+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 111, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 177) } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 177) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3022697, timeInactiveMicros:0, 3022ms
2020-05-08T21:58:34.416+0000 I  COMMAND  [conn183] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975111, 177), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 111, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975111, 177) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:415 protocol:op_msg 3022ms
2020-05-08T21:58:34.738+0000 I  NETWORK  [conn185] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:34.739+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.740+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:34.745+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.238+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.296+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:35.296+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.297+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:35.738+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:35.744+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.172+0000 I  NETWORK  [conn183] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:36.173+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.238+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.305+0000 I  NETWORK  [conn182] end connection 172.31.0.221:51516 (58 connections now open)
2020-05-08T21:58:36.305+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51760 #188 (59 connections now open)
2020-05-08T21:58:36.305+0000 I  NETWORK  [conn188] received client metadata from 172.31.0.221:51760 conn188: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.306+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51762 #189 (60 connections now open)
2020-05-08T21:58:36.306+0000 I  NETWORK  [conn189] received client metadata from 172.31.0.221:51762 conn189: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.307+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.348+0000 I  COMMAND  [conn178] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975111, 109), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("feb0c59b-98df-43e7-88e4-e9ae30c4a4e1") }, txnNumber: 99, autocommit: false } numYields:0 ok:0 errMsg:"operation exceeded time limit" errName:MaxTimeMSExpired errCode:50 reslen:246 protocol:op_msg 5010ms
2020-05-08T21:58:36.348+0000 I  NETWORK  [conn178] end connection 172.31.0.221:51496 (59 connections now open)
2020-05-08T21:58:36.380+0000 I  NETWORK  [conn181] end connection 172.31.0.221:51514 (58 connections now open)
2020-05-08T21:58:36.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51812 #190 (59 connections now open)
2020-05-08T21:58:36.381+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:51814 #191 (60 connections now open)
2020-05-08T21:58:36.381+0000 I  NETWORK  [conn190] received client metadata from 172.31.0.221:51812 conn190: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.381+0000 I  NETWORK  [conn191] received client metadata from 172.31.0.221:51814 conn191: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:36.383+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:36.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:36.739+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.739+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:36.739+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:36.740+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.740+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:36.742+0000 I  COMMAND  [conn191] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 359ms
2020-05-08T21:58:36.750+0000 I  TXN      [conn180] transaction parameters:{ lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 106, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975111, 164) }, numParticipants:2, terminationCause:committed, commitType:singleWriteShard, commitDurationMicros:4352457, timeActiveMicros:5369400, timeInactiveMicros:1293, 5370ms
2020-05-08T21:58:36.750+0000 I  COMMAND  [conn180] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975112, 23), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b97b7ce8-0d6a-4e27-91c5-e714d794626a") }, txnNumber: 106, autocommit: false } numYields:0 reslen:214 protocol:op_msg 4352ms
2020-05-08T21:58:36.751+0000 I  NETWORK  [conn180] end connection 172.31.0.221:51512 (59 connections now open)
2020-05-08T21:58:36.751+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975113, 14) }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:2910837, timeActiveMicros:2912755, timeInactiveMicros:816, 2913ms
2020-05-08T21:58:36.754+0000 I  COMMAND  [conn185] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975113, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 2914ms
2020-05-08T21:58:36.756+0000 I  COMMAND  [conn189] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975116, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065") } } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:232 protocol:op_msg 449ms
2020-05-08T21:58:36.757+0000 I  TXN      [conn191] transaction parameters:{ lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975116, 2) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:8607, timeActiveMicros:373821, timeInactiveMicros:1058, 374ms
2020-05-08T21:58:37.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.201+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.202+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.240+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.618+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.672+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:37.740+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:37.856+0000 I  NETWORK  [conn185] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:37.856+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:37.861+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:38.172+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:38.356+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.356+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.357+0000 I  TXN      [conn191] transaction parameters:{ lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 93, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 632) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 632) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:509087, timeInactiveMicros:0, 509ms
2020-05-08T21:58:38.358+0000 I  COMMAND  [conn191] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 632), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 93, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 632) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:423 protocol:op_msg 509ms
2020-05-08T21:58:38.358+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 38, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 242) } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 242) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1071648, timeInactiveMicros:0, 1071ms
2020-05-08T21:58:38.358+0000 I  COMMAND  [conn185] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 242), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 38, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975117, 242) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-3-82-35-209.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:414 protocol:op_msg 1071ms
2020-05-08T21:58:38.396+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.396+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:38.397+0000 I  TXN      [conn183] transaction parameters:{ lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 112, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 5) } }, globalReadTimestamp:{ ts: Timestamp(1588975114, 5) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3974169, timeInactiveMicros:0, 3974ms
2020-05-08T21:58:38.397+0000 I  COMMAND  [conn183] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975114, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("75cf2dd2-95c5-464a-87bd-4bf303bea116") }, txnNumber: 112, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975114, 5) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 3974ms
2020-05-08T21:58:38.397+0000 I  NETWORK  [conn183] end connection 172.31.0.221:51518 (58 connections now open)
2020-05-08T21:58:38.448+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.448+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:38.513+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-54-221-21-21.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.514+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.514+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:38.517+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:38.856+0000 I  COMMAND  [conn189] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 518 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975117, 498), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065") }, txnNumber: 62, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1238ms
2020-05-08T21:58:38.862+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 39, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 9) } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 9) }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:496969, timeInactiveMicros:0, 496ms
2020-05-08T21:58:38.862+0000 I  COMMAND  [conn185] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 39, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975118, 9) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:386 protocol:op_msg 497ms
2020-05-08T21:58:38.863+0000 I  TXN      [conn189] transaction parameters:{ lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 62, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975117, 499) }, numParticipants:2, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:1245214, timeInactiveMicros:488, 1245ms
2020-05-08T21:58:38.873+0000 I  COMMAND  [conn191] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 521 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975118, 32), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 97, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 477ms
2020-05-08T21:58:38.883+0000 I  TXN      [conn191] transaction parameters:{ lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 97, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975118, 32) }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:8249, timeActiveMicros:486799, timeInactiveMicros:508, 487ms
2020-05-08T21:58:39.240+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.240+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:39.358+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975113, 1), t: 27 }, now { ts: Timestamp(1588975119, 1), t: 30 }
2020-05-08T21:58:40.535+0000 I  NETWORK  [conn189] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:40.536+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:40.542+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.036+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:41.536+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.536+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:41.538+0000 I  COMMAND  [conn185] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1000), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 83, autocommit: false } numYields:0 reslen:439 protocol:op_msg 1846ms
2020-05-08T21:58:41.712+0000 I  NETWORK  [conn191] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:41.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.052+0000 I  TXN      [conn189] transaction parameters:{ lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 108, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975119, 1019) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2340136, timeActiveMicros:2344098, timeInactiveMicros:920, 2345ms
2020-05-08T21:58:42.053+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.056+0000 I  NETWORK  [conn185] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:42.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.057+0000 I  NETWORK  [conn189] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-08T21:58:42.057+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:42.556+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:42.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.030+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T21:58:43.031+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:43.038+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:43.056+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.056+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:43.057+0000 I  COMMAND  [conn185] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975121, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 83, autocommit: false } numYields:0 reslen:515 protocol:op_msg 1518ms
2020-05-08T21:58:43.213+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:43.713+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:44.057+0000 I  COMMAND  [conn185] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975123, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 84, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975123, 4) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 999ms
2020-05-08T21:58:44.058+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.058+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:44.058+0000 I  COMMAND  [conn189] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975119, 1026), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065") }, txnNumber: 108, autocommit: false } numYields:0 reslen:497 protocol:op_msg 4346ms
2020-05-08T21:58:44.059+0000 I  COMMAND  [conn191] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975120, 344), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 263, autocommit: false } numYields:0 reslen:440 protocol:op_msg 3349ms
2020-05-08T21:58:44.179+0000 I  COMMAND  [conn189] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065") }, txnNumber: 108, autocommit: false } numYields:0 reslen:430 protocol:op_msg 119ms
2020-05-08T21:58:44.179+0000 I  COMMAND  [conn191] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 263, autocommit: false } numYields:0 reslen:399 protocol:op_msg 119ms
2020-05-08T21:58:44.206+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 84, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975123, 4) } }, globalReadTimestamp:{ ts: Timestamp(1588975123, 4) }, numParticipants:2, coordinator:rs_shard2, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:145389, timeActiveMicros:1147006, timeInactiveMicros:1069, 1148ms
2020-05-08T21:58:44.206+0000 I  COMMAND  [conn185] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 84, autocommit: false } numYields:0 reslen:214 protocol:op_msg 145ms
2020-05-08T21:58:44.800+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.801+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.864+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.864+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.928+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.929+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:44.992+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:44.992+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.300+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.427+0000 I  NETWORK  [conn191] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:45.428+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.429+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:45.800+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:45.927+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.079+0000 I  NETWORK  [conn185] Marking host ec2-54-159-37-160.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:46.080+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:46.300+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.425+0000 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb5d5b96b7369da8ea76060 to 5eb5d5b9883dd86ab8e095b5; invalidating user cache
2020-05-08T21:58:46.427+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:46.580+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.580+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:46.581+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:46.581+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 340, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975126, 16) } }, globalReadTimestamp:{ ts: Timestamp(1588975126, 16) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:502220, timeInactiveMicros:0, 502ms
2020-05-08T21:58:46.581+0000 I  COMMAND  [conn185] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975126, 16), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 340, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975126, 16) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-159-37-160.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:379 protocol:op_msg 502ms
2020-05-08T21:58:46.800+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.800+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.800+0000 I  SHARDING [Sharding-Fixed-6] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:46.801+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975119, 1), t: 30 }, now { ts: Timestamp(1588975126, 23), t: 33 }
2020-05-08T21:58:46.927+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.086+0000 I  NETWORK  [conn185] Marking host ec2-54-226-181-14.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:47.087+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:47.300+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.300+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:47.427+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:47.518+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:47.586+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-08T21:58:47.927+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.086+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.086+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.087+0000 I  COMMAND  [conn185] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975126, 18), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 340, autocommit: false } numYields:0 reslen:516 protocol:op_msg 1505ms
2020-05-08T21:58:48.104+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.160+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-221-21-21.compute-1.amazonaws.com:27019 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:48.428+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.428+0000 I  SHARDING [Sharding-Fixed-7] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:48.429+0000 I  COMMAND  [conn189] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 392), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065") }, txnNumber: 120, autocommit: false } numYields:0 reslen:353 protocol:op_msg 4016ms
2020-05-08T21:58:48.431+0000 I  COMMAND  [conn185] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 599 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 342, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:339 protocol:op_msg 327ms
2020-05-08T21:58:48.468+0000 I  TXN      [conn191] transaction parameters:{ lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 277, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975124, 387) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:readOnly, commitDurationMicros:4044195, timeActiveMicros:4059631, timeInactiveMicros:699, 4060ms
2020-05-08T21:58:48.468+0000 I  NETWORK  [conn189] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:48.469+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.475+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:48.927+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:49.107+0000 I  NETWORK  [conn185] Marking host ec2-3-82-35-209.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: Coordinator 92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8:342 stopped due to: Transaction coordinator service stepping down
2020-05-08T21:58:49.108+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.108+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.342+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T21:58:49.342+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:49.343+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:49.369+0000 I  NETWORK  [conn188] end connection 172.31.0.221:51760 (57 connections now open)
2020-05-08T21:58:49.370+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52038 #194 (58 connections now open)
2020-05-08T21:58:49.371+0000 I  NETWORK  [conn194] received client metadata from 172.31.0.221:52038 conn194: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52040 #195 (59 connections now open)
2020-05-08T21:58:49.371+0000 I  NETWORK  [conn195] received client metadata from 172.31.0.221:52040 conn195: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.372+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.372+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:49.373+0000 I  TXN      [conn189] transaction parameters:{ lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 121, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 12) } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 12) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:943483, timeInactiveMicros:0, 943ms
2020-05-08T21:58:49.373+0000 I  COMMAND  [conn189] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975128, 12), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("2acaeb7f-fbf3-4f10-8820-3c9fc0e29065") }, txnNumber: 121, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 12) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 943ms
2020-05-08T21:58:49.373+0000 I  COMMAND  [conn191] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975124, 408), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 277, autocommit: false } numYields:0 reslen:466 protocol:op_msg 4949ms
2020-05-08T21:58:49.373+0000 I  NETWORK  [conn189] end connection 172.31.0.221:51762 (58 connections now open)
2020-05-08T21:58:49.408+0000 I  NETWORK  [conn190] end connection 172.31.0.221:51812 (57 connections now open)
2020-05-08T21:58:49.408+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52062 #196 (58 connections now open)
2020-05-08T21:58:49.408+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52064 #197 (59 connections now open)
2020-05-08T21:58:49.408+0000 I  NETWORK  [conn196] received client metadata from 172.31.0.221:52062 conn196: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.408+0000 I  NETWORK  [conn197] received client metadata from 172.31.0.221:52064 conn197: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.410+0000 I  NETWORK  [conn186] end connection 172.31.0.221:51694 (58 connections now open)
2020-05-08T21:58:49.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52066 #198 (59 connections now open)
2020-05-08T21:58:49.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52068 #199 (60 connections now open)
2020-05-08T21:58:49.411+0000 I  NETWORK  [conn198] received client metadata from 172.31.0.221:52066 conn198: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.411+0000 I  NETWORK  [conn199] received client metadata from 172.31.0.221:52068 conn199: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:49.588+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.589+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:49.952+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:49.953+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.088+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.144+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:50.144+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.449+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.588+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:50.655+0000 I  COMMAND  [conn198] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 607 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d494951e-ef69-4bea-9763-9225a3c5ffc6") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:0 reslen:253 protocol:op_msg 1243ms
2020-05-08T21:58:50.657+0000 I  CONNPOOL [conn191] Ending connection to host ec2-35-172-222-251.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-08T21:58:50.661+0000 I  COMMAND  [conn191] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority", wtimeout: 10000 }, maxTimeMS: 5000, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975129, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("319096fd-cb5d-4d0b-88a2-d5608b69efc7") }, txnNumber: 277, autocommit: false } numYields:0 reslen:399 protocol:op_msg 1286ms
2020-05-08T21:58:50.661+0000 I  NETWORK  [conn191] end connection 172.31.0.221:51814 (59 connections now open)
2020-05-08T21:58:50.755+0000 I  NETWORK  [conn198] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:50.755+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.758+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:50.763+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:51.088+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:51.255+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.255+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:51.256+0000 I  TXN      [conn196] transaction parameters:{ lsid: { id: UUID("d2f1da63-060e-448f-b635-521438bbf15c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 7) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1846354, timeInactiveMicros:0, 1846ms
2020-05-08T21:58:51.256+0000 I  COMMAND  [conn196] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d2f1da63-060e-448f-b635-521438bbf15c") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1846ms
2020-05-08T21:58:51.256+0000 I  TXN      [conn195] transaction parameters:{ lsid: { id: UUID("0baa230e-1d50-4ea7-9626-10b2da21e471"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 1) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1884496, timeInactiveMicros:0, 1884ms
2020-05-08T21:58:51.256+0000 I  COMMAND  [conn195] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975129, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0baa230e-1d50-4ea7-9626-10b2da21e471") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-35-172-222-251.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 1884ms
2020-05-08T21:58:51.588+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.588+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.589+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-107-21-173-199.compute-1.amazonaws.com:27019
2020-05-08T21:58:51.843+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 5 connections to that host remain open
2020-05-08T21:58:51.844+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 4 connections to that host remain open
2020-05-08T21:58:51.852+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 3 connections to that host remain open
2020-05-08T21:58:51.873+0000 I  TXN      [conn198] transaction parameters:{ lsid: { id: UUID("d494951e-ef69-4bea-9763-9225a3c5ffc6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975129, 7) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:1214817, timeActiveMicros:2460100, timeInactiveMicros:1284, 2461ms
2020-05-08T21:58:51.873+0000 I  COMMAND  [conn195] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0baa230e-1d50-4ea7-9626-10b2da21e471") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 616ms
2020-05-08T21:58:51.874+0000 I  COMMAND  [conn198] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975130, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d494951e-ef69-4bea-9763-9225a3c5ffc6") }, txnNumber: 1, autocommit: false } numYields:0 reslen:427 protocol:op_msg 1215ms
2020-05-08T21:58:51.876+0000 I  COMMAND  [conn196] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 30), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d2f1da63-060e-448f-b635-521438bbf15c") }, txnNumber: 1, autocommit: false } numYields:0 reslen:396 protocol:op_msg 618ms
2020-05-08T21:58:51.897+0000 I  TXN      [conn185] transaction parameters:{ lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 342, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975128, 7) } }, globalReadTimestamp:{ ts: Timestamp(1588975128, 7) }, numParticipants:2, coordinator:rs_shard1, terminationCause:committed, commitType:twoPhaseCommit, commitDurationMicros:3464533, timeActiveMicros:3793384, timeInactiveMicros:1058, 3794ms
2020-05-08T21:58:51.897+0000 I  COMMAND  [conn185] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard1" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975128, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("92d60b2e-e09b-4f45-b4fc-08a1c01ab1f8") }, txnNumber: 342, autocommit: false } numYields:0 reslen:214 protocol:op_msg 3464ms
2020-05-08T21:58:51.897+0000 I  NETWORK  [conn185] end connection 172.31.0.221:51692 (58 connections now open)
2020-05-08T21:58:51.959+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:58:52.117+0000 I  NETWORK  [replSetDistLockPinger] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.899+0000 I  NETWORK  [conn196] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.900+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:52.902+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:52.904+0000 I  NETWORK  [conn198] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:52.904+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:52.928+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.928+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:52.928+0000 I  CONNPOOL [ShardRegistry] Connecting to ec2-3-80-27-189.compute-1.amazonaws.com:27019
2020-05-08T21:58:53.400+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.400+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:53.401+0000 I  COMMAND  [conn195] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 89), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0baa230e-1d50-4ea7-9626-10b2da21e471") }, txnNumber: 3, autocommit: false } numYields:0 reslen:438 protocol:op_msg 1501ms
2020-05-08T21:58:53.930+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.930+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.931+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.932+0000 E  SHARDING [UpdateReplicaSetOnConfigServer] RSChangeWatcher: could not update config db with connection string rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018 :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:53.933+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:53.941+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:58:54.371+0000 I  NETWORK  [conn194] end connection 172.31.0.221:52038 (57 connections now open)
2020-05-08T21:58:54.371+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52272 #204 (58 connections now open)
2020-05-08T21:58:54.371+0000 I  NETWORK  [conn204] received client metadata from 172.31.0.221:52272 conn204: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52274 #205 (59 connections now open)
2020-05-08T21:58:54.372+0000 I  NETWORK  [conn205] received client metadata from 172.31.0.221:52274 conn205: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.408+0000 I  NETWORK  [conn197] end connection 172.31.0.221:52064 (58 connections now open)
2020-05-08T21:58:54.409+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52284 #206 (59 connections now open)
2020-05-08T21:58:54.409+0000 I  NETWORK  [conn206] received client metadata from 172.31.0.221:52284 conn206: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.409+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52286 #207 (60 connections now open)
2020-05-08T21:58:54.409+0000 I  NETWORK  [conn207] received client metadata from 172.31.0.221:52286 conn207: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.411+0000 I  NETWORK  [conn199] end connection 172.31.0.221:52068 (59 connections now open)
2020-05-08T21:58:54.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52288 #208 (60 connections now open)
2020-05-08T21:58:54.411+0000 I  NETWORK  [conn208] received client metadata from 172.31.0.221:52288 conn208: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52290 #209 (61 connections now open)
2020-05-08T21:58:54.411+0000 I  NETWORK  [conn209] received client metadata from 172.31.0.221:52290 conn209: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:54.433+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.433+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:54.434+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975126, 24), t: 33 }, now { ts: Timestamp(1588975134, 4), t: 38 }
2020-05-08T21:58:54.606+0000 I  TXN      [conn196] transaction parameters:{ lsid: { id: UUID("d2f1da63-060e-448f-b635-521438bbf15c"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 49) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 53) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2721311, timeActiveMicros:2728290, timeInactiveMicros:1176, 2729ms
2020-05-08T21:58:54.606+0000 I  NETWORK  [conn204] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:54.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.608+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.610+0000 I  TXN      [conn198] transaction parameters:{ lsid: { id: UUID("d494951e-ef69-4bea-9763-9225a3c5ffc6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975131, 53) } }, globalReadTimestamp:{ ts: Timestamp(1588975131, 53) }, numParticipants:2, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleWriteShard, commitDurationMicros:2722868, timeActiveMicros:2732727, timeInactiveMicros:2229, 2734ms
2020-05-08T21:58:54.610+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:54.615+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.106+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.106+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.107+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-34-207-119-213.compute-1.amazonaws.com:27018
2020-05-08T21:58:55.108+0000 I  COMMAND  [conn195] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, recoveryToken: {}, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975133, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0baa230e-1d50-4ea7-9626-10b2da21e471") }, txnNumber: 3, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1706ms
2020-05-08T21:58:55.108+0000 I  NETWORK  [conn195] end connection 172.31.0.221:52040 (60 connections now open)
2020-05-08T21:58:55.168+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:55.604+0000 I  NETWORK  [conn204] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:55.605+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:55.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.106+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.606+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:56.896+0000 I  CONNPOOL [conn196] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:58:56.896+0000 I  COMMAND  [conn196] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 67), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d2f1da63-060e-448f-b635-521438bbf15c") }, txnNumber: 2, autocommit: false } numYields:0 reslen:494 protocol:op_msg 5011ms
2020-05-08T21:58:56.896+0000 I  NETWORK  [conn196] end connection 172.31.0.221:52062 (59 connections now open)
2020-05-08T21:58:56.899+0000 I  CONNPOOL [conn198] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-08T21:58:56.899+0000 I  COMMAND  [conn198] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975131, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("d494951e-ef69-4bea-9763-9225a3c5ffc6") }, txnNumber: 2, autocommit: false } numYields:0 reslen:494 protocol:op_msg 5012ms
2020-05-08T21:58:56.899+0000 I  NETWORK  [conn198] end connection 172.31.0.221:52066 (58 connections now open)
2020-05-08T21:58:57.106+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:57.606+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:57.606+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:58.110+0000 I  NETWORK  [conn204] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:58:58.110+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:58.610+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:58:59.110+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.110+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.111+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975136, 6), t: 38 }, now { ts: Timestamp(1588975137, 2), t: 39 }
2020-05-08T21:58:59.111+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:58:59.111+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.111+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:58:59.372+0000 I  NETWORK  [conn205] end connection 172.31.0.221:52274 (57 connections now open)
2020-05-08T21:58:59.372+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52564 #213 (58 connections now open)
2020-05-08T21:58:59.372+0000 I  NETWORK  [conn213] received client metadata from 172.31.0.221:52564 conn213: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.373+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52566 #214 (59 connections now open)
2020-05-08T21:58:59.373+0000 I  NETWORK  [conn214] received client metadata from 172.31.0.221:52566 conn214: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.409+0000 I  NETWORK  [conn207] end connection 172.31.0.221:52286 (58 connections now open)
2020-05-08T21:58:59.410+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52576 #215 (59 connections now open)
2020-05-08T21:58:59.410+0000 I  NETWORK  [conn215] received client metadata from 172.31.0.221:52576 conn215: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.410+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52578 #216 (60 connections now open)
2020-05-08T21:58:59.410+0000 I  NETWORK  [conn216] received client metadata from 172.31.0.221:52578 conn216: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.411+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:58:59.411+0000 I  NETWORK  [conn209] end connection 172.31.0.221:52290 (59 connections now open)
2020-05-08T21:58:59.412+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52580 #217 (60 connections now open)
2020-05-08T21:58:59.412+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52582 #218 (61 connections now open)
2020-05-08T21:58:59.412+0000 I  NETWORK  [conn217] received client metadata from 172.31.0.221:52580 conn217: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.412+0000 I  NETWORK  [conn218] received client metadata from 172.31.0.221:52582 conn218: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:58:59.417+0000 I  -        [conn208] operation was interrupted because a client disconnected
2020-05-08T21:58:59.417+0000 I  CONNPOOL [conn208] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 4 connections to that host remain open
2020-05-08T21:58:59.417+0000 I  TXN      [conn208] transaction parameters:{ lsid: { id: UUID("3c8761c9-2d63-4c2c-b1de-18d7e2419836"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975133, 15) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5005131, timeInactiveMicros:0, 5005ms
2020-05-08T21:58:59.417+0000 I  COMMAND  [conn208] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 607 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3c8761c9-2d63-4c2c-b1de-18d7e2419836") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5005ms
2020-05-08T21:58:59.417+0000 I  NETWORK  [conn208] end connection 172.31.0.221:52288 (60 connections now open)
2020-05-08T21:58:59.822+0000 I  NETWORK  [conn204] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:58:59.823+0000 I  COMMAND  [conn204] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975133, 15), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("0f4d6a61-839b-4a23-af85-a2ce47b65680") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:328 protocol:op_msg 5449ms
2020-05-08T21:58:59.823+0000 I  NETWORK  [conn204] end connection 172.31.0.221:52272 (59 connections now open)
2020-05-08T21:59:01.901+0000 I  CONNPOOL [TaskExecutorPool-0] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:04.373+0000 I  NETWORK  [conn214] end connection 172.31.0.221:52566 (58 connections now open)
2020-05-08T21:59:04.373+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52820 #221 (59 connections now open)
2020-05-08T21:59:04.373+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52822 #222 (60 connections now open)
2020-05-08T21:59:04.374+0000 I  NETWORK  [conn221] received client metadata from 172.31.0.221:52820 conn221: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.374+0000 I  NETWORK  [conn222] received client metadata from 172.31.0.221:52822 conn222: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.375+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:04.410+0000 I  NETWORK  [conn216] end connection 172.31.0.221:52578 (59 connections now open)
2020-05-08T21:59:04.410+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52832 #224 (60 connections now open)
2020-05-08T21:59:04.411+0000 I  NETWORK  [conn224] received client metadata from 172.31.0.221:52832 conn224: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.411+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52834 #225 (61 connections now open)
2020-05-08T21:59:04.411+0000 I  NETWORK  [conn225] received client metadata from 172.31.0.221:52834 conn225: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.412+0000 I  NETWORK  [conn218] end connection 172.31.0.221:52582 (60 connections now open)
2020-05-08T21:59:04.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52836 #227 (61 connections now open)
2020-05-08T21:59:04.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52838 #228 (62 connections now open)
2020-05-08T21:59:04.413+0000 I  NETWORK  [conn227] received client metadata from 172.31.0.221:52836 conn227: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:04.413+0000 I  NETWORK  [conn228] received client metadata from 172.31.0.221:52838 conn228: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:05.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:05.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:06.814+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975137, 2), t: 39 }, now { ts: Timestamp(1588975146, 502), t: 41 }
2020-05-08T21:59:09.381+0000 I  NETWORK  [conn222] end connection 172.31.0.221:52822 (61 connections now open)
2020-05-08T21:59:09.382+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52964 #236 (62 connections now open)
2020-05-08T21:59:09.382+0000 I  NETWORK  [conn236] received client metadata from 172.31.0.221:52964 conn236: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.382+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52966 #237 (63 connections now open)
2020-05-08T21:59:09.383+0000 I  NETWORK  [conn237] received client metadata from 172.31.0.221:52966 conn237: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.385+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.411+0000 I  NETWORK  [conn225] end connection 172.31.0.221:52834 (62 connections now open)
2020-05-08T21:59:09.412+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52972 #239 (63 connections now open)
2020-05-08T21:59:09.412+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52974 #240 (64 connections now open)
2020-05-08T21:59:09.412+0000 I  NETWORK  [conn239] received client metadata from 172.31.0.221:52972 conn239: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.412+0000 I  NETWORK  [conn240] received client metadata from 172.31.0.221:52974 conn240: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.413+0000 I  NETWORK  [conn227] end connection 172.31.0.221:52836 (63 connections now open)
2020-05-08T21:59:09.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52976 #241 (64 connections now open)
2020-05-08T21:59:09.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:52978 #242 (65 connections now open)
2020-05-08T21:59:09.414+0000 I  NETWORK  [conn242] received client metadata from 172.31.0.221:52978 conn242: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.414+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.414+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.414+0000 I  NETWORK  [conn241] received client metadata from 172.31.0.221:52976 conn241: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:09.609+0000 I  NETWORK  [conn240] Marking host ec2-34-207-119-213.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:09.609+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:09.615+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.615+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:09.616+0000 I  TXN      [conn242] transaction parameters:{ lsid: { id: UUID("eb7c2aa5-71c3-4c61-a639-9cad6cf2a99b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975149, 19) }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:201338, timeInactiveMicros:0, 201ms
2020-05-08T21:59:09.616+0000 I  COMMAND  [conn242] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 502), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb7c2aa5-71c3-4c61-a639-9cad6cf2a99b") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-34-207-119-213.compute-1.amazonaws.com:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:417 protocol:op_msg 201ms
2020-05-08T21:59:10.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:10.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:11.202+0000 I  NETWORK  [conn240] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-08T21:59:11.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:11.703+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.203+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.703+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:12.891+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-159-37-160.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:13.203+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.203+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:13.204+0000 I  COMMAND  [conn242] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975149, 102), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb7c2aa5-71c3-4c61-a639-9cad6cf2a99b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 3288ms
2020-05-08T21:59:13.743+0000 I  NETWORK  [conn240] Marking host ec2-35-172-222-251.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:59:13.744+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:14.243+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.243+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.244+0000 I  COMMAND  [conn242] command admin.$cmd command: abortTransaction { abortTransaction: 1, writeConcern: { w: "majority" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975152, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb7c2aa5-71c3-4c61-a639-9cad6cf2a99b") }, txnNumber: 1, autocommit: false } numYields:0 reslen:514 protocol:op_msg 1039ms
2020-05-08T21:59:14.383+0000 I  NETWORK  [conn237] end connection 172.31.0.221:52966 (64 connections now open)
2020-05-08T21:59:14.383+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53114 #245 (65 connections now open)
2020-05-08T21:59:14.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53116 #246 (66 connections now open)
2020-05-08T21:59:14.384+0000 I  NETWORK  [conn245] received client metadata from 172.31.0.221:53114 conn245: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.384+0000 I  NETWORK  [conn246] received client metadata from 172.31.0.221:53116 conn246: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.386+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:14.389+0000 I  -        [conn236] operation was interrupted because a client disconnected
2020-05-08T21:59:14.389+0000 I  CONNPOOL [conn236] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 8 connections to that host remain open
2020-05-08T21:59:14.389+0000 I  TXN      [conn236] transaction parameters:{ lsid: { id: UUID("89454ae8-8578-467c-85e7-3b25ce84235e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975146, 502) }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5004723, timeInactiveMicros:0, 5004ms
2020-05-08T21:59:14.389+0000 I  COMMAND  [conn236] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 686 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 502), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("89454ae8-8578-467c-85e7-3b25ce84235e") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-08T21:59:14.389+0000 I  NETWORK  [conn236] end connection 172.31.0.221:52964 (65 connections now open)
2020-05-08T21:59:14.412+0000 I  NETWORK  [conn239] end connection 172.31.0.221:52972 (64 connections now open)
2020-05-08T21:59:14.412+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53126 #248 (65 connections now open)
2020-05-08T21:59:14.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53128 #249 (66 connections now open)
2020-05-08T21:59:14.413+0000 I  NETWORK  [conn248] received client metadata from 172.31.0.221:53126 conn248: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.413+0000 I  NETWORK  [conn249] received client metadata from 172.31.0.221:53128 conn249: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.414+0000 I  NETWORK  [conn241] end connection 172.31.0.221:52976 (65 connections now open)
2020-05-08T21:59:14.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53130 #251 (66 connections now open)
2020-05-08T21:59:14.414+0000 I  NETWORK  [conn251] received client metadata from 172.31.0.221:53130 conn251: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.414+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53132 #252 (67 connections now open)
2020-05-08T21:59:14.415+0000 I  NETWORK  [conn252] received client metadata from 172.31.0.221:53132 conn252: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:14.705+0000 I  COMMAND  [conn240] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, writeConcern: { w: "majority" }, txnNumber: 1, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975146, 502), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("514a96b9-ce2f-4d5d-a6ba-7d624596e230") } } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:185 protocol:op_msg 5291ms
2020-05-08T21:59:14.705+0000 I  NETWORK  [conn240] end connection 172.31.0.221:52974 (66 connections now open)
2020-05-08T21:59:14.708+0000 I  COMMAND  [conn242] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975154, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("eb7c2aa5-71c3-4c61-a639-9cad6cf2a99b") }, txnNumber: 2, startTransaction: true, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975154, 1) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 462ms
2020-05-08T21:59:14.708+0000 I  NETWORK  [conn242] end connection 172.31.0.221:52978 (65 connections now open)
2020-05-08T21:59:15.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-159-37-160.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.072+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-3-82-35-209.compute-1.amazonaws.com:27018
2020-05-08T21:59:15.968+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:15.969+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-08T21:59:16.468+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.469+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:16.608+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:16.630+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975151, 1), t: 41 }, now { ts: Timestamp(1588975156, 3), t: 43 }
2020-05-08T21:59:19.384+0000 I  NETWORK  [conn246] end connection 172.31.0.221:53116 (64 connections now open)
2020-05-08T21:59:19.384+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53290 #258 (65 connections now open)
2020-05-08T21:59:19.385+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53292 #259 (66 connections now open)
2020-05-08T21:59:19.385+0000 I  NETWORK  [conn258] received client metadata from 172.31.0.221:53290 conn258: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.385+0000 I  NETWORK  [conn259] received client metadata from 172.31.0.221:53292 conn259: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.387+0000 I  CONNPOOL [TaskExecutorPool-0] Connecting to ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.413+0000 I  NETWORK  [conn249] end connection 172.31.0.221:53128 (65 connections now open)
2020-05-08T21:59:19.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53302 #261 (66 connections now open)
2020-05-08T21:59:19.413+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53304 #262 (67 connections now open)
2020-05-08T21:59:19.413+0000 I  NETWORK  [conn261] received client metadata from 172.31.0.221:53302 conn261: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.414+0000 I  NETWORK  [conn262] received client metadata from 172.31.0.221:53304 conn262: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.415+0000 I  NETWORK  [conn252] end connection 172.31.0.221:53132 (66 connections now open)
2020-05-08T21:59:19.415+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53306 #264 (67 connections now open)
2020-05-08T21:59:19.415+0000 I  NETWORK  [conn264] received client metadata from 172.31.0.221:53306 conn264: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.415+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53308 #265 (68 connections now open)
2020-05-08T21:59:19.416+0000 I  NETWORK  [conn265] received client metadata from 172.31.0.221:53308 conn265: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:19.417+0000 I  NETWORK  [conn264] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.417+0000 I  -        [conn251] operation was interrupted because a client disconnected
2020-05-08T21:59:19.417+0000 I  CONNPOOL [conn251] Ending connection to host ec2-54-226-181-14.compute-1.amazonaws.com:27018 due to bad connection status: InternalError: Connection is in an unknown state; 11 connections to that host remain open
2020-05-08T21:59:19.417+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:19.417+0000 I  COMMAND  [conn251] command jepsendb.jepsencoll command: find { find: "jepsencoll", readConcern: { level: "majority" }, filter: { _id: 690 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975154, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("efa075e2-2257-4a54-bcf8-0c7d7031a44d") } } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5001ms
2020-05-08T21:59:19.417+0000 I  NETWORK  [conn251] end connection 172.31.0.221:53130 (67 connections now open)
2020-05-08T21:59:19.607+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.607+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/ec2-3-82-35-209.compute-1.amazonaws.com:27018,ec2-54-159-37-160.compute-1.amazonaws.com:27018,ec2-54-226-181-14.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.608+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:19.608+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.608+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:19.917+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.917+0000 I  SHARDING [Sharding-Fixed-8] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:19.918+0000 I  TXN      [conn264] transaction parameters:{ lsid: { id: UUID("375eb9dd-9358-44b4-bf17-c554a4ec9efd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false, readConcern: { level: "snapshot" } }, globalReadTimestamp:{ ts: Timestamp(1588975156, 9) }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:501844, timeInactiveMicros:0, 501ms
2020-05-08T21:59:19.918+0000 I  COMMAND  [conn264] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1588975156, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("375eb9dd-9358-44b4-bf17-c554a4ec9efd") }, txnNumber: 1, startTransaction: true, readConcern: { level: "snapshot" }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from ec2-54-236-6-178.compute-1.amazonaws.com:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:378 protocol:op_msg 501ms
2020-05-08T21:59:20.282+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975157, 5), t: 43 }, now { ts: Timestamp(1588975159, 1), t: 44 }
2020-05-08T21:59:22.862+0000 I  NETWORK  [conn264] Marking host ec2-54-236-6-178.compute-1.amazonaws.com:27018 as failed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-08T21:59:22.862+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.362+0000 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-08T21:59:23.862+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.862+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/ec2-34-207-119-213.compute-1.amazonaws.com:27018,ec2-35-172-222-251.compute-1.amazonaws.com:27018,ec2-54-236-6-178.compute-1.amazonaws.com:27018
2020-05-08T21:59:23.863+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-3-80-27-189.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:23.863+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:23.863+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:24.387+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53444 #266 (68 connections now open)
2020-05-08T21:59:24.388+0000 I  NETWORK  [conn266] received client metadata from 172.31.0.221:53444 conn266: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.416+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53450 #267 (69 connections now open)
2020-05-08T21:59:24.416+0000 I  NETWORK  [conn267] received client metadata from 172.31.0.221:53450 conn267: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:24.446+0000 I  TXN      [conn264] transaction parameters:{ lsid: { id: UUID("375eb9dd-9358-44b4-bf17-c554a4ec9efd"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { level: "snapshot", afterClusterTime: Timestamp(1588975159, 42) } }, globalReadTimestamp:{ ts: Timestamp(1588975159, 42) }, numParticipants:2, coordinator:rs_shard2, terminationCause:aborted, abortCause:TransactionCoordinatorSteppingDown, commitType:twoPhaseCommit, commitDurationMicros:4517972, timeActiveMicros:4521218, timeInactiveMicros:451, 4521ms
2020-05-08T21:59:24.446+0000 I  COMMAND  [conn264] command admin.$cmd command: commitTransaction { commitTransaction: 1, writeConcern: { w: "majority" }, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1588975159, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("375eb9dd-9358-44b4-bf17-c554a4ec9efd") }, txnNumber: 2, autocommit: false } numYields:0 reslen:311 protocol:op_msg 4518ms
2020-05-08T21:59:24.447+0000 I  NETWORK  [conn264] end connection 172.31.0.221:53306 (68 connections now open)
2020-05-08T21:59:24.470+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975159, 1), t: 44 }, now { ts: Timestamp(1588975164, 9), t: 46 }
2020-05-08T21:59:26.420+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53460 #268 (69 connections now open)
2020-05-08T21:59:26.420+0000 I  NETWORK  [conn268] received client metadata from 172.31.0.221:53460 conn268: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:26.421+0000 I  NETWORK  [conn268] end connection 172.31.0.221:53460 (68 connections now open)
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn265] end connection 172.31.0.221:53308 (67 connections now open)
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn261] end connection 172.31.0.221:53302 (66 connections now open)
2020-05-08T21:59:26.422+0000 I  NETWORK  [conn259] end connection 172.31.0.221:53292 (65 connections now open)
2020-05-08T21:59:26.427+0000 I  NETWORK  [listener] connection accepted from 172.31.0.221:53470 #269 (66 connections now open)
2020-05-08T21:59:26.427+0000 I  NETWORK  [conn269] received client metadata from 172.31.0.221:53470 conn269: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "4.9.0-8-amd64" }, platform: "Java/Oracle Corporation/1.8.0_252-8u252-b09-1~deb9u1-b09" }
2020-05-08T21:59:26.427+0000 I  NETWORK  [conn269] end connection 172.31.0.221:53470 (65 connections now open)
2020-05-08T21:59:26.821+0000 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1588975164, 9), t: 46 }, now { ts: Timestamp(1588975166, 3), t: 47 }
2020-05-08T21:59:26.821+0000 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host ec2-107-21-173-199.compute-1.amazonaws.com:27019 as failed :: caused by :: NotMaster: not master
2020-05-08T21:59:26.821+0000 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.821+0000 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/ec2-107-21-173-199.compute-1.amazonaws.com:27019,ec2-3-80-27-189.compute-1.amazonaws.com:27019,ec2-54-221-21-21.compute-1.amazonaws.com:27019
2020-05-08T21:59:26.877+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-34-207-119-213.compute-1.amazonaws.com:27018 because the pool meets constraints; 2 connections to that host remain open
2020-05-08T21:59:30.194+0000 I  CONNPOOL [ShardRegistry] Ending idle connection to host ec2-54-236-6-178.compute-1.amazonaws.com:27018 because the pool meets constraints; 1 connections to that host remain open
