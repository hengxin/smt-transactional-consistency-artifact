2020-05-09 05:31:35 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T05:31:35.262-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T05:31:35.264-0700 I  CONTROL  [main] 
2020-05-09T05:31:35.264-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T05:31:35.264-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T05:31:35.264-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T05:31:35.264-0700 I  CONTROL  [main] 
2020-05-09T05:31:35.264-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T05:31:35.265-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:35.267-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T05:31:35.267-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n4:27017:1589027495:8024958533017945185 (sleeping for 30000ms)
2020-05-09T05:31:35.267-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T05:31:35.267-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T05:31:35.268-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:35.268-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:36.068-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589027495, 9), t: 2 }
2020-05-09T05:31:36.068-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T05:31:36.069-0700 I  SHARDING [mongosMain] Waiting for signing keys, sleeping for 1s and trying again.
2020-05-09T05:31:36.507-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:31:37.073-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T05:31:37.074-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T05:31:37.078-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("b8fc8d2f-13e2-440b-a005-a3bf75bc35b9"), lastMod: 0 } took 0 ms
2020-05-09T05:31:37.078-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T05:31:37.079-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T05:31:37.079-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T05:31:37.079-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T05:31:37.079-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T05:31:37.317-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39074 #9 (1 connection now open)
2020-05-09T05:31:37.317-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.1:39074 conn9: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:37.319-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39108 #10 (2 connections now open)
2020-05-09T05:31:37.319-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:39108 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:41.312-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39278 #11 (3 connections now open)
2020-05-09T05:31:41.313-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:39278 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:41.315-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39288 #12 (4 connections now open)
2020-05-09T05:31:41.316-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:39288 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:44.452-0700 I  COMMAND  [conn11] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589027497, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3da187f3-abd5-4f13-b802-4eb985aa8690") } } numYields:0 reslen:163 protocol:op_msg 3129ms
2020-05-09T05:31:44.455-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 1 ms
2020-05-09T05:31:44.458-0700 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:44.458-0700 I  NETWORK  [conn11] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:44.459-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T05:31:44.459-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T05:31:44.459-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T05:31:44.459-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T05:31:44.459-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T05:31:44.459-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T05:31:44.463-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:44.463-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:44.463-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:44.464-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:44.549-0700 I  NETWORK  [conn11] end connection 192.168.122.1:39278 (3 connections now open)
2020-05-09T05:31:44.550-0700 I  NETWORK  [conn12] end connection 192.168.122.1:39288 (2 connections now open)
2020-05-09T05:31:51.986-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39482 #19 (3 connections now open)
2020-05-09T05:31:51.987-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39484 #20 (4 connections now open)
2020-05-09T05:31:51.987-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:39482 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.987-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:39484 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.996-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39508 #21 (5 connections now open)
2020-05-09T05:31:51.996-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:39508 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.996-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39516 #22 (6 connections now open)
2020-05-09T05:31:51.997-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39518 #23 (7 connections now open)
2020-05-09T05:31:51.997-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:39516 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.997-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:39518 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.999-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:39536 #24 (8 connections now open)
2020-05-09T05:31:51.999-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:39536 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.024-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 2 ms
2020-05-09T05:31:52.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T05:31:52.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:31:54.525-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T05:31:55.631-0700 I  NETWORK  [conn19] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:31:55.632-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:55.635-0700 I  SHARDING [conn21] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027511, 20), t: 2 }, now { ts: Timestamp(1589027514, 1), t: 3 }
2020-05-09T05:31:55.637-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:56.132-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:56.632-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:56.632-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:56.633-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:56.634-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("882a1c20-5dfe-473e-81c0-9591ef8eaba5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 604, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027515, 1852) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1032588, timeInactiveMicros:0, 1032ms
2020-05-09T05:31:56.634-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1852), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("882a1c20-5dfe-473e-81c0-9591ef8eaba5") }, txnNumber: 604, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027515, 1852) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1032ms
2020-05-09T05:31:56.634-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("907c9c9c-d1a2-4a7f-a693-5b493f5f5f29"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 539, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027515, 1852) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1033350, timeInactiveMicros:0, 1033ms
2020-05-09T05:31:56.635-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1852), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907c9c9c-d1a2-4a7f-a693-5b493f5f5f29") }, txnNumber: 539, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027515, 1852) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1033ms
2020-05-09T05:31:56.769-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("7f666874-ec70-4282-9474-2614e55f2265"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 641, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1133288, timeInactiveMicros:0, 1133ms
2020-05-09T05:31:56.770-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 593 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1905), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f666874-ec70-4282-9474-2614e55f2265") }, txnNumber: 641, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7f666874-ec70-4282-9474-2614e55f2265:641 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1133ms
2020-05-09T05:31:56.770-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("907c9c9c-d1a2-4a7f-a693-5b493f5f5f29"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 540, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027516, 11) } }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:131797, timeInactiveMicros:0, 131ms
2020-05-09T05:31:56.770-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("882a1c20-5dfe-473e-81c0-9591ef8eaba5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 605, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027516, 11) } }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:131920, timeInactiveMicros:0, 131ms
2020-05-09T05:31:56.770-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027516, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907c9c9c-d1a2-4a7f-a693-5b493f5f5f29") }, txnNumber: 540, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027516, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 907c9c9c-d1a2-4a7f-a693-5b493f5f5f29:540 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 131ms
2020-05-09T05:31:56.770-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027516, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("882a1c20-5dfe-473e-81c0-9591ef8eaba5") }, txnNumber: 605, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027516, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 882a1c20-5dfe-473e-81c0-9591ef8eaba5:605 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 132ms
2020-05-09T05:31:57.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:31:57.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:31:57.205-0700 I  NETWORK  [conn19] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:31:57.219-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027514, 1), t: 3 }, now { ts: Timestamp(1589027516, 2), t: 4 }
2020-05-09T05:31:58.048-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:58.416-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:58.705-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:59.205-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:59.705-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:00.205-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.205-0700 I  NETWORK  [conn20] end connection 192.168.122.1:39484 (7 connections now open)
2020-05-09T05:32:02.205-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:02.205-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:02.206-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027517, 429), t: 4 }, now { ts: Timestamp(1589027520, 1), t: 5 }
2020-05-09T05:32:02.206-0700 I  NETWORK  [Sharding-Fixed-2] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:02.206-0700 I  TXN      [conn19] transaction parameters:{ lsid: { id: UUID("907c9c9c-d1a2-4a7f-a693-5b493f5f5f29"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 576, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:5002099, timeInactiveMicros:0, 5002ms
2020-05-09T05:32:02.206-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:40518 #48 (8 connections now open)
2020-05-09T05:32:02.206-0700 I  COMMAND  [conn19] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 419), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("907c9c9c-d1a2-4a7f-a693-5b493f5f5f29") }, txnNumber: 576, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 5002ms
2020-05-09T05:32:02.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:40520 #49 (9 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.1:40518 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.207-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:02.207-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:02.207-0700 I  NETWORK  [conn19] end connection 192.168.122.1:39482 (8 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.1:40520 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.210-0700 I  NETWORK  [conn49] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:02.211-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.237-0700 I  NETWORK  [conn23] end connection 192.168.122.1:39518 (7 connections now open)
2020-05-09T05:32:02.238-0700 I  NETWORK  [conn24] end connection 192.168.122.1:39536 (6 connections now open)
2020-05-09T05:32:02.238-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:40542 #50 (7 connections now open)
2020-05-09T05:32:02.239-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:40544 #51 (8 connections now open)
2020-05-09T05:32:02.239-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.1:40542 conn50: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.239-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:40548 #52 (9 connections now open)
2020-05-09T05:32:02.239-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.1:40544 conn51: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.239-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:40546 #53 (10 connections now open)
2020-05-09T05:32:02.239-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:40548 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.239-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:40546 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.241-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.242-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.242-0700 I  -        [conn21] operation was interrupted because a client disconnected
2020-05-09T05:32:02.243-0700 I  CONNPOOL [conn21] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 2 connections to that host remain open
2020-05-09T05:32:02.243-0700 I  TXN      [conn21] transaction parameters:{ lsid: { id: UUID("7f666874-ec70-4282-9474-2614e55f2265"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 676, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5006148, timeInactiveMicros:0, 5006ms
2020-05-09T05:32:02.243-0700 I  COMMAND  [conn21] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 650 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 429), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7f666874-ec70-4282-9474-2614e55f2265") }, txnNumber: 676, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5006ms
2020-05-09T05:32:02.244-0700 I  NETWORK  [conn21] end connection 192.168.122.1:39508 (9 connections now open)
2020-05-09T05:32:02.423-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:02.707-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:02.708-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:02.711-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:03.211-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:03.711-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:03.712-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:03.713-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1503359, timeInactiveMicros:0, 1503ms
2020-05-09T05:32:03.713-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 1, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: not master" errName:NotMaster errCode:10107 reslen:340 protocol:op_msg 1503ms
2020-05-09T05:32:03.757-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027520, 1), t: 5 }, now { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:04.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:32:04.420-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:04.594-0700 I  NETWORK  [conn50] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:04.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:04.597-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:04.705-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:04.706-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:04.707-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("882a1c20-5dfe-473e-81c0-9591ef8eaba5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 644, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:7470212, timeInactiveMicros:0, 7470ms
2020-05-09T05:32:04.707-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 429), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("882a1c20-5dfe-473e-81c0-9591ef8eaba5") }, txnNumber: 644, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 7470ms
2020-05-09T05:32:04.708-0700 I  NETWORK  [conn22] end connection 192.168.122.1:39516 (8 connections now open)
2020-05-09T05:32:05.096-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:05.595-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:05.595-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:05.596-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 2, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027523, 2) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1876812, timeInactiveMicros:0, 1876ms
2020-05-09T05:32:05.596-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027523, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 2, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027523, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1877ms
2020-05-09T05:32:05.596-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3356071, timeInactiveMicros:0, 3356ms
2020-05-09T05:32:05.596-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 1, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3356ms
2020-05-09T05:32:05.691-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 646 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 1, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 3449ms
2020-05-09T05:32:05.692-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:729, timeActiveMicros:3449840, timeInactiveMicros:674, 3450ms
2020-05-09T05:32:05.863-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T05:32:06.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:32:06.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:32:06.270-0700 I  NETWORK  [replSetDistLockPinger] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:06.271-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:06.406-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027526, 490), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 48, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027526, 490) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 106ms
2020-05-09T05:32:06.407-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 48, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027526, 490) } }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:720, timeActiveMicros:106698, timeInactiveMicros:326, 107ms
2020-05-09T05:32:06.446-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 46, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027526, 549) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:107514, timeInactiveMicros:0, 107ms
2020-05-09T05:32:06.446-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027526, 549), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 46, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027526, 549) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 107ms
2020-05-09T05:32:06.771-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:06.771-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:07.076-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:32:07.078-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6a2a233caaefe806e3e97 to 5eb6a2a56cd5bebe167d1938; invalidating user cache
2020-05-09T05:32:07.375-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027522, 12), t: 6 }, now { ts: Timestamp(1589027527, 851), t: 7 }
2020-05-09T05:32:08.706-0700 I  NETWORK  [conn51] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:32:08.707-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:08.714-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:09.208-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:09.208-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:09.209-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:09.209-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 496, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:509980, timeInactiveMicros:0, 509ms
2020-05-09T05:32:09.209-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 503, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027528, 1558) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:519130, timeInactiveMicros:0, 519ms
2020-05-09T05:32:09.210-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1576), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 496, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 510ms
2020-05-09T05:32:09.210-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1558), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 503, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027528, 1558) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 519ms
2020-05-09T05:32:09.210-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:09.210-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:10.083-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027527, 851), t: 7 }, now { ts: Timestamp(1589027529, 4), t: 8 }
2020-05-09T05:32:10.594-0700 I  NETWORK  [conn51] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:10.596-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:11.096-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:11.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:12.095-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:12.095-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:12.097-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 504, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027529, 5) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2882269, timeInactiveMicros:0, 2882ms
2020-05-09T05:32:12.097-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1114 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1580), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 524, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 3383ms
2020-05-09T05:32:12.097-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 497, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027529, 5) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2882228, timeInactiveMicros:0, 2882ms
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027529, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 497, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027529, 5) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2882ms
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027529, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 504, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027529, 5) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2882ms
2020-05-09T05:32:12.098-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:12.099-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 524, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:758, timeActiveMicros:3384282, timeInactiveMicros:936, 3385ms
2020-05-09T05:32:12.100-0700 I  NETWORK  [conn50] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:12.101-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:12.101-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:12.102-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:12.597-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:12.597-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:13.941-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:13.942-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:14.026-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 519, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1865545, timeInactiveMicros:0, 1865ms
2020-05-09T05:32:14.027-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 127), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 519, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 6ad32ea0-48ce-4eac-a286-1097091f9cad:519 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 1865ms
2020-05-09T05:32:14.027-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 521, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1872314, timeInactiveMicros:0, 1872ms
2020-05-09T05:32:14.027-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1121 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 119), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 521, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7da44ddd-7dba-4b0e-914f-199e7425f3ca:521 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1872ms
2020-05-09T05:32:14.028-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 525, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1927830, timeInactiveMicros:0, 1927ms
2020-05-09T05:32:14.028-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1117 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 58), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 525, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a233855e-225c-4f9e-b268-ab679177e70e:525 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1927ms
2020-05-09T05:32:14.037-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T05:32:14.090-0700 I  NETWORK  [conn50] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:14.090-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:14.091-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:14.091-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:14.402-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1118 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 110), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 525, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 310ms
2020-05-09T05:32:14.402-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1122 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 108), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 522, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 311ms
2020-05-09T05:32:14.404-0700 I  SHARDING [conn50] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027530, 2), t: 8 }, now { ts: Timestamp(1589027534, 135), t: 10 }
2020-05-09T05:32:14.404-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 525, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1575, timeActiveMicros:311964, timeInactiveMicros:775, 312ms
2020-05-09T05:32:14.405-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 522, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2806, timeActiveMicros:314488, timeInactiveMicros:785, 315ms
2020-05-09T05:32:14.405-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 529, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027534, 112) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:311750, timeInactiveMicros:0, 311ms
2020-05-09T05:32:14.406-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 112), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 529, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027534, 112) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 311ms
2020-05-09T05:32:14.441-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:14.441-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:14.441-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T05:32:15.264-0700 I  NETWORK  [conn49] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:15.265-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:15.296-0700 I  NETWORK  [conn51] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:15.296-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:15.299-0700 I  NETWORK  [conn50] Marking host n5:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:15.300-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:15.765-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:15.765-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1116 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 345), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 527, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 1608ms
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1139 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 427), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 534, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 1587ms
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1130 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 277), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 531, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:374 protocol:op_msg 1636ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 534, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:978, timeActiveMicros:1588021, timeInactiveMicros:531, 1588ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 531, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:919, timeActiveMicros:1637169, timeInactiveMicros:486, 1637ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 527, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1961, timeActiveMicros:1610443, timeInactiveMicros:622, 1611ms
2020-05-09T05:32:16.063-0700 I  NETWORK  [conn49] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:16.063-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.067-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.564-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.064-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.379-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:17.380-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:17.380-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:17.564-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.590-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027534, 135), t: 10 }, now { ts: Timestamp(1589027536, 2), t: 11 }
2020-05-09T05:32:17.590-0700 I  NETWORK  [Uptime-reporter] Marking host n1:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:17.591-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:17.881-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:18.064-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.064-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.065-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:18.065-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:18.588-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027536, 2), t: 11 }, now { ts: Timestamp(1589027537, 5), t: 12 }
2020-05-09T05:32:18.606-0700 I  TXN      [conn51] transaction parameters:{ lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 531, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2539460, timeInactiveMicros:0, 2539ms
2020-05-09T05:32:18.606-0700 I  COMMAND  [conn51] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("6ad32ea0-48ce-4eac-a286-1097091f9cad") }, txnNumber: 531, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 6ad32ea0-48ce-4eac-a286-1097091f9cad:531 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n8:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 2539ms
2020-05-09T05:32:18.607-0700 I  TXN      [conn50] transaction parameters:{ lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 538, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2540464, timeInactiveMicros:0, 2540ms
2020-05-09T05:32:18.608-0700 I  COMMAND  [conn50] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 53), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a233855e-225c-4f9e-b268-ab679177e70e") }, txnNumber: 538, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a233855e-225c-4f9e-b268-ab679177e70e:538 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n8:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 2540ms
2020-05-09T05:32:18.608-0700 I  TXN      [conn49] transaction parameters:{ lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 533, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2545788, timeInactiveMicros:0, 2545ms
2020-05-09T05:32:18.608-0700 I  COMMAND  [conn49] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 31), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7da44ddd-7dba-4b0e-914f-199e7425f3ca") }, txnNumber: 533, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7da44ddd-7dba-4b0e-914f-199e7425f3ca:533 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 2545ms
2020-05-09T05:32:18.634-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T05:32:18.675-0700 I  NETWORK  [conn49] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:21.265-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n5:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 8731 timed out, deadline was 2020-05-09T05:32:21.265-0700, op was RemoteCommand 8731 -- target:[n5:27018] db:admin expDate:2020-05-09T05:32:21.265-0700 cmd:{ isMaster: 1 }
2020-05-09T05:32:21.265-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host n6:27018 as failed :: caused by :: NetworkInterfaceExceededTimeLimit: Request 8732 timed out, deadline was 2020-05-09T05:32:21.265-0700, op was RemoteCommand 8732 -- target:[n6:27018] db:admin expDate:2020-05-09T05:32:21.265-0700 cmd:{ isMaster: 1 }
2020-05-09T05:32:21.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n5:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:21.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Ending connection to host n6:27018 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:21.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T05:32:21.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T05:32:23.680-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41430 #67 (9 connections now open)
2020-05-09T05:32:23.681-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41432 #68 (10 connections now open)
2020-05-09T05:32:23.681-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.1:41430 conn67: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:23.681-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:41432 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:23.892-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41442 #69 (11 connections now open)
2020-05-09T05:32:23.893-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:41442 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:24.134-0700 I  NETWORK  [conn52] end connection 192.168.122.1:40548 (10 connections now open)
2020-05-09T05:32:24.135-0700 I  NETWORK  [conn53] end connection 192.168.122.1:40546 (9 connections now open)
2020-05-09T05:32:24.135-0700 I  NETWORK  [conn48] end connection 192.168.122.1:40518 (8 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:41466 #70 (9 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.1:41466 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn70] end connection 192.168.122.1:41466 (8 connections now open)
2020-05-09T05:32:26.675-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
