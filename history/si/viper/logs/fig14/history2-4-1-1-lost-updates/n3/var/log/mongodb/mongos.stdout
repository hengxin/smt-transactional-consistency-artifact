2020-05-09 05:31:35 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T05:31:35.260-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] 
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] 
2020-05-09T05:31:35.264-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T05:31:35.264-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T05:31:35.265-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:35.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T05:31:35.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T05:31:35.265-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n3:27017:1589027495:1203799030626098870 (sleeping for 30000ms)
2020-05-09T05:31:35.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T05:31:35.267-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:35.267-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:36.067-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589027495, 9), t: 2 }
2020-05-09T05:31:36.068-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T05:31:36.506-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:31:38.072-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T05:31:38.073-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T05:31:38.076-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("d78e00ac-dd07-4ab1-adf8-c59fc0d03bc9"), lastMod: 0 } took 0 ms
2020-05-09T05:31:38.076-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T05:31:38.076-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T05:31:38.076-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T05:31:38.077-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T05:31:38.077-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T05:31:38.321-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55054 #9 (1 connection now open)
2020-05-09T05:31:38.322-0700 I  NETWORK  [conn9] end connection 192.168.122.1:55054 (0 connections now open)
2020-05-09T05:31:39.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55064 #10 (1 connection now open)
2020-05-09T05:31:39.327-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55070 #11 (2 connections now open)
2020-05-09T05:31:39.327-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:55064 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:39.327-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:55070 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:41.308-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55198 #12 (3 connections now open)
2020-05-09T05:31:41.311-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55202 #13 (4 connections now open)
2020-05-09T05:31:41.311-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:55198 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:41.312-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:55202 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:43.904-0700 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589027498, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("8be4f5ac-baa3-40e8-b7ba-a98e320207d2") } } numYields:0 reslen:163 protocol:op_msg 2582ms
2020-05-09T05:31:43.908-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 1 ms
2020-05-09T05:31:43.910-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:43.911-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:43.911-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T05:31:43.911-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T05:31:43.911-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T05:31:43.911-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T05:31:43.911-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T05:31:43.911-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T05:31:43.914-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:43.914-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:43.915-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:43.915-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:44.032-0700 I  NETWORK  [conn12] end connection 192.168.122.1:55198 (3 connections now open)
2020-05-09T05:31:44.033-0700 I  NETWORK  [conn13] end connection 192.168.122.1:55202 (2 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55380 #20 (3 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55392 #21 (4 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:55380 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.984-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:55392 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.996-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55446 #22 (5 connections now open)
2020-05-09T05:31:51.997-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:55446 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.997-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55454 #23 (6 connections now open)
2020-05-09T05:31:51.997-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:55454 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.998-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55468 #24 (7 connections now open)
2020-05-09T05:31:51.999-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:55468 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.999-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:55472 #25 (8 connections now open)
2020-05-09T05:31:51.999-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.1:55472 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.023-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:52.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T05:31:52.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:54.040-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-09T05:31:55.631-0700 I  NETWORK  [conn23] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:31:55.632-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:55.635-0700 I  SHARDING [conn20] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027511, 20), t: 2 }, now { ts: Timestamp(1589027514, 1), t: 3 }
2020-05-09T05:31:55.638-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:55.648-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:56.132-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:56.632-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:56.632-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:56.633-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:56.769-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 576, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1145825, timeInactiveMicros:0, 1145ms
2020-05-09T05:31:56.769-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 593 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1901), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b") }, txnNumber: 576, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction b75633b5-1f6b-4257-8ec1-b6992e736c1b:576 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1146ms
2020-05-09T05:31:56.771-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 640, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1132587, timeInactiveMicros:0, 1132ms
2020-05-09T05:31:56.771-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("7796e98d-c204-4b15-9361-c26b4245dce1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 590, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1123215, timeInactiveMicros:0, 1123ms
2020-05-09T05:31:56.771-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1911), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6") }, txnNumber: 640, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 3accf2e4-003d-4860-9c3c-13d1888dc6e6:640 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 1132ms
2020-05-09T05:31:56.771-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 593 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1913), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7796e98d-c204-4b15-9361-c26b4245dce1") }, txnNumber: 590, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7796e98d-c204-4b15-9361-c26b4245dce1:590 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1123ms
2020-05-09T05:31:57.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:31:57.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:31:57.192-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:31:57.193-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:57.204-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:57.219-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027514, 1), t: 3 }, now { ts: Timestamp(1589027516, 2), t: 4 }
2020-05-09T05:31:57.692-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:58.192-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:58.692-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:59.192-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:59.692-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:00.192-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:00.693-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:00.693-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:00.694-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027518, 3), t: 4 }, now { ts: Timestamp(1589027520, 1), t: 5 }
2020-05-09T05:32:00.694-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:00.694-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 697, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3507389, timeInactiveMicros:0, 3507ms
2020-05-09T05:32:00.694-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 415), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6") }, txnNumber: 697, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 3507ms
2020-05-09T05:32:00.694-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:00.695-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:00.695-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 655, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3511105, timeInactiveMicros:0, 3511ms
2020-05-09T05:32:00.695-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 409), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b") }, txnNumber: 655, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 3511ms
2020-05-09T05:32:01.495-0700 I  NETWORK  [conn22] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:01.496-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:01.497-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:01.498-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:01.996-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:01.996-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:01.997-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 656, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027520, 10) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1300058, timeInactiveMicros:0, 1300ms
2020-05-09T05:32:01.998-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027520, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b") }, txnNumber: 656, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027520, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1300ms
2020-05-09T05:32:01.998-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("7796e98d-c204-4b15-9361-c26b4245dce1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 665, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4794153, timeInactiveMicros:0, 4794ms
2020-05-09T05:32:01.998-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 417), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7796e98d-c204-4b15-9361-c26b4245dce1") }, txnNumber: 665, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 4794ms
2020-05-09T05:32:01.998-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 698, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027520, 10) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1300887, timeInactiveMicros:0, 1300ms
2020-05-09T05:32:01.998-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027520, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6") }, txnNumber: 698, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027520, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1301ms
2020-05-09T05:32:02.184-0700 I  NETWORK  [conn25] end connection 192.168.122.1:55472 (7 connections now open)
2020-05-09T05:32:02.185-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56440 #52 (8 connections now open)
2020-05-09T05:32:02.185-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56442 #53 (9 connections now open)
2020-05-09T05:32:02.185-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:56440 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.186-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:56442 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.187-0700 I  NETWORK  [conn21] end connection 192.168.122.1:55392 (8 connections now open)
2020-05-09T05:32:02.188-0700 I  NETWORK  [conn52] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:02.188-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56444 #54 (9 connections now open)
2020-05-09T05:32:02.188-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.188-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56446 #55 (10 connections now open)
2020-05-09T05:32:02.188-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.1:56444 conn54: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.189-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:56446 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.191-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.205-0700 I  NETWORK  [conn24] end connection 192.168.122.1:55468 (9 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56456 #56 (10 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:56458 #57 (11 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.1:56456 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.208-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.1:56458 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.213-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.424-0700 I  NETWORK  [conn20] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:02.426-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.427-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.496-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.689-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.848-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:02.849-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:02.850-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:02.996-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:03.189-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:03.496-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:03.689-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:03.689-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:03.757-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027520, 1), t: 5 }, now { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:03.996-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:04.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:32:04.496-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:04.496-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:04.498-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("7796e98d-c204-4b15-9361-c26b4245dce1"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 666, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027522, 10) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2496138, timeInactiveMicros:0, 2496ms
2020-05-09T05:32:04.498-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 699, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027522, 11) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2496276, timeInactiveMicros:0, 2496ms
2020-05-09T05:32:04.498-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 657, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027522, 11) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2496630, timeInactiveMicros:0, 2496ms
2020-05-09T05:32:04.498-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7796e98d-c204-4b15-9361-c26b4245dce1") }, txnNumber: 666, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027522, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2496ms
2020-05-09T05:32:04.499-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("b75633b5-1f6b-4257-8ec1-b6992e736c1b") }, txnNumber: 657, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027522, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2496ms
2020-05-09T05:32:04.499-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("3accf2e4-003d-4860-9c3c-13d1888dc6e6") }, txnNumber: 699, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027522, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2496ms
2020-05-09T05:32:04.499-0700 I  NETWORK  [conn22] end connection 192.168.122.1:55446 (10 connections now open)
2020-05-09T05:32:04.499-0700 I  NETWORK  [conn23] end connection 192.168.122.1:55454 (9 connections now open)
2020-05-09T05:32:04.499-0700 I  NETWORK  [conn20] end connection 192.168.122.1:55380 (8 connections now open)
2020-05-09T05:32:04.594-0700 I  NETWORK  [conn56] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:04.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:04.598-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:05.095-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:05.594-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:05.594-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:05.595-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3405097, timeInactiveMicros:0, 3405ms
2020-05-09T05:32:05.595-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 1, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3405ms
2020-05-09T05:32:05.691-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 646 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 1, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 3479ms
2020-05-09T05:32:05.691-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 651 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 1, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 3504ms
2020-05-09T05:32:05.693-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1087, timeActiveMicros:3480270, timeInactiveMicros:852, 3481ms
2020-05-09T05:32:05.693-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1203, timeActiveMicros:3505530, timeInactiveMicros:774, 3506ms
2020-05-09T05:32:06.441-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027526, 546), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 65, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027526, 546) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 104ms
2020-05-09T05:32:06.442-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 65, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027526, 546) } }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:643, timeActiveMicros:104778, timeInactiveMicros:402, 105ms
2020-05-09T05:32:06.915-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:06.916-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:06.916-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:07.071-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:07.072-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:32:07.374-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027522, 12), t: 6 }, now { ts: Timestamp(1589027527, 851), t: 7 }
2020-05-09T05:32:08.715-0700 I  NETWORK  [conn56] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:08.716-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:08.732-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:08.809-0700 I  NETWORK  [conn54] Marking host n4:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:32:08.811-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:08.996-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:08.997-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:08.997-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:09.216-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:09.217-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:09.310-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:09.311-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:09.312-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 374, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027528, 1601) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:505549, timeInactiveMicros:0, 505ms
2020-05-09T05:32:09.312-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1601), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 374, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027528, 1601) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 505ms
2020-05-09T05:32:09.339-0700 I  CONNPOOL [ShardRegistry] Connecting to n6:27018
2020-05-09T05:32:09.792-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6a2a233caaefe806e3e97 to 5eb6a2a56cd5bebe167d1938; invalidating user cache
2020-05-09T05:32:10.083-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027527, 851), t: 7 }, now { ts: Timestamp(1589027529, 4), t: 8 }
2020-05-09T05:32:10.594-0700 I  NETWORK  [conn52] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:10.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:11.096-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:11.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:12.095-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:12.095-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:12.096-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1107 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1591), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 507, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 3365ms
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1114 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1581), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 467, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 3382ms
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1107 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027529, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 377, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 2753ms
2020-05-09T05:32:12.098-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:12.098-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 377, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:710, timeActiveMicros:2753855, timeInactiveMicros:428, 2754ms
2020-05-09T05:32:12.098-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 467, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:797, timeActiveMicros:3383327, timeInactiveMicros:560, 3383ms
2020-05-09T05:32:12.098-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 507, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:904, timeActiveMicros:3366657, timeInactiveMicros:667, 3367ms
2020-05-09T05:32:12.101-0700 I  NETWORK  [conn52] Marking host n6:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:12.101-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:12.101-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:12.102-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:12.597-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:12.597-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:14.027-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 469, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1923499, timeInactiveMicros:0, 1923ms
2020-05-09T05:32:14.027-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1117 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 68), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 469, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction f830b160-1938-4006-9945-2c6c05f18c38:469 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1923ms
2020-05-09T05:32:14.027-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 509, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027532, 69) } }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1922252, timeInactiveMicros:0, 1922ms
2020-05-09T05:32:14.027-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 69), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 509, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027532, 69) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 5a1c252e-9430-49e0-b59d-70be46ed3b71:509 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 1922ms
2020-05-09T05:32:14.027-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 379, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1925303, timeInactiveMicros:0, 1925ms
2020-05-09T05:32:14.027-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1117 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 65), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 379, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 90a4ce57-c3e1-4836-b0b3-bbea9504f555:379 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1925ms
2020-05-09T05:32:14.030-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T05:32:14.036-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T05:32:14.107-0700 I  NETWORK  [conn56] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:14.108-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:14.108-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:14.109-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:32:14.111-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:14.402-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1118 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 209), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 403, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 214ms
2020-05-09T05:32:14.403-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 211), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 534, startTransaction: true, autocommit: false } nShards:1 nMatched:0 nModified:0 upsert:1 numYields:0 reslen:283 protocol:op_msg 207ms
2020-05-09T05:32:14.404-0700 I  SHARDING [conn56] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027530, 2), t: 8 }, now { ts: Timestamp(1589027534, 135), t: 10 }
2020-05-09T05:32:14.405-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 403, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1463, timeActiveMicros:215747, timeInactiveMicros:702, 216ms
2020-05-09T05:32:14.405-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 534, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1146, timeActiveMicros:208659, timeInactiveMicros:1133, 209ms
2020-05-09T05:32:14.406-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 481, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027534, 135) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:294177, timeInactiveMicros:0, 294ms
2020-05-09T05:32:14.406-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 135), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 481, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027534, 135) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 294ms
2020-05-09T05:32:14.611-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:14.611-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:15.028-0700 I  NETWORK  [conn54] Marking host n5:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:32:15.029-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:15.030-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:15.528-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:15.528-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:15.530-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 632, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027534, 1536) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:557016, timeInactiveMicros:0, 557ms
2020-05-09T05:32:15.530-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 1536), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 632, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027534, 1536) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 557ms
2020-05-09T05:32:16.054-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1214 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027535, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 496, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1035ms
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1214 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 1575), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 601, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1062ms
2020-05-09T05:32:16.056-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 633, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027535, 13) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:522974, timeInactiveMicros:0, 522ms
2020-05-09T05:32:16.056-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 496, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1407, timeActiveMicros:1037214, timeInactiveMicros:459, 1037ms
2020-05-09T05:32:16.056-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027535, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 633, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027535, 13) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 523ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 601, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1087, timeActiveMicros:1063525, timeInactiveMicros:587, 1064ms
2020-05-09T05:32:16.058-0700 I  NETWORK  [conn54] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:16.059-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.066-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.126-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.559-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.059-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.560-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:18.059-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.060-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.061-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:18.062-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:18.062-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:18.588-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027534, 135), t: 10 }, now { ts: Timestamp(1589027537, 5), t: 12 }
2020-05-09T05:32:18.609-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 604, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2543026, timeInactiveMicros:0, 2543ms
2020-05-09T05:32:18.609-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 49), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 604, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction f830b160-1938-4006-9945-2c6c05f18c38:604 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n8:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 2543ms
2020-05-09T05:32:18.609-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 638, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2483690, timeInactiveMicros:0, 2483ms
2020-05-09T05:32:18.609-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 497, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2551537, timeInactiveMicros:0, 2551ms
2020-05-09T05:32:18.609-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1217 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 77), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 638, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 5a1c252e-9430-49e0-b59d-70be46ed3b71:638 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 2483ms
2020-05-09T05:32:18.609-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 497, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 90a4ce57-c3e1-4836-b0b3-bbea9504f555:497 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 2551ms
2020-05-09T05:32:18.633-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T05:32:18.642-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:18.643-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:18.643-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:20.087-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:20.088-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:20.088-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:20.630-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027539, 417), t: 12 }, now { ts: Timestamp(1589027540, 105), t: 13 }
2020-05-09T05:32:20.710-0700 I  NETWORK  [conn54] Marking host n8:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:20.711-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:20.721-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:20.755-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:21.211-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:21.710-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:22.210-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:22.211-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:22.213-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 808, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:NoSuchTransaction, commitType:singleShard, commitDurationMicros:1504004, timeActiveMicros:1505160, timeInactiveMicros:428, 1505ms
2020-05-09T05:32:22.213-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 745, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027540, 730) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1505097, timeInactiveMicros:0, 1505ms
2020-05-09T05:32:22.213-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027540, 730), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 745, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027540, 730) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1505ms
2020-05-09T05:32:22.214-0700 I  COMMAND  [conn54] command admin.$cmd command: commitTransaction { commitTransaction: 1, maxTimeMS: 5000, recoveryToken: { recoveryShardId: "rs_shard2" }, $db: "admin", $clusterTime: { clusterTime: Timestamp(1589027540, 731), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 808, autocommit: false } numYields:0 reslen:430 protocol:op_msg 1505ms
2020-05-09T05:32:22.949-0700 I  NETWORK  [conn56] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:22.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:22.952-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:23.450-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:23.950-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:23.951-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:23.952-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 746, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027542, 2) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1734073, timeInactiveMicros:0, 1734ms
2020-05-09T05:32:23.952-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 809, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027542, 1) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1737291, timeInactiveMicros:0, 1737ms
2020-05-09T05:32:23.953-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027542, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 746, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027542, 2) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1734ms
2020-05-09T05:32:23.953-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027542, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 809, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027542, 1) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1737ms
2020-05-09T05:32:24.099-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1380 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027540, 735), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71") }, txnNumber: 921, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 3378ms
2020-05-09T05:32:24.099-0700 I  COMMAND  [conn54] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027543, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555") }, txnNumber: 810, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027543, 14) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 141ms
2020-05-09T05:32:24.100-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("5a1c252e-9430-49e0-b59d-70be46ed3b71"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 921, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:712, timeActiveMicros:3379209, timeInactiveMicros:539, 3379ms
2020-05-09T05:32:24.100-0700 I  TXN      [conn56] transaction parameters:{ lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 747, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027543, 14) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:143739, timeInactiveMicros:0, 143ms
2020-05-09T05:32:24.100-0700 I  TXN      [conn54] transaction parameters:{ lsid: { id: UUID("90a4ce57-c3e1-4836-b0b3-bbea9504f555"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 810, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027543, 14) } }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:699, timeActiveMicros:142529, timeInactiveMicros:339, 142ms
2020-05-09T05:32:24.100-0700 I  COMMAND  [conn56] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027543, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("f830b160-1938-4006-9945-2c6c05f18c38") }, txnNumber: 747, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027543, 14) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 143ms
2020-05-09T05:32:24.134-0700 I  NETWORK  [conn54] end connection 192.168.122.1:56444 (7 connections now open)
2020-05-09T05:32:24.134-0700 I  NETWORK  [conn52] end connection 192.168.122.1:56440 (6 connections now open)
2020-05-09T05:32:24.135-0700 I  NETWORK  [conn56] end connection 192.168.122.1:56456 (5 connections now open)
2020-05-09T05:32:24.136-0700 I  NETWORK  [conn55] end connection 192.168.122.1:56446 (4 connections now open)
2020-05-09T05:32:24.136-0700 I  NETWORK  [conn57] end connection 192.168.122.1:56458 (3 connections now open)
2020-05-09T05:32:24.137-0700 I  NETWORK  [conn53] end connection 192.168.122.1:56442 (2 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57402 #70 (3 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:57406 #71 (4 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.1:57402 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.1:57406 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:24.143-0700 I  NETWORK  [conn70] end connection 192.168.122.1:57402 (3 connections now open)
2020-05-09T05:32:24.143-0700 I  NETWORK  [conn71] end connection 192.168.122.1:57406 (2 connections now open)
