2020-05-09T05:31:27.541-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T05:31:27.558-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-09T05:31:27.558-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=1858 port=27019 dbpath=/var/lib/mongodb 64-bit host=n1
2020-05-09T05:31:27.558-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-09T05:31:27.558-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T05:31:27.558-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T05:31:27.558-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-09T05:31:27.558-0700 I  CONTROL  [initandlisten] modules: none
2020-05-09T05:31:27.559-0700 I  CONTROL  [initandlisten] build environment:
2020-05-09T05:31:27.559-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-09T05:31:27.559-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-09T05:31:27.559-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-09T05:31:27.559-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-09T05:31:27.559-0700 I  STORAGE  [initandlisten] 
2020-05-09T05:31:27.559-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-09T05:31:27.559-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-09T05:31:27.559-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-09T05:31:28.318-0700 I  STORAGE  [initandlisten] WiredTiger message [1589027488:318302][1858:0x7f3c1ab2b140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-09T05:31:28.370-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-09T05:31:28.419-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-09T05:31:28.456-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.456-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-09T05:31:28.456-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-09T05:31:28.456-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-09T05:31:28.458-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.459-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-09T05:31:28.459-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-09T05:31:28.460-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-09T05:31:28.460-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-09T05:31:28.460-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 45337295-2318-4c71-aebe-76f0417cb7c4 and options: { capped: true, size: 10485760 }
2020-05-09T05:31:28.553-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-09T05:31:28.554-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-09T05:31:28.555-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-09T05:31:28.562-0700 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-05-09T05:31:28.562-0700 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-05-09T05:31:28.563-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 58f02ab4-0e8f-44cd-ba3a-e04d63242fd7 and options: {}
2020-05-09T05:31:28.668-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-09T05:31:28.668-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: b004d6fe-939d-418a-aa5f-ebb15515df8a and options: {}
2020-05-09T05:31:28.803-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-09T05:31:28.803-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-09T05:31:28.803-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 15795e22-c2a5-453d-9036-c4a5fd5ac555 and options: {}
2020-05-09T05:31:28.946-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-09T05:31:28.946-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-09T05:31:28.947-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-09T05:31:28.947-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-09T05:31:28.947-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: cedfd248-17e2-489a-92e2-36b08fb5de28 and options: {}
2020-05-09T05:31:29.096-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-09T05:31:29.097-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-09T05:31:29.097-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-09T05:31:29.097-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-09T05:31:29.097-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-09T05:31:29.099-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("27f504d8-e56f-41d3-916d-f7c53dd014eb"), lastMod: 0 } took 0 ms
2020-05-09T05:31:29.099-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-05-09T05:31:29.099-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T05:31:29.099-0700 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-05-09T05:31:29.099-0700 I  NETWORK  [listener] waiting for connections on port 27019
2020-05-09T05:31:29.099-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-05-09T05:31:29.099-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-05-09T05:31:29.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48620 #1 (1 connection now open)
2020-05-09T05:31:29.745-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48638 #2 (2 connections now open)
2020-05-09T05:31:29.761-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:48620 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:29.761-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:48638 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:29.837-0700 I  NETWORK  [conn1] end connection 192.168.122.1:48620 (1 connection now open)
2020-05-09T05:31:29.838-0700 I  NETWORK  [conn2] end connection 192.168.122.1:48638 (0 connections now open)
2020-05-09T05:31:29.844-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48660 #3 (1 connection now open)
2020-05-09T05:31:29.845-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48666 #4 (2 connections now open)
2020-05-09T05:31:29.845-0700 I  NETWORK  [conn3] received client metadata from 192.168.122.1:48660 conn3: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:29.845-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.1:48666 conn4: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:29.872-0700 I  REPL     [conn3] replSetInitiate admin command received from client
2020-05-09T05:31:29.917-0700 I  REPL     [conn3] replSetInitiate config object with 3 members parses ok
2020-05-09T05:31:29.917-0700 I  REPL     [conn3] Scheduling remote command request for initiate quorum check: RemoteCommand 1 -- target:n2:27019 db:admin cmd:{ replSetHeartbeat: "rs_config", checkEmpty: true, configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 0 }
2020-05-09T05:31:29.917-0700 I  REPL     [conn3] Scheduling remote command request for initiate quorum check: RemoteCommand 2 -- target:n3:27019 db:admin cmd:{ replSetHeartbeat: "rs_config", checkEmpty: true, configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 0 }
2020-05-09T05:31:29.918-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T05:31:29.918-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:31:29.919-0700 I  REPL     [conn3] ******
2020-05-09T05:31:29.919-0700 I  REPL     [conn3] creating replication oplog of size: 36624MB...
2020-05-09T05:31:29.919-0700 I  STORAGE  [conn3] createCollection: local.oplog.rs with generated UUID: ff27581c-faa3-4b48-bf68-8ea761c6e073 and options: { capped: true, size: 38404022476.0, autoIndexId: false }
2020-05-09T05:31:29.920-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:39976 #9 (3 connections now open)
2020-05-09T05:31:29.920-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38004 #10 (4 connections now open)
2020-05-09T05:31:29.920-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.12:39976 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:29.921-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.13:38004 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:29.977-0700 I  STORAGE  [conn3] Starting OplogTruncaterThread local.oplog.rs
2020-05-09T05:31:29.977-0700 I  STORAGE  [conn3] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-09T05:31:29.977-0700 I  STORAGE  [conn3] Scanning the oplog to determine where to place markers for truncation
2020-05-09T05:31:29.977-0700 I  STORAGE  [conn3] WiredTiger record store oplog processing took 0ms
2020-05-09T05:31:30.253-0700 I  REPL     [conn3] ******
2020-05-09T05:31:30.254-0700 I  STORAGE  [conn3] createCollection: local.system.replset with generated UUID: ebddab76-a6ea-4fe6-ba1d-6ad59f14ca1c and options: {}
2020-05-09T05:31:30.382-0700 I  INDEX    [conn3] index build: done building index _id_ on ns local.system.replset
2020-05-09T05:31:30.397-0700 I  SHARDING [conn3] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-09T05:31:30.397-0700 I  STORAGE  [conn3] createCollection: admin.system.version with provided UUID: e05230b0-3df8-490e-b58c-1b6f829b8a06 and options: { uuid: UUID("e05230b0-3df8-490e-b58c-1b6f829b8a06") }
2020-05-09T05:31:30.501-0700 I  INDEX    [conn3] index build: done building index _id_ on ns admin.system.version
2020-05-09T05:31:30.501-0700 I  COMMAND  [conn3] setting featureCompatibilityVersion to 4.2
2020-05-09T05:31:30.501-0700 I  NETWORK  [conn3] Skip closing connection for connection # 10
2020-05-09T05:31:30.501-0700 I  NETWORK  [conn3] Skip closing connection for connection # 9
2020-05-09T05:31:30.501-0700 I  NETWORK  [conn3] Skip closing connection for connection # 4
2020-05-09T05:31:30.501-0700 I  NETWORK  [conn3] Skip closing connection for connection # 3
2020-05-09T05:31:30.502-0700 I  REPL     [conn3] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n1:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n2:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n3:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb6a2a133caaefe806e3e90') } }
2020-05-09T05:31:30.502-0700 I  REPL     [conn3] This node is n1:27019 in the config
2020-05-09T05:31:30.502-0700 I  REPL     [conn3] transition to STARTUP2 from STARTUP
2020-05-09T05:31:30.502-0700 I  REPL     [conn3] Starting replication storage threads
2020-05-09T05:31:30.503-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP
2020-05-09T05:31:30.503-0700 I  REPL     [replexec-0] Member n3:27019 is now in state STARTUP
2020-05-09T05:31:30.505-0700 I  REPL     [conn3] transition to RECOVERING from STARTUP2
2020-05-09T05:31:30.505-0700 I  REPL     [conn3] Starting replication fetcher thread
2020-05-09T05:31:30.505-0700 I  REPL     [conn3] Starting replication applier thread
2020-05-09T05:31:30.505-0700 I  REPL     [conn3] Starting replication reporter thread
2020-05-09T05:31:30.505-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-09T05:31:30.505-0700 I  COMMAND  [conn3] command local.oplog.rs command: replSetInitiate { replSetInitiate: { _id: "rs_config", configsvr: true, settings: { heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000 }, members: [ { _id: 0, priority: 3, host: "n1:27019" }, { _id: 1, priority: 2, host: "n2:27019" }, { _id: 2, priority: 1, host: "n3:27019" } ] }, $db: "admin", $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "primaryPreferred" } } numYields:0 reslen:252 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 19 } }, ReplicationStateTransition: { acquireCount: { w: 19 } }, Global: { acquireCount: { r: 4, w: 13, W: 2 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 93 } }, Database: { acquireCount: { r: 2, w: 9, W: 4 } }, Collection: { acquireCount: { r: 2, w: 2, W: 13 } }, Mutex: { acquireCount: { r: 16 } }, oplog: { acquireCount: { r: 1, w: 1, W: 1 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 632ms
2020-05-09T05:31:30.505-0700 I  REPL     [rsBackgroundSync] waiting for 2 pings from other members before syncing
2020-05-09T05:31:30.505-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-09T05:31:30.505-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-09T05:31:30.945-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38022 #11 (5 connections now open)
2020-05-09T05:31:30.945-0700 I  NETWORK  [conn11] end connection 192.168.122.13:38022 (4 connections now open)
2020-05-09T05:31:30.956-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40000 #12 (5 connections now open)
2020-05-09T05:31:30.956-0700 I  NETWORK  [conn12] end connection 192.168.122.12:40000 (4 connections now open)
2020-05-09T05:31:31.505-0700 I  REPL     [replexec-0] Member n3:27019 is now in state STARTUP2
2020-05-09T05:31:31.505-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:31:31.505-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 0
2020-05-09T05:31:31.505-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 9 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 } }
2020-05-09T05:31:31.505-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 10 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 } }
2020-05-09T05:31:31.506-0700 I  REPL     [replexec-0] Member n2:27019 is now in state STARTUP2
2020-05-09T05:31:31.506-0700 I  ELECTION [replexec-2] VoteRequester(term 0 dry run) received a yes vote from n2:27019; response message: { term: 0, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589027490, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T05:31:31.506-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 1
2020-05-09T05:31:31.520-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 11 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 } }
2020-05-09T05:31:31.521-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 12 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 } }
2020-05-09T05:31:31.839-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40034 #13 (5 connections now open)
2020-05-09T05:31:31.839-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.12:40034 conn13: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:31.842-0700 I  SHARDING [conn13] Marking collection config.transactions as collection version: <unsharded>
2020-05-09T05:31:31.845-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40036 #14 (6 connections now open)
2020-05-09T05:31:31.850-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.12:40036 conn14: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:31.851-0700 I  ELECTION [replexec-1] VoteRequester(term 1) received a yes vote from n2:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589027490, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T05:31:31.851-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 1
2020-05-09T05:31:31.851-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-09T05:31:31.851-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:31:31.851-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-05-09T05:31:31.851-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:31:31.852-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-09T05:31:31.853-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38066 #16 (7 connections now open)
2020-05-09T05:31:31.854-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(0, 0), t: 0 }. My Last Applied: { ts: Timestamp(1589027490, 1), t: -1 }
2020-05-09T05:31:31.854-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T05:31:31.854-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T05:31:31.854-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 1
2020-05-09T05:31:31.854-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.13:38066 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:31.854-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:31.855-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:31.855-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T05:31:31.855-0700 I  STORAGE  [rsSync-0] createCollection: config.transactions with generated UUID: b8867898-33e5-43f7-ae4e-4419b90d4e08 and options: {}
2020-05-09T05:31:31.989-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.transactions
2020-05-09T05:31:31.990-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40050 #17 (8 connections now open)
2020-05-09T05:31:31.991-0700 I  STORAGE  [rsSync-0] createCollection: config.chunks with provided UUID: c5169003-16a3-4ce4-9766-ec4bf03e6bc0 and options: { uuid: UUID("c5169003-16a3-4ce4-9766-ec4bf03e6bc0") }
2020-05-09T05:31:31.991-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.12:40050 conn17: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:32.112-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.chunks
2020-05-09T05:31:32.113-0700 I  SHARDING [rsSync-0] Marking collection config.chunks as collection version: <unsharded>
2020-05-09T05:31:32.279-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T05:31:32.279-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:32.280-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:32.281-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:32.299-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-05-09T05:31:32.312-0700 I  COMMAND  [rsSync-0] command config.chunks command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 321ms
2020-05-09T05:31:32.390-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T05:31:32.390-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:32.391-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:32.393-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:32.403-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-05-09T05:31:32.423-0700 I  COMMAND  [rsSync-0] command config.chunks command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_shard_1_min_1", key: { ns: 1, shard: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 2, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 110ms
2020-05-09T05:31:32.499-0700 I  INDEX    [rsSync-0] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T05:31:32.499-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:32.499-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:32.501-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:32.513-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-05-09T05:31:32.531-0700 I  COMMAND  [rsSync-0] command config.chunks command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_lastmod_1", key: { ns: 1, lastmod: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 2, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 108ms
2020-05-09T05:31:32.532-0700 I  STORAGE  [rsSync-0] createCollection: config.migrations with provided UUID: 470d8b2e-1642-4f6b-a22a-56d320d9eccd and options: { uuid: UUID("470d8b2e-1642-4f6b-a22a-56d320d9eccd") }
2020-05-09T05:31:32.535-0700 I  NETWORK  [conn3] end connection 192.168.122.1:48660 (7 connections now open)
2020-05-09T05:31:32.535-0700 I  NETWORK  [conn4] end connection 192.168.122.1:48666 (6 connections now open)
2020-05-09T05:31:32.539-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48784 #18 (7 connections now open)
2020-05-09T05:31:32.539-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.1:48784 conn18: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:32.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48802 #19 (8 connections now open)
2020-05-09T05:31:32.540-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.1:48802 conn19: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:32.584-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.migrations
2020-05-09T05:31:32.584-0700 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-05-09T05:31:32.670-0700 I  INDEX    [rsSync-0] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-05-09T05:31:32.670-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:32.670-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:32.671-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:32.684-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.migrations
2020-05-09T05:31:32.703-0700 I  COMMAND  [rsSync-0] command config.migrations command: createIndexes { createIndexes: "migrations", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 170ms
2020-05-09T05:31:32.703-0700 I  STORAGE  [rsSync-0] createCollection: config.shards with provided UUID: a6531981-377b-47cc-9e83-f5ede27b9c20 and options: { uuid: UUID("a6531981-377b-47cc-9e83-f5ede27b9c20") }
2020-05-09T05:31:32.760-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.shards
2020-05-09T05:31:32.761-0700 I  SHARDING [rsSync-0] Marking collection config.shards as collection version: <unsharded>
2020-05-09T05:31:32.844-0700 I  INDEX    [rsSync-0] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-05-09T05:31:32.845-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:32.845-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:32.846-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:32.853-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:31:32.854-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:31:32.854-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T05:31:32.854-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T05:31:32.854-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:32.857-0700 I  INDEX    [rsSync-0] index build: done building index host_1 on ns config.shards
2020-05-09T05:31:32.873-0700 I  COMMAND  [rsSync-0] command config.shards command: createIndexes { createIndexes: "shards", indexes: [ { name: "host_1", key: { host: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 169ms
2020-05-09T05:31:32.873-0700 I  STORAGE  [rsSync-0] createCollection: config.locks with provided UUID: 21de64ce-9b9e-46b1-91d0-1a263695e96e and options: { uuid: UUID("21de64ce-9b9e-46b1-91d0-1a263695e96e") }
2020-05-09T05:31:32.929-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.locks
2020-05-09T05:31:33.029-0700 I  INDEX    [rsSync-0] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-05-09T05:31:33.029-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.029-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.030-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.044-0700 I  INDEX    [rsSync-0] index build: done building index ts_1 on ns config.locks
2020-05-09T05:31:33.053-0700 I  COMMAND  [rsSync-0] command config.locks command: createIndexes { createIndexes: "locks", indexes: [ { name: "ts_1", key: { ts: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 180ms
2020-05-09T05:31:33.109-0700 I  INDEX    [rsSync-0] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-05-09T05:31:33.109-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.110-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.112-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.122-0700 I  INDEX    [rsSync-0] index build: done building index state_1_process_1 on ns config.locks
2020-05-09T05:31:33.138-0700 I  STORAGE  [rsSync-0] createCollection: config.lockpings with provided UUID: 06fbc13c-eb1d-4254-80f8-deeaa8ca575b and options: { uuid: UUID("06fbc13c-eb1d-4254-80f8-deeaa8ca575b") }
2020-05-09T05:31:33.192-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.lockpings
2020-05-09T05:31:33.298-0700 I  INDEX    [rsSync-0] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-05-09T05:31:33.298-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.298-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.300-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.323-0700 I  INDEX    [rsSync-0] index build: done building index ping_1 on ns config.lockpings
2020-05-09T05:31:33.350-0700 I  COMMAND  [rsSync-0] command config.lockpings command: createIndexes { createIndexes: "lockpings", indexes: [ { name: "ping_1", key: { ping: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 212ms
2020-05-09T05:31:33.351-0700 I  STORAGE  [rsSync-0] createCollection: config.tags with provided UUID: 45146aa2-93c3-49ab-aeb7-e2f4e7fc6973 and options: { uuid: UUID("45146aa2-93c3-49ab-aeb7-e2f4e7fc6973") }
2020-05-09T05:31:33.457-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.tags
2020-05-09T05:31:33.457-0700 I  SHARDING [rsSync-0] Marking collection config.tags as collection version: <unsharded>
2020-05-09T05:31:33.552-0700 I  INDEX    [rsSync-0] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-05-09T05:31:33.552-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.552-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.554-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.560-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_min_1 on ns config.tags
2020-05-09T05:31:33.571-0700 I  COMMAND  [rsSync-0] command config.tags command: createIndexes { createIndexes: "tags", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { r: 1, w: 2 } }, Database: { acquireCount: { r: 1, w: 2 } }, Collection: { acquireCount: { r: 4, w: 1, R: 1, W: 2 } }, Mutex: { acquireCount: { r: 4 } } } storage:{} protocol:op_msg 219ms
2020-05-09T05:31:33.597-0700 I  INDEX    [rsSync-0] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-05-09T05:31:33.597-0700 I  INDEX    [rsSync-0] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.597-0700 I  INDEX    [rsSync-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.598-0700 I  INDEX    [rsSync-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.602-0700 I  INDEX    [rsSync-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-05-09T05:31:33.605-0700 I  SHARDING [rsSync-0] Marking collection config.version as collection version: <unsharded>
2020-05-09T05:31:33.605-0700 I  STORAGE  [rsSync-0] createCollection: config.version with generated UUID: 29fcac5c-5002-4f90-86a5-77b647807503 and options: {}
2020-05-09T05:31:33.634-0700 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.version
2020-05-09T05:31:33.635-0700 I  SHARDING [rsSync-0] Marking collection config.locks as collection version: <unsharded>
2020-05-09T05:31:33.636-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:31:33.636-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-05-09T05:31:33.636-0700 I  REPL     [rsSync-0] Transition to primary failed :: caused by :: PrimarySteppedDown: By the time this node was ready to complete its transition to PRIMARY it was no longer eligible to do so
2020-05-09T05:31:33.636-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:33.636-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 3 }
2020-05-09T05:31:33.637-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-09T05:31:33.637-0700 W  SHARDING [Balancer] Balancer settings could not be loaded and will be retried in 10 seconds :: caused by :: InterruptedDueToReplStateChange: Failed to refresh the balancer settings :: caused by :: Error waiting for snapshot not less than { ts: Timestamp(1589027493, 14), t: 1 }, current relevant optime is { ts: Timestamp(0, 0), t: -1 }. :: caused by :: operation was interrupted
2020-05-09T05:31:33.637-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:31:33.637-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:31:33.637-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:31:33.637-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Marking collection config.collections as collection version: <unsharded>
2020-05-09T05:31:33.637-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-05-09T05:31:33.638-0700 I  COMMAND  [conn16] command local.oplog.rs command: find { find: "oplog.rs", sort: { $natural: -1 }, limit: 1, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1589027491, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 queryHash:87EBF82D planCacheKey:87EBF82D reslen:524 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 1781338 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 153 } }, Mutex: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 1781ms
2020-05-09T05:31:33.638-0700 I  COMMAND  [conn17] command admin.system.version command: find { find: UUID("e05230b0-3df8-490e-b58c-1b6f829b8a06"), noCursorTimeout: true, $readPreference: { mode: "secondaryPreferred" }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:385 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 1645057 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 1645ms
2020-05-09T05:31:33.638-0700 I  COMMAND  [ftdc] serverStatus was very slow: { after basic: 0, after asserts: 0, after connections: 0, after electionMetrics: 0, after extra_info: 0, after flowControl: 0, after freeMonitoring: 0, after globalLock: 0, after locks: 0, after logicalSessionRecordCache: 0, after network: 0, after opLatencies: 0, after opReadConcernCounters: 0, after opcounters: 0, after opcountersRepl: 0, after oplogTruncation: 1637, after repl: 1637, after security: 1637, after shardedIndexConsistency: 1637, after shardingStatistics: 1637, after storageEngine: 1637, after tcmalloc: 1637, after trafficRecording: 1637, after transactions: 1637, after transportSecurity: 1637, after twoPhaseCommitCoordinator: 1637, after wiredTiger: 1638, at end: 1638 }
2020-05-09T05:31:33.639-0700 I  NETWORK  [conn17] end connection 192.168.122.12:40050 (7 connections now open)
2020-05-09T05:31:33.639-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: TransactionCoordinatorSteppingDown: operation was interrupted
2020-05-09T05:31:33.642-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38118 #20 (8 connections now open)
2020-05-09T05:31:33.642-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.13:38118 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:33.688-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38120 #21 (9 connections now open)
2020-05-09T05:31:33.689-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.13:38120 conn21: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:33.691-0700 I  NETWORK  [conn21] end connection 192.168.122.13:38120 (8 connections now open)
2020-05-09T05:31:33.704-0700 I  SHARDING [conn20] Marking collection config.lockpings as collection version: <unsharded>
2020-05-09T05:31:33.844-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38122 #22 (9 connections now open)
2020-05-09T05:31:33.844-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.13:38122 conn22: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:33.846-0700 I  NETWORK  [conn22] end connection 192.168.122.13:38122 (8 connections now open)
2020-05-09T05:31:33.854-0700 I  REPL     [replexec-3] Member n2:27019 is now in state STARTUP2
2020-05-09T05:31:33.855-0700 I  REPL     [replexec-2] Member n3:27019 is now in state STARTUP2
2020-05-09T05:31:34.089-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38124 #23 (9 connections now open)
2020-05-09T05:31:34.090-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.13:38124 conn23: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:34.091-0700 I  NETWORK  [conn23] end connection 192.168.122.13:38124 (8 connections now open)
2020-05-09T05:31:34.231-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38126 #24 (9 connections now open)
2020-05-09T05:31:34.232-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.13:38126 conn24: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:34.233-0700 I  NETWORK  [conn24] end connection 192.168.122.13:38126 (8 connections now open)
2020-05-09T05:31:34.458-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38128 #25 (9 connections now open)
2020-05-09T05:31:34.458-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.13:38128 conn25: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:34.460-0700 I  NETWORK  [conn25] end connection 192.168.122.13:38128 (8 connections now open)
2020-05-09T05:31:34.590-0700 I  NETWORK  [conn18] end connection 192.168.122.1:48784 (7 connections now open)
2020-05-09T05:31:34.592-0700 I  NETWORK  [conn19] end connection 192.168.122.1:48802 (6 connections now open)
2020-05-09T05:31:34.723-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:31:34.723-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 1
2020-05-09T05:31:34.723-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 19 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027493, 14), t: 1 } }
2020-05-09T05:31:34.723-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 20 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027493, 14), t: 1 } }
2020-05-09T05:31:34.724-0700 I  ELECTION [replexec-2] VoteRequester(term 1 dry run) received a yes vote from n2:27019; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589027493, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027493, 9) }
2020-05-09T05:31:34.724-0700 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 2
2020-05-09T05:31:34.724-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:31:34.724-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:31:34.732-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 21 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027493, 14), t: 1 } }
2020-05-09T05:31:34.733-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 22 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027493, 14), t: 1 } }
2020-05-09T05:31:34.742-0700 I  ELECTION [replexec-1] VoteRequester(term 2) received a yes vote from n3:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1589027493, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(0, 0) }
2020-05-09T05:31:34.742-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 2
2020-05-09T05:31:34.742-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T05:31:34.742-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was :27017
2020-05-09T05:31:34.742-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:31:34.742-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T05:31:34.742-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T05:31:34.744-0700 I  REPL     [replexec-1] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027493, 9), t: 1 }. My Last Applied: { ts: Timestamp(1589027493, 14), t: 1 }
2020-05-09T05:31:34.744-0700 I  REPL     [replexec-1] Exited primary catch-up mode.
2020-05-09T05:31:34.744-0700 I  REPL     [replexec-1] Stopping replication producer
2020-05-09T05:31:34.744-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 2
2020-05-09T05:31:34.745-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:34.745-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:34.745-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T05:31:34.746-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:31:34.746-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:31:34.746-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:31:34.747-0700 W  QUERY    [conn16] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824821119174836226), stats: { stage: "COLLSCAN", nReturned: 2, executionTimeMillisEstimate: 0, works: 23, advanced: 2, needTime: 10, needYield: 0, saveState: 10, restoreState: 10, isEOF: 0, direction: "forward", docsExamined: 2 }
2020-05-09T05:31:34.830-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38134 #28 (7 connections now open)
2020-05-09T05:31:34.830-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.13:38134 conn28: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:34.831-0700 I  NETWORK  [conn28] end connection 192.168.122.13:38134 (6 connections now open)
2020-05-09T05:31:35.173-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38136 #29 (7 connections now open)
2020-05-09T05:31:35.174-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.13:38136 conn29: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.175-0700 I  NETWORK  [conn29] end connection 192.168.122.13:38136 (6 connections now open)
2020-05-09T05:31:35.249-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57702 #30 (7 connections now open)
2020-05-09T05:31:35.249-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.16:57702 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.249-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43820 #31 (8 connections now open)
2020-05-09T05:31:35.249-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.18:43820 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.250-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57712 #32 (9 connections now open)
2020-05-09T05:31:35.251-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43826 #33 (10 connections now open)
2020-05-09T05:31:35.251-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.16:57712 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.251-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57716 #34 (11 connections now open)
2020-05-09T05:31:35.251-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.18:43826 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.251-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43830 #35 (12 connections now open)
2020-05-09T05:31:35.251-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.16:57716 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.251-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:57720 #36 (13 connections now open)
2020-05-09T05:31:35.251-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.18:43830 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.251-0700 I  NETWORK  [conn36] received client metadata from 192.168.122.16:57720 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.252-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43834 #37 (14 connections now open)
2020-05-09T05:31:35.252-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:43836 #38 (15 connections now open)
2020-05-09T05:31:35.252-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.18:43834 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.252-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.18:43836 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.254-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43184 #39 (16 connections now open)
2020-05-09T05:31:35.254-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.11:43184 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.255-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43188 #40 (17 connections now open)
2020-05-09T05:31:35.255-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43190 #41 (18 connections now open)
2020-05-09T05:31:35.255-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.11:43188 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.255-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.11:43190 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.256-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43192 #42 (19 connections now open)
2020-05-09T05:31:35.256-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:43194 #43 (20 connections now open)
2020-05-09T05:31:35.256-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.11:43192 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.256-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.11:43194 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.261-0700 I  NETWORK  [conn13] end connection 192.168.122.12:40034 (19 connections now open)
2020-05-09T05:31:35.265-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40154 #44 (20 connections now open)
2020-05-09T05:31:35.266-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38186 #45 (21 connections now open)
2020-05-09T05:31:35.267-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.12:40154 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.267-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.13:38186 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.267-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48034 #46 (22 connections now open)
2020-05-09T05:31:35.267-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51642 #47 (23 connections now open)
2020-05-09T05:31:35.267-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.17:48034 conn46: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44404 #48 (24 connections now open)
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.19:51642 conn47: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56370 #49 (25 connections now open)
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.15:44404 conn48: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40188 #50 (26 connections now open)
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.14:56370 conn49: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40192 #51 (27 connections now open)
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn50] received client metadata from 192.168.122.12:40188 conn50: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38220 #52 (28 connections now open)
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn51] received client metadata from 192.168.122.12:40192 conn51: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38222 #53 (29 connections now open)
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.13:38220 conn52: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.268-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.13:38222 conn53: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48060 #54 (30 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51664 #55 (31 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [conn54] received client metadata from 192.168.122.17:48060 conn54: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40202 #56 (32 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.19:51664 conn55: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44428 #57 (33 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.12:40202 conn56: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48068 #58 (34 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.15:44428 conn57: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40208 #59 (35 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.17:48068 conn58: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.269-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51674 #60 (36 connections now open)
2020-05-09T05:31:35.269-0700 I  NETWORK  [conn59] received client metadata from 192.168.122.12:40208 conn59: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38238 #61 (37 connections now open)
2020-05-09T05:31:35.270-0700 I  NETWORK  [conn60] received client metadata from 192.168.122.19:51674 conn60: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56402 #62 (38 connections now open)
2020-05-09T05:31:35.270-0700 I  NETWORK  [conn61] received client metadata from 192.168.122.13:38238 conn61: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44440 #63 (39 connections now open)
2020-05-09T05:31:35.270-0700 I  NETWORK  [conn62] received client metadata from 192.168.122.14:56402 conn62: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56406 #64 (40 connections now open)
2020-05-09T05:31:35.270-0700 I  NETWORK  [conn63] received client metadata from 192.168.122.15:44440 conn63: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38246 #65 (41 connections now open)
2020-05-09T05:31:35.270-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.14:56406 conn64: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.270-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48084 #66 (42 connections now open)
2020-05-09T05:31:35.270-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.13:38246 conn65: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.271-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51688 #67 (43 connections now open)
2020-05-09T05:31:35.271-0700 I  NETWORK  [conn66] received client metadata from 192.168.122.17:48084 conn66: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.271-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48088 #68 (44 connections now open)
2020-05-09T05:31:35.271-0700 I  NETWORK  [conn67] received client metadata from 192.168.122.19:51688 conn67: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.271-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44452 #69 (45 connections now open)
2020-05-09T05:31:35.272-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.17:48088 conn68: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.272-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51694 #70 (46 connections now open)
2020-05-09T05:31:35.272-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.15:44452 conn69: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.272-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56420 #71 (47 connections now open)
2020-05-09T05:31:35.272-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.19:51694 conn70: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.272-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44458 #72 (48 connections now open)
2020-05-09T05:31:35.272-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.14:56420 conn71: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.272-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56424 #73 (49 connections now open)
2020-05-09T05:31:35.272-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.15:44458 conn72: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.272-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.14:56424 conn73: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.352-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38298 #74 (50 connections now open)
2020-05-09T05:31:35.353-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.13:38298 conn74: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.354-0700 I  NETWORK  [conn74] end connection 192.168.122.13:38298 (49 connections now open)
2020-05-09T05:31:35.737-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:38300 #75 (50 connections now open)
2020-05-09T05:31:35.737-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.13:38300 conn75: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.738-0700 I  NETWORK  [conn75] end connection 192.168.122.13:38300 (49 connections now open)
2020-05-09T05:31:36.065-0700 I  STORAGE  [conn14] Triggering the first stable checkpoint. Initial Data: Timestamp(1589027490, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1589027494, 2)
2020-05-09T05:31:36.065-0700 I  SHARDING [monitoring-keys-for-HMAC] Marking collection admin.system.keys as collection version: <unsharded>
2020-05-09T05:31:36.065-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:40294 #76 (50 connections now open)
2020-05-09T05:31:36.065-0700 I  SHARDING [Balancer] Marking collection config.settings as collection version: <unsharded>
2020-05-09T05:31:36.066-0700 I  COMMAND  [conn33] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 815ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn52] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 798ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn36] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 814ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn68] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 795ms
2020-05-09T05:31:36.067-0700 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn67] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27017:1589027495:3290208215892541551" }, update: { $set: { ping: new Date(1589027495267) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 795ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn61] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n3:27017:1589027495:1203799030626098870" }, update: { $set: { ping: new Date(1589027495265) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 796ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn59] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 797ms
2020-05-09T05:31:36.067-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn64] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 796ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn72] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 794ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn70] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 795ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn42] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: EOF keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 1 } } } protocol:op_msg 811ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn66] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27017:1589027495:4498723705184841883" }, update: { $set: { ping: new Date(1589027495267) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 796ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn57] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 798ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn35] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27017:1589027495:-4028076255853485019" }, update: { $set: { ping: new Date(1589027495248) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 816ms
2020-05-09T05:31:36.068-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn69] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27017:1589027495:-3092204051443899780" }, update: { $set: { ping: new Date(1589027495267) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:614 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 795ms
2020-05-09T05:31:36.067-0700 I  NETWORK  [conn76] received client metadata from 192.168.122.12:40294 conn76: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn40] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 812ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn73] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27017:1589027495:8024958533017945185" }, update: { $set: { ping: new Date(1589027495267) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 794ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn43] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 811ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn50] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n2:27017:1589027495:3135941772378158776" }, update: { $set: { ping: new Date(1589027495265) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 799ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn60] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 797ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn58] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 797ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn41] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1589027495:563410028455241219" }, update: { $set: { ping: new Date(1589027495253) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:612 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 811ms
2020-05-09T05:31:36.067-0700 I  STORAGE  [monitoring-keys-for-HMAC] createCollection: admin.system.keys with generated UUID: a78bf257-4e1b-4b0b-b48d-c7e7ac8a89ce and options: {}
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn32] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 816ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn54] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 798ms
2020-05-09T05:31:36.067-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn53] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 798ms
2020-05-09T05:31:36.067-0700 I  COMMAND  [conn34] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27017:1589027495:7883765758298039767" }, update: { $set: { ping: new Date(1589027495248) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:613 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 816ms
2020-05-09T05:31:36.068-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:31:36.069-0700 I  COMMAND  [conn51] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 799ms
2020-05-09T05:31:36.069-0700 I  COMMAND  [conn65] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 797ms
2020-05-09T05:31:36.069-0700 I  COMMAND  [conn55] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 799ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn38] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 815ms
2020-05-09T05:31:36.068-0700 I  COMMAND  [conn62] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 798ms
2020-05-09T05:31:36.069-0700 I  COMMAND  [conn63] command config.shards command: find { find: "shards", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 cursorExhausted:1 numYields:0 nreturned:0 reslen:549 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 798ms
2020-05-09T05:31:36.069-0700 I  COMMAND  [conn71] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 796ms
2020-05-09T05:31:36.171-0700 I  INDEX    [monitoring-keys-for-HMAC] index build: done building index _id_ on ns admin.system.keys
2020-05-09T05:31:36.190-0700 I  NETWORK  [conn16] end connection 192.168.122.13:38066 (49 connections now open)
2020-05-09T05:31:36.306-0700 I  COMMAND  [conn37] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 hasSortStage:1 cursorExhausted:1 numYields:1 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 104366 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 1053ms
2020-05-09T05:31:36.306-0700 I  COMMAND  [conn56] command admin.system.keys command: find { find: "system.keys", filter: { purpose: "HMAC", expiresAt: { $gt: Timestamp(0, 0) } }, sort: { expiresAt: 1 }, readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "admin" } planSummary: COLLSCAN keysExamined:0 docsExamined:0 hasSortStage:1 cursorExhausted:1 numYields:1 nreturned:0 queryHash:6DC32749 planCacheKey:6DC32749 reslen:553 locks:{ ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 2 } }, Database: { acquireCount: { r: 2 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 104364 } }, Collection: { acquireCount: { r: 2 } }, Mutex: { acquireCount: { r: 2 } } } storage:{} protocol:op_msg 1036ms
2020-05-09T05:31:36.311-0700 I  COMMAND  [monitoring-keys-for-HMAC] command admin.system.keys command: insert { insert: "system.keys", bypassDocumentValidation: false, ordered: true, documents: [ { _id: 6824821114879868942, purpose: "HMAC", key: BinData(0, 63937D133E8576AFC67C701091E4D1B249D7D1AB), expiresAt: Timestamp(1596803493, 0) } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, $db: "admin" } ninserted:1 keysInserted:1 numYields:0 reslen:339 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { W: 3 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 152 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 244ms
2020-05-09T05:31:36.744-0700 I  REPL     [replexec-2] Member n3:27019 is now in state SECONDARY
2020-05-09T05:31:36.745-0700 I  REPL     [replexec-1] Member n2:27019 is now in state SECONDARY
2020-05-09T05:31:37.077-0700 I  SHARDING [conn37] Marking collection config.mongos as collection version: <unsharded>
2020-05-09T05:31:37.077-0700 I  STORAGE  [conn37] createCollection: config.mongos with generated UUID: e69f3cd9-17f0-4bf0-af22-c63c4aeb731b and options: {}
2020-05-09T05:31:37.134-0700 I  INDEX    [conn37] index build: done building index _id_ on ns config.mongos
2020-05-09T05:31:37.207-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1589027497075), up: 0, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027496, 3), signature: { hash: BinData(0, 9753C48AA3A57B8A28637EFC24A03BADE316BA64), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027496, 3), t: 2 } }, $db: "config" } numYields:0 reslen:639 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { w: 3 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 135 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 130ms
2020-05-09T05:31:37.207-0700 I  COMMAND  [conn54] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1589027497076), up: 0, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027496, 3), signature: { hash: BinData(0, 9753C48AA3A57B8A28637EFC24A03BADE316BA64), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027496, 3), t: 2 } }, $db: "config" } numYields:0 reslen:639 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 56885 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 129ms
2020-05-09T05:31:37.207-0700 I  COMMAND  [conn71] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1589027497075), up: 0, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027496, 3), signature: { hash: BinData(0, 9753C48AA3A57B8A28637EFC24A03BADE316BA64), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027496, 3), t: 2 } }, $db: "config" } numYields:0 reslen:639 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 57169 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 129ms
2020-05-09T05:31:37.207-0700 I  COMMAND  [conn55] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1589027497075), up: 0, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027496, 3), signature: { hash: BinData(0, 9753C48AA3A57B8A28637EFC24A03BADE316BA64), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027496, 3), t: 2 } }, $db: "config" } numYields:0 reslen:639 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { w: 3 } }, Collection: { acquireCount: { r: 1, w: 2, W: 1 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 57591 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 130ms
2020-05-09T05:31:37.207-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1589027497075), up: 0, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027496, 3), signature: { hash: BinData(0, 9753C48AA3A57B8A28637EFC24A03BADE316BA64), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027496, 3), t: 2 } }, $db: "config" } numYields:0 reslen:639 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 56725 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 129ms
2020-05-09T05:31:39.338-0700 I  NETWORK  [conn41] Starting new replica set monitor for rs_shard1/n4:27018
2020-05-09T05:31:39.339-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T05:31:39.341-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:39.341-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T05:31:39.341-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T05:31:39.345-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56588 #81 (50 connections now open)
2020-05-09T05:31:39.345-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.14:56588 conn81: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:39.346-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56594 #82 (51 connections now open)
2020-05-09T05:31:39.347-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.14:56594 conn82: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:39.347-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56596 #83 (52 connections now open)
2020-05-09T05:31:39.347-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.14:56596 conn83: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:39.348-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56598 #84 (53 connections now open)
2020-05-09T05:31:39.348-0700 I  NETWORK  [conn84] received client metadata from 192.168.122.14:56598 conn84: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:39.348-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:56600 #85 (54 connections now open)
2020-05-09T05:31:39.348-0700 I  NETWORK  [conn85] received client metadata from 192.168.122.14:56600 conn85: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.178-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44646 #86 (55 connections now open)
2020-05-09T05:31:40.179-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58010 #87 (56 connections now open)
2020-05-09T05:31:40.179-0700 I  NETWORK  [conn86] received client metadata from 192.168.122.15:44646 conn86: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.179-0700 I  NETWORK  [conn87] received client metadata from 192.168.122.16:58010 conn87: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.181-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44654 #88 (57 connections now open)
2020-05-09T05:31:40.181-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58018 #89 (58 connections now open)
2020-05-09T05:31:40.181-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.15:44654 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.181-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:44658 #90 (59 connections now open)
2020-05-09T05:31:40.181-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.16:58018 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.181-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58024 #91 (60 connections now open)
2020-05-09T05:31:40.182-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.15:44658 conn90: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.182-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.16:58024 conn91: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.182-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:58026 #92 (61 connections now open)
2020-05-09T05:31:40.183-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.16:58026 conn92: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.321-0700 I  SHARDING [conn41] going to insert new entry for shard into config.shards: { _id: "rs_shard1", host: "rs_shard1/n4:27018,n5:27018,n6:27018", state: 1 }
2020-05-09T05:31:40.324-0700 I  STORAGE  [conn41] createCollection: config.changelog with generated UUID: 9c4cf9f3-eb07-46ea-ae83-50a43544d4b1 and options: { capped: true, size: 209715200 }
2020-05-09T05:31:40.438-0700 I  INDEX    [conn41] index build: done building index _id_ on ns config.changelog
2020-05-09T05:31:40.504-0700 I  COMMAND  [conn41] command config.changelog command: create { create: "changelog", capped: true, size: 209715200, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "config" } numYields:0 reslen:272 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { r: 1, W: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 179ms
2020-05-09T05:31:40.504-0700 I  SHARDING [conn41] about to log metadata event into changelog: { _id: "n1:27019-2020-05-09T05:31:40.504-0700-5eb6a2ac33caaefe806e4057", server: "n1:27019", shard: "config", clientAddr: "192.168.122.11:43190", time: new Date(1589027500504), what: "addShard", ns: "", details: { name: "rs_shard1", host: "rs_shard1/n4:27018" } }
2020-05-09T05:31:40.504-0700 I  SHARDING [conn41] Marking collection config.changelog as collection version: <unsharded>
2020-05-09T05:31:40.517-0700 I  COMMAND  [conn41] command admin.$cmd command: _configsvrAddShard { _configsvrAddShard: "rs_shard1/n4:27018", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("93dc227e-4f59-41d1-817a-d6318abad6cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027498, 4), signature: { hash: BinData(0, 5B35242D07370DB48621B9FAF7B7E0D276CB8032), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:33842", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027498, 4), t: 2 } }, $db: "admin" } numYields:0 reslen:531 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 7 } }, Global: { acquireCount: { r: 4, w: 3 } }, Database: { acquireCount: { r: 3, w: 3 } }, Collection: { acquireCount: { r: 4, w: 2, W: 1 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 10, W: 1 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 1179ms
2020-05-09T05:31:40.524-0700 I  NETWORK  [conn41] Starting new replica set monitor for rs_shard2/n7:27018
2020-05-09T05:31:40.525-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T05:31:40.527-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:40.527-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T05:31:40.528-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T05:31:40.536-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48320 #97 (62 connections now open)
2020-05-09T05:31:40.537-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.17:48320 conn97: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.539-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48326 #98 (63 connections now open)
2020-05-09T05:31:40.539-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48328 #99 (64 connections now open)
2020-05-09T05:31:40.539-0700 I  NETWORK  [conn98] received client metadata from 192.168.122.17:48326 conn98: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.540-0700 I  NETWORK  [conn99] received client metadata from 192.168.122.17:48328 conn99: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48330 #100 (65 connections now open)
2020-05-09T05:31:40.541-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48332 #101 (66 connections now open)
2020-05-09T05:31:40.541-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.17:48330 conn100: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.541-0700 I  NETWORK  [conn101] received client metadata from 192.168.122.17:48332 conn101: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.163-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51948 #102 (67 connections now open)
2020-05-09T05:31:41.164-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.19:51948 conn102: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.166-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51952 #103 (68 connections now open)
2020-05-09T05:31:41.167-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51954 #104 (69 connections now open)
2020-05-09T05:31:41.167-0700 I  NETWORK  [conn103] received client metadata from 192.168.122.19:51952 conn103: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.167-0700 I  NETWORK  [conn104] received client metadata from 192.168.122.19:51954 conn104: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.168-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:51956 #105 (70 connections now open)
2020-05-09T05:31:41.168-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.19:51956 conn105: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.255-0700 I  SHARDING [conn41] going to insert new entry for shard into config.shards: { _id: "rs_shard2", host: "rs_shard2/n7:27018,n8:27018,n9:27018", state: 1 }
2020-05-09T05:31:41.256-0700 I  SHARDING [conn41] about to log metadata event into changelog: { _id: "n1:27019-2020-05-09T05:31:41.256-0700-5eb6a2ad33caaefe806e4090", server: "n1:27019", shard: "config", clientAddr: "192.168.122.11:43190", time: new Date(1589027501256), what: "addShard", ns: "", details: { name: "rs_shard2", host: "rs_shard2/n7:27018" } }
2020-05-09T05:31:41.289-0700 I  COMMAND  [conn41] command admin.$cmd command: _configsvrAddShard { _configsvrAddShard: "rs_shard2/n7:27018", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("93dc227e-4f59-41d1-817a-d6318abad6cf"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027500, 5), signature: { hash: BinData(0, 1A5DDC1FE33190895603FCCDF72B1E00A176A572), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:33842", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027500, 5), t: 2 } }, $db: "admin" } numYields:0 reslen:531 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 2 } }, ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 3, w: 2 } }, Database: { acquireCount: { r: 3, w: 2 } }, Collection: { acquireCount: { r: 3, w: 2 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 8, W: 1 } } } flowControl:{ acquireCount: 2, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 765ms
2020-05-09T05:31:41.316-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:44238 #106 (71 connections now open)
2020-05-09T05:31:41.316-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.18:44238 conn106: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.339-0700 I  SHARDING [conn41] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40a3
2020-05-09T05:31:41.340-0700 I  SHARDING [conn41] Marking collection config.databases as collection version: <unsharded>
2020-05-09T05:31:41.340-0700 I  CONNPOOL [ShardRegistry] Connecting to n4:27018
2020-05-09T05:31:41.344-0700 I  SHARDING [conn41] Registering new database { _id: "jepsendb", primary: "rs_shard1", partitioned: false, version: { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } } in sharding catalog
2020-05-09T05:31:41.345-0700 I  STORAGE  [conn41] createCollection: config.databases with generated UUID: 9866430c-b016-43b6-9574-b509c467f0d3 and options: {}
2020-05-09T05:31:41.441-0700 I  INDEX    [conn41] index build: done building index _id_ on ns config.databases
2020-05-09T05:31:41.526-0700 I  SHARDING [conn41] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:41.570-0700 I  SHARDING [conn41] distributed lock with ts: 5eb6a2ad33caaefe806e40a3' unlocked.
2020-05-09T05:31:41.570-0700 I  COMMAND  [conn41] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("41248678-1ecd-4640-b946-9beba126d6d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027501, 3), signature: { hash: BinData(0, 0A6DE963D9DB7196755249F2A13BB99507B73BAF), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:33970", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027501, 3), t: 2 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 6 } }, ReplicationStateTransition: { acquireCount: { w: 7 } }, Global: { acquireCount: { r: 1, w: 6 } }, Database: { acquireCount: { r: 1, w: 6 } }, Collection: { acquireCount: { r: 4, w: 5, W: 1 } }, Mutex: { acquireCount: { r: 12 } } } flowControl:{ acquireCount: 6, timeAcquiringMicros: 7 } storage:{} protocol:op_msg 249ms
2020-05-09T05:31:41.607-0700 I  SHARDING [conn41] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2ad33caaefe806e40f0
2020-05-09T05:31:41.621-0700 I  SHARDING [conn41] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2ad33caaefe806e40f9
2020-05-09T05:31:41.793-0700 I  SHARDING [conn41] distributed lock with ts: 5eb6a2ad33caaefe806e40f9' unlocked.
2020-05-09T05:31:41.810-0700 I  SHARDING [conn41] distributed lock with ts: 5eb6a2ad33caaefe806e40f0' unlocked.
2020-05-09T05:31:41.810-0700 I  COMMAND  [conn41] command admin.$cmd command: _configsvrCreateCollection { _configsvrCreateCollection: "jepsendb.jepsencoll", options: { capped: false, writeConcern: { w: "majority" }, lsid: { id: UUID("41248678-1ecd-4640-b946-9beba126d6d2") } }, writeConcern: { w: "majority" }, lsid: { id: UUID("41248678-1ecd-4640-b946-9beba126d6d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027501, 9), signature: { hash: BinData(0, 0A6DE963D9DB7196755249F2A13BB99507B73BAF), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:33970", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027501, 9), t: 2 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 5 } }, Global: { acquireCount: { r: 1, w: 4 } }, Database: { acquireCount: { r: 1, w: 4 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { r: 9 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 222ms
2020-05-09T05:31:41.823-0700 I  SHARDING [conn41] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2ad33caaefe806e4117
2020-05-09T05:31:41.842-0700 I  SHARDING [conn41] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2ad33caaefe806e411c
2020-05-09T05:31:42.350-0700 I  STORAGE  [conn82] createCollection: config.collections with generated UUID: 62b88a6b-0971-4550-bf98-58f7e636364c and options: {}
2020-05-09T05:31:42.471-0700 I  INDEX    [conn82] index build: done building index _id_ on ns config.collections
2020-05-09T05:31:42.472-0700 I  WRITE    [conn82] update config.collections command: { q: { _id: "jepsendb.jepsencoll" }, u: { _id: "jepsendb.jepsencoll", lastmodEpoch: ObjectId('5eb6a2aeecc1ba4072ee52e8'), lastmod: new Date(4294967302), dropped: false, key: { _id: "hashed" }, unique: false, uuid: UUID("d075f6ec-3562-4e33-82e1-88864582ea58") }, multi: false, upsert: true } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:1 numYields:0 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 3 } }, ReplicationStateTransition: { acquireCount: { w: 3 } }, Global: { acquireCount: { w: 3 } }, Database: { acquireCount: { w: 3 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 3 } storage:{} 121ms
2020-05-09T05:31:42.572-0700 I  COMMAND  [conn82] command config.$cmd command: update { update: "collections", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "jepsendb.jepsencoll" }, u: { _id: "jepsendb.jepsencoll", lastmodEpoch: ObjectId('5eb6a2aeecc1ba4072ee52e8'), lastmod: new Date(4294967302), dropped: false, key: { _id: "hashed" }, unique: false, uuid: UUID("d075f6ec-3562-4e33-82e1-88864582ea58") }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, lsid: { id: UUID("41248678-1ecd-4640-b946-9beba126d6d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027502, 11), signature: { hash: BinData(0, 9623348AD2101F6322BC0C93EC2073B0FD22395E), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:33970", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027502, 11), t: 2 } }, $db: "config" } numYields:0 reslen:650 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 4 } }, Global: { acquireCount: { r: 1, w: 3 } }, Database: { acquireCount: { w: 3 } }, Collection: { acquireCount: { r: 2, w: 2, W: 1 } }, Mutex: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 3, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 221ms
2020-05-09T05:31:43.058-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:43.060-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:43.085-0700 I  SHARDING [conn41] distributed lock with ts: 5eb6a2ad33caaefe806e411c' unlocked.
2020-05-09T05:31:43.098-0700 I  SHARDING [conn41] distributed lock with ts: 5eb6a2ad33caaefe806e4117' unlocked.
2020-05-09T05:31:43.098-0700 I  COMMAND  [conn41] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "jepsendb.jepsencoll", key: { _id: "hashed" }, unique: false, numInitialChunks: 7, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("41248678-1ecd-4640-b946-9beba126d6d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027501, 14), signature: { hash: BinData(0, 0A6DE963D9DB7196755249F2A13BB99507B73BAF), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n1:27017", client: "192.168.122.1:33970", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027501, 14), t: 2 } }, $db: "admin" } numYields:0 reslen:585 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 4 } }, ReplicationStateTransition: { acquireCount: { w: 6 } }, Global: { acquireCount: { r: 2, w: 4 } }, Database: { acquireCount: { r: 2, w: 4 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { r: 10, W: 1 } } } flowControl:{ acquireCount: 4, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 1282ms
2020-05-09T05:31:43.367-0700 I  SHARDING [conn56] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40ab
2020-05-09T05:31:43.368-0700 I  SHARDING [conn56] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:43.381-0700 I  SHARDING [conn56] distributed lock with ts: 5eb6a2ad33caaefe806e40ab' unlocked.
2020-05-09T05:31:43.381-0700 I  COMMAND  [conn56] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("c0a6c99a-170e-4888-a626-445b861ea469"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027498, 4), signature: { hash: BinData(0, 5B35242D07370DB48621B9FAF7B7E0D276CB8032), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n2:27017", client: "192.168.122.1:47562", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027498, 4), t: 2 } }, $db: "admin" } numYields:0 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 11 } }, ReplicationStateTransition: { acquireCount: { w: 24 } }, Global: { acquireCount: { r: 17, w: 7 } }, Database: { acquireCount: { r: 13, w: 7 } }, Collection: { acquireCount: { r: 9, w: 7 } }, Mutex: { acquireCount: { r: 22 } }, oplog: { acquireCount: { r: 4 } } } flowControl:{ acquireCount: 7, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 2058ms
2020-05-09T05:31:43.398-0700 I  SHARDING [conn56] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2af33caaefe806e41f1
2020-05-09T05:31:43.414-0700 I  SHARDING [conn56] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2af33caaefe806e41f8
2020-05-09T05:31:43.432-0700 I  SHARDING [conn56] distributed lock with ts: 5eb6a2af33caaefe806e41f8' unlocked.
2020-05-09T05:31:43.448-0700 I  SHARDING [conn56] distributed lock with ts: 5eb6a2af33caaefe806e41f1' unlocked.
2020-05-09T05:31:43.461-0700 I  SHARDING [conn56] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2af33caaefe806e4213
2020-05-09T05:31:43.479-0700 I  SHARDING [conn56] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2af33caaefe806e4218
2020-05-09T05:31:43.483-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:43.485-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:43.493-0700 I  SHARDING [conn56] distributed lock with ts: 5eb6a2af33caaefe806e4218' unlocked.
2020-05-09T05:31:43.508-0700 I  SHARDING [conn56] distributed lock with ts: 5eb6a2af33caaefe806e4213' unlocked.
2020-05-09T05:31:43.889-0700 I  SHARDING [conn65] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40a6
2020-05-09T05:31:43.890-0700 I  SHARDING [conn65] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:43.903-0700 I  SHARDING [conn65] distributed lock with ts: 5eb6a2ad33caaefe806e40a6' unlocked.
2020-05-09T05:31:43.904-0700 I  COMMAND  [conn65] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("8be4f5ac-baa3-40e8-b7ba-a98e320207d2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027498, 4), signature: { hash: BinData(0, 5B35242D07370DB48621B9FAF7B7E0D276CB8032), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n3:27017", client: "192.168.122.1:55198", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027498, 4), t: 2 } }, $db: "admin" } numYields:10 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 23 } }, ReplicationStateTransition: { acquireCount: { w: 39 } }, Global: { acquireCount: { r: 21, w: 18 } }, Database: { acquireCount: { r: 16, w: 18 } }, Collection: { acquireCount: { r: 11, w: 18 } }, Mutex: { acquireCount: { r: 26 } }, oplog: { acquireCount: { r: 5 } } } flowControl:{ acquireCount: 18, timeAcquiringMicros: 20 } storage:{} protocol:op_msg 2581ms
2020-05-09T05:31:43.920-0700 I  SHARDING [conn65] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2af33caaefe806e4262
2020-05-09T05:31:43.934-0700 I  SHARDING [conn65] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2af33caaefe806e4269
2020-05-09T05:31:43.952-0700 I  SHARDING [conn65] distributed lock with ts: 5eb6a2af33caaefe806e4269' unlocked.
2020-05-09T05:31:43.965-0700 I  SHARDING [conn65] distributed lock with ts: 5eb6a2af33caaefe806e4262' unlocked.
2020-05-09T05:31:43.982-0700 I  SHARDING [conn65] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2af33caaefe806e4283
2020-05-09T05:31:43.998-0700 I  SHARDING [conn65] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2af33caaefe806e4289
2020-05-09T05:31:44.001-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:44.002-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 0 ms
2020-05-09T05:31:44.014-0700 I  SHARDING [conn65] distributed lock with ts: 5eb6a2af33caaefe806e4289' unlocked.
2020-05-09T05:31:44.028-0700 I  SHARDING [conn65] distributed lock with ts: 5eb6a2af33caaefe806e4283' unlocked.
2020-05-09T05:31:44.405-0700 I  SHARDING [conn71] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40ac
2020-05-09T05:31:44.405-0700 I  SHARDING [conn71] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:44.451-0700 I  SHARDING [conn71] distributed lock with ts: 5eb6a2ad33caaefe806e40ac' unlocked.
2020-05-09T05:31:44.451-0700 I  COMMAND  [conn71] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("3da187f3-abd5-4f13-b802-4eb985aa8690"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027497, 6), signature: { hash: BinData(0, 2D0A2292DCCF9C822935EA372D27DED963F25D41), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n4:27017", client: "192.168.122.1:39278", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027497, 6), t: 2 } }, $db: "admin" } numYields:17 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 32 } }, ReplicationStateTransition: { acquireCount: { w: 51 } }, Global: { acquireCount: { r: 25, w: 26 } }, Database: { acquireCount: { r: 19, w: 26 } }, Collection: { acquireCount: { r: 13, w: 26 } }, Mutex: { acquireCount: { r: 30 } }, oplog: { acquireCount: { r: 6 } } } flowControl:{ acquireCount: 26, timeAcquiringMicros: 31 } storage:{} protocol:op_msg 3127ms
2020-05-09T05:31:44.468-0700 I  SHARDING [conn71] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2b033caaefe806e42cf
2020-05-09T05:31:44.479-0700 I  SHARDING [conn71] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2b033caaefe806e42d6
2020-05-09T05:31:44.491-0700 I  SHARDING [conn71] distributed lock with ts: 5eb6a2b033caaefe806e42d6' unlocked.
2020-05-09T05:31:44.501-0700 I  SHARDING [conn71] distributed lock with ts: 5eb6a2b033caaefe806e42cf' unlocked.
2020-05-09T05:31:44.514-0700 I  SHARDING [conn71] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2b033caaefe806e42f1
2020-05-09T05:31:44.522-0700 I  SHARDING [conn71] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2b033caaefe806e42f6
2020-05-09T05:31:44.526-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:44.527-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 0 ms
2020-05-09T05:31:44.537-0700 I  SHARDING [conn71] distributed lock with ts: 5eb6a2b033caaefe806e42f6' unlocked.
2020-05-09T05:31:44.545-0700 I  SHARDING [conn71] distributed lock with ts: 5eb6a2b033caaefe806e42f1' unlocked.
2020-05-09T05:31:44.966-0700 I  SHARDING [conn55] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40bb
2020-05-09T05:31:44.967-0700 I  SHARDING [conn55] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:44.978-0700 I  SHARDING [conn55] distributed lock with ts: 5eb6a2ad33caaefe806e40bb' unlocked.
2020-05-09T05:31:44.978-0700 I  COMMAND  [conn55] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("d36398ca-4da3-4f7d-87e9-181104b715fe"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027497, 6), signature: { hash: BinData(0, 2D0A2292DCCF9C822935EA372D27DED963F25D41), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n9:27017", client: "192.168.122.1:41010", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027497, 6), t: 2 } }, $db: "admin" } numYields:27 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 44 } }, ReplicationStateTransition: { acquireCount: { w: 66 } }, Global: { acquireCount: { r: 29, w: 37 } }, Database: { acquireCount: { r: 22, w: 37 } }, Collection: { acquireCount: { r: 15, w: 37 } }, Mutex: { acquireCount: { r: 34 } }, oplog: { acquireCount: { r: 7 } } } flowControl:{ acquireCount: 37, timeAcquiringMicros: 44 } storage:{} protocol:op_msg 3653ms
2020-05-09T05:31:44.994-0700 I  SHARDING [conn55] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2b033caaefe806e4337
2020-05-09T05:31:45.005-0700 I  SHARDING [conn55] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2b033caaefe806e433e
2020-05-09T05:31:45.014-0700 I  SHARDING [conn55] distributed lock with ts: 5eb6a2b033caaefe806e433e' unlocked.
2020-05-09T05:31:45.025-0700 I  SHARDING [conn55] distributed lock with ts: 5eb6a2b033caaefe806e4337' unlocked.
2020-05-09T05:31:45.037-0700 I  SHARDING [conn55] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2b133caaefe806e4359
2020-05-09T05:31:45.046-0700 I  SHARDING [conn55] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2b133caaefe806e435e
2020-05-09T05:31:45.050-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:45.051-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 0 ms
2020-05-09T05:31:45.059-0700 I  SHARDING [conn55] distributed lock with ts: 5eb6a2b133caaefe806e435e' unlocked.
2020-05-09T05:31:45.068-0700 I  SHARDING [conn55] distributed lock with ts: 5eb6a2b133caaefe806e4359' unlocked.
2020-05-09T05:31:45.493-0700 I  SHARDING [conn37] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40b8
2020-05-09T05:31:45.494-0700 I  SHARDING [conn37] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:45.505-0700 I  SHARDING [conn37] distributed lock with ts: 5eb6a2ad33caaefe806e40b8' unlocked.
2020-05-09T05:31:45.505-0700 I  COMMAND  [conn37] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("23a72864-8cf3-4a5c-9252-6f53e95cd3f2"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027497, 6), signature: { hash: BinData(0, 2D0A2292DCCF9C822935EA372D27DED963F25D41), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n8:27017", client: "192.168.122.1:39220", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027497, 6), t: 2 } }, $db: "admin" } numYields:37 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 56 } }, ReplicationStateTransition: { acquireCount: { w: 81 } }, Global: { acquireCount: { r: 33, w: 48 } }, Database: { acquireCount: { r: 25, w: 48 } }, Collection: { acquireCount: { r: 17, w: 48 } }, Mutex: { acquireCount: { r: 38 } }, oplog: { acquireCount: { r: 8 } } } flowControl:{ acquireCount: 48, timeAcquiringMicros: 68 } storage:{} protocol:op_msg 4180ms
2020-05-09T05:31:45.507-0700 W  SHARDING [conn54] config server local time went backwards, from last seen: 2020-05-09T05:31:45.505-0700 to 2020-05-09T05:31:45.504-0700
2020-05-09T05:31:45.507-0700 W  SHARDING [conn63] config server local time went backwards, from last seen: 2020-05-09T05:31:45.505-0700 to 2020-05-09T05:31:45.504-0700
2020-05-09T05:31:45.526-0700 I  SHARDING [conn37] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2b133caaefe806e439c
2020-05-09T05:31:45.534-0700 I  SHARDING [conn37] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2b133caaefe806e43a4
2020-05-09T05:31:45.544-0700 I  SHARDING [conn37] distributed lock with ts: 5eb6a2b133caaefe806e43a4' unlocked.
2020-05-09T05:31:45.551-0700 I  SHARDING [conn37] distributed lock with ts: 5eb6a2b133caaefe806e439c' unlocked.
2020-05-09T05:31:45.562-0700 I  SHARDING [conn37] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2b133caaefe806e43bd
2020-05-09T05:31:45.569-0700 I  SHARDING [conn37] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2b133caaefe806e43c3
2020-05-09T05:31:45.573-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:45.575-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:45.582-0700 I  SHARDING [conn37] distributed lock with ts: 5eb6a2b133caaefe806e43c3' unlocked.
2020-05-09T05:31:45.594-0700 I  SHARDING [conn37] distributed lock with ts: 5eb6a2b133caaefe806e43bd' unlocked.
2020-05-09T05:31:46.015-0700 I  SHARDING [conn54] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40ae
2020-05-09T05:31:46.015-0700 I  SHARDING [conn54] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:46.023-0700 I  SHARDING [conn54] distributed lock with ts: 5eb6a2ad33caaefe806e40ae' unlocked.
2020-05-09T05:31:46.023-0700 I  COMMAND  [conn54] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("5b9e3103-97a1-4bda-bdd5-2b130db52416"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027497, 6), signature: { hash: BinData(0, 2D0A2292DCCF9C822935EA372D27DED963F25D41), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n7:27017", client: "192.168.122.1:38488", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027497, 6), t: 2 } }, $db: "admin" } numYields:41 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 62 } }, ReplicationStateTransition: { acquireCount: { w: 90 } }, Global: { acquireCount: { r: 37, w: 53 } }, Database: { acquireCount: { r: 28, w: 53 } }, Collection: { acquireCount: { r: 19, w: 53 } }, Mutex: { acquireCount: { r: 42 } }, oplog: { acquireCount: { r: 9 } } } flowControl:{ acquireCount: 53, timeAcquiringMicros: 66 } storage:{} protocol:op_msg 4699ms
2020-05-09T05:31:46.037-0700 I  SHARDING [conn54] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2b233caaefe806e43fb
2020-05-09T05:31:46.045-0700 I  SHARDING [conn54] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2b233caaefe806e4402
2020-05-09T05:31:46.062-0700 I  SHARDING [conn54] distributed lock with ts: 5eb6a2b233caaefe806e4402' unlocked.
2020-05-09T05:31:46.073-0700 I  SHARDING [conn54] distributed lock with ts: 5eb6a2b233caaefe806e43fb' unlocked.
2020-05-09T05:31:46.079-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:46.081-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 0 ms
2020-05-09T05:31:46.086-0700 I  SHARDING [conn54] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2b233caaefe806e4423
2020-05-09T05:31:46.095-0700 I  SHARDING [conn54] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2b233caaefe806e4430
2020-05-09T05:31:46.107-0700 I  SHARDING [conn54] distributed lock with ts: 5eb6a2b233caaefe806e4430' unlocked.
2020-05-09T05:31:46.113-0700 I  SHARDING [conn54] distributed lock with ts: 5eb6a2b233caaefe806e4423' unlocked.
2020-05-09T05:31:46.527-0700 I  SHARDING [conn63] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40b2
2020-05-09T05:31:46.528-0700 I  SHARDING [conn63] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:46.537-0700 I  SHARDING [conn63] distributed lock with ts: 5eb6a2ad33caaefe806e40b2' unlocked.
2020-05-09T05:31:46.537-0700 I  COMMAND  [conn63] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("3ad1eaac-c591-4f0c-b73b-11afb95a20b0"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027498, 4), signature: { hash: BinData(0, 5B35242D07370DB48621B9FAF7B7E0D276CB8032), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:57864", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027498, 4), t: 2 } }, $db: "admin" } numYields:55 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 78 } }, ReplicationStateTransition: { acquireCount: { w: 109 } }, Global: { acquireCount: { r: 41, w: 68 } }, Database: { acquireCount: { r: 31, w: 68 } }, Collection: { acquireCount: { r: 21, w: 68 } }, Mutex: { acquireCount: { r: 46 } }, oplog: { acquireCount: { r: 10 } } } flowControl:{ acquireCount: 68, timeAcquiringMicros: 86 } storage:{} protocol:op_msg 5213ms
2020-05-09T05:31:47.040-0700 I  SHARDING [conn34] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2ad33caaefe806e40b5
2020-05-09T05:31:47.041-0700 I  SHARDING [conn34] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:47.052-0700 I  SHARDING [conn34] distributed lock with ts: 5eb6a2ad33caaefe806e40b5' unlocked.
2020-05-09T05:31:47.053-0700 I  COMMAND  [conn34] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("2d7a6e85-2051-4f10-9d68-479d1999c1ec"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027497, 6), signature: { hash: BinData(0, 2D0A2292DCCF9C822935EA372D27DED963F25D41), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n6:27017", client: "192.168.122.1:55150", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027497, 6), t: 2 } }, $db: "admin" } numYields:54 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 79 } }, ReplicationStateTransition: { acquireCount: { w: 113 } }, Global: { acquireCount: { r: 45, w: 68 } }, Database: { acquireCount: { r: 34, w: 68 } }, Collection: { acquireCount: { r: 23, w: 68 } }, Mutex: { acquireCount: { r: 50 } }, oplog: { acquireCount: { r: 11 } } } flowControl:{ acquireCount: 68, timeAcquiringMicros: 82 } storage:{} protocol:op_msg 5728ms
2020-05-09T05:31:51.350-0700 I  SHARDING [conn34] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2b733caaefe806e44b7
2020-05-09T05:31:51.351-0700 I  SHARDING [conn34] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:51.361-0700 I  SHARDING [conn34] distributed lock with ts: 5eb6a2b733caaefe806e44b7' unlocked.
2020-05-09T05:31:51.376-0700 I  SHARDING [conn34] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2b733caaefe806e44d0
2020-05-09T05:31:51.385-0700 I  SHARDING [conn34] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2b733caaefe806e44d7
2020-05-09T05:31:51.399-0700 I  SHARDING [conn34] distributed lock with ts: 5eb6a2b733caaefe806e44d7' unlocked.
2020-05-09T05:31:51.407-0700 I  SHARDING [conn34] distributed lock with ts: 5eb6a2b733caaefe806e44d0' unlocked.
2020-05-09T05:31:51.418-0700 I  SHARDING [conn34] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2b733caaefe806e44f1
2020-05-09T05:31:51.428-0700 I  SHARDING [conn34] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2b733caaefe806e44f7
2020-05-09T05:31:51.432-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:51.434-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:51.443-0700 I  SHARDING [conn34] distributed lock with ts: 5eb6a2b733caaefe806e44f7' unlocked.
2020-05-09T05:31:51.454-0700 I  SHARDING [conn34] distributed lock with ts: 5eb6a2b733caaefe806e44f1' unlocked.
2020-05-09T05:31:51.864-0700 I  SHARDING [conn63] distributed lock 'jepsendb' acquired for 'enableSharding', ts : 5eb6a2b733caaefe806e44b9
2020-05-09T05:31:51.864-0700 I  SHARDING [conn63] Enabling sharding for database [jepsendb] in config db
2020-05-09T05:31:51.876-0700 I  SHARDING [conn63] distributed lock with ts: 5eb6a2b733caaefe806e44b9' unlocked.
2020-05-09T05:31:51.876-0700 I  COMMAND  [conn63] command admin.$cmd command: _configsvrEnableSharding { _configsvrEnableSharding: "jepsendb", writeConcern: { w: "majority", wtimeout: 60000 }, lsid: { id: UUID("780bfa32-dc67-4e9e-9f81-e9c0fbfac08d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027508, 4), signature: { hash: BinData(0, A4874C71028BFFFFDFAAE344FE3A96E3D7BC0017), keyId: 6824821114879868942 } }, $client: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25", mongos: { host: "n5:27017", client: "192.168.122.1:58012", version: "4.2.6" } }, $configServerState: { opTime: { ts: Timestamp(1589027508, 4), t: 2 } }, $db: "admin" } numYields:1 reslen:505 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 6 } }, ReplicationStateTransition: { acquireCount: { w: 10 } }, Global: { acquireCount: { r: 5, w: 5 } }, Database: { acquireCount: { r: 4, w: 5 } }, Collection: { acquireCount: { r: 3, w: 5 } }, Mutex: { acquireCount: { r: 10 } }, oplog: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 5, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 537ms
2020-05-09T05:31:51.891-0700 I  SHARDING [conn63] distributed lock 'jepsendb' acquired for 'createCollection', ts : 5eb6a2b733caaefe806e452a
2020-05-09T05:31:51.901-0700 I  SHARDING [conn63] distributed lock 'jepsendb.jepsencoll' acquired for 'createCollection', ts : 5eb6a2b733caaefe806e4531
2020-05-09T05:31:51.911-0700 I  SHARDING [conn63] distributed lock with ts: 5eb6a2b733caaefe806e4531' unlocked.
2020-05-09T05:31:51.921-0700 I  SHARDING [conn63] distributed lock with ts: 5eb6a2b733caaefe806e452a' unlocked.
2020-05-09T05:31:51.932-0700 I  SHARDING [conn63] distributed lock 'jepsendb' acquired for 'shardCollection', ts : 5eb6a2b733caaefe806e454c
2020-05-09T05:31:51.940-0700 I  SHARDING [conn63] distributed lock 'jepsendb.jepsencoll' acquired for 'shardCollection', ts : 5eb6a2b733caaefe806e4552
2020-05-09T05:31:51.942-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:51.944-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:51.952-0700 I  SHARDING [conn63] distributed lock with ts: 5eb6a2b733caaefe806e4552' unlocked.
2020-05-09T05:31:51.959-0700 I  SHARDING [conn63] distributed lock with ts: 5eb6a2b733caaefe806e454c' unlocked.
2020-05-09T05:31:51.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49418 #109 (72 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49426 #110 (73 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.1:49418 conn109: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.984-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.1:49426 conn110: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.006-0700 I  NETWORK  [conn109] end connection 192.168.122.1:49418 (72 connections now open)
2020-05-09T05:31:52.006-0700 I  NETWORK  [conn110] end connection 192.168.122.1:49426 (71 connections now open)
2020-05-09T05:31:52.962-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:31:53.065-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:31:53.065-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-09T05:31:53.065-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-09T05:31:53.065-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:53.065-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:53.065-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:31:53.065-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-09T05:31:53.065-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:31:53.596-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49866 #111 (72 connections now open)
2020-05-09T05:31:53.596-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49870 #112 (73 connections now open)
2020-05-09T05:31:53.596-0700 I  NETWORK  [conn111] received client metadata from 192.168.122.1:49866 conn111: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:53.597-0700 I  NETWORK  [conn112] received client metadata from 192.168.122.1:49870 conn112: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:53.600-0700 I  REPL     [replexec-4] Member n3:27019 is now in state SECONDARY
2020-05-09T05:31:53.600-0700 I  REPL     [replexec-3] Member n2:27019 is now in state PRIMARY
2020-05-09T05:31:53.600-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-09T05:31:54.706-0700
2020-05-09T05:31:53.606-0700 I  NETWORK  [conn111] end connection 192.168.122.1:49866 (72 connections now open)
2020-05-09T05:31:53.606-0700 I  NETWORK  [conn112] end connection 192.168.122.1:49870 (71 connections now open)
2020-05-09T05:31:53.823-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027511, 20), t: 2 } }
2020-05-09T05:31:53.823-0700 I  ELECTION [conn9] Sending vote response: { term: 3, voteGranted: false, reason: "candidate's term (2) is lower than mine (3)" }
2020-05-09T05:31:53.823-0700 I  NETWORK  [conn9] end connection 192.168.122.12:39976 (70 connections now open)
2020-05-09T05:31:54.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41132 #113 (71 connections now open)
2020-05-09T05:31:54.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41134 #114 (72 connections now open)
2020-05-09T05:31:54.208-0700 I  NETWORK  [conn113] received client metadata from 192.168.122.12:41132 conn113: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:54.208-0700 I  NETWORK  [conn114] received client metadata from 192.168.122.12:41134 conn114: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:54.527-0700 I  NETWORK  [conn10] end connection 192.168.122.13:38004 (71 connections now open)
2020-05-09T05:31:54.706-0700 I  REPL     [replexec-3] Canceling priority takeover callback
2020-05-09T05:31:54.706-0700 I  ELECTION [replexec-3] Not starting an election for a priority takeover, since we are not electable due to: Not standing for election because member is not caught up enough to the most up-to-date member to call for priority takeover - must be within 2 seconds (mask 0x80)
2020-05-09T05:31:54.879-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:39188 #115 (72 connections now open)
2020-05-09T05:31:54.880-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.13:39188 conn115: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:55.066-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T05:31:55.067-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-09T05:31:55.069-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-09T05:31:55.072-0700 I  REPL     [replication-1] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n3:27019, my last fetched oplog optime: { ts: Timestamp(1589027514, 1), t: 3 }, latest oplog optime of sync source: { ts: Timestamp(1589027514, 1), t: 3 } (n2:27019 is)
2020-05-09T05:31:55.072-0700 I  REPL     [replication-1] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n3:27019, OpTime { ts: Timestamp(1589027514, 1), t: 3 }, its sync source index:-1
2020-05-09T05:31:55.072-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1589027514, 1), t: 3 }; sync source index: -1; primary index: 1) is no longer valid
2020-05-09T05:31:55.072-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-09T05:31:55.072-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T05:31:55.073-0700 I  ELECTION [replexec-2] Scheduling priority takeover at 2020-05-09T05:31:56.099-0700
2020-05-09T05:31:55.076-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-09T05:31:55.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50006 #117 (73 connections now open)
2020-05-09T05:31:55.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50008 #118 (74 connections now open)
2020-05-09T05:31:55.137-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.1:50006 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.138-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.1:50008 conn118: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.141-0700 I  NETWORK  [conn117] end connection 192.168.122.1:50006 (73 connections now open)
2020-05-09T05:31:55.141-0700 I  NETWORK  [conn118] end connection 192.168.122.1:50008 (72 connections now open)
2020-05-09T05:31:55.652-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50030 #119 (73 connections now open)
2020-05-09T05:31:55.652-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50038 #120 (74 connections now open)
2020-05-09T05:31:55.652-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.1:50030 conn119: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.652-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.1:50038 conn120: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.654-0700 I  NETWORK  [conn119] end connection 192.168.122.1:50030 (73 connections now open)
2020-05-09T05:31:55.654-0700 I  NETWORK  [conn120] end connection 192.168.122.1:50038 (72 connections now open)
2020-05-09T05:31:56.099-0700 I  REPL     [replexec-2] Canceling priority takeover callback
2020-05-09T05:31:56.099-0700 I  ELECTION [replexec-2] Starting an election for a priority takeover
2020-05-09T05:31:56.099-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 3
2020-05-09T05:31:56.099-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 125 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027514, 1), t: 3 } }
2020-05-09T05:31:56.099-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 126 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027514, 1), t: 3 } }
2020-05-09T05:31:56.100-0700 I  ELECTION [replexec-5] VoteRequester(term 3 dry run) received a yes vote from n2:27019; response message: { term: 3, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000003') }, lastCommittedOpTime: Timestamp(1589027514, 1), $clusterTime: { clusterTime: Timestamp(1589027515, 1901), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027514, 1) }
2020-05-09T05:31:56.100-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 4
2020-05-09T05:31:56.106-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 127 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027514, 1), t: 3 } }
2020-05-09T05:31:56.106-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 128 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027514, 1), t: 3 } }
2020-05-09T05:31:56.110-0700 I  ELECTION [replexec-2] VoteRequester(term 4) received a yes vote from n3:27019; response message: { term: 4, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027514, 1), $clusterTime: { clusterTime: Timestamp(1589027515, 1901), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027514, 1) }
2020-05-09T05:31:56.110-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 4
2020-05-09T05:31:56.110-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T05:31:56.110-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:31:56.110-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was :27017
2020-05-09T05:31:56.110-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T05:31:56.110-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T05:31:56.113-0700 I  REPL     [replexec-2] Member n2:27019 is now in state SECONDARY
2020-05-09T05:31:56.113-0700 I  REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027514, 1), t: 3 }. My Last Applied: { ts: Timestamp(1589027514, 1), t: 3 }
2020-05-09T05:31:56.113-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T05:31:56.113-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T05:31:56.113-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 4
2020-05-09T05:31:56.114-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:56.114-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:56.114-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:31:56.117-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:31:56.117-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:31:56.118-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:31:56.118-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:31:56.118-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:31:56.170-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50046 #122 (73 connections now open)
2020-05-09T05:31:56.171-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50052 #123 (74 connections now open)
2020-05-09T05:31:56.171-0700 I  NETWORK  [conn122] received client metadata from 192.168.122.1:50046 conn122: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.171-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.1:50052 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.175-0700 I  NETWORK  [conn122] end connection 192.168.122.1:50046 (73 connections now open)
2020-05-09T05:31:56.176-0700 I  NETWORK  [conn123] end connection 192.168.122.1:50052 (72 connections now open)
2020-05-09T05:31:56.601-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50076 #124 (73 connections now open)
2020-05-09T05:31:56.602-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50078 #125 (74 connections now open)
2020-05-09T05:31:56.602-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.1:50076 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.602-0700 I  NETWORK  [conn125] received client metadata from 192.168.122.1:50078 conn125: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.605-0700 I  NETWORK  [conn124] end connection 192.168.122.1:50076 (73 connections now open)
2020-05-09T05:31:56.605-0700 I  NETWORK  [conn125] end connection 192.168.122.1:50078 (72 connections now open)
2020-05-09T05:31:56.914-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50164 #126 (73 connections now open)
2020-05-09T05:31:56.915-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50166 #127 (74 connections now open)
2020-05-09T05:31:56.915-0700 I  NETWORK  [conn126] received client metadata from 192.168.122.1:50164 conn126: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.915-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.1:50166 conn127: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.918-0700 I  NETWORK  [conn126] end connection 192.168.122.1:50164 (73 connections now open)
2020-05-09T05:31:56.918-0700 I  NETWORK  [conn127] end connection 192.168.122.1:50166 (72 connections now open)
2020-05-09T05:31:57.199-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:39518 #128 (73 connections now open)
2020-05-09T05:31:57.199-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.13:39518 conn128: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:57.218-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1919), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 585ms
2020-05-09T05:31:57.218-0700 I  COMMAND  [conn65] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1913), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 379ms
2020-05-09T05:31:57.218-0700 I  COMMAND  [conn71] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1905), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 585ms
2020-05-09T05:31:57.218-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1905), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 585ms
2020-05-09T05:31:57.218-0700 I  COMMAND  [conn54] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1919), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 585ms
2020-05-09T05:31:57.218-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:31:57.218-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027516, 2), signature: { hash: BinData(0, 89D96DA2F8500134175C568BB87BAC035B78E89A), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 800ms
2020-05-09T05:31:57.219-0700 I  COMMAND  [conn55] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027516, 2), signature: { hash: BinData(0, 89D96DA2F8500134175C568BB87BAC035B78E89A), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 428ms
2020-05-09T05:31:57.219-0700 I  COMMAND  [conn63] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1921), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 585ms
2020-05-09T05:31:57.219-0700 I  COMMAND  [conn56] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027515, 1917), signature: { hash: BinData(0, FC955E575DC557614640C16D41464AC5F7A322B3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027514, 1), t: 3 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 379ms
2020-05-09T05:31:57.219-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:31:57.536-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50222 #129 (74 connections now open)
2020-05-09T05:31:57.536-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50226 #130 (75 connections now open)
2020-05-09T05:31:57.536-0700 I  NETWORK  [conn129] received client metadata from 192.168.122.1:50222 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:57.537-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.1:50226 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:57.539-0700 I  NETWORK  [conn129] end connection 192.168.122.1:50222 (74 connections now open)
2020-05-09T05:31:57.539-0700 I  NETWORK  [conn130] end connection 192.168.122.1:50226 (73 connections now open)
2020-05-09T05:31:58.574-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T05:31:59.030-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50320 #131 (74 connections now open)
2020-05-09T05:31:59.030-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50324 #132 (75 connections now open)
2020-05-09T05:31:59.030-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.1:50320 conn131: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:59.030-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.1:50324 conn132: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:59.032-0700 I  NETWORK  [conn131] end connection 192.168.122.1:50320 (74 connections now open)
2020-05-09T05:31:59.033-0700 I  NETWORK  [conn132] end connection 192.168.122.1:50324 (73 connections now open)
2020-05-09T05:31:59.579-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:31:59.579-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:31:59.579-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T05:31:59.579-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T05:31:59.580-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:59.580-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:59.580-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:31:59.580-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-09T05:31:59.580-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:00.524-0700 I  REPL     [replexec-3] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:00.532-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-09T05:32:00.532-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-09T05:32:01.538-0700
2020-05-09T05:32:00.581-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T05:32:00.581-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-09T05:32:00.583-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T05:32:00.603-0700 I  NETWORK  [conn76] end connection 192.168.122.12:40294 (72 connections now open)
2020-05-09T05:32:00.607-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41614 #135 (73 connections now open)
2020-05-09T05:32:00.608-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41612 #136 (74 connections now open)
2020-05-09T05:32:00.608-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.12:41614 conn135: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:00.608-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.12:41612 conn136: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:00.992-0700 I  NETWORK  [conn115] end connection 192.168.122.13:39188 (73 connections now open)
2020-05-09T05:32:01.055-0700 I  ELECTION [conn113] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:32:01.055-0700 I  ELECTION [conn113] Sending vote response: { term: 5, voteGranted: false, reason: "candidate's term (4) is lower than mine (5)" }
2020-05-09T05:32:01.056-0700 I  NETWORK  [conn114] end connection 192.168.122.12:41134 (72 connections now open)
2020-05-09T05:32:01.056-0700 I  NETWORK  [conn113] end connection 192.168.122.12:41132 (71 connections now open)
2020-05-09T05:32:01.253-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50404 #137 (72 connections now open)
2020-05-09T05:32:01.254-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50408 #138 (73 connections now open)
2020-05-09T05:32:01.254-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.1:50404 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:01.254-0700 I  NETWORK  [conn138] received client metadata from 192.168.122.1:50408 conn138: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:01.258-0700 I  NETWORK  [conn137] end connection 192.168.122.1:50404 (72 connections now open)
2020-05-09T05:32:01.258-0700 I  NETWORK  [conn138] end connection 192.168.122.1:50408 (71 connections now open)
2020-05-09T05:32:01.311-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:39650 #139 (72 connections now open)
2020-05-09T05:32:01.312-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.13:39650 conn139: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:01.312-0700 I  ELECTION [conn139] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:32:01.312-0700 I  ELECTION [conn139] Sending vote response: { term: 5, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027518, 5), t: 4 }, my last applied OpTime: { ts: Timestamp..." }
2020-05-09T05:32:01.538-0700 I  REPL     [replexec-2] Canceling priority takeover callback
2020-05-09T05:32:01.538-0700 I  ELECTION [replexec-2] Starting an election for a priority takeover
2020-05-09T05:32:01.538-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 5
2020-05-09T05:32:01.538-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 157 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027520, 1), t: 5 } }
2020-05-09T05:32:01.538-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 158 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027520, 1), t: 5 } }
2020-05-09T05:32:01.539-0700 I  ELECTION [replexec-1] VoteRequester(term 5 dry run) received a yes vote from n3:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027520, 1), $clusterTime: { clusterTime: Timestamp(1589027520, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027520, 1) }
2020-05-09T05:32:01.539-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 6
2020-05-09T05:32:01.540-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:01.543-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 159 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027520, 1), t: 5 } }
2020-05-09T05:32:01.543-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 160 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 6, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027520, 1), t: 5 } }
2020-05-09T05:32:01.548-0700 I  ELECTION [replexec-2] VoteRequester(term 6) received a yes vote from n3:27019; response message: { term: 6, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027520, 1), $clusterTime: { clusterTime: Timestamp(1589027520, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027520, 1) }
2020-05-09T05:32:01.548-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 6
2020-05-09T05:32:01.548-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T05:32:01.548-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was n2:27019
2020-05-09T05:32:01.548-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T05:32:01.768-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-09T05:32:02.548-0700 I  REPL     [replexec-4] Catchup timed out after becoming primary.
2020-05-09T05:32:02.548-0700 I  REPL     [replexec-4] Exited primary catch-up mode.
2020-05-09T05:32:02.548-0700 I  REPL     [replexec-4] Stopping replication producer
2020-05-09T05:32:02.548-0700 I  REPL     [replexec-1] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T05:32:02.548-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:02.548-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 6
2020-05-09T05:32:02.548-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:02.549-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:02.549-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:02.549-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T05:32:02.551-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:02.551-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:02.551-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:02.552-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:02.552-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:02.555-0700 W  QUERY    [conn20] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824821239433920524), stats: { stage: "COLLSCAN", nReturned: 14, executionTimeMillisEstimate: 1, works: 133, advanced: 14, needTime: 59, needYield: 0, saveState: 59, restoreState: 59, isEOF: 0, direction: "forward", docsExamined: 14 }
2020-05-09T05:32:03.098-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50552 #142 (73 connections now open)
2020-05-09T05:32:03.098-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50556 #143 (74 connections now open)
2020-05-09T05:32:03.098-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.1:50552 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:03.098-0700 I  NETWORK  [conn143] received client metadata from 192.168.122.1:50556 conn143: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:03.103-0700 I  NETWORK  [conn142] end connection 192.168.122.1:50552 (73 connections now open)
2020-05-09T05:32:03.103-0700 I  NETWORK  [conn143] end connection 192.168.122.1:50556 (72 connections now open)
2020-05-09T05:32:03.756-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:03.756-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:03.757-0700 I  COMMAND  [conn65] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027522, 12), signature: { hash: BinData(0, F1DFBE6DA6114536E9F8E7990E941D29BCD291A2), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027520, 1), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 906ms
2020-05-09T05:32:03.757-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027522, 12), signature: { hash: BinData(0, F1DFBE6DA6114536E9F8E7990E941D29BCD291A2), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027520, 1), t: 5 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 3 } storage:{} protocol:op_msg 907ms
2020-05-09T05:32:04.472-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50632 #144 (73 connections now open)
2020-05-09T05:32:04.473-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50634 #145 (74 connections now open)
2020-05-09T05:32:04.473-0700 I  NETWORK  [conn144] received client metadata from 192.168.122.1:50632 conn144: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:04.473-0700 I  NETWORK  [conn145] received client metadata from 192.168.122.1:50634 conn145: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:04.477-0700 I  NETWORK  [conn144] end connection 192.168.122.1:50632 (73 connections now open)
2020-05-09T05:32:04.477-0700 I  NETWORK  [conn145] end connection 192.168.122.1:50634 (72 connections now open)
2020-05-09T05:32:04.760-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-09T05:32:05.259-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50642 #146 (73 connections now open)
2020-05-09T05:32:05.259-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50652 #147 (74 connections now open)
2020-05-09T05:32:05.260-0700 I  NETWORK  [conn146] received client metadata from 192.168.122.1:50642 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:05.260-0700 I  NETWORK  [conn147] received client metadata from 192.168.122.1:50652 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:05.264-0700 I  NETWORK  [conn146] end connection 192.168.122.1:50642 (73 connections now open)
2020-05-09T05:32:05.264-0700 I  NETWORK  [conn147] end connection 192.168.122.1:50652 (72 connections now open)
2020-05-09T05:32:06.196-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:06.269-0700 I  REPL     [replexec-0] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:06.269-0700 I  REPL     [replexec-0] can't see a majority of the set, relinquishing primary
2020-05-09T05:32:06.269-0700 I  REPL     [replexec-0] Stepping down from primary in response to heartbeat
2020-05-09T05:32:06.269-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:06.269-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:06.269-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 7, userOpsRunning: 0 }
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn37] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27017:1589027495:-4028076255853485019" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027525, 113), signature: { hash: BinData(0, 7254D78896B42790307889D05802C4EE3545499E), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 201ms
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn54] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 I  REPL     [replexec-0] transition to SECONDARY from PRIMARY
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn73] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn63] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn54] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27017:1589027495:4498723705184841883" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 119), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 201ms
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn73] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27017:1589027495:8024958533017945185" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 112), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 200ms
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn63] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27017:1589027495:-3092204051443899780" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 120), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:746 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 200ms
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn55] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn34] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn55] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27017:1589027495:3290208215892541551" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 94), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 201ms
2020-05-09T05:32:06.270-0700 W  COMMAND  [conn43] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:06.270-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn34] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27017:1589027495:7883765758298039767" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 121), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 200ms
2020-05-09T05:32:06.270-0700 I  COMMAND  [conn43] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1589027495:563410028455241219" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 120), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:744 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 200ms
2020-05-09T05:32:06.756-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:06.756-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:32:06.911-0700 I  ELECTION [conn135] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027522, 12), t: 6 } }
2020-05-09T05:32:06.911-0700 I  ELECTION [conn135] Sending vote response: { term: 6, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027522, 12), t: 6 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T05:32:06.912-0700 I  NETWORK  [conn135] end connection 192.168.122.12:41614 (71 connections now open)
2020-05-09T05:32:06.976-0700 I  REPL     [replexec-1] Member n2:27019 is now in state PRIMARY
2020-05-09T05:32:06.976-0700 I  ELECTION [replexec-1] Scheduling priority takeover at 2020-05-09T05:32:08.008-0700
2020-05-09T05:32:07.271-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T05:32:07.273-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T05:32:07.274-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589027526, 126), t: 6 }. source's GTE: { ts: Timestamp(1589027526, 1537), t: 7 }
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-09T05:32:07.275-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 72 }
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-09T05:32:07.275-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 139
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 136
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 128
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 105
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 104
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 103
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 102
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 101
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 100
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 99
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 98
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 92
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 91
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 85
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 84
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-05-09T05:32:07.275-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 71
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 57
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 56
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 55
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 54
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 53
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-05-09T05:32:07.276-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 14
2020-05-09T05:32:07.276-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T05:32:07.276-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T05:32:07.276-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T05:32:07.299-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41958 #150 (72 connections now open)
2020-05-09T05:32:07.299-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:41954 #151 (73 connections now open)
2020-05-09T05:32:07.300-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.12:41958 conn150: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.300-0700 I  NETWORK  [conn151] received client metadata from 192.168.122.12:41954 conn151: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.315-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:07.317-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-09T05:32:07.318-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T05:32:07.318-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 06fbc13c-eb1d-4254-80f8-deeaa8ca575b to /var/lib/mongodb/rollback/config.lockpings/removed.2020-05-09T12-32-07.0.bson
2020-05-09T05:32:07.319-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T05:32:07.319-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T05:32:07.319-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T05:32:07.319-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T05:32:07.327-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589027522, 12) Initial Data Timestamp: Timestamp(1589027490, 1)
2020-05-09T05:32:07.328-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T05:32:07.338-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T05:32:07.338-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 202 records totaling to 44694 bytes
2020-05-09T05:32:07.338-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T05:32:07.338-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T05:32:07.342-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T05:32:07.343-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T05:32:07.360-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T05:32:07.360-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T05:32:07.360-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589027522, 12)
2020-05-09T05:32:07.360-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 0 insert operations, 7 update operations and 0 delete operations.
2020-05-09T05:32:07.360-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589027526, 120), t: 6 }
2020-05-09T05:32:07.360-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589027526, 120) }
2020-05-09T05:32:07.360-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T05:32:07.363-0700 I  NETWORK  [conn136] end connection 192.168.122.12:41612 (72 connections now open)
2020-05-09T05:32:07.364-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589027522, 12) (top of oplog: { ts: Timestamp(1589027522, 12), t: 6 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T05:32:07.364-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589027522, 12)
2020-05-09T05:32:07.364-0700 I  REPL     [rsBackgroundSync] No oplog entries to apply for recovery. Start point is at the top of the oplog.
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] Not updating committed snapshot because we are in rollback
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T05:32:07.275-0700
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T05:32:07.365-0700
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.lockpings
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589027526, 126), t: 6 }
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T05:32:06.069-0700
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T05:32:06.069-0700
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589027526, 120)
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589027522, 12)
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 		update: 7
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 0
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 7
2020-05-09T05:32:07.365-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T05:32:07.365-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T05:32:07.367-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T05:32:07.371-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50724 #152 (73 connections now open)
2020-05-09T05:32:07.371-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50728 #153 (74 connections now open)
2020-05-09T05:32:07.371-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:50724 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:07.371-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:50728 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:07.374-0700 I  NETWORK  [conn152] end connection 192.168.122.1:50724 (73 connections now open)
2020-05-09T05:32:07.374-0700 I  NETWORK  [conn153] end connection 192.168.122.1:50728 (72 connections now open)
2020-05-09T05:32:07.455-0700 I  NETWORK  [conn139] end connection 192.168.122.13:39650 (71 connections now open)
2020-05-09T05:32:07.775-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:39988 #154 (72 connections now open)
2020-05-09T05:32:07.776-0700 I  NETWORK  [conn154] received client metadata from 192.168.122.13:39988 conn154: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.777-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:08.071-0700 I  ELECTION [conn154] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027522, 12), t: 6 } }
2020-05-09T05:32:08.071-0700 I  ELECTION [conn154] Sending vote response: { term: 7, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027522, 12), t: 6 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T05:32:08.460-0700 I  ELECTION [replexec-4] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:32:08.460-0700 I  ELECTION [replexec-4] conducting a dry run election to see if we could be elected. current term: 7
2020-05-09T05:32:08.460-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 190 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027527, 851), t: 7 } }
2020-05-09T05:32:08.460-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 191 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027527, 851), t: 7 } }
2020-05-09T05:32:08.461-0700 I  ELECTION [replexec-5] VoteRequester(term 7 dry run) received a yes vote from n3:27019; response message: { term: 7, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027522, 12), $clusterTime: { clusterTime: Timestamp(1589027527, 979), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027522, 12) }
2020-05-09T05:32:08.461-0700 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 8
2020-05-09T05:32:08.461-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:08.464-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 192 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027527, 851), t: 7 } }
2020-05-09T05:32:08.464-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 193 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 8, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027527, 851), t: 7 } }
2020-05-09T05:32:08.464-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T05:32:08.469-0700 I  ELECTION [replexec-4] VoteRequester(term 8) received a yes vote from n3:27019; response message: { term: 8, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027522, 12), $clusterTime: { clusterTime: Timestamp(1589027527, 979), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027522, 12) }
2020-05-09T05:32:08.469-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 8
2020-05-09T05:32:08.469-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-09T05:32:08.469-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n2:27019
2020-05-09T05:32:08.469-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-09T05:32:08.469-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:08.476-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T05:32:08.476-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027522, 12), t: 6 }. My Last Applied: { ts: Timestamp(1589027527, 851), t: 7 }
2020-05-09T05:32:08.476-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-09T05:32:08.476-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-09T05:32:08.476-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 8
2020-05-09T05:32:08.476-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:08.476-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:08.476-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:08.476-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:08.476-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:08.479-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:08.479-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:08.479-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:08.480-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:08.480-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:08.480-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:08.480-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:08.481-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:08.481-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:08.982-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:10.036-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-09T05:32:10.073-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42082 #158 (73 connections now open)
2020-05-09T05:32:10.074-0700 I  NETWORK  [conn158] received client metadata from 192.168.122.12:42082 conn158: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:10.082-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn63] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1589027528159), up: 30, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027528, 381), signature: { hash: BinData(0, 03FC3A77C790AE119EA901B57F33950E63F73458), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1419ms
2020-05-09T05:32:10.082-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn56] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1589027528155), up: 30, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027528, 1588), signature: { hash: BinData(0, 03FC3A77C790AE119EA901B57F33950E63F73458), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 993ms
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn43] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1589027528154), up: 30, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027529, 1), signature: { hash: BinData(0, E9B26D457C672BFADA47A8243FF09DEF2FC42F12), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 895ms
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn50] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027528, 1588), signature: { hash: BinData(0, 03FC3A77C790AE119EA901B57F33950E63F73458), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 880ms
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027529, 1), signature: { hash: BinData(0, E9B26D457C672BFADA47A8243FF09DEF2FC42F12), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 874ms
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn73] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027529, 2), signature: { hash: BinData(0, E9B26D457C672BFADA47A8243FF09DEF2FC42F12), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 871ms
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn53] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027528, 1601), signature: { hash: BinData(0, 03FC3A77C790AE119EA901B57F33950E63F73458), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 771ms
2020-05-09T05:32:10.082-0700 I  COMMAND  [conn65] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027528, 1601), signature: { hash: BinData(0, 03FC3A77C790AE119EA901B57F33950E63F73458), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 865ms
2020-05-09T05:32:10.083-0700 I  COMMAND  [conn82] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27018:1589027499:6435143864506819548" }, update: { $set: { ping: new Date(1589027529366) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027529, 2), signature: { hash: BinData(0, E9B26D457C672BFADA47A8243FF09DEF2FC42F12), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 715ms
2020-05-09T05:32:10.083-0700 I  COMMAND  [conn61] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1589027528155), up: 30, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027528, 1601), signature: { hash: BinData(0, 03FC3A77C790AE119EA901B57F33950E63F73458), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027527, 851), t: 7 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 1085ms
2020-05-09T05:32:10.476-0700 I  REPL     [replexec-4] Member n2:27019 is now in state SECONDARY
2020-05-09T05:32:10.538-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50830 #159 (74 connections now open)
2020-05-09T05:32:10.538-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50828 #160 (75 connections now open)
2020-05-09T05:32:10.538-0700 I  NETWORK  [conn159] received client metadata from 192.168.122.1:50830 conn159: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:10.538-0700 I  NETWORK  [conn160] received client metadata from 192.168.122.1:50828 conn160: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:10.541-0700 I  NETWORK  [conn159] end connection 192.168.122.1:50830 (74 connections now open)
2020-05-09T05:32:10.541-0700 I  NETWORK  [conn160] end connection 192.168.122.1:50828 (73 connections now open)
2020-05-09T05:32:11.320-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:45832 #161 (74 connections now open)
2020-05-09T05:32:11.321-0700 I  NETWORK  [conn161] received client metadata from 192.168.122.18:45832 conn161: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:11.426-0700 I  REPL     [conn128] stepping down from primary, because a new term has begun: 9
2020-05-09T05:32:11.427-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:11.427-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:11.427-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 5, userOpsRunning: 1 }
2020-05-09T05:32:11.428-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T05:32:11.428-0700 W  COMMAND  [conn98] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:11.428-0700 W  COMMAND  [conn103] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:11.428-0700 I  COMMAND  [conn98] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27018:1589027500:8843213706502976374" }, update: { $set: { ping: new Date(1589027530557) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027530, 2), signature: { hash: BinData(0, 0CFE2A2CABCBF7C5C55B0EA54C51ECAEDCF0920A), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 870ms
2020-05-09T05:32:11.428-0700 W  COMMAND  [conn34] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:11.428-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:11.428-0700 I  COMMAND  [conn103] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27018:1589027501:3108026142901478785" }, update: { $set: { ping: new Date(1589027531187) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027530, 3), signature: { hash: BinData(0, 0CFE2A2CABCBF7C5C55B0EA54C51ECAEDCF0920A), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 240ms
2020-05-09T05:32:11.428-0700 W  COMMAND  [conn161] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:11.428-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027530, 2), signature: { hash: BinData(0, 0CFE2A2CABCBF7C5C55B0EA54C51ECAEDCF0920A), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 288ms
2020-05-09T05:32:11.428-0700 I  COMMAND  [conn161] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27018:1589027501:6657455084422948315" }, update: { $set: { ping: new Date(1589027531319) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027531, 3), signature: { hash: BinData(0, F6853492644CDDF3BC19EB9CAEA273AA716E3055), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027501, 4), t: 2 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:731 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 106ms
2020-05-09T05:32:11.428-0700 W  COMMAND  [conn63] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:11.429-0700 I  COMMAND  [conn63] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027530, 2), signature: { hash: BinData(0, 0CFE2A2CABCBF7C5C55B0EA54C51ECAEDCF0920A), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 289ms
2020-05-09T05:32:11.507-0700 I  ELECTION [conn150] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027530, 2), t: 8 } }
2020-05-09T05:32:11.507-0700 I  ELECTION [conn150] Sending vote response: { term: 9, voteGranted: false, reason: "candidate's term (8) is lower than mine (9)" }
2020-05-09T05:32:11.508-0700 I  NETWORK  [conn150] end connection 192.168.122.12:41958 (73 connections now open)
2020-05-09T05:32:11.511-0700 I  ELECTION [conn151] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027530, 2), t: 8 } }
2020-05-09T05:32:11.511-0700 I  ELECTION [conn151] Sending vote response: { term: 9, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027530, 2), t: 8 }, my last applied OpTime: { ts: Timestamp..." }
2020-05-09T05:32:11.512-0700 I  NETWORK  [conn151] end connection 192.168.122.12:41954 (72 connections now open)
2020-05-09T05:32:12.319-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42132 #162 (73 connections now open)
2020-05-09T05:32:12.320-0700 I  NETWORK  [conn162] received client metadata from 192.168.122.12:42132 conn162: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:12.477-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-09T05:32:12.477-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-09T05:32:13.603-0700
2020-05-09T05:32:12.936-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50948 #163 (74 connections now open)
2020-05-09T05:32:12.936-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:50944 #164 (75 connections now open)
2020-05-09T05:32:12.936-0700 I  NETWORK  [conn163] received client metadata from 192.168.122.1:50948 conn163: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:12.937-0700 I  NETWORK  [conn164] received client metadata from 192.168.122.1:50944 conn164: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:12.940-0700 I  NETWORK  [conn164] end connection 192.168.122.1:50944 (74 connections now open)
2020-05-09T05:32:12.941-0700 I  NETWORK  [conn163] end connection 192.168.122.1:50948 (73 connections now open)
2020-05-09T05:32:13.429-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T05:32:13.603-0700 I  REPL     [replexec-0] Canceling priority takeover callback
2020-05-09T05:32:13.603-0700 I  ELECTION [replexec-0] Not starting an election for a priority takeover, since we are not electable due to: Not standing for election because member is not caught up enough to the most up-to-date member to call for priority takeover - must be within 2 seconds (mask 0x80)
2020-05-09T05:32:13.976-0700 I  REPL     [replexec-4] Member n2:27019 is now in state RS_DOWN - Request 216 timed out, deadline was 2020-05-09T05:32:13.976-0700, op was RemoteCommand 216 -- target:[n2:27019] db:admin expDate:2020-05-09T05:32:13.976-0700 cmd:{ replSetHeartbeat: "rs_config", configVersion: 1, hbv: 1, from: "n1:27019", fromId: 0, term: 9 }
2020-05-09T05:32:13.976-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:14.049-0700 I  ELECTION [conn154] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 9, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027531, 4), t: 8 } }
2020-05-09T05:32:14.049-0700 I  ELECTION [conn154] Sending vote response: { term: 9, voteGranted: true, reason: "" }
2020-05-09T05:32:14.058-0700 I  ELECTION [conn154] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027531, 4), t: 8 } }
2020-05-09T05:32:14.058-0700 I  ELECTION [conn154] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-09T05:32:14.277-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T05:32:14.278-0700 I  CONNPOOL [RS] Connecting to n2:27019
2020-05-09T05:32:14.279-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589027531, 4), t: 8 }. source's GTE: { ts: Timestamp(1589027532, 1), t: 9 }
2020-05-09T05:32:14.279-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589027530, 2), t: 8 }
2020-05-09T05:32:14.279-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T05:32:14.279-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n2:27019)
2020-05-09T05:32:14.279-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T05:32:14.279-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 74 }
2020-05-09T05:32:14.279-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 162
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 161
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 158
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 154
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 128
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-09T05:32:14.279-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 105
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 104
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 103
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 102
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 101
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 100
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 99
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 98
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 97
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 92
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 91
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 90
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 87
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 86
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 85
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 84
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 83
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 82
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 73
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 72
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 71
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 70
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 69
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 68
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 67
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 66
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 65
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 64
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 63
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 62
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 61
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 60
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 59
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 58
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 57
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 56
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 55
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 54
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 53
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 52
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 51
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 50
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 49
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 48
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 47
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 46
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T05:32:14.280-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 43
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-05-09T05:32:14.281-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 14
2020-05-09T05:32:14.281-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T05:32:14.281-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T05:32:14.281-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T05:32:14.287-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589027530, 3), t: 8 }
2020-05-09T05:32:14.289-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 3
2020-05-09T05:32:14.289-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T05:32:14.289-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 06fbc13c-eb1d-4254-80f8-deeaa8ca575b to /var/lib/mongodb/rollback/config.lockpings/removed.2020-05-09T12-32-14.1.bson
2020-05-09T05:32:14.290-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T05:32:14.290-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T05:32:14.290-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T05:32:14.290-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T05:32:14.336-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589027530, 2) Initial Data Timestamp: Timestamp(1589027490, 1)
2020-05-09T05:32:14.338-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T05:32:14.351-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T05:32:14.351-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 221 records totaling to 48407 bytes
2020-05-09T05:32:14.351-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T05:32:14.351-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T05:32:14.354-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T05:32:14.354-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T05:32:14.371-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T05:32:14.371-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T05:32:14.371-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589027530, 2)
2020-05-09T05:32:14.371-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 1 insert operations, 1 update operations and 0 delete operations.
2020-05-09T05:32:14.371-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589027531, 1), t: 8 }
2020-05-09T05:32:14.371-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589027531, 1) }
2020-05-09T05:32:14.371-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T05:32:14.373-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589027530, 2) (top of oplog: { ts: Timestamp(1589027530, 3), t: 8 }, appliedThrough: { ts: Timestamp(0, 0), t: -1 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T05:32:14.373-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589027530, 2)
2020-05-09T05:32:14.373-0700 I  REPL     [rsBackgroundSync] Replaying stored operations from Timestamp(1589027530, 2) (inclusive) to Timestamp(1589027530, 3) (inclusive).
2020-05-09T05:32:14.374-0700 I  REPL     [rsBackgroundSync] Applied 1 operations in 1 batches. Last operation applied with optime: { ts: Timestamp(1589027530, 3), t: 8 }
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T05:32:14.375-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T05:32:14.279-0700
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T05:32:14.375-0700
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n2:27019
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.lockpings
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 3
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589027531, 4), t: 8 }
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589027530, 3), t: 8 }
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T05:32:11.321-0700
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T05:32:11.188-0700
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 0 second(s)
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589027531, 1)
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589027530, 2)
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 		update: 1
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 1
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 2
2020-05-09T05:32:14.375-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T05:32:14.375-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T05:32:14.376-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n2:27019
2020-05-09T05:32:14.376-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T05:32:14.376-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T05:32:14.376-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T05:32:14.376-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T05:32:14.376-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-09T05:32:14.377-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source changed from n2:27019 to n3:27019
2020-05-09T05:32:14.377-0700 I  CONNPOOL [RS] Connecting to n3:27019
2020-05-09T05:32:14.824-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51152 #168 (74 connections now open)
2020-05-09T05:32:14.825-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51150 #169 (75 connections now open)
2020-05-09T05:32:14.825-0700 I  NETWORK  [conn168] received client metadata from 192.168.122.1:51152 conn168: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:14.825-0700 I  NETWORK  [conn169] received client metadata from 192.168.122.1:51150 conn169: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:14.828-0700 I  NETWORK  [conn169] end connection 192.168.122.1:51150 (74 connections now open)
2020-05-09T05:32:14.828-0700 I  NETWORK  [conn168] end connection 192.168.122.1:51152 (73 connections now open)
2020-05-09T05:32:14.945-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42446 #170 (74 connections now open)
2020-05-09T05:32:14.945-0700 I  NETWORK  [conn170] received client metadata from 192.168.122.12:42446 conn170: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:15.093-0700 I  NETWORK  [conn170] end connection 192.168.122.12:42446 (73 connections now open)
2020-05-09T05:32:15.474-0700 I  REPL     [replexec-5] Member n3:27019 is now in state PRIMARY
2020-05-09T05:32:15.474-0700 I  ELECTION [replexec-5] Scheduling priority takeover at 2020-05-09T05:32:16.611-0700
2020-05-09T05:32:15.768-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51214 #171 (74 connections now open)
2020-05-09T05:32:15.768-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51216 #172 (75 connections now open)
2020-05-09T05:32:15.769-0700 I  NETWORK  [conn171] received client metadata from 192.168.122.1:51214 conn171: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:15.769-0700 I  NETWORK  [conn172] received client metadata from 192.168.122.1:51216 conn172: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:15.772-0700 I  NETWORK  [conn171] end connection 192.168.122.1:51214 (74 connections now open)
2020-05-09T05:32:15.772-0700 I  NETWORK  [conn172] end connection 192.168.122.1:51216 (73 connections now open)
2020-05-09T05:32:15.977-0700 I  REPL     [replexec-0] Member n2:27019 is now in state SECONDARY
2020-05-09T05:32:16.559-0700 I  REPL     [replexec-3] Canceling priority takeover callback
2020-05-09T05:32:16.559-0700 I  ELECTION [replexec-3] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:32:16.559-0700 I  ELECTION [replexec-3] conducting a dry run election to see if we could be elected. current term: 10
2020-05-09T05:32:16.559-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 239 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:16.559-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 240 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:16.560-0700 I  ELECTION [replexec-2] VoteRequester(term 10 dry run) received a yes vote from n2:27019; response message: { term: 10, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1589027534, 135), $clusterTime: { clusterTime: Timestamp(1589027535, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027534, 135) }
2020-05-09T05:32:16.560-0700 I  ELECTION [replexec-2] dry election run succeeded, running for election in term 11
2020-05-09T05:32:16.569-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 241 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:16.569-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 242 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:16.575-0700 I  ELECTION [replexec-3] VoteRequester(term 11) received a yes vote from n2:27019; response message: { term: 11, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff0000000000000009') }, lastCommittedOpTime: Timestamp(1589027534, 135), $clusterTime: { clusterTime: Timestamp(1589027535, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027534, 135) }
2020-05-09T05:32:16.575-0700 I  ELECTION [replexec-3] election succeeded, assuming primary role in term 11
2020-05-09T05:32:16.575-0700 I  REPL     [replexec-3] transition to PRIMARY from SECONDARY
2020-05-09T05:32:16.575-0700 I  REPL     [replexec-3] Resetting sync source to empty, which was n3:27019
2020-05-09T05:32:16.575-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:16.575-0700 I  REPL     [replexec-3] Entering primary catch-up mode.
2020-05-09T05:32:16.575-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:32:16.578-0700 I  REPL     [replexec-3] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:16.578-0700 I  REPL     [replexec-3] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027534, 135), t: 10 }. My Last Applied: { ts: Timestamp(1589027534, 135), t: 10 }
2020-05-09T05:32:16.578-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T05:32:16.578-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T05:32:16.578-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 11
2020-05-09T05:32:16.578-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:16.578-0700 I  CONNPOOL [RS] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:16.578-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:16.578-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:16.578-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T05:32:16.581-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:16.581-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:16.581-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:16.582-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:16.582-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:16.582-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:16.582-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:16.583-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:16.584-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.586-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.588-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:16.588-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:16.710-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51248 #174 (74 connections now open)
2020-05-09T05:32:16.710-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51256 #175 (75 connections now open)
2020-05-09T05:32:16.710-0700 I  NETWORK  [conn174] received client metadata from 192.168.122.1:51248 conn174: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:16.710-0700 I  NETWORK  [conn175] received client metadata from 192.168.122.1:51256 conn175: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:16.714-0700 I  NETWORK  [conn174] end connection 192.168.122.1:51248 (74 connections now open)
2020-05-09T05:32:16.714-0700 I  NETWORK  [conn175] end connection 192.168.122.1:51256 (73 connections now open)
2020-05-09T05:32:17.016-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-09T05:32:17.085-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.582-0700 I  ELECTION [conn154] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:17.582-0700 I  ELECTION [conn154] Sending vote response: { term: 11, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027534, 135), t: 10 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T05:32:17.585-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.588-0700 I  REPL     [replexec-5] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:17.588-0700 I  REPL     [replexec-5] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:17.588-0700 I  REPL     [replexec-5] can't see a majority of the set, relinquishing primary
2020-05-09T05:32:17.588-0700 I  REPL     [replexec-5] Stepping down from primary in response to heartbeat
2020-05-09T05:32:17.588-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:17.588-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:17.588-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 3, userOpsRunning: 0 }
2020-05-09T05:32:17.589-0700 W  COMMAND  [conn54] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:17.589-0700 W  COMMAND  [conn73] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:17.589-0700 I  REPL     [replexec-5] transition to SECONDARY from PRIMARY
2020-05-09T05:32:17.589-0700 I  COMMAND  [conn54] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1589027537376), up: 40, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027536, 77), signature: { hash: BinData(0, B13E34C06B4DEA627F1D47D7EE8A61DCCB088A37), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 208ms
2020-05-09T05:32:17.589-0700 W  COMMAND  [conn37] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:17.589-0700 I  COMMAND  [conn73] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1589027537377), up: 40, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027536, 77), signature: { hash: BinData(0, B13E34C06B4DEA627F1D47D7EE8A61DCCB088A37), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 208ms
2020-05-09T05:32:17.589-0700 I  COMMAND  [conn37] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1589027537377), up: 40, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027536, 77), signature: { hash: BinData(0, B13E34C06B4DEA627F1D47D7EE8A61DCCB088A37), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 207ms
2020-05-09T05:32:17.590-0700 I  SHARDING [Balancer] caught exception while doing balance: operation was interrupted
2020-05-09T05:32:17.590-0700 I  SHARDING [Balancer] couldn't create config.actionlog collection: :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:17.590-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:17.700-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42548 #176 (74 connections now open)
2020-05-09T05:32:17.701-0700 I  NETWORK  [conn176] received client metadata from 192.168.122.12:42548 conn176: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:17.705-0700 I  ELECTION [conn176] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027536, 2), t: 11 } }
2020-05-09T05:32:17.705-0700 I  ELECTION [conn176] Sending vote response: { term: 12, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027536, 2), t: 11 }, my last applied OpTime: { ts: Timestam..." }
2020-05-09T05:32:18.085-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.426-0700 I  NETWORK  [conn14] end connection 192.168.122.12:40036 (73 connections now open)
2020-05-09T05:32:18.577-0700 I  REPL     [replexec-4] Member n2:27019 is now in state PRIMARY
2020-05-09T05:32:18.577-0700 I  ELECTION [replexec-4] Scheduling priority takeover at 2020-05-09T05:32:19.594-0700
2020-05-09T05:32:18.578-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:18.590-0700 I  REPL     [rsBackgroundSync] sync source candidate: n2:27019
2020-05-09T05:32:18.592-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n2:27019
2020-05-09T05:32:18.987-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51316 #177 (74 connections now open)
2020-05-09T05:32:18.987-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51318 #178 (75 connections now open)
2020-05-09T05:32:18.987-0700 I  NETWORK  [conn177] received client metadata from 192.168.122.1:51316 conn177: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:18.987-0700 I  NETWORK  [conn178] received client metadata from 192.168.122.1:51318 conn178: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:18.989-0700 I  NETWORK  [conn177] end connection 192.168.122.1:51316 (74 connections now open)
2020-05-09T05:32:18.990-0700 I  NETWORK  [conn178] end connection 192.168.122.1:51318 (73 connections now open)
2020-05-09T05:32:19.594-0700 I  REPL     [replexec-5] Canceling priority takeover callback
2020-05-09T05:32:19.594-0700 I  ELECTION [replexec-5] Starting an election for a priority takeover
2020-05-09T05:32:19.594-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 12
2020-05-09T05:32:19.594-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 288 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027539, 417), t: 12 } }
2020-05-09T05:32:19.594-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 289 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 12, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027539, 417), t: 12 } }
2020-05-09T05:32:19.594-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T05:32:19.595-0700 I  ELECTION [replexec-1] VoteRequester(term 12 dry run) received a yes vote from n3:27019; response message: { term: 12, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1589027537, 5), $clusterTime: { clusterTime: Timestamp(1589027539, 769), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027537, 5) }
2020-05-09T05:32:19.595-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 13
2020-05-09T05:32:19.605-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 291 -- target:n2:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027539, 417), t: 12 } }
2020-05-09T05:32:19.606-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 292 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027539, 417), t: 12 } }
2020-05-09T05:32:19.621-0700 I  ELECTION [replexec-5] VoteRequester(term 13) received a yes vote from n2:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000c') }, lastCommittedOpTime: Timestamp(1589027539, 417), $clusterTime: { clusterTime: Timestamp(1589027539, 769), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027539, 417) }
2020-05-09T05:32:19.621-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 13
2020-05-09T05:32:19.621-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-09T05:32:19.621-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n2:27019
2020-05-09T05:32:19.621-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-09T05:32:19.621-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:19.622-0700 I  REPL     [replexec-3] Member n2:27019 is now in state SECONDARY
2020-05-09T05:32:19.622-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027539, 417), t: 12 }. My Last Applied: { ts: Timestamp(1589027539, 417), t: 12 }
2020-05-09T05:32:19.622-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-09T05:32:19.622-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-09T05:32:19.622-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 13
2020-05-09T05:32:19.622-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:19.622-0700 I  CONNPOOL [RS] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:19.623-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:19.623-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:19.623-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:19.624-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:19.624-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:19.625-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:19.625-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:19.625-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:19.627-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T05:32:20.024-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n2:27019: InvalidSyncSource: Sync source was cleared. Was n2:27019
2020-05-09T05:32:20.610-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:42630 #181 (74 connections now open)
2020-05-09T05:32:20.611-0700 I  NETWORK  [conn181] received client metadata from 192.168.122.12:42630 conn181: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:20.629-0700 I  COMMAND  [conn63] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n5:27017" }, u: { $set: { _id: "n5:27017", ping: new Date(1589027540262), up: 42, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027540, 104), signature: { hash: BinData(0, DD394D69E7D89E52D785945D633649299E8FAC21), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027539, 417), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 363ms
2020-05-09T05:32:20.629-0700 I  COMMAND  [conn50] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n2:27017" }, u: { $set: { _id: "n2:27017", ping: new Date(1589027540086), up: 42, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027540, 101), signature: { hash: BinData(0, DD394D69E7D89E52D785945D633649299E8FAC21), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027539, 417), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 540ms
2020-05-09T05:32:20.629-0700 I  COMMAND  [conn61] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n3:27017" }, u: { $set: { _id: "n3:27017", ping: new Date(1589027540086), up: 42, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027540, 100), signature: { hash: BinData(0, DD394D69E7D89E52D785945D633649299E8FAC21), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027539, 417), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 540ms
2020-05-09T05:32:20.629-0700 I  COMMAND  [conn41] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n1:27017" }, u: { $set: { _id: "n1:27017", ping: new Date(1589027540086), up: 42, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027540, 100), signature: { hash: BinData(0, DD394D69E7D89E52D785945D633649299E8FAC21), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027539, 417), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 540ms
2020-05-09T05:32:20.629-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:20.630-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:21.213-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51358 #182 (75 connections now open)
2020-05-09T05:32:21.214-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:51366 #183 (76 connections now open)
2020-05-09T05:32:21.214-0700 I  NETWORK  [conn182] received client metadata from 192.168.122.1:51358 conn182: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:21.214-0700 I  NETWORK  [conn183] received client metadata from 192.168.122.1:51366 conn183: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:21.218-0700 I  NETWORK  [conn182] end connection 192.168.122.1:51358 (75 connections now open)
2020-05-09T05:32:21.218-0700 I  NETWORK  [conn183] end connection 192.168.122.1:51366 (74 connections now open)
2020-05-09T05:32:22.129-0700 I  REPL     [replexec-2] Member n2:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:22.129-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:22.129-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-09T05:32:22.129-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-09T05:32:22.129-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:22.129-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:22.129-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:22.130-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T05:32:22.130-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:22.622-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:22.622-0700 I  CONNPOOL [Replication] Ending connection to host n2:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:22.622-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:32:22.622-0700 I  CONNPOOL [Replication] Connecting to n2:27019
2020-05-09T05:32:23.218-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T05:32:24.270-0700 I  ELECTION [replexec-4] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T05:32:25.368-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T05:32:26.384-0700 I  ELECTION [replexec-1] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T05:32:27.427-0700 I  ELECTION [replexec-2] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
