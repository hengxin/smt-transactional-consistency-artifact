2020-05-09T05:31:27.535-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T05:31:27.555-0700 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] MongoDB starting : pid=1846 port=27019 dbpath=/var/lib/mongodb 64-bit host=n2
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] db version v4.2.6
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] modules: none
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] build environment:
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten]     distmod: debian92
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten]     distarch: x86_64
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten]     target_arch: x86_64
2020-05-09T05:31:27.556-0700 I  CONTROL  [initandlisten] options: { config: "/etc/mongod.conf", net: { bindIp: "0.0.0.0" }, processManagement: { timeZoneInfo: "/usr/share/zoneinfo" }, replication: { replSetName: "rs_config" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/var/lib/mongodb", journal: { enabled: true } }, systemLog: { destination: "file", logAppend: true, path: "/var/log/mongodb/mongod.log" } }
2020-05-09T05:31:27.556-0700 I  STORAGE  [initandlisten] 
2020-05-09T05:31:27.556-0700 I  STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2020-05-09T05:31:27.556-0700 I  STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2020-05-09T05:31:27.556-0700 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=63957M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
2020-05-09T05:31:28.295-0700 I  STORAGE  [initandlisten] WiredTiger message [1589027488:295984][1846:0x7fedf3dda140], txn-recover: Set global recovery timestamp: (0, 0)
2020-05-09T05:31:28.342-0700 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2020-05-09T05:31:28.404-0700 I  STORAGE  [initandlisten] Timestamp monitor starting
2020-05-09T05:31:28.435-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.435-0700 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2020-05-09T05:31:28.435-0700 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2020-05-09T05:31:28.435-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] ** WARNING: You are running on a NUMA machine.
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] **          We suggest launching mongod like this to avoid performance problems:
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] **              numactl --interleave=all mongod [other options]
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] **        We suggest setting it to 'never'
2020-05-09T05:31:28.437-0700 I  CONTROL  [initandlisten] 
2020-05-09T05:31:28.439-0700 I  SHARDING [initandlisten] Marking collection local.system.replset as collection version: <unsharded>
2020-05-09T05:31:28.439-0700 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
2020-05-09T05:31:28.439-0700 I  SHARDING [initandlisten] Marking collection admin.system.roles as collection version: <unsharded>
2020-05-09T05:31:28.439-0700 I  SHARDING [initandlisten] Marking collection admin.system.version as collection version: <unsharded>
2020-05-09T05:31:28.440-0700 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 7d2dcda9-0f21-4d63-8307-175d8c871365 and options: { capped: true, size: 10485760 }
2020-05-09T05:31:28.531-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
2020-05-09T05:31:28.531-0700 I  SHARDING [initandlisten] Marking collection local.startup_log as collection version: <unsharded>
2020-05-09T05:31:28.532-0700 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/var/lib/mongodb/diagnostic.data'
2020-05-09T05:31:28.537-0700 I  SHARDING [shard-registry-reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2020-05-09T05:31:28.537-0700 I  SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2020-05-09T05:31:28.537-0700 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 67241ed9-1446-43c0-9e2e-fa1a45514fc0 and options: {}
2020-05-09T05:31:28.647-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
2020-05-09T05:31:28.647-0700 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: b3242edc-abd4-41f5-ba6e-81d050779a72 and options: {}
2020-05-09T05:31:28.767-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
2020-05-09T05:31:28.768-0700 I  SHARDING [initandlisten] Marking collection local.replset.minvalid as collection version: <unsharded>
2020-05-09T05:31:28.768-0700 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 43ad102a-32f3-4df5-9364-c214bfede3c8 and options: {}
2020-05-09T05:31:28.907-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
2020-05-09T05:31:28.908-0700 I  SHARDING [initandlisten] Marking collection local.replset.election as collection version: <unsharded>
2020-05-09T05:31:28.908-0700 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
2020-05-09T05:31:28.908-0700 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2020-05-09T05:31:28.908-0700 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 5ca0099b-6dc0-44e4-8983-38b148e0d76b and options: {}
2020-05-09T05:31:29.041-0700 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
2020-05-09T05:31:29.042-0700 I  SHARDING [ftdc] Marking collection local.oplog.rs as collection version: <unsharded>
2020-05-09T05:31:29.042-0700 I  SHARDING [initandlisten] Marking collection local.system.rollback.id as collection version: <unsharded>
2020-05-09T05:31:29.042-0700 I  REPL     [initandlisten] Initialized the rollback ID to 1
2020-05-09T05:31:29.042-0700 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2020-05-09T05:31:29.044-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27019.sock
2020-05-09T05:31:29.044-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("863785ac-3f27-4227-8260-947dcb4aad5b"), lastMod: 0 } took 0 ms
2020-05-09T05:31:29.044-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T05:31:29.045-0700 I  NETWORK  [listener] waiting for connections on port 27019
2020-05-09T05:31:29.045-0700 I  CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2020-05-09T05:31:29.045-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2020-05-09T05:31:29.045-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Cannot use non-local read concern until replica set is finished initializing.
2020-05-09T05:31:29.744-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45460 #1 (1 connection now open)
2020-05-09T05:31:29.745-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45472 #2 (2 connections now open)
2020-05-09T05:31:29.761-0700 I  NETWORK  [conn2] received client metadata from 192.168.122.1:45472 conn2: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:29.761-0700 I  NETWORK  [conn1] received client metadata from 192.168.122.1:45460 conn1: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:29.838-0700 I  NETWORK  [conn1] end connection 192.168.122.1:45460 (1 connection now open)
2020-05-09T05:31:29.838-0700 I  NETWORK  [conn2] end connection 192.168.122.1:45472 (0 connections now open)
2020-05-09T05:31:29.908-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:51474 #3 (1 connection now open)
2020-05-09T05:31:29.916-0700 I  NETWORK  [conn3] end connection 192.168.122.11:51474 (0 connections now open)
2020-05-09T05:31:29.918-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:51478 #4 (1 connection now open)
2020-05-09T05:31:29.918-0700 I  NETWORK  [conn4] received client metadata from 192.168.122.11:51478 conn4: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:29.919-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:31:30.955-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:33710 #6 (2 connections now open)
2020-05-09T05:31:30.956-0700 I  NETWORK  [conn6] end connection 192.168.122.13:33710 (1 connection now open)
2020-05-09T05:31:30.959-0700 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: bba5fb66-d744-4a69-b05b-44cfb89cf682 and options: {}
2020-05-09T05:31:31.072-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:33724 #9 (2 connections now open)
2020-05-09T05:31:31.072-0700 I  NETWORK  [conn9] received client metadata from 192.168.122.13:33724 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:31.073-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:31:31.077-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
2020-05-09T05:31:31.079-0700 I  REPL     [replexec-0] New replica set config in use: { _id: "rs_config", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "n1:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 3.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "n2:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 2.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "n3:27019", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 1, electionTimeoutMillis: 1000, catchUpTimeoutMillis: 1000, catchUpTakeoverDelayMillis: 3000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5eb6a2a133caaefe806e3e90') } }
2020-05-09T05:31:31.079-0700 I  REPL     [replexec-0] This node is n2:27019 in the config
2020-05-09T05:31:31.079-0700 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
2020-05-09T05:31:31.080-0700 I  REPL     [replexec-0] Starting replication storage threads
2020-05-09T05:31:31.080-0700 I  REPL     [replexec-3] Member n3:27019 is now in state STARTUP2
2020-05-09T05:31:31.080-0700 I  REPL     [replexec-2] Member n1:27019 is now in state SECONDARY
2020-05-09T05:31:31.096-0700 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: b058d721-7156-4685-bd04-264f0440aac8 and options: { temp: true }
2020-05-09T05:31:31.232-0700 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-09T05:31:31.233-0700 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
2020-05-09T05:31:31.233-0700 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (b058d721-7156-4685-bd04-264f0440aac8).
2020-05-09T05:31:31.256-0700 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: 9ef76c63-b147-4daf-9f28-b4e3e3494d85 and options: { temp: true }
2020-05-09T05:31:31.364-0700 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
2020-05-09T05:31:31.365-0700 I  REPL     [replication-0] sync source candidate: n1:27019
2020-05-09T05:31:31.365-0700 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
2020-05-09T05:31:31.365-0700 I  REPL     [replication-0] ******
2020-05-09T05:31:31.365-0700 I  REPL     [replication-0] creating replication oplog of size: 36624MB...
2020-05-09T05:31:31.365-0700 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: eade7028-345b-4459-8e04-4331205967ee and options: { capped: true, size: 38403972915.0, autoIndexId: false }
2020-05-09T05:31:31.450-0700 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2020-05-09T05:31:31.450-0700 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2020-05-09T05:31:31.450-0700 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2020-05-09T05:31:31.450-0700 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
2020-05-09T05:31:31.505-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 0, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 } }
2020-05-09T05:31:31.506-0700 I  ELECTION [conn4] Sending vote response: { term: 0, voteGranted: true, reason: "" }
2020-05-09T05:31:31.521-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 } }
2020-05-09T05:31:31.521-0700 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-09T05:31:31.836-0700 I  REPL     [replication-0] ******
2020-05-09T05:31:31.837-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
2020-05-09T05:31:31.837-0700 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
2020-05-09T05:31:31.837-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T05:31:31.846-0700 I  SHARDING [replication-1] Marking collection local.temp_oplog_buffer as collection version: <unsharded>
2020-05-09T05:31:31.846-0700 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:admin.system.version
2020-05-09T05:31:31.850-0700 I  COMMAND  [conn4] command local.replset.election command: replSetRequestVotes { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027490, 1), t: -1 }, $clusterTime: { clusterTime: Timestamp(1589027490, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "admin" } numYields:0 reslen:293 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 2 } }, Global: { acquireCount: { r: 1, w: 1 }, acquireWaitCount: { w: 1 }, timeAcquiringMicros: { w: 315356 } }, Database: { acquireCount: { r: 1, w: 1 } }, Collection: { acquireCount: { r: 1, w: 1 } }, Mutex: { acquireCount: { r: 3 } } } storage:{} protocol:op_msg 328ms
2020-05-09T05:31:31.853-0700 I  STORAGE  [repl-writer-worker-15] createCollection: admin.system.version with provided UUID: e05230b0-3df8-490e-b58c-1b6f829b8a06 and options: { uuid: UUID("e05230b0-3df8-490e-b58c-1b6f829b8a06") }
2020-05-09T05:31:31.989-0700 I  INDEX    [repl-writer-worker-15] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
2020-05-09T05:31:31.989-0700 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:32.539-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45632 #14 (3 connections now open)
2020-05-09T05:31:32.540-0700 I  NETWORK  [conn14] received client metadata from 192.168.122.1:45632 conn14: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:32.540-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:45644 #15 (4 connections now open)
2020-05-09T05:31:32.541-0700 I  NETWORK  [conn15] received client metadata from 192.168.122.1:45644 conn15: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:33.582-0700 I  REPL     [replexec-1] Member n1:27019 is now in state PRIMARY
2020-05-09T05:31:33.638-0700 I  COMMAND  [repl-writer-worker-0] setting featureCompatibilityVersion to 4.2
2020-05-09T05:31:33.638-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 15
2020-05-09T05:31:33.638-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 14
2020-05-09T05:31:33.638-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 9
2020-05-09T05:31:33.638-0700 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 4
2020-05-09T05:31:33.639-0700 I  INITSYNC [replication-1] CollectionCloner ns:admin.system.version finished cloning with status: OK
2020-05-09T05:31:33.640-0700 I  INDEX    [replication-1] index build: inserted 1 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.646-0700 I  INDEX    [replication-1] index build: done building index _id_ on ns admin.system.version
2020-05-09T05:31:33.647-0700 I  INITSYNC [replication-1] Finished cloning data: OK. Beginning oplog replay.
2020-05-09T05:31:33.648-0700 I  INITSYNC [replication-0] Writing to the oplog and applying operations until { : Timestamp(1589027493, 14) } before initial sync can complete. (started fetching at { : Timestamp(1589027490, 1) } and applying at { : Timestamp(1589027490, 1) })
2020-05-09T05:31:33.648-0700 I  SHARDING [replication-0] Marking collection local.replset.oplogTruncateAfterPoint as collection version: <unsharded>
2020-05-09T05:31:33.649-0700 I  STORAGE  [repl-writer-worker-3] createCollection: config.transactions with provided UUID: b8867898-33e5-43f7-ae4e-4419b90d4e08 and options: { uuid: UUID("b8867898-33e5-43f7-ae4e-4419b90d4e08") }
2020-05-09T05:31:33.689-0700 I  INDEX    [repl-writer-worker-3] index build: done building index _id_ on ns config.transactions
2020-05-09T05:31:33.691-0700 I  STORAGE  [repl-writer-worker-7] createCollection: config.chunks with provided UUID: c5169003-16a3-4ce4-9766-ec4bf03e6bc0 and options: { uuid: UUID("c5169003-16a3-4ce4-9766-ec4bf03e6bc0") }
2020-05-09T05:31:33.732-0700 I  INDEX    [repl-writer-worker-7] index build: done building index _id_ on ns config.chunks
2020-05-09T05:31:33.808-0700 I  INDEX    [repl-writer-worker-11] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T05:31:33.808-0700 I  INDEX    [repl-writer-worker-11] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.808-0700 I  STORAGE  [repl-writer-worker-11] Index build initialized: 666ef8bc-1d3b-4058-862f-7d7ba36b795c: config.chunks (c5169003-16a3-4ce4-9766-ec4bf03e6bc0 ): indexes: 1
2020-05-09T05:31:33.809-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.811-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.819-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.chunks
2020-05-09T05:31:33.826-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 666ef8bc-1d3b-4058-862f-7d7ba36b795c: config.chunks ( c5169003-16a3-4ce4-9766-ec4bf03e6bc0 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T05:31:33.896-0700 I  INDEX    [repl-writer-worker-15] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T05:31:33.896-0700 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.897-0700 I  STORAGE  [repl-writer-worker-15] Index build initialized: 8d827d3f-8214-4dc5-aac7-81babd0d978b: config.chunks (c5169003-16a3-4ce4-9766-ec4bf03e6bc0 ): indexes: 1
2020-05-09T05:31:33.897-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.899-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:33.907-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_shard_1_min_1 on ns config.chunks
2020-05-09T05:31:33.921-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 8d827d3f-8214-4dc5-aac7-81babd0d978b: config.chunks ( c5169003-16a3-4ce4-9766-ec4bf03e6bc0 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-05-09T05:31:33.996-0700 I  INDEX    [repl-writer-worker-3] index build: starting on config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" } using method: Hybrid
2020-05-09T05:31:33.996-0700 I  INDEX    [repl-writer-worker-3] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:33.996-0700 I  STORAGE  [repl-writer-worker-3] Index build initialized: 97c099ad-0653-4804-b36e-b11d69a36748: config.chunks (c5169003-16a3-4ce4-9766-ec4bf03e6bc0 ): indexes: 1
2020-05-09T05:31:33.996-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:33.997-0700 I  STORAGE  [repl-writer-worker-5] createCollection: config.migrations with provided UUID: 470d8b2e-1642-4f6b-a22a-56d320d9eccd and options: { uuid: UUID("470d8b2e-1642-4f6b-a22a-56d320d9eccd") }
2020-05-09T05:31:33.998-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.032-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_lastmod_1 on ns config.chunks
2020-05-09T05:31:34.052-0700 I  INDEX    [repl-writer-worker-5] index build: done building index _id_ on ns config.migrations
2020-05-09T05:31:34.062-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 97c099ad-0653-4804-b36e-b11d69a36748: config.chunks ( c5169003-16a3-4ce4-9766-ec4bf03e6bc0 ). Index specs built: 1. Indexes in catalog before build: 3. Indexes in catalog after build: 4
2020-05-09T05:31:34.120-0700 I  INDEX    [repl-writer-worker-9] index build: starting on config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" } using method: Hybrid
2020-05-09T05:31:34.121-0700 I  INDEX    [repl-writer-worker-9] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.121-0700 I  STORAGE  [repl-writer-worker-9] Index build initialized: 5263ebe4-2a63-4088-ae3e-516f7b3b149a: config.migrations (470d8b2e-1642-4f6b-a22a-56d320d9eccd ): indexes: 1
2020-05-09T05:31:34.121-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.123-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.123-0700 I  STORAGE  [repl-writer-worker-11] createCollection: config.shards with provided UUID: a6531981-377b-47cc-9e83-f5ede27b9c20 and options: { uuid: UUID("a6531981-377b-47cc-9e83-f5ede27b9c20") }
2020-05-09T05:31:34.131-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.migrations
2020-05-09T05:31:34.180-0700 I  INDEX    [repl-writer-worker-11] index build: done building index _id_ on ns config.shards
2020-05-09T05:31:34.184-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 5263ebe4-2a63-4088-ae3e-516f7b3b149a: config.migrations ( 470d8b2e-1642-4f6b-a22a-56d320d9eccd ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T05:31:34.252-0700 I  INDEX    [repl-writer-worker-15] index build: starting on config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" } using method: Hybrid
2020-05-09T05:31:34.252-0700 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.252-0700 I  STORAGE  [repl-writer-worker-15] Index build initialized: bc9f74e0-161a-4ce0-a7f2-4d579c6e81ec: config.shards (a6531981-377b-47cc-9e83-f5ede27b9c20 ): indexes: 1
2020-05-09T05:31:34.252-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.254-0700 I  STORAGE  [repl-writer-worker-1] createCollection: config.locks with provided UUID: 21de64ce-9b9e-46b1-91d0-1a263695e96e and options: { uuid: UUID("21de64ce-9b9e-46b1-91d0-1a263695e96e") }
2020-05-09T05:31:34.254-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.286-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index host_1 on ns config.shards
2020-05-09T05:31:34.307-0700 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns config.locks
2020-05-09T05:31:34.312-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: bc9f74e0-161a-4ce0-a7f2-4d579c6e81ec: config.shards ( a6531981-377b-47cc-9e83-f5ede27b9c20 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T05:31:34.350-0700 I  INDEX    [repl-writer-worker-5] index build: starting on config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" } using method: Hybrid
2020-05-09T05:31:34.350-0700 I  INDEX    [repl-writer-worker-5] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.350-0700 I  STORAGE  [repl-writer-worker-5] Index build initialized: d32133e6-d517-47ff-bdff-45442f12e98b: config.locks (21de64ce-9b9e-46b1-91d0-1a263695e96e ): indexes: 1
2020-05-09T05:31:34.350-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.351-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.358-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ts_1 on ns config.locks
2020-05-09T05:31:34.360-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: d32133e6-d517-47ff-bdff-45442f12e98b: config.locks ( 21de64ce-9b9e-46b1-91d0-1a263695e96e ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T05:31:34.402-0700 I  INDEX    [repl-writer-worker-9] index build: starting on config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" } using method: Hybrid
2020-05-09T05:31:34.402-0700 I  INDEX    [repl-writer-worker-9] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.402-0700 I  STORAGE  [repl-writer-worker-9] Index build initialized: 8e1db403-8215-4f81-aba2-6eb34d1abb23: config.locks (21de64ce-9b9e-46b1-91d0-1a263695e96e ): indexes: 1
2020-05-09T05:31:34.402-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.404-0700 I  STORAGE  [repl-writer-worker-11] createCollection: config.lockpings with provided UUID: 06fbc13c-eb1d-4254-80f8-deeaa8ca575b and options: { uuid: UUID("06fbc13c-eb1d-4254-80f8-deeaa8ca575b") }
2020-05-09T05:31:34.404-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.436-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index state_1_process_1 on ns config.locks
2020-05-09T05:31:34.460-0700 I  INDEX    [repl-writer-worker-11] index build: done building index _id_ on ns config.lockpings
2020-05-09T05:31:34.462-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 8e1db403-8215-4f81-aba2-6eb34d1abb23: config.locks ( 21de64ce-9b9e-46b1-91d0-1a263695e96e ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-05-09T05:31:34.513-0700 I  INDEX    [repl-writer-worker-15] index build: starting on config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" } using method: Hybrid
2020-05-09T05:31:34.513-0700 I  INDEX    [repl-writer-worker-15] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.513-0700 I  STORAGE  [repl-writer-worker-15] Index build initialized: 42bb79a4-fb0e-44ab-ad85-19b5d95533f2: config.lockpings (06fbc13c-eb1d-4254-80f8-deeaa8ca575b ): indexes: 1
2020-05-09T05:31:34.513-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.514-0700 I  STORAGE  [repl-writer-worker-1] createCollection: config.tags with provided UUID: 45146aa2-93c3-49ab-aeb7-e2f4e7fc6973 and options: { uuid: UUID("45146aa2-93c3-49ab-aeb7-e2f4e7fc6973") }
2020-05-09T05:31:34.515-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.567-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ping_1 on ns config.lockpings
2020-05-09T05:31:34.583-0700 I  NETWORK  [conn14] end connection 192.168.122.1:45632 (3 connections now open)
2020-05-09T05:31:34.584-0700 I  NETWORK  [conn15] end connection 192.168.122.1:45644 (2 connections now open)
2020-05-09T05:31:34.606-0700 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns config.tags
2020-05-09T05:31:34.618-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 42bb79a4-fb0e-44ab-ad85-19b5d95533f2: config.lockpings ( 06fbc13c-eb1d-4254-80f8-deeaa8ca575b ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T05:31:34.723-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027493, 14), t: 1 } }
2020-05-09T05:31:34.723-0700 I  ELECTION [conn4] Sending vote response: { term: 1, voteGranted: true, reason: "" }
2020-05-09T05:31:34.733-0700 I  ELECTION [conn4] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 2, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027493, 14), t: 1 } }
2020-05-09T05:31:34.733-0700 I  ELECTION [conn4] Sending vote response: { term: 2, voteGranted: true, reason: "" }
2020-05-09T05:31:34.743-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:51612 #16 (3 connections now open)
2020-05-09T05:31:34.743-0700 I  NETWORK  [conn16] received client metadata from 192.168.122.11:51612 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:34.761-0700 I  INDEX    [repl-writer-worker-5] index build: starting on config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" } using method: Hybrid
2020-05-09T05:31:34.761-0700 I  INDEX    [repl-writer-worker-5] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.761-0700 I  STORAGE  [repl-writer-worker-5] Index build initialized: 17783d2a-70b2-4d56-99c0-a27b708aa8e4: config.tags (45146aa2-93c3-49ab-aeb7-e2f4e7fc6973 ): indexes: 1
2020-05-09T05:31:34.761-0700 I  REPL     [repl-writer-worker-5] applied op: command { ts: Timestamp(1589027493, 10), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("45146aa2-93c3-49ab-aeb7-e2f4e7fc6973"), wall: new Date(1589027493559), o: { createIndexes: "tags", v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1" } }, took 153ms
2020-05-09T05:31:34.761-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.762-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.771-0700 I  NETWORK  [conn4] end connection 192.168.122.11:51478 (2 connections now open)
2020-05-09T05:31:34.780-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_min_1 on ns config.tags
2020-05-09T05:31:34.810-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 17783d2a-70b2-4d56-99c0-a27b708aa8e4: config.tags ( 45146aa2-93c3-49ab-aeb7-e2f4e7fc6973 ). Index specs built: 1. Indexes in catalog before build: 1. Indexes in catalog after build: 2
2020-05-09T05:31:34.891-0700 I  INDEX    [repl-writer-worker-9] index build: starting on config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" } using method: Hybrid
2020-05-09T05:31:34.891-0700 I  INDEX    [repl-writer-worker-9] build may temporarily use up to 200 megabytes of RAM
2020-05-09T05:31:34.891-0700 I  STORAGE  [repl-writer-worker-9] Index build initialized: 0747eafd-e9c5-42ad-8759-cfc172eeddf3: config.tags (45146aa2-93c3-49ab-aeb7-e2f4e7fc6973 ): indexes: 1
2020-05-09T05:31:34.892-0700 I  REPL     [repl-writer-worker-9] applied op: command { ts: Timestamp(1589027493, 12), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("45146aa2-93c3-49ab-aeb7-e2f4e7fc6973"), wall: new Date(1589027493601), o: { createIndexes: "tags", v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1" } }, took 128ms
2020-05-09T05:31:34.892-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: collection scan done. scanned 0 total records in 0 seconds
2020-05-09T05:31:34.893-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: inserted 0 keys from external sorter into index in 0 seconds
2020-05-09T05:31:34.894-0700 I  STORAGE  [repl-writer-worker-11] createCollection: config.version with provided UUID: 29fcac5c-5002-4f90-86a5-77b647807503 and options: { uuid: UUID("29fcac5c-5002-4f90-86a5-77b647807503") }
2020-05-09T05:31:34.907-0700 I  INDEX    [IndexBuildsCoordinatorMongod-0] index build: done building index ns_1_tag_1 on ns config.tags
2020-05-09T05:31:34.969-0700 I  STORAGE  [IndexBuildsCoordinatorMongod-0] Index build completed successfully: 0747eafd-e9c5-42ad-8759-cfc172eeddf3: config.tags ( 45146aa2-93c3-49ab-aeb7-e2f4e7fc6973 ). Index specs built: 1. Indexes in catalog before build: 2. Indexes in catalog after build: 3
2020-05-09T05:31:35.034-0700 I  INDEX    [repl-writer-worker-11] index build: done building index _id_ on ns config.version
2020-05-09T05:31:35.034-0700 I  REPL     [repl-writer-worker-11] applied op: command { ts: Timestamp(1589027493, 13), t: 1, h: 0, v: 2, op: "c", ns: "config.$cmd", ui: UUID("29fcac5c-5002-4f90-86a5-77b647807503"), wall: new Date(1589027493634), o: { create: "version", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.version" } } }, took 141ms
2020-05-09T05:31:35.036-0700 I  SHARDING [repl-writer-worker-13] Marking collection config.version as collection version: <unsharded>
2020-05-09T05:31:35.038-0700 I  INITSYNC [replication-0] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(1589027494, 2), t: 2 }
2020-05-09T05:31:35.038-0700 I  INITSYNC [replication-0] Initial sync attempt finishing up.
2020-05-09T05:31:35.038-0700 I  INITSYNC [replication-0] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1589027491233), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 32, initialSyncOplogStart: Timestamp(1589027490, 1), initialSyncOplogEnd: Timestamp(1589027493, 14), databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1589027491844), end: new Date(1589027493647), elapsedMillis: 1803, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1589027491850), end: new Date(1589027493647), elapsedMillis: 1797, receivedBatches: 1 } } } }
2020-05-09T05:31:35.038-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:31:35.038-0700 I  STORAGE  [replication-1] Finishing collection drop for local.temp_oplog_buffer (9ef76c63-b147-4daf-9f28-b4e3e3494d85).
2020-05-09T05:31:35.060-0700 I  SHARDING [replication-1] Marking collection config.transactions as collection version: <unsharded>
2020-05-09T05:31:35.060-0700 I  INITSYNC [replication-1] initial sync done; took 3s.
2020-05-09T05:31:35.060-0700 I  REPL     [replication-1] transition to RECOVERING from STARTUP2
2020-05-09T05:31:35.060-0700 I  REPL     [replication-1] Starting replication fetcher thread
2020-05-09T05:31:35.061-0700 I  REPL     [replication-1] Starting replication applier thread
2020-05-09T05:31:35.061-0700 I  REPL     [replication-1] Starting replication reporter thread
2020-05-09T05:31:35.061-0700 I  REPL     [rsSync-0] Starting oplog application
2020-05-09T05:31:35.061-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T05:31:35.062-0700 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2020-05-09T05:31:35.062-0700 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2020-05-09T05:31:35.248-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:59998 #17 (3 connections now open)
2020-05-09T05:31:35.249-0700 I  NETWORK  [conn17] received client metadata from 192.168.122.16:59998 conn17: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.279-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:52804 #18 (4 connections now open)
2020-05-09T05:31:35.279-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:60008 #19 (5 connections now open)
2020-05-09T05:31:35.280-0700 I  NETWORK  [conn18] received client metadata from 192.168.122.18:52804 conn18: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.280-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:51650 #20 (6 connections now open)
2020-05-09T05:31:35.280-0700 I  NETWORK  [conn19] received client metadata from 192.168.122.16:60008 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.280-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:50684 #21 (7 connections now open)
2020-05-09T05:31:35.280-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.11:51650 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.280-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:33876 #22 (8 connections now open)
2020-05-09T05:31:35.280-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.12:50684 conn21: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.280-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48458 #23 (9 connections now open)
2020-05-09T05:31:35.281-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.13:33876 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.281-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:39584 #24 (10 connections now open)
2020-05-09T05:31:35.281-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.17:48458 conn23: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.281-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38482 #25 (11 connections now open)
2020-05-09T05:31:35.281-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.19:39584 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.281-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:39068 #26 (12 connections now open)
2020-05-09T05:31:35.281-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.15:38482 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:35.281-0700 I  NETWORK  [conn26] received client metadata from 192.168.122.14:39068 conn26: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.062-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:31:36.063-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:31:36.064-0700 I  REPL     [replexec-3] Member n3:27019 is now in state SECONDARY
2020-05-09T05:31:36.064-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T05:31:36.068-0700 I  STORAGE  [replication-2] Triggering the first stable checkpoint. Initial Data: Timestamp(1589027494, 2) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1589027494, 2)
2020-05-09T05:31:36.069-0700 I  COMMAND  [conn19] command config.version command: find { find: "version", readConcern: { level: "majority", afterOpTime: { ts: Timestamp(0, 0), t: -1 } }, maxTimeMS: 30000, $readPreference: { mode: "nearest" }, $replData: 1, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $configServerState: { opTime: { ts: Timestamp(0, 0), t: -1 } }, $db: "config" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:636 locks:{ ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { r: 1 } }, Database: { acquireCount: { r: 1 } }, Collection: { acquireCount: { r: 1 } }, Mutex: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 788ms
2020-05-09T05:31:36.070-0700 I  SHARDING [repl-writer-worker-5] Marking collection config.lockpings as collection version: <unsharded>
2020-05-09T05:31:36.144-0700 I  SHARDING [monitoring-keys-for-HMAC] Marking collection admin.system.keys as collection version: <unsharded>
2020-05-09T05:31:36.192-0700 I  STORAGE  [repl-writer-worker-9] createCollection: admin.system.keys with provided UUID: a78bf257-4e1b-4b0b-b48d-c7e7ac8a89ce and options: { uuid: UUID("a78bf257-4e1b-4b0b-b48d-c7e7ac8a89ce") }
2020-05-09T05:31:36.302-0700 I  INDEX    [repl-writer-worker-9] index build: done building index _id_ on ns admin.system.keys
2020-05-09T05:31:36.303-0700 I  REPL     [repl-writer-worker-9] applied op: command { ts: Timestamp(1589027496, 1), t: 2, h: 0, v: 2, op: "c", ns: "admin.$cmd", ui: UUID("a78bf257-4e1b-4b0b-b48d-c7e7ac8a89ce"), wall: new Date(1589027496171), o: { create: "system.keys", idIndex: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.keys" } } }, took 111ms
2020-05-09T05:31:36.508-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:39722 #28 (13 connections now open)
2020-05-09T05:31:36.508-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38604 #29 (14 connections now open)
2020-05-09T05:31:36.508-0700 I  NETWORK  [conn28] received client metadata from 192.168.122.19:39722 conn28: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.508-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34022 #30 (15 connections now open)
2020-05-09T05:31:36.508-0700 I  NETWORK  [conn29] received client metadata from 192.168.122.15:38604 conn29: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.509-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:39190 #31 (16 connections now open)
2020-05-09T05:31:36.509-0700 I  NETWORK  [conn30] received client metadata from 192.168.122.13:34022 conn30: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.509-0700 I  NETWORK  [conn31] received client metadata from 192.168.122.14:39190 conn31: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.859-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34026 #32 (17 connections now open)
2020-05-09T05:31:36.859-0700 I  NETWORK  [conn32] received client metadata from 192.168.122.13:34026 conn32: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:36.863-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:34028 #33 (18 connections now open)
2020-05-09T05:31:36.863-0700 I  NETWORK  [conn33] received client metadata from 192.168.122.13:34028 conn33: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:37.070-0700 I  SHARDING [conn28] Marking collection config.settings as collection version: <unsharded>
2020-05-09T05:31:37.073-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48610 #34 (19 connections now open)
2020-05-09T05:31:37.073-0700 I  NETWORK  [conn34] received client metadata from 192.168.122.17:48610 conn34: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:37.079-0700 I  SHARDING [conn34] Marking collection config.collections as collection version: <unsharded>
2020-05-09T05:31:37.140-0700 I  STORAGE  [repl-writer-worker-15] createCollection: config.mongos with provided UUID: e69f3cd9-17f0-4bf0-af22-c63c4aeb731b and options: { uuid: UUID("e69f3cd9-17f0-4bf0-af22-c63c4aeb731b") }
2020-05-09T05:31:37.201-0700 I  INDEX    [repl-writer-worker-15] index build: done building index _id_ on ns config.mongos
2020-05-09T05:31:37.203-0700 I  SHARDING [repl-writer-worker-5] Marking collection config.mongos as collection version: <unsharded>
2020-05-09T05:31:38.070-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:50890 #35 (20 connections now open)
2020-05-09T05:31:38.071-0700 I  NETWORK  [conn35] received client metadata from 192.168.122.12:50890 conn35: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:39.345-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:39282 #36 (21 connections now open)
2020-05-09T05:31:39.346-0700 I  NETWORK  [conn36] received client metadata from 192.168.122.14:39282 conn36: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.178-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:38716 #37 (22 connections now open)
2020-05-09T05:31:40.179-0700 I  NETWORK  [conn37] received client metadata from 192.168.122.15:38716 conn37: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.179-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:60312 #38 (23 connections now open)
2020-05-09T05:31:40.180-0700 I  NETWORK  [conn38] received client metadata from 192.168.122.16:60312 conn38: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.338-0700 I  SHARDING [repl-writer-worker-2] Marking collection config.shards as collection version: <unsharded>
2020-05-09T05:31:40.444-0700 I  STORAGE  [repl-writer-worker-7] createCollection: config.changelog with provided UUID: 9c4cf9f3-eb07-46ea-ae83-50a43544d4b1 and options: { uuid: UUID("9c4cf9f3-eb07-46ea-ae83-50a43544d4b1"), capped: true, size: 209715200 }
2020-05-09T05:31:40.501-0700 I  INDEX    [repl-writer-worker-7] index build: done building index _id_ on ns config.changelog
2020-05-09T05:31:40.509-0700 I  SHARDING [repl-writer-worker-0] Marking collection config.changelog as collection version: <unsharded>
2020-05-09T05:31:40.536-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48752 #39 (24 connections now open)
2020-05-09T05:31:40.537-0700 I  NETWORK  [conn39] received client metadata from 192.168.122.17:48752 conn39: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:40.543-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:48764 #40 (25 connections now open)
2020-05-09T05:31:40.545-0700 I  NETWORK  [conn40] received client metadata from 192.168.122.17:48764 conn40: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.163-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:39902 #41 (26 connections now open)
2020-05-09T05:31:41.164-0700 I  NETWORK  [conn41] received client metadata from 192.168.122.19:39902 conn41: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.316-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:53222 #42 (27 connections now open)
2020-05-09T05:31:41.316-0700 I  NETWORK  [conn42] received client metadata from 192.168.122.18:53222 conn42: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.319-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:53236 #43 (28 connections now open)
2020-05-09T05:31:41.319-0700 I  NETWORK  [conn43] received client metadata from 192.168.122.18:53236 conn43: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.319-0700 I  NETWORK  [conn43] end connection 192.168.122.18:53236 (27 connections now open)
2020-05-09T05:31:41.327-0700 I  SHARDING [repl-writer-worker-5] Marking collection config.locks as collection version: <unsharded>
2020-05-09T05:31:41.451-0700 I  STORAGE  [repl-writer-worker-2] createCollection: config.databases with provided UUID: 9866430c-b016-43b6-9574-b509c467f0d3 and options: { uuid: UUID("9866430c-b016-43b6-9574-b509c467f0d3") }
2020-05-09T05:31:41.521-0700 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns config.databases
2020-05-09T05:31:41.521-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:53242 #44 (28 connections now open)
2020-05-09T05:31:41.521-0700 I  NETWORK  [conn44] received client metadata from 192.168.122.18:53242 conn44: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.523-0700 I  SHARDING [repl-writer-worker-7] Marking collection config.databases as collection version: <unsharded>
2020-05-09T05:31:41.989-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:39438 #45 (29 connections now open)
2020-05-09T05:31:41.990-0700 I  NETWORK  [conn45] received client metadata from 192.168.122.14:39438 conn45: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:41.991-0700 I  SHARDING [conn45] Marking collection config.tags as collection version: <unsharded>
2020-05-09T05:31:42.328-0700 I  SHARDING [repl-writer-worker-10] Marking collection config.chunks as collection version: <unsharded>
2020-05-09T05:31:42.481-0700 I  STORAGE  [repl-writer-worker-5] createCollection: config.collections with provided UUID: 62b88a6b-0971-4550-bf98-58f7e636364c and options: { uuid: UUID("62b88a6b-0971-4550-bf98-58f7e636364c") }
2020-05-09T05:31:42.566-0700 I  INDEX    [repl-writer-worker-5] index build: done building index _id_ on ns config.collections
2020-05-09T05:31:51.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46260 #46 (30 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [conn46] received client metadata from 192.168.122.1:46260 conn46: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.985-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46278 #47 (31 connections now open)
2020-05-09T05:31:51.985-0700 I  NETWORK  [conn47] received client metadata from 192.168.122.1:46278 conn47: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.003-0700 I  NETWORK  [conn46] end connection 192.168.122.1:46260 (30 connections now open)
2020-05-09T05:31:52.006-0700 I  NETWORK  [conn47] end connection 192.168.122.1:46278 (29 connections now open)
2020-05-09T05:31:53.174-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:31:53.174-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 2
2020-05-09T05:31:53.174-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 810 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027511, 20), t: 2 } }
2020-05-09T05:31:53.174-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 811 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 2, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027511, 20), t: 2 } }
2020-05-09T05:31:53.175-0700 I  ELECTION [replexec-4] VoteRequester(term 2 dry run) received a yes vote from n3:27019; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027511, 20), $clusterTime: { clusterTime: Timestamp(1589027511, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027511, 20) }
2020-05-09T05:31:53.175-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 3
2020-05-09T05:31:53.175-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:31:53.175-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:31:53.179-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 812 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027511, 20), t: 2 } }
2020-05-09T05:31:53.181-0700 I  REPL     [replexec-3] Scheduling remote command request for vote request: RemoteCommand 813 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 3, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027511, 20), t: 2 } }
2020-05-09T05:31:53.186-0700 I  ELECTION [replexec-0] VoteRequester(term 3) received a yes vote from n3:27019; response message: { term: 3, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027511, 20), $clusterTime: { clusterTime: Timestamp(1589027511, 20), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027511, 20) }
2020-05-09T05:31:53.187-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 3
2020-05-09T05:31:53.187-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T05:31:53.187-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was n1:27019
2020-05-09T05:31:53.187-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T05:31:53.597-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46700 #48 (30 connections now open)
2020-05-09T05:31:53.597-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46710 #49 (31 connections now open)
2020-05-09T05:31:53.597-0700 I  NETWORK  [conn49] received client metadata from 192.168.122.1:46710 conn49: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:53.597-0700 I  NETWORK  [conn48] received client metadata from 192.168.122.1:46700 conn48: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:53.606-0700 I  NETWORK  [conn48] end connection 192.168.122.1:46700 (30 connections now open)
2020-05-09T05:31:53.606-0700 I  NETWORK  [conn49] end connection 192.168.122.1:46710 (29 connections now open)
2020-05-09T05:31:54.143-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1589027511, 20), t: 2 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T05:31:54.144-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T05:31:54.187-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T05:31:54.187-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T05:31:54.187-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T05:31:54.187-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 3
2020-05-09T05:31:54.187-0700 I  REPL     [replexec-5] Member n1:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T05:31:54.188-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:54.188-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:54.188-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T05:31:54.190-0700 I  SHARDING [rsSync-0] Marking collection config.migrations as collection version: <unsharded>
2020-05-09T05:31:54.190-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:31:54.190-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Checking consistency of sharded collection indexes across the cluster
2020-05-09T05:31:54.191-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:31:54.191-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:31:54.191-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:31:54.191-0700 I  NETWORK  [PeriodicShardedIndexConsistencyChecker] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:54.192-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T05:31:54.192-0700 I  NETWORK  [PeriodicShardedIndexConsistencyChecker] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:54.192-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T05:31:54.192-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T05:31:54.192-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T05:31:54.192-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T05:31:54.192-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T05:31:54.192-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 0 ms
2020-05-09T05:31:54.193-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 0 ms
2020-05-09T05:31:54.194-0700 W  QUERY    [conn33] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824821205074182145), stats: { stage: "COLLSCAN", nReturned: 142, executionTimeMillisEstimate: 8, works: 2045, advanced: 142, needTime: 951, needYield: 0, saveState: 951, restoreState: 951, isEOF: 0, direction: "forward", docsExamined: 142 }
2020-05-09T05:31:54.194-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:54.194-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:54.200-0700 I  SHARDING [PeriodicShardedIndexConsistencyChecker] Found 0 collections with inconsistent indexes
2020-05-09T05:31:55.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46836 #64 (30 connections now open)
2020-05-09T05:31:55.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46842 #65 (31 connections now open)
2020-05-09T05:31:55.138-0700 I  NETWORK  [conn64] received client metadata from 192.168.122.1:46836 conn64: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.138-0700 I  NETWORK  [conn65] received client metadata from 192.168.122.1:46842 conn65: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.141-0700 I  NETWORK  [conn64] end connection 192.168.122.1:46836 (30 connections now open)
2020-05-09T05:31:55.141-0700 I  NETWORK  [conn65] end connection 192.168.122.1:46842 (29 connections now open)
2020-05-09T05:31:55.195-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:55.195-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:31:55.604-0700 I  SHARDING [TransactionCoordinator] Marking collection config.transaction_coordinators as collection version: <unsharded>
2020-05-09T05:31:55.604-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:31:55.604-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:31:55.652-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46870 #68 (30 connections now open)
2020-05-09T05:31:55.652-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46874 #69 (31 connections now open)
2020-05-09T05:31:55.652-0700 I  NETWORK  [conn68] received client metadata from 192.168.122.1:46870 conn68: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.652-0700 I  NETWORK  [conn69] received client metadata from 192.168.122.1:46874 conn69: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:55.654-0700 I  NETWORK  [conn68] end connection 192.168.122.1:46870 (30 connections now open)
2020-05-09T05:31:55.654-0700 I  NETWORK  [conn69] end connection 192.168.122.1:46874 (29 connections now open)
2020-05-09T05:31:56.099-0700 I  ELECTION [conn16] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 3, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027514, 1), t: 3 } }
2020-05-09T05:31:56.100-0700 I  ELECTION [conn16] Sending vote response: { term: 3, voteGranted: true, reason: "" }
2020-05-09T05:31:56.106-0700 I  REPL     [conn16] stepping down from primary, because a new term has begun: 4
2020-05-09T05:31:56.107-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:31:56.107-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:31:56.107-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T05:31:56.107-0700 I  REPL     [replexec-3] transition to SECONDARY from PRIMARY
2020-05-09T05:31:56.107-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:31:56.107-0700 I  ELECTION [conn16] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 4, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027514, 1), t: 3 } }
2020-05-09T05:31:56.108-0700 I  ELECTION [conn16] Sending vote response: { term: 4, voteGranted: true, reason: "" }
2020-05-09T05:31:56.112-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:52824 #70 (30 connections now open)
2020-05-09T05:31:56.112-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.11:52824 conn70: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:56.112-0700 I  NETWORK  [conn16] end connection 192.168.122.11:51612 (29 connections now open)
2020-05-09T05:31:56.170-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46882 #71 (30 connections now open)
2020-05-09T05:31:56.171-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46886 #72 (31 connections now open)
2020-05-09T05:31:56.171-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.1:46882 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.171-0700 I  NETWORK  [conn72] received client metadata from 192.168.122.1:46886 conn72: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.175-0700 I  NETWORK  [conn71] end connection 192.168.122.1:46882 (30 connections now open)
2020-05-09T05:31:56.175-0700 I  NETWORK  [conn72] end connection 192.168.122.1:46886 (29 connections now open)
2020-05-09T05:31:56.187-0700 I  REPL     [replexec-0] Member n1:27019 is now in state PRIMARY
2020-05-09T05:31:56.600-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46906 #73 (30 connections now open)
2020-05-09T05:31:56.600-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46910 #74 (31 connections now open)
2020-05-09T05:31:56.600-0700 I  NETWORK  [conn73] received client metadata from 192.168.122.1:46906 conn73: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.600-0700 I  NETWORK  [conn74] received client metadata from 192.168.122.1:46910 conn74: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.603-0700 I  NETWORK  [conn73] end connection 192.168.122.1:46906 (30 connections now open)
2020-05-09T05:31:56.604-0700 I  NETWORK  [conn74] end connection 192.168.122.1:46910 (29 connections now open)
2020-05-09T05:31:56.760-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:40794 #75 (30 connections now open)
2020-05-09T05:31:56.761-0700 I  NETWORK  [conn75] received client metadata from 192.168.122.19:40794 conn75: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:56.914-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:46998 #76 (31 connections now open)
2020-05-09T05:31:56.914-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47000 #77 (32 connections now open)
2020-05-09T05:31:56.915-0700 I  NETWORK  [conn76] received client metadata from 192.168.122.1:46998 conn76: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.915-0700 I  NETWORK  [conn77] received client metadata from 192.168.122.1:47000 conn77: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:56.917-0700 I  NETWORK  [conn76] end connection 192.168.122.1:46998 (31 connections now open)
2020-05-09T05:31:56.917-0700 I  NETWORK  [conn77] end connection 192.168.122.1:47000 (30 connections now open)
2020-05-09T05:31:57.108-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:31:57.321-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:31:57.536-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47066 #78 (31 connections now open)
2020-05-09T05:31:57.536-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47068 #79 (32 connections now open)
2020-05-09T05:31:57.537-0700 I  NETWORK  [conn78] received client metadata from 192.168.122.1:47066 conn78: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:57.537-0700 I  NETWORK  [conn79] received client metadata from 192.168.122.1:47068 conn79: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:57.539-0700 I  NETWORK  [conn78] end connection 192.168.122.1:47066 (31 connections now open)
2020-05-09T05:31:57.539-0700 I  NETWORK  [conn79] end connection 192.168.122.1:47068 (30 connections now open)
2020-05-09T05:31:58.223-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:33194 #80 (31 connections now open)
2020-05-09T05:31:58.224-0700 I  NETWORK  [conn80] received client metadata from 192.168.122.16:33194 conn80: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:58.878-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:39886 #81 (32 connections now open)
2020-05-09T05:31:58.879-0700 I  NETWORK  [conn81] received client metadata from 192.168.122.15:39886 conn81: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:31:59.030-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47160 #82 (33 connections now open)
2020-05-09T05:31:59.030-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47166 #83 (34 connections now open)
2020-05-09T05:31:59.030-0700 I  NETWORK  [conn82] received client metadata from 192.168.122.1:47160 conn82: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:59.030-0700 I  NETWORK  [conn83] received client metadata from 192.168.122.1:47166 conn83: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:59.033-0700 I  NETWORK  [conn82] end connection 192.168.122.1:47160 (33 connections now open)
2020-05-09T05:31:59.033-0700 I  NETWORK  [conn83] end connection 192.168.122.1:47166 (32 connections now open)
2020-05-09T05:31:59.580-0700 I  ELECTION [replexec-5] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:31:59.580-0700 I  ELECTION [replexec-5] conducting a dry run election to see if we could be elected. current term: 4
2020-05-09T05:31:59.580-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 872 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:31:59.580-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 873 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 4, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:31:59.581-0700 I  ELECTION [replexec-1] VoteRequester(term 4 dry run) received a yes vote from n3:27019; response message: { term: 4, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027518, 5), $clusterTime: { clusterTime: Timestamp(1589027519, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027518, 5) }
2020-05-09T05:31:59.581-0700 I  ELECTION [replexec-1] dry election run succeeded, running for election in term 5
2020-05-09T05:31:59.581-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:31:59.585-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 874 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:31:59.585-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 875 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 5, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:31:59.585-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:31:59.589-0700 I  ELECTION [replexec-5] VoteRequester(term 5) received a yes vote from n3:27019; response message: { term: 5, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027518, 5), $clusterTime: { clusterTime: Timestamp(1589027519, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027518, 5) }
2020-05-09T05:31:59.589-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 5
2020-05-09T05:31:59.589-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-09T05:31:59.589-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n1:27019
2020-05-09T05:31:59.589-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-09T05:31:59.589-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:00.392-0700 I  REPL     [replexec-5] Member n1:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T05:32:00.392-0700 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027518, 5), t: 4 }. My Last Applied: { ts: Timestamp(1589027518, 5), t: 4 }
2020-05-09T05:32:00.392-0700 I  REPL     [replexec-5] Exited primary catch-up mode.
2020-05-09T05:32:00.392-0700 I  REPL     [replexec-5] Stopping replication producer
2020-05-09T05:32:00.392-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 5
2020-05-09T05:32:00.392-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:00.392-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:00.392-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:00.392-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:00.392-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:00.394-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:00.394-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:00.395-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:00.395-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:00.395-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:00.582-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53144 #84 (33 connections now open)
2020-05-09T05:32:00.582-0700 I  NETWORK  [conn84] received client metadata from 192.168.122.11:53144 conn84: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:00.588-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53146 #85 (34 connections now open)
2020-05-09T05:32:00.588-0700 I  NETWORK  [conn85] received client metadata from 192.168.122.11:53146 conn85: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:00.589-0700 I  COMMAND  [conn29] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027518, 5), signature: { hash: BinData(0, 0C39061107F2F24DF14A5DCC3529D64C4F4163FB), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027518, 5), t: 4 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 121ms
2020-05-09T05:32:00.589-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:00.589-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:00.611-0700 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027518, 5), t: 4 } }
2020-05-09T05:32:00.611-0700 I  ELECTION [conn9] Sending vote response: { term: 5, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027518, 5), t: 4 }, my last applied OpTime: { ts: Timestamp..." }
2020-05-09T05:32:00.694-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53166 #88 (35 connections now open)
2020-05-09T05:32:00.695-0700 I  NETWORK  [conn88] received client metadata from 192.168.122.11:53166 conn88: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:00.866-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:54348 #89 (36 connections now open)
2020-05-09T05:32:00.867-0700 I  NETWORK  [conn89] received client metadata from 192.168.122.18:54348 conn89: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:01.236-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T05:32:01.253-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47240 #90 (37 connections now open)
2020-05-09T05:32:01.254-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47250 #91 (38 connections now open)
2020-05-09T05:32:01.254-0700 I  NETWORK  [conn90] received client metadata from 192.168.122.1:47240 conn90: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:01.254-0700 I  NETWORK  [conn91] received client metadata from 192.168.122.1:47250 conn91: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:01.257-0700 I  NETWORK  [conn90] end connection 192.168.122.1:47240 (37 connections now open)
2020-05-09T05:32:01.257-0700 I  NETWORK  [conn91] end connection 192.168.122.1:47250 (36 connections now open)
2020-05-09T05:32:02.268-0700 I  REPL     [replexec-2] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:02.268-0700 I  REPL     [replexec-2] can't see a majority of the set, relinquishing primary
2020-05-09T05:32:02.268-0700 I  REPL     [replexec-2] Stepping down from primary in response to heartbeat
2020-05-09T05:32:02.268-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:02.268-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:02.268-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:02.269-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T05:32:02.269-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:02.548-0700 I  NETWORK  [conn84] end connection 192.168.122.11:53144 (35 connections now open)
2020-05-09T05:32:02.559-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53204 #92 (36 connections now open)
2020-05-09T05:32:02.560-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53202 #93 (37 connections now open)
2020-05-09T05:32:02.560-0700 I  NETWORK  [conn92] received client metadata from 192.168.122.11:53204 conn92: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:02.560-0700 I  NETWORK  [conn9] end connection 192.168.122.13:33724 (36 connections now open)
2020-05-09T05:32:02.560-0700 I  NETWORK  [conn93] received client metadata from 192.168.122.11:53202 conn93: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:02.560-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35534 #94 (37 connections now open)
2020-05-09T05:32:02.561-0700 I  NETWORK  [conn94] received client metadata from 192.168.122.13:35534 conn94: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:02.590-0700 I  CONNPOOL [Replication] Ending connection to host n3:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:02.590-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:32:02.600-0700 I  REPL     [replexec-0] Member n1:27019 is now in state PRIMARY
2020-05-09T05:32:03.011-0700 I  ELECTION [conn70] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 5, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027520, 1), t: 5 } }
2020-05-09T05:32:03.011-0700 I  ELECTION [conn70] Sending vote response: { term: 6, voteGranted: false, reason: "candidate's term (5) is lower than mine (6)" }
2020-05-09T05:32:03.012-0700 I  NETWORK  [conn70] end connection 192.168.122.11:52824 (36 connections now open)
2020-05-09T05:32:03.091-0700 I  REPL     [replexec-1] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:03.098-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47392 #96 (37 connections now open)
2020-05-09T05:32:03.098-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47396 #97 (38 connections now open)
2020-05-09T05:32:03.098-0700 I  NETWORK  [conn96] received client metadata from 192.168.122.1:47392 conn96: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:03.099-0700 I  NETWORK  [conn97] received client metadata from 192.168.122.1:47396 conn97: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:03.103-0700 I  NETWORK  [conn96] end connection 192.168.122.1:47392 (37 connections now open)
2020-05-09T05:32:03.103-0700 I  NETWORK  [conn97] end connection 192.168.122.1:47396 (36 connections now open)
2020-05-09T05:32:03.270-0700 I  REPL     [rsBackgroundSync] sync source candidate: n3:27019
2020-05-09T05:32:03.274-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n3:27019
2020-05-09T05:32:03.279-0700 I  REPL     [replication-2] Choosing new sync source. Our current sync source is not primary and does not have a sync source, so we require that it is ahead of us. Current sync source: n3:27019, my last fetched oplog optime: { ts: Timestamp(1589027522, 12), t: 6 }, latest oplog optime of sync source: { ts: Timestamp(1589027522, 12), t: 6 } (n1:27019 is)
2020-05-09T05:32:03.279-0700 I  REPL     [replication-2] Canceling oplog query due to OplogQueryMetadata. We have to choose a new sync source. Current source: n3:27019, OpTime { ts: Timestamp(1589027522, 12), t: 6 }, its sync source index:-1
2020-05-09T05:32:03.279-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n3:27019 (config version: 1; last applied optime: { ts: Timestamp(1589027522, 12), t: 6 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T05:32:03.279-0700 I  REPL     [rsBackgroundSync] Clearing sync source n3:27019 to choose a new one.
2020-05-09T05:32:03.279-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T05:32:03.292-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n3:27019: InvalidSyncSource: Sync source was cleared. Was n3:27019
2020-05-09T05:32:04.472-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47474 #100 (37 connections now open)
2020-05-09T05:32:04.473-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47478 #101 (38 connections now open)
2020-05-09T05:32:04.473-0700 I  NETWORK  [conn100] received client metadata from 192.168.122.1:47474 conn100: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:04.473-0700 I  NETWORK  [conn101] received client metadata from 192.168.122.1:47478 conn101: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:04.476-0700 I  NETWORK  [conn100] end connection 192.168.122.1:47474 (37 connections now open)
2020-05-09T05:32:04.477-0700 I  NETWORK  [conn101] end connection 192.168.122.1:47478 (36 connections now open)
2020-05-09T05:32:05.259-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47480 #102 (37 connections now open)
2020-05-09T05:32:05.259-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47488 #103 (38 connections now open)
2020-05-09T05:32:05.260-0700 I  NETWORK  [conn102] received client metadata from 192.168.122.1:47480 conn102: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:05.260-0700 I  NETWORK  [conn103] received client metadata from 192.168.122.1:47488 conn103: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:05.264-0700 I  NETWORK  [conn102] end connection 192.168.122.1:47480 (37 connections now open)
2020-05-09T05:32:05.265-0700 I  NETWORK  [conn103] end connection 192.168.122.1:47488 (36 connections now open)
2020-05-09T05:32:06.259-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:32:06.259-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 6
2020-05-09T05:32:06.259-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 905 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027522, 12), t: 6 } }
2020-05-09T05:32:06.259-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 906 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 6, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027522, 12), t: 6 } }
2020-05-09T05:32:06.260-0700 I  ELECTION [replexec-4] VoteRequester(term 6 dry run) received a yes vote from n3:27019; response message: { term: 6, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027522, 12), $clusterTime: { clusterTime: Timestamp(1589027526, 121), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027522, 12) }
2020-05-09T05:32:06.260-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 7
2020-05-09T05:32:06.260-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:06.278-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 907 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027522, 12), t: 6 } }
2020-05-09T05:32:06.278-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 908 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 7, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027522, 12), t: 6 } }
2020-05-09T05:32:06.278-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:32:06.282-0700 I  CONNPOOL [Replication] Connecting to n3:27019
2020-05-09T05:32:06.288-0700 I  ELECTION [replexec-0] VoteRequester(term 7) received a yes vote from n3:27019; response message: { term: 7, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027522, 12), $clusterTime: { clusterTime: Timestamp(1589027526, 121), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027522, 12) }
2020-05-09T05:32:06.288-0700 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 7
2020-05-09T05:32:06.288-0700 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
2020-05-09T05:32:06.288-0700 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
2020-05-09T05:32:06.288-0700 I  REPL     [replexec-0] Entering primary catch-up mode.
2020-05-09T05:32:06.288-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:06.697-0700 I  REPL     [replexec-0] Member n1:27019 is now in state RS_DOWN - Couldn't get a connection within the time limit
2020-05-09T05:32:06.697-0700 I  REPL     [replexec-0] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1589027522, 12), t: 6 }. My Last Applied: { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:06.697-0700 I  REPL     [replexec-0] Exited primary catch-up mode.
2020-05-09T05:32:06.697-0700 I  REPL     [replexec-0] Stopping replication producer
2020-05-09T05:32:06.697-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 7
2020-05-09T05:32:06.697-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:06.697-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:06.697-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:06.699-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:06.699-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:06.699-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:06.700-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:06.700-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:07.072-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35688 #105 (37 connections now open)
2020-05-09T05:32:07.073-0700 I  NETWORK  [conn105] received client metadata from 192.168.122.13:35688 conn105: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.076-0700 I  NETWORK  [listener] connection accepted from 192.168.122.19:41394 #106 (38 connections now open)
2020-05-09T05:32:07.076-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:33632 #107 (39 connections now open)
2020-05-09T05:32:07.077-0700 I  NETWORK  [conn106] received client metadata from 192.168.122.19:41394 conn106: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.18:54666 #108 (40 connections now open)
2020-05-09T05:32:07.077-0700 I  NETWORK  [conn107] received client metadata from 192.168.122.16:33632 conn107: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.14:40862 #109 (41 connections now open)
2020-05-09T05:32:07.077-0700 I  NETWORK  [conn108] received client metadata from 192.168.122.18:54666 conn108: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.077-0700 I  NETWORK  [conn109] received client metadata from 192.168.122.14:40862 conn109: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.077-0700 I  NETWORK  [listener] connection accepted from 192.168.122.17:50278 #110 (42 connections now open)
2020-05-09T05:32:07.078-0700 I  NETWORK  [conn110] received client metadata from 192.168.122.17:50278 conn110: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.137-0700 I  NETWORK  [listener] connection accepted from 192.168.122.12:52514 #111 (43 connections now open)
2020-05-09T05:32:07.137-0700 I  NETWORK  [conn111] received client metadata from 192.168.122.12:52514 conn111: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.311-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53500 #112 (44 connections now open)
2020-05-09T05:32:07.311-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53502 #115 (45 connections now open)
2020-05-09T05:32:07.312-0700 I  NETWORK  [conn112] received client metadata from 192.168.122.11:53500 conn112: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.312-0700 I  NETWORK  [conn115] received client metadata from 192.168.122.11:53502 conn115: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:07.365-0700 I  NETWORK  [conn115] end connection 192.168.122.11:53502 (44 connections now open)
2020-05-09T05:32:07.371-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47564 #116 (45 connections now open)
2020-05-09T05:32:07.371-0700 I  NETWORK  [conn116] received client metadata from 192.168.122.1:47564 conn116: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:07.372-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47568 #117 (46 connections now open)
2020-05-09T05:32:07.372-0700 I  NETWORK  [conn117] received client metadata from 192.168.122.1:47568 conn117: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:07.374-0700 I  COMMAND  [conn34] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27017:1589027495:4498723705184841883" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 1535), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 602ms
2020-05-09T05:32:07.374-0700 I  COMMAND  [conn28] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27017:1589027495:3290208215892541551" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 1533), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 602ms
2020-05-09T05:32:07.374-0700 I  COMMAND  [conn105] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027527, 178), signature: { hash: BinData(0, 9DACECD878EE663F8414BE2124A31AA7E3A578EE), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 300ms
2020-05-09T05:32:07.374-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:07.374-0700 I  NETWORK  [conn116] end connection 192.168.122.1:47564 (45 connections now open)
2020-05-09T05:32:07.374-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:07.375-0700 I  NETWORK  [conn117] end connection 192.168.122.1:47568 (44 connections now open)
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn29] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n5:27017:1589027495:-3092204051443899780" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 1536), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:628 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 603ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn89] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27017:1589027495:-4028076255853485019" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 126), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:628 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 603ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn88] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n1:27017:1589027495:563410028455241219" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027527, 275), signature: { hash: BinData(0, 9DACECD878EE663F8414BE2124A31AA7E3A578EE), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:626 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 267ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn111] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027527, 336), signature: { hash: BinData(0, 9DACECD878EE663F8414BE2124A31AA7E3A578EE), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 237ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn109] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1589027527249), up: 30, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027527, 632), signature: { hash: BinData(0, 9DACECD878EE663F8414BE2124A31AA7E3A578EE), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 124ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn108] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1589027527249), up: 30, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027527, 184), signature: { hash: BinData(0, 9DACECD878EE663F8414BE2124A31AA7E3A578EE), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 124ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn19] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n6:27017:1589027495:7883765758298039767" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 1529), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 603ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn30] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n3:27017:1589027495:1203799030626098870" }, update: { $set: { ping: new Date(1589027526068) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 2010), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 458ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn31] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n4:27017:1589027495:8024958533017945185" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 1535), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 603ms
2020-05-09T05:32:07.375-0700 I  COMMAND  [conn35] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n2:27017:1589027495:3135941772378158776" }, update: { $set: { ping: new Date(1589027526069) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027526, 2006), signature: { hash: BinData(0, 02D27E7854B9B14F2C8D0D2E62E77AB04559CCE3), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027522, 12), t: 6 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:627 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 462ms
2020-05-09T05:32:08.067-0700 I  REPL     [replexec-3] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:08.067-0700 I  REPL     [replexec-3] can't see a majority of the set, relinquishing primary
2020-05-09T05:32:08.067-0700 I  REPL     [replexec-3] Stepping down from primary in response to heartbeat
2020-05-09T05:32:08.067-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:08.067-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:08.067-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:08.068-0700 I  REPL     [replexec-4] transition to SECONDARY from PRIMARY
2020-05-09T05:32:08.068-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:09.086-0700 I  ELECTION [replexec-5] Not starting an election, since we are not electable due to: Not standing for election because I cannot see a majority (mask 0x1)
2020-05-09T05:32:09.087-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:35760 #118 (45 connections now open)
2020-05-09T05:32:09.088-0700 I  NETWORK  [conn118] received client metadata from 192.168.122.13:35760 conn118: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:09.112-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-09T05:32:09.119-0700 I  ELECTION [conn92] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 7, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027527, 851), t: 7 } }
2020-05-09T05:32:09.119-0700 I  ELECTION [conn92] Sending vote response: { term: 8, voteGranted: false, reason: "candidate's term (7) is lower than mine (8)" }
2020-05-09T05:32:09.120-0700 I  NETWORK  [conn92] end connection 192.168.122.11:53204 (44 connections now open)
2020-05-09T05:32:09.120-0700 I  REPL     [replexec-1] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:09.152-0700 I  NETWORK  [conn93] end connection 192.168.122.11:53202 (43 connections now open)
2020-05-09T05:32:09.183-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53560 #119 (44 connections now open)
2020-05-09T05:32:09.184-0700 I  NETWORK  [conn119] received client metadata from 192.168.122.11:53560 conn119: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:09.247-0700 I  NETWORK  [conn94] end connection 192.168.122.13:35534 (43 connections now open)
2020-05-09T05:32:09.311-0700 I  NETWORK  [conn112] end connection 192.168.122.11:53500 (42 connections now open)
2020-05-09T05:32:09.471-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53564 #120 (43 connections now open)
2020-05-09T05:32:09.472-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53562 #121 (44 connections now open)
2020-05-09T05:32:09.472-0700 I  NETWORK  [conn120] received client metadata from 192.168.122.11:53564 conn120: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:09.472-0700 I  NETWORK  [conn121] received client metadata from 192.168.122.11:53562 conn121: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:10.069-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:32:10.071-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:32:10.072-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T05:32:10.538-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47666 #123 (45 connections now open)
2020-05-09T05:32:10.538-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47668 #124 (46 connections now open)
2020-05-09T05:32:10.538-0700 I  NETWORK  [conn123] received client metadata from 192.168.122.1:47666 conn123: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:10.538-0700 I  NETWORK  [conn124] received client metadata from 192.168.122.1:47668 conn124: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:10.541-0700 I  NETWORK  [conn124] end connection 192.168.122.1:47668 (45 connections now open)
2020-05-09T05:32:10.541-0700 I  NETWORK  [conn123] end connection 192.168.122.1:47666 (44 connections now open)
2020-05-09T05:32:11.282-0700 I  ELECTION [replexec-1] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:32:11.282-0700 I  ELECTION [replexec-1] conducting a dry run election to see if we could be elected. current term: 8
2020-05-09T05:32:11.282-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 941 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027530, 2), t: 8 } }
2020-05-09T05:32:11.282-0700 I  REPL     [replexec-1] Scheduling remote command request for vote request: RemoteCommand 942 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 8, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027530, 2), t: 8 } }
2020-05-09T05:32:11.283-0700 I  ELECTION [replexec-0] VoteRequester(term 8 dry run) received a yes vote from n3:27019; response message: { term: 8, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027530, 2), $clusterTime: { clusterTime: Timestamp(1589027530, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027530, 2) }
2020-05-09T05:32:11.283-0700 I  ELECTION [replexec-5] dry election run succeeded, running for election in term 9
2020-05-09T05:32:11.283-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:11.287-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 943 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027530, 2), t: 8 } }
2020-05-09T05:32:11.287-0700 I  REPL     [replexec-5] Scheduling remote command request for vote request: RemoteCommand 944 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 9, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027530, 2), t: 8 } }
2020-05-09T05:32:11.290-0700 I  ELECTION [replexec-1] VoteRequester(term 9) received a yes vote from n3:27019; response message: { term: 9, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(1589027530, 2), $clusterTime: { clusterTime: Timestamp(1589027530, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027530, 2) }
2020-05-09T05:32:11.291-0700 I  ELECTION [replexec-1] election succeeded, assuming primary role in term 9
2020-05-09T05:32:11.291-0700 I  REPL     [replexec-1] transition to PRIMARY from SECONDARY
2020-05-09T05:32:11.291-0700 I  REPL     [replexec-1] Resetting sync source to empty, which was n1:27019
2020-05-09T05:32:11.291-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:11.291-0700 I  REPL     [replexec-1] Entering primary catch-up mode.
2020-05-09T05:32:11.291-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:32:11.394-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1589027530, 3), t: 8 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T05:32:12.084-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T05:32:12.291-0700 I  REPL     [replexec-3] Catchup timed out after becoming primary.
2020-05-09T05:32:12.291-0700 I  REPL     [replexec-3] Exited primary catch-up mode.
2020-05-09T05:32:12.291-0700 I  REPL     [replexec-3] Stopping replication producer
2020-05-09T05:32:12.291-0700 I  REPL     [replexec-1] Member n1:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:12.291-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 9
2020-05-09T05:32:12.292-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:12.292-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:12.292-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:12.294-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:12.294-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:12.295-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:12.297-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:12.297-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:12.431-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:40510 #126 (45 connections now open)
2020-05-09T05:32:12.432-0700 I  NETWORK  [listener] connection accepted from 192.168.122.15:40512 #127 (46 connections now open)
2020-05-09T05:32:12.432-0700 I  NETWORK  [conn126] received client metadata from 192.168.122.15:40510 conn126: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:12.432-0700 I  NETWORK  [conn127] received client metadata from 192.168.122.15:40512 conn127: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:12.641-0700 I  NETWORK  [listener] connection accepted from 192.168.122.16:33870 #128 (47 connections now open)
2020-05-09T05:32:12.643-0700 I  NETWORK  [conn128] received client metadata from 192.168.122.16:33870 conn128: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:12.936-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47788 #129 (48 connections now open)
2020-05-09T05:32:12.937-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47790 #130 (49 connections now open)
2020-05-09T05:32:12.937-0700 I  NETWORK  [conn129] received client metadata from 192.168.122.1:47788 conn129: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:12.937-0700 I  NETWORK  [conn130] received client metadata from 192.168.122.1:47790 conn130: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:12.941-0700 I  NETWORK  [conn129] end connection 192.168.122.1:47788 (48 connections now open)
2020-05-09T05:32:12.941-0700 I  NETWORK  [conn130] end connection 192.168.122.1:47790 (47 connections now open)
2020-05-09T05:32:13.934-0700 I  REPL     [replexec-1] Member n3:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:13.934-0700 I  REPL     [replexec-1] can't see a majority of the set, relinquishing primary
2020-05-09T05:32:13.934-0700 I  REPL     [replexec-1] Stepping down from primary in response to heartbeat
2020-05-09T05:32:13.934-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:13.935-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:13.935-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 23, userOpsRunning: 0 }
2020-05-09T05:32:13.935-0700 W  COMMAND  [conn89] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.935-0700 I  COMMAND  [conn89] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 51), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1388ms
2020-05-09T05:32:13.936-0700 W  COMMAND  [conn111] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.936-0700 I  COMMAND  [conn111] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 92), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1337ms
2020-05-09T05:32:13.936-0700 W  COMMAND  [conn119] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.936-0700 I  COMMAND  [conn119] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 74), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 1337ms
2020-05-09T05:32:13.936-0700 W  COMMAND  [conn44] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.936-0700 I  COMMAND  [conn44] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n8:27018:1589027501:6657455084422948315" }, update: { $set: { ping: new Date(1589027531319) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 134), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } planSummary: IDHACK keysExamined:0 docsExamined:0 nMatched:0 nModified:0 upsert:1 keysInserted:2 numYields:0 reslen:731 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1506ms
2020-05-09T05:32:13.936-0700 W  COMMAND  [conn35] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.936-0700 I  COMMAND  [conn35] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 92), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1338ms
2020-05-09T05:32:13.937-0700 W  COMMAND  [conn34] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.937-0700 I  COMMAND  [conn34] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 49), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1402ms
2020-05-09T05:32:13.938-0700 W  COMMAND  [conn29] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.938-0700 I  COMMAND  [conn29] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 134), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1506ms
2020-05-09T05:32:13.938-0700 W  COMMAND  [conn110] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.939-0700 I  COMMAND  [conn110] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 49), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1403ms
2020-05-09T05:32:13.939-0700 W  COMMAND  [conn105] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.939-0700 I  COMMAND  [conn105] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 69), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1340ms
2020-05-09T05:32:13.939-0700 W  COMMAND  [conn75] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.939-0700 I  COMMAND  [conn75] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n9:27018:1589027501:3108026142901478785" }, update: { $set: { ping: new Date(1589027531187) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 134), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:1 keysInserted:1 keysDeleted:1 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1508ms
2020-05-09T05:32:13.939-0700 W  COMMAND  [conn106] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.939-0700 I  COMMAND  [conn106] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 52), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1395ms
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn108] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn128] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn109] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn108] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 51), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1392ms
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn107] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn109] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 127), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1341ms
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn128] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 136), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1296ms
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn31] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn107] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 136), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } protocol:op_msg 1299ms
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn31] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 127), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1342ms
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn127] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn40] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn19] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn40] command config.lockpings command: findAndModify { findAndModify: "lockpings", query: { _id: "n7:27018:1589027500:8843213706502976374" }, update: { $set: { ping: new Date(1589027530557) } }, upsert: true, writeConcern: { w: "majority", wtimeout: 15000 }, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 134), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } planSummary: IDHACK keysExamined:1 docsExamined:1 nMatched:1 nModified:0 numYields:0 reslen:745 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1510ms
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn28] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 I  REPL     [replexec-1] transition to SECONDARY from PRIMARY
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn127] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 134), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1507ms
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn19] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 136), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1299ms
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn126] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn88] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.941-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:13.941-0700 W  TXN      [TransactionCoordinator] Coordinator recovery failed and coordinateCommit requests will not be allowed :: caused by :: PrimarySteppedDown: Primary stepped down while waiting for replication
2020-05-09T05:32:13.940-0700 W  COMMAND  [conn30] Unable to gather storage statistics for a slow operation due to lock aquire timeout
2020-05-09T05:32:13.941-0700 I  COMMAND  [conn88] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 74), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } protocol:op_msg 1342ms
2020-05-09T05:32:13.940-0700 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard1" }, u: { $set: { host: "rs_shard1/n4:27018,n5:27018,n6:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 52), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1395ms
2020-05-09T05:32:13.941-0700 I  COMMAND  [conn126] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 134), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1508ms
2020-05-09T05:32:13.941-0700 I  COMMAND  [conn30] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027532, 69), signature: { hash: BinData(0, 1A2A13CF5B20599418FEEE8F4A96D7CD2D6F15B7), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027530, 2), t: 8 } }, $db: "config" } numYields:0 reslen:705 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } protocol:op_msg 1342ms
2020-05-09T05:32:14.050-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36032 #131 (48 connections now open)
2020-05-09T05:32:14.050-0700 I  NETWORK  [conn131] received client metadata from 192.168.122.13:36032 conn131: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:14.058-0700 I  ELECTION [conn131] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 10, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027531, 4), t: 8 } }
2020-05-09T05:32:14.058-0700 I  ELECTION [conn131] Sending vote response: { term: 10, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027531, 4), t: 8 }, my last applied OpTime: { ts: Timestamp..." }
2020-05-09T05:32:14.061-0700 I  NETWORK  [conn118] end connection 192.168.122.13:35760 (47 connections now open)
2020-05-09T05:32:14.090-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53830 #132 (48 connections now open)
2020-05-09T05:32:14.091-0700 I  NETWORK  [conn132] received client metadata from 192.168.122.11:53830 conn132: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:14.109-0700 I  NETWORK  [listener] connection accepted from 192.168.122.13:36038 #133 (49 connections now open)
2020-05-09T05:32:14.110-0700 I  NETWORK  [conn133] received client metadata from 192.168.122.13:36038 conn133: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:14.148-0700 I  REPL     [replexec-4] Member n3:27019 is now in state PRIMARY
2020-05-09T05:32:14.148-0700 I  ELECTION [replexec-4] Scheduling catchup takeover at 2020-05-09T05:32:17.148-0700
2020-05-09T05:32:14.279-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53834 #134 (50 connections now open)
2020-05-09T05:32:14.279-0700 I  NETWORK  [conn134] received client metadata from 192.168.122.11:53834 conn134: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:14.282-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:53836 #135 (51 connections now open)
2020-05-09T05:32:14.282-0700 I  NETWORK  [conn135] received client metadata from 192.168.122.11:53836 conn135: { driver: { name: "MongoDB Internal Client", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:14.292-0700 I  REPL     [replexec-1] Member n1:27019 is now in state ROLLBACK
2020-05-09T05:32:14.376-0700 I  NETWORK  [conn135] end connection 192.168.122.11:53836 (50 connections now open)
2020-05-09T05:32:14.649-0700 I  REPL     [replexec-3] Canceling catchup takeover callback
2020-05-09T05:32:14.649-0700 I  ELECTION [replexec-3] Scheduling priority takeover at 2020-05-09T05:32:16.735-0700
2020-05-09T05:32:14.659-0700 I  NETWORK  [conn121] end connection 192.168.122.11:53562 (49 connections now open)
2020-05-09T05:32:14.792-0700 I  REPL     [replexec-5] Member n1:27019 is now in state SECONDARY
2020-05-09T05:32:14.825-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47994 #136 (50 connections now open)
2020-05-09T05:32:14.825-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47998 #137 (51 connections now open)
2020-05-09T05:32:14.826-0700 I  NETWORK  [conn136] received client metadata from 192.168.122.1:47994 conn136: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:14.826-0700 I  NETWORK  [conn137] received client metadata from 192.168.122.1:47998 conn137: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:14.828-0700 I  NETWORK  [conn136] end connection 192.168.122.1:47994 (50 connections now open)
2020-05-09T05:32:14.828-0700 I  NETWORK  [conn137] end connection 192.168.122.1:47998 (49 connections now open)
2020-05-09T05:32:14.942-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:32:14.943-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:32:14.943-0700 I  REPL     [rsBackgroundSync] Starting rollback due to OplogStartMissing: Our last optime fetched: { ts: Timestamp(1589027532, 136), t: 9 }. source's GTE: { ts: Timestamp(1589027534, 135), t: 10 }
2020-05-09T05:32:14.943-0700 I  REPL     [rsBackgroundSync] Replication commit point: { ts: Timestamp(1589027530, 2), t: 8 }
2020-05-09T05:32:14.944-0700 I  REPL     [rsBackgroundSync] Rollback using 'recoverToStableTimestamp' method.
2020-05-09T05:32:14.944-0700 I  REPL     [rsBackgroundSync] Scheduling rollback (sync source: n1:27019)
2020-05-09T05:32:14.944-0700 I  ROLLBACK [rsBackgroundSync] transition to ROLLBACK
2020-05-09T05:32:14.944-0700 I  REPL     [rsBackgroundSync] State transition ops metrics: { lastStateTransition: "rollback", userOpsKilled: 0, userOpsRunning: 50 }
2020-05-09T05:32:14.944-0700 I  REPL     [rsBackgroundSync] Canceling priority takeover callback
2020-05-09T05:32:14.944-0700 I  REPL     [rsBackgroundSync] transition to ROLLBACK from SECONDARY
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 134
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 133
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 132
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 131
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 128
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 127
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 126
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 120
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 119
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 111
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 110
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 109
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 108
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 107
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 106
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 105
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 89
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 88
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 85
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 81
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 80
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 75
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 45
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 44
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 42
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 41
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 40
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 39
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 38
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 37
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 36
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 35
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 34
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 33
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 32
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 31
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 30
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 29
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 28
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 26
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 25
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 24
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 23
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 22
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 21
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 20
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 19
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 18
2020-05-09T05:32:14.944-0700 I  NETWORK  [rsBackgroundSync] Skip closing connection for connection # 17
2020-05-09T05:32:14.944-0700 I  ROLLBACK [rsBackgroundSync] Waiting for all background operations to complete before starting rollback
2020-05-09T05:32:14.944-0700 I  ROLLBACK [rsBackgroundSync] Finished waiting for background operations to complete before rollback
2020-05-09T05:32:14.944-0700 I  ROLLBACK [rsBackgroundSync] finding common point
2020-05-09T05:32:14.947-0700 I  ROLLBACK [rsBackgroundSync] Rollback common point is { ts: Timestamp(1589027530, 3), t: 8 }
2020-05-09T05:32:14.957-0700 I  REPL     [rsBackgroundSync] Incremented the rollback ID to 2
2020-05-09T05:32:14.957-0700 I  ROLLBACK [rsBackgroundSync] finding record store counts
2020-05-09T05:32:14.957-0700 I  ROLLBACK [rsBackgroundSync] Preparing to write deleted documents to a rollback file for collection config.lockpings with uuid 06fbc13c-eb1d-4254-80f8-deeaa8ca575b to /var/lib/mongodb/rollback/config.lockpings/removed.2020-05-09T12-32-14.0.bson
2020-05-09T05:32:14.957-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing all databases
2020-05-09T05:32:14.958-0700 I  STORAGE  [rsBackgroundSync] closeCatalog: closing storage engine catalog
2020-05-09T05:32:14.958-0700 I  STORAGE  [rsBackgroundSync] Deregistering all the collections
2020-05-09T05:32:14.958-0700 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
2020-05-09T05:32:15.057-0700 I  ROLLBACK [rsBackgroundSync] Rolling back to the stable timestamp. StableTimestamp: Timestamp(1589027530, 2) Initial Data Timestamp: Timestamp(1589027494, 2)
2020-05-09T05:32:15.058-0700 I  STORAGE  [rsBackgroundSync] openCatalog: loading storage engine catalog
2020-05-09T05:32:15.066-0700 I  STORAGE  [rsBackgroundSync] OplogTruncaterThread local.oplog.rs already started
2020-05-09T05:32:15.066-0700 I  STORAGE  [rsBackgroundSync] The size storer reports that the oplog contains 222 records totaling to 48515 bytes
2020-05-09T05:32:15.066-0700 I  STORAGE  [rsBackgroundSync] Scanning the oplog to determine where to place markers for truncation
2020-05-09T05:32:15.067-0700 I  STORAGE  [rsBackgroundSync] WiredTiger record store oplog processing took 0ms
2020-05-09T05:32:15.070-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reconciling catalog and idents
2020-05-09T05:32:15.070-0700 I  STORAGE  [rsBackgroundSync] openCatalog: reopening all databases
2020-05-09T05:32:15.087-0700 I  STORAGE  [rsBackgroundSync] openCatalog: updating cached oplog pointer
2020-05-09T05:32:15.087-0700 I  STORAGE  [rsBackgroundSync] openCatalog: finished reloading collection catalog
2020-05-09T05:32:15.087-0700 I  STORAGE  [rsBackgroundSync] recoverToStableTimestamp successful. Stable Timestamp: Timestamp(1589027530, 2)
2020-05-09T05:32:15.087-0700 I  ROLLBACK [rsBackgroundSync] Rollback reverted 1 insert operations, 1 update operations and 0 delete operations.
2020-05-09T05:32:15.087-0700 I  ROLLBACK [rsBackgroundSync] Marking to truncate all oplog entries with timestamps greater than or equal to { ts: Timestamp(1589027532, 1), t: 9 }
2020-05-09T05:32:15.087-0700 I  REPL     [rsBackgroundSync] Removing unapplied entries starting at: { : Timestamp(1589027532, 1) }
2020-05-09T05:32:15.087-0700 I  REPL     [rsBackgroundSync] Replication recovery oplog truncation finished in: 0ms
2020-05-09T05:32:15.090-0700 I  REPL     [rsBackgroundSync] Recovering from stable timestamp: Timestamp(1589027530, 2) (top of oplog: { ts: Timestamp(1589027530, 3), t: 8 }, appliedThrough: { ts: Timestamp(1589027530, 2), t: 8 }, TruncateAfter: Timestamp(0, 0))
2020-05-09T05:32:15.090-0700 I  REPL     [rsBackgroundSync] Starting recovery oplog application at the stable timestamp: Timestamp(1589027530, 2)
2020-05-09T05:32:15.090-0700 I  REPL     [rsBackgroundSync] Replaying stored operations from Timestamp(1589027530, 2) (inclusive) to Timestamp(1589027530, 3) (inclusive).
2020-05-09T05:32:15.092-0700 I  REPL     [rsBackgroundSync] Applied 1 operations in 1 batches. Last operation applied with optime: { ts: Timestamp(1589027530, 3), t: 8 }
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] Triggering the rollback op observer
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] Resetting key manager cache
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] Rollback complete
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] Rollback summary:
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	start time: 2020-05-09T05:32:14.944-0700
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	end time: 2020-05-09T05:32:15.093-0700
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	sync source: n1:27019
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	rollback data file directory: /var/lib/mongodb/rollback/config.lockpings
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	rollback id: 2
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	last optime on branch of history rolled back: { ts: Timestamp(1589027532, 136), t: 9 }
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	common point optime: { ts: Timestamp(1589027530, 3), t: 8 }
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	last wall clock time on the branch of history rolled back: 2020-05-09T05:32:12.431-0700
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	wall clock time of the first operation after the common point: 2020-05-09T05:32:10.557-0700
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	difference in wall clock times: 1 second(s)
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	truncate timestamp: Timestamp(1589027532, 1)
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	stable timestamp: Timestamp(1589027530, 2)
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	shard identity document rolled back: false
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	config server config version document rolled back: false
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	affected sessions: none
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	affected namespaces: 
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 		config.lockpings
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	counts of interesting commands rolled back: 
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 		insert: 1
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 		delete: 0
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 		update: 1
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] 	total number of entries rolled back (including no-ops): 3
2020-05-09T05:32:15.093-0700 I  ROLLBACK [rsBackgroundSync] transition to SECONDARY
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] transition to SECONDARY from ROLLBACK
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] Resetting sync source to empty, which was n1:27019
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] Rollback successful.
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] Stopping replication producer
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] Resetting last fetched optimes in bgsync
2020-05-09T05:32:15.093-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:32:15.095-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:32:15.195-0700 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to n8:27018 due to ShutdownInProgress: Pool for n8:27018 has expired.
2020-05-09T05:32:15.195-0700 I  CONNPOOL [TaskExecutorPool-0] Dropping all pooled connections to n9:27018 due to ShutdownInProgress: Pool for n9:27018 has expired.
2020-05-09T05:32:15.359-0700 I  ELECTION [replexec-5] Scheduling priority takeover at 2020-05-09T05:32:17.428-0700
2020-05-09T05:32:15.768-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48046 #139 (50 connections now open)
2020-05-09T05:32:15.768-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48048 #140 (51 connections now open)
2020-05-09T05:32:15.768-0700 I  NETWORK  [conn139] received client metadata from 192.168.122.1:48046 conn139: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:15.769-0700 I  NETWORK  [conn140] received client metadata from 192.168.122.1:48048 conn140: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:15.771-0700 I  NETWORK  [conn139] end connection 192.168.122.1:48046 (50 connections now open)
2020-05-09T05:32:15.772-0700 I  NETWORK  [conn140] end connection 192.168.122.1:48048 (49 connections now open)
2020-05-09T05:32:16.559-0700 I  ELECTION [conn120] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 10, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:16.560-0700 I  ELECTION [conn120] Sending vote response: { term: 10, voteGranted: true, reason: "" }
2020-05-09T05:32:16.569-0700 I  REPL     [conn120] Canceling priority takeover callback
2020-05-09T05:32:16.570-0700 I  ELECTION [conn120] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 11, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:16.570-0700 I  ELECTION [conn120] Sending vote response: { term: 11, voteGranted: true, reason: "" }
2020-05-09T05:32:16.710-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48090 #141 (50 connections now open)
2020-05-09T05:32:16.711-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48096 #142 (51 connections now open)
2020-05-09T05:32:16.711-0700 I  NETWORK  [conn141] received client metadata from 192.168.122.1:48090 conn141: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:16.711-0700 I  NETWORK  [conn142] received client metadata from 192.168.122.1:48096 conn142: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:16.714-0700 I  NETWORK  [conn141] end connection 192.168.122.1:48090 (50 connections now open)
2020-05-09T05:32:16.714-0700 I  NETWORK  [conn142] end connection 192.168.122.1:48096 (49 connections now open)
2020-05-09T05:32:17.360-0700 I  REPL     [replexec-0] Member n3:27019 is now in state SECONDARY
2020-05-09T05:32:17.583-0700 I  ELECTION [conn131] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 2, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027534, 135), t: 10 } }
2020-05-09T05:32:17.583-0700 I  ELECTION [conn131] Sending vote response: { term: 11, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027534, 135), t: 10 }, my last applied OpTime: { ts: Timest..." }
2020-05-09T05:32:17.699-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:32:17.699-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 11
2020-05-09T05:32:17.699-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 985 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027536, 2), t: 11 } }
2020-05-09T05:32:17.699-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 986 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 11, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027536, 2), t: 11 } }
2020-05-09T05:32:17.699-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:32:17.700-0700 I  ELECTION [replexec-4] VoteRequester(term 11 dry run) received a yes vote from n3:27019; response message: { term: 11, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1589027534, 135), $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027534, 135) }
2020-05-09T05:32:17.700-0700 I  ELECTION [replexec-4] dry election run succeeded, running for election in term 12
2020-05-09T05:32:17.705-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 988 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027536, 2), t: 11 } }
2020-05-09T05:32:17.705-0700 I  REPL     [replexec-4] Scheduling remote command request for vote request: RemoteCommand 989 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 12, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027536, 2), t: 11 } }
2020-05-09T05:32:17.705-0700 I  ELECTION [replexec-2] VoteRequester(term 12) received a no vote from n1:27019 with reason "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027536, 2), t: 11 }, my last applied OpTime: { ts: Timestamp(1589027537, 3), t: 11 }"; response message: { term: 12, voteGranted: false, reason: "candidate's data is staler than mine. candidate's last applied OpTime: { ts: Timestamp(1589027536, 2), t: 11 }, my last applied OpTime: { ts: Timestam...", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000b') }, lastCommittedOpTime: Timestamp(1589027536, 2), $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027537, 3) }
2020-05-09T05:32:17.710-0700 I  ELECTION [replexec-5] VoteRequester(term 12) received a yes vote from n3:27019; response message: { term: 12, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1589027534, 135), $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027534, 135) }
2020-05-09T05:32:17.710-0700 I  ELECTION [replexec-5] election succeeded, assuming primary role in term 12
2020-05-09T05:32:17.710-0700 I  REPL     [replexec-5] transition to PRIMARY from SECONDARY
2020-05-09T05:32:17.710-0700 I  REPL     [replexec-5] Resetting sync source to empty, which was n1:27019
2020-05-09T05:32:17.710-0700 I  REPL     [replexec-5] Entering primary catch-up mode.
2020-05-09T05:32:17.711-0700 I  REPL     [replexec-5] Heartbeats updated catchup target optime to { ts: Timestamp(1589027537, 3), t: 11 }
2020-05-09T05:32:17.711-0700 I  REPL     [replexec-5] Latest known optime per replica set member:
2020-05-09T05:32:17.711-0700 I  REPL     [replexec-5] Member ID: MemberId(0), latest known optime: { ts: Timestamp(1589027537, 3), t: 11 }
2020-05-09T05:32:17.712-0700 I  REPL     [replexec-5] Member ID: MemberId(1), latest known optime: unknown
2020-05-09T05:32:17.712-0700 I  REPL     [replexec-5] Member ID: MemberId(2), latest known optime: { ts: Timestamp(1589027534, 135), t: 10 }
2020-05-09T05:32:17.920-0700 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InvalidSyncSource: sync source n1:27019 (config version: 1; last applied optime: { ts: Timestamp(1589027536, 2), t: 11 }; sync source index: -1; primary index: 0) is no longer valid
2020-05-09T05:32:17.920-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:32:17.922-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:32:17.926-0700 I  REPL     [rsSync-0] Caught up to the latest known optime successfully after becoming primary. Target optime: { ts: Timestamp(1589027537, 3), t: 11 }. My Last Applied: { ts: Timestamp(1589027537, 3), t: 11 }
2020-05-09T05:32:17.926-0700 I  REPL     [rsSync-0] Exited primary catch-up mode.
2020-05-09T05:32:17.926-0700 I  REPL     [rsSync-0] Stopping replication producer
2020-05-09T05:32:17.926-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 12
2020-05-09T05:32:17.926-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:17.926-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:17.926-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:17.926-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:17.927-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
2020-05-09T05:32:17.928-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:17.928-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:17.929-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:17.930-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:17.930-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:17.930-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:17.930-0700 I  NETWORK  [Balancer] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:17.931-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:17.932-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T05:32:17.932-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:17.935-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T05:32:18.420-0700 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to n1:27019: InvalidSyncSource: Sync source was cleared. Was n1:27019
2020-05-09T05:32:18.587-0700 I  COMMAND  [conn108] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027536, 2), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 527ms
2020-05-09T05:32:18.587-0700 I  COMMAND  [conn31] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n4:27017" }, u: { $set: { _id: "n4:27017", ping: new Date(1589027537377), up: 40, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027536, 2), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 522ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn35] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 4), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 525ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn105] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 4), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 525ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 5), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027536, 2), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1 } storage:{} protocol:op_msg 521ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn19] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 5), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 520ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn126] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 5), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 519ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn110] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n7:27017" }, u: { $set: { _id: "n7:27017", ping: new Date(1589027537376), up: 40, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027536, 2), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 206ms
2020-05-09T05:32:18.588-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn89] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n8:27017" }, u: { $set: { _id: "n8:27017", ping: new Date(1589027537377), up: 40, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027536, 2), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 528ms
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn88] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 5), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027534, 135), t: 10 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 523ms
2020-05-09T05:32:18.588-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:18.588-0700 I  COMMAND  [conn109] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027537, 3), signature: { hash: BinData(0, 2F346375240B52D03588B57DE59FCD41F8240AE4), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027536, 2), t: 11 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 522ms
2020-05-09T05:32:18.986-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48146 #146 (50 connections now open)
2020-05-09T05:32:18.986-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48150 #147 (51 connections now open)
2020-05-09T05:32:18.987-0700 I  NETWORK  [conn146] received client metadata from 192.168.122.1:48146 conn146: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:18.987-0700 I  NETWORK  [conn147] received client metadata from 192.168.122.1:48150 conn147: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:18.989-0700 I  NETWORK  [conn146] end connection 192.168.122.1:48146 (50 connections now open)
2020-05-09T05:32:18.990-0700 I  NETWORK  [conn147] end connection 192.168.122.1:48150 (49 connections now open)
2020-05-09T05:32:19.195-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:32:19.195-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:32:19.525-0700 I  COMMAND  [conn19] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n6:27017" }, u: { $set: { _id: "n6:27017", ping: new Date(1589027539254), up: 42, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027538, 175), signature: { hash: BinData(0, 8AAC69669D347F52FADAB4361BD384A07BF81441), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027537, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 269ms
2020-05-09T05:32:19.525-0700 I  COMMAND  [conn28] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "n9:27017" }, u: { $set: { _id: "n9:27017", ping: new Date(1589027539255), up: 42, waiting: true, mongoVersion: "4.2.6", advisoryHostFQDNs: [] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027539, 416), signature: { hash: BinData(0, 9A85AC69B79BCEBCF63190C03E94199320B55E5C), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027537, 5), t: 12 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 2 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 268ms
2020-05-09T05:32:19.595-0700 I  NETWORK  [listener] connection accepted from 192.168.122.11:54116 #150 (50 connections now open)
2020-05-09T05:32:19.595-0700 I  NETWORK  [conn150] received client metadata from 192.168.122.11:54116 conn150: { driver: { name: "NetworkInterfaceTL", version: "4.2.6" }, os: { type: "Linux", name: "PRETTY_NAME="Debian GNU/Linux 9 (stretch)"", architecture: "x86_64", version: "Kernel 5.6.0-1-amd64" } }
2020-05-09T05:32:19.606-0700 I  REPL     [conn150] stepping down from primary, because a new term has begun: 13
2020-05-09T05:32:19.606-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:19.606-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:19.606-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
2020-05-09T05:32:19.606-0700 I  REPL     [replexec-2] transition to SECONDARY from PRIMARY
2020-05-09T05:32:19.606-0700 I  SHARDING [Balancer] CSRS balancer is now stopped
2020-05-09T05:32:19.607-0700 I  ELECTION [conn150] Received vote request: { replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 13, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027539, 417), t: 12 } }
2020-05-09T05:32:19.607-0700 I  ELECTION [conn150] Sending vote response: { term: 13, voteGranted: true, reason: "" }
2020-05-09T05:32:19.607-0700 I  REPL     [rsBackgroundSync] could not find member to sync from
2020-05-09T05:32:19.622-0700 I  NETWORK  [conn120] end connection 192.168.122.11:53564 (49 connections now open)
2020-05-09T05:32:20.025-0700 I  NETWORK  [conn134] end connection 192.168.122.11:53834 (48 connections now open)
2020-05-09T05:32:20.108-0700 I  REPL     [replexec-3] Member n1:27019 is now in state PRIMARY
2020-05-09T05:32:20.607-0700 I  REPL     [rsBackgroundSync] sync source candidate: n1:27019
2020-05-09T05:32:20.609-0700 I  REPL     [rsBackgroundSync] Changed sync source from empty to n1:27019
2020-05-09T05:32:20.609-0700 I  CONNPOOL [RS] Connecting to n1:27019
2020-05-09T05:32:21.214-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48200 #152 (49 connections now open)
2020-05-09T05:32:21.214-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48206 #153 (50 connections now open)
2020-05-09T05:32:21.214-0700 I  NETWORK  [conn152] received client metadata from 192.168.122.1:48200 conn152: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:21.215-0700 I  NETWORK  [conn153] received client metadata from 192.168.122.1:48206 conn153: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:21.218-0700 I  NETWORK  [conn152] end connection 192.168.122.1:48200 (49 connections now open)
2020-05-09T05:32:21.218-0700 I  NETWORK  [conn153] end connection 192.168.122.1:48206 (48 connections now open)
2020-05-09T05:32:22.187-0700 I  ELECTION [replexec-2] Starting an election, since we've seen no PRIMARY in the past 1000ms
2020-05-09T05:32:22.187-0700 I  ELECTION [replexec-2] conducting a dry run election to see if we could be elected. current term: 13
2020-05-09T05:32:22.187-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1029 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027540, 105), t: 13 } }
2020-05-09T05:32:22.187-0700 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 1030 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: true, term: 13, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027540, 105), t: 13 } }
2020-05-09T05:32:22.188-0700 I  ELECTION [replexec-3] VoteRequester(term 13 dry run) received a yes vote from n3:27019; response message: { term: 13, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1589027540, 105), $clusterTime: { clusterTime: Timestamp(1589027540, 731), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027540, 105) }
2020-05-09T05:32:22.189-0700 I  ELECTION [replexec-3] dry election run succeeded, running for election in term 14
2020-05-09T05:32:22.189-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:22.195-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1031 -- target:n1:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027540, 105), t: 13 } }
2020-05-09T05:32:22.195-0700 I  REPL     [replexec-0] Scheduling remote command request for vote request: RemoteCommand 1032 -- target:n3:27019 db:admin cmd:{ replSetRequestVotes: 1, setName: "rs_config", dryRun: false, term: 14, candidateIndex: 1, configVersion: 1, lastCommittedOp: { ts: Timestamp(1589027540, 105), t: 13 } }
2020-05-09T05:32:22.200-0700 I  ELECTION [replexec-2] VoteRequester(term 14) received a yes vote from n3:27019; response message: { term: 14, voteGranted: true, reason: "", ok: 1.0, $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('7fffffff000000000000000a') }, lastCommittedOpTime: Timestamp(1589027540, 105), $clusterTime: { clusterTime: Timestamp(1589027540, 731), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1589027540, 105) }
2020-05-09T05:32:22.200-0700 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 14
2020-05-09T05:32:22.200-0700 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
2020-05-09T05:32:22.200-0700 I  REPL     [replexec-2] Resetting sync source to empty, which was n1:27019
2020-05-09T05:32:22.200-0700 I  CONNPOOL [Replication] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 0 connections to that host remain open
2020-05-09T05:32:22.200-0700 I  REPL     [replexec-2] Entering primary catch-up mode.
2020-05-09T05:32:22.200-0700 I  CONNPOOL [Replication] Connecting to n1:27019
2020-05-09T05:32:23.200-0700 I  REPL     [replexec-2] Catchup timed out after becoming primary.
2020-05-09T05:32:23.200-0700 I  REPL     [replexec-2] Exited primary catch-up mode.
2020-05-09T05:32:23.200-0700 I  REPL     [replexec-2] Stopping replication producer
2020-05-09T05:32:23.200-0700 I  REPL     [replexec-4] Member n1:27019 is now in state RS_DOWN - no response within election timeout period
2020-05-09T05:32:23.200-0700 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
2020-05-09T05:32:23.200-0700 I  CONNPOOL [RS] Ending connection to host n1:27019 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
2020-05-09T05:32:23.200-0700 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 14
2020-05-09T05:32:23.201-0700 I  REPL     [RstlKillOpThread] Starting to kill user operations
2020-05-09T05:32:23.201-0700 I  REPL     [RstlKillOpThread] Stopped killing user operations
2020-05-09T05:32:23.201-0700 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 1 }
2020-05-09T05:32:23.203-0700 I  TXN      [rsSync-0] Waiting for coordinator tasks from previous term to complete
2020-05-09T05:32:23.203-0700 I  SHARDING [Balancer] CSRS balancer is starting
2020-05-09T05:32:23.204-0700 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2020-05-09T05:32:23.205-0700 I  SHARDING [Balancer] CSRS balancer thread is recovering
2020-05-09T05:32:23.205-0700 I  SHARDING [Balancer] CSRS balancer thread is recovered
2020-05-09T05:32:23.208-0700 W  QUERY    [conn33] GetMore command executor error: FAILURE, status: CappedPositionLost: CollectionScan died due to failure to restore tailable cursor position. Last seen record id: RecordId(6824821329628233729), stats: { stage: "COLLSCAN", nReturned: 7, executionTimeMillisEstimate: 0, works: 36, advanced: 7, needTime: 14, needYield: 0, saveState: 14, restoreState: 14, isEOF: 0, direction: "forward", docsExamined: 7 }
2020-05-09T05:32:24.202-0700 I  COMMAND  [conn89] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027542, 9), signature: { hash: BinData(0, D123CB6B2CFDFC2EF000941F5862578384D0AA27), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027540, 105), t: 13 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 942ms
2020-05-09T05:32:24.202-0700 I  COMMAND  [conn108] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027542, 9), signature: { hash: BinData(0, D123CB6B2CFDFC2EF000941F5862578384D0AA27), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027540, 105), t: 13 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 249ms
2020-05-09T05:32:24.202-0700 I  COMMAND  [conn110] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027543, 2), signature: { hash: BinData(0, 81FDB6B7908B432F0A36F987D8BDFE7545232743), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027540, 105), t: 13 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 2 } storage:{} protocol:op_msg 249ms
2020-05-09T05:32:24.202-0700 I  TXN      [TransactionCoordinator] Need to resume coordinating commit for 0 transactions
2020-05-09T05:32:24.202-0700 I  TXN      [TransactionCoordinator] Incoming coordinateCommit requests are now enabled
2020-05-09T05:32:24.202-0700 I  COMMAND  [conn28] command config.$cmd command: update { update: "shards", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "rs_shard2" }, u: { $set: { host: "rs_shard2/n7:27018,n8:27018,n9:27018" } }, multi: false, upsert: false } ], writeConcern: { w: "majority", wtimeout: 60000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1589027542, 9), signature: { hash: BinData(0, D123CB6B2CFDFC2EF000941F5862578384D0AA27), keyId: 6824821114879868942 } }, $configServerState: { opTime: { ts: Timestamp(1589027540, 105), t: 13 } }, $db: "config" } numYields:0 reslen:587 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } }, Database: { acquireCount: { w: 1 } }, Collection: { acquireCount: { w: 1 } }, Mutex: { acquireCount: { r: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 1 } storage:{} protocol:op_msg 251ms
