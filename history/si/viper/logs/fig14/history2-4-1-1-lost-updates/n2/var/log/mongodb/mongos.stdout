2020-05-09 05:31:35 Jepsen starting /usr/bin/mongos --config /etc/mongos.conf
2020-05-09T05:31:35.258-0700 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] 
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] ** WARNING: Access control is not enabled for the database.
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] **          Read and write access to data and configuration is unrestricted.
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] ** WARNING: You are running this process as the root user, which is not recommended.
2020-05-09T05:31:35.263-0700 I  CONTROL  [main] 
2020-05-09T05:31:35.263-0700 I  SHARDING [mongosMain] mongos version v4.2.6
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] db version v4.2.6
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] git version: 20364840b8f1af16917e4c23c1b5f5efd8b352f8
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] allocator: tcmalloc
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] modules: none
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] build environment:
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain]     distmod: debian92
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain]     distarch: x86_64
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain]     target_arch: x86_64
2020-05-09T05:31:35.263-0700 I  CONTROL  [mongosMain] options: { config: "/etc/mongos.conf", net: { bindIp: "0.0.0.0" }, sharding: { configDB: "rs_config/n1:27019,n2:27019,n3:27019" } }
2020-05-09T05:31:35.264-0700 I  NETWORK  [mongosMain] Starting new replica set monitor for rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:35.264-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n1:27019
2020-05-09T05:31:35.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n3:27019
2020-05-09T05:31:35.265-0700 I  SHARDING [thread1] creating distributed lock ping thread for process n2:27017:1589027495:3135941772378158776 (sleeping for 30000ms)
2020-05-09T05:31:35.265-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n2:27019
2020-05-09T05:31:35.267-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:35.267-0700 I  SHARDING [Sharding-Fixed-0] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:31:36.068-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(0, 0), t: -1 }, now { ts: Timestamp(1589027495, 9), t: 2 }
2020-05-09T05:31:36.069-0700 W  SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2020-05-09T05:31:38.069-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:31:38.072-0700 W  FTDC     [mongosMain] FTDC is disabled because neither '--logpath' nor set parameter 'diagnosticDataCollectionDirectoryPath' are specified.
2020-05-09T05:31:38.073-0700 I  FTDC     [mongosMain] Initializing full-time diagnostic data capture with directory ''
2020-05-09T05:31:38.075-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config from version {} to version { uuid: UUID("ccf944a8-53d3-425d-9439-ecaf3d850996"), lastMod: 0 } took 0 ms
2020-05-09T05:31:38.075-0700 I  NETWORK  [listener] Listening on /tmp/mongodb-27017.sock
2020-05-09T05:31:38.075-0700 I  NETWORK  [listener] Listening on 0.0.0.0
2020-05-09T05:31:38.075-0700 I  NETWORK  [listener] waiting for connections on port 27017
2020-05-09T05:31:38.075-0700 I  CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: Collection config.system.sessions is not sharded.
2020-05-09T05:31:38.075-0700 I  CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Collection config.system.sessions is not sharded.
2020-05-09T05:31:38.321-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47408 #9 (1 connection now open)
2020-05-09T05:31:38.322-0700 I  NETWORK  [conn9] end connection 192.168.122.1:47408 (0 connections now open)
2020-05-09T05:31:39.326-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47420 #10 (1 connection now open)
2020-05-09T05:31:39.327-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47428 #11 (2 connections now open)
2020-05-09T05:31:39.327-0700 I  NETWORK  [conn10] received client metadata from 192.168.122.1:47420 conn10: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:39.328-0700 I  NETWORK  [conn11] received client metadata from 192.168.122.1:47428 conn11: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:41.312-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47562 #12 (3 connections now open)
2020-05-09T05:31:41.312-0700 I  NETWORK  [conn12] received client metadata from 192.168.122.1:47562 conn12: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:41.314-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47572 #13 (4 connections now open)
2020-05-09T05:31:41.315-0700 I  NETWORK  [conn13] received client metadata from 192.168.122.1:47572 conn13: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:43.382-0700 I  COMMAND  [conn12] command jepsendb command: enableSharding { enableSharding: "jepsendb", $db: "admin", $clusterTime: { clusterTime: Timestamp(1589027498, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("c0a6c99a-170e-4888-a626-445b861ea469") } } numYields:0 reslen:163 protocol:op_msg 2059ms
2020-05-09T05:31:43.386-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database jepsendb from version {} to version { uuid: UUID("953d62b5-374e-4f3b-94a4-02bad1e2f449"), lastMod: 1 } took 1 ms
2020-05-09T05:31:43.389-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:43.389-0700 I  NETWORK  [conn12] Starting new replica set monitor for rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:43.389-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n4:27018
2020-05-09T05:31:43.389-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n5:27018
2020-05-09T05:31:43.389-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n6:27018
2020-05-09T05:31:43.389-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n9:27018
2020-05-09T05:31:43.389-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n7:27018
2020-05-09T05:31:43.389-0700 I  CONNPOOL [ReplicaSetMonitor-TaskExecutor] Connecting to n8:27018
2020-05-09T05:31:43.393-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:43.393-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:31:43.394-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:43.395-0700 I  SHARDING [Sharding-Fixed-1] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:43.511-0700 I  NETWORK  [conn12] end connection 192.168.122.1:47562 (3 connections now open)
2020-05-09T05:31:43.511-0700 I  NETWORK  [conn13] end connection 192.168.122.1:47572 (2 connections now open)
2020-05-09T05:31:51.984-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47752 #20 (3 connections now open)
2020-05-09T05:31:51.985-0700 I  NETWORK  [conn20] received client metadata from 192.168.122.1:47752 conn20: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.986-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47768 #21 (4 connections now open)
2020-05-09T05:31:51.986-0700 I  NETWORK  [conn21] received client metadata from 192.168.122.1:47768 conn21: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.998-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47816 #22 (5 connections now open)
2020-05-09T05:31:51.998-0700 I  NETWORK  [conn22] received client metadata from 192.168.122.1:47816 conn22: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:51.999-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47830 #23 (6 connections now open)
2020-05-09T05:31:51.999-0700 I  NETWORK  [conn23] received client metadata from 192.168.122.1:47830 conn23: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.000-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47836 #24 (7 connections now open)
2020-05-09T05:31:52.000-0700 I  NETWORK  [conn24] received client metadata from 192.168.122.1:47836 conn24: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.001-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:47844 #25 (8 connections now open)
2020-05-09T05:31:52.001-0700 I  NETWORK  [conn25] received client metadata from 192.168.122.1:47844 conn25: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:31:52.023-0700 I  SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for collection jepsendb.jepsencoll to version 1|6||5eb6a2aeecc1ba4072ee52e8 took 1 ms
2020-05-09T05:31:52.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n7:27018
2020-05-09T05:31:52.097-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:53.071-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n8:27018
2020-05-09T05:31:53.097-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:31:53.097-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:31:55.631-0700 I  NETWORK  [conn23] Marking host n7:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:31:55.632-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:55.635-0700 I  SHARDING [conn20] Received reply from shard n4:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027511, 20), t: 2 }, now { ts: Timestamp(1589027514, 1), t: 3 }
2020-05-09T05:31:55.650-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:56.132-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:31:56.632-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:56.632-0700 I  SHARDING [Sharding-Fixed-3] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:31:56.633-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n9:27018
2020-05-09T05:31:56.634-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 549, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027515, 1852) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1032623, timeInactiveMicros:0, 1032ms
2020-05-09T05:31:56.634-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("ef85a771-3a17-4349-9f15-bff95bdd2b05"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 435, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027515, 1851) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1032991, timeInactiveMicros:0, 1032ms
2020-05-09T05:31:56.634-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1852), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15") }, txnNumber: 549, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027515, 1852) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1032ms
2020-05-09T05:31:56.634-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1851), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef85a771-3a17-4349-9f15-bff95bdd2b05") }, txnNumber: 435, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027515, 1851) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1033ms
2020-05-09T05:31:56.769-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 655, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1119462, timeInactiveMicros:0, 1119ms
2020-05-09T05:31:56.769-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 593 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027515, 1917), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48") }, txnNumber: 655, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 7eea782b-5bbc-49af-a641-58746afe6a48:655 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1119ms
2020-05-09T05:31:56.770-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 550, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027516, 11) } }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:131229, timeInactiveMicros:0, 131ms
2020-05-09T05:31:56.770-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027516, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15") }, txnNumber: 550, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027516, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction e334ba7d-8112-44e1-aeb4-69f7f56b8a15:550 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 131ms
2020-05-09T05:31:56.770-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("ef85a771-3a17-4349-9f15-bff95bdd2b05"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 436, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027516, 11) } }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:131756, timeInactiveMicros:0, 131ms
2020-05-09T05:31:56.770-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027516, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef85a771-3a17-4349-9f15-bff95bdd2b05") }, txnNumber: 436, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027516, 11) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction ef85a771-3a17-4349-9f15-bff95bdd2b05:436 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n9:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 132ms
2020-05-09T05:31:57.097-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n6:27018
2020-05-09T05:31:57.097-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n5:27018
2020-05-09T05:31:57.192-0700 I  NETWORK  [conn23] Marking host n4:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:31:57.193-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:57.204-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:57.219-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027514, 1), t: 3 }, now { ts: Timestamp(1589027516, 2), t: 4 }
2020-05-09T05:31:57.692-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:58.192-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:58.692-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:59.192-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:31:59.692-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:00.192-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:00.692-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:00.692-0700 I  SHARDING [Sharding-Fixed-2] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:00.693-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027518, 3), t: 4 }, now { ts: Timestamp(1589027520, 1), t: 5 }
2020-05-09T05:32:00.693-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:00.693-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:00.694-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:00.694-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 709, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027517, 381) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:3527728, timeInactiveMicros:0, 3527ms
2020-05-09T05:32:00.694-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 381), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48") }, txnNumber: 709, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027517, 381) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 3527ms
2020-05-09T05:32:01.493-0700 I  NETWORK  [conn23] Marking host n6:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:01.494-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:01.495-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:01.498-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:01.994-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:01.994-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:01.995-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 710, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027520, 10) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1297234, timeInactiveMicros:0, 1297ms
2020-05-09T05:32:01.995-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 652, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:4791696, timeInactiveMicros:0, 4791ms
2020-05-09T05:32:01.996-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 419), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15") }, txnNumber: 652, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 4792ms
2020-05-09T05:32:01.996-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027520, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48") }, txnNumber: 710, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027520, 10) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n6:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1297ms
2020-05-09T05:32:02.165-0700 I  NETWORK  [conn21] end connection 192.168.122.1:47768 (7 connections now open)
2020-05-09T05:32:02.167-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48776 #52 (8 connections now open)
2020-05-09T05:32:02.168-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48778 #53 (9 connections now open)
2020-05-09T05:32:02.168-0700 I  NETWORK  [conn52] received client metadata from 192.168.122.1:48776 conn52: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.168-0700 I  NETWORK  [conn53] received client metadata from 192.168.122.1:48778 conn53: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.170-0700 I  CONNPOOL [TaskExecutorPool-0] Connecting to n4:27018
2020-05-09T05:32:02.189-0700 I  NETWORK  [conn25] end connection 192.168.122.1:47844 (8 connections now open)
2020-05-09T05:32:02.189-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48802 #55 (9 connections now open)
2020-05-09T05:32:02.190-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48804 #56 (10 connections now open)
2020-05-09T05:32:02.190-0700 I  NETWORK  [conn55] received client metadata from 192.168.122.1:48802 conn55: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.190-0700 I  NETWORK  [conn56] received client metadata from 192.168.122.1:48804 conn56: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.191-0700 I  -        [conn23] operation was interrupted because a client disconnected
2020-05-09T05:32:02.191-0700 I  CONNPOOL [conn23] Ending connection to host n4:27018 due to bad connection status: InternalError: Connection is in an unknown state; 3 connections to that host remain open
2020-05-09T05:32:02.192-0700 I  TXN      [conn23] transaction parameters:{ lsid: { id: UUID("ef85a771-3a17-4349-9f15-bff95bdd2b05"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 498, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:ClientDisconnect, timeActiveMicros:5003994, timeInactiveMicros:0, 5003ms
2020-05-09T05:32:02.192-0700 I  COMMAND  [conn23] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 650 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027517, 416), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("ef85a771-3a17-4349-9f15-bff95bdd2b05") }, txnNumber: 498, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered non-retryable error during query :: caused by :: operation was interrupted" errName:ClientDisconnect errCode:279 reslen:303 protocol:op_msg 5004ms
2020-05-09T05:32:02.192-0700 I  NETWORK  [conn55] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:02.192-0700 I  NETWORK  [conn23] end connection 192.168.122.1:47830 (9 connections now open)
2020-05-09T05:32:02.193-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.206-0700 I  NETWORK  [conn24] end connection 192.168.122.1:47836 (8 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48814 #57 (9 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:48816 #58 (10 connections now open)
2020-05-09T05:32:02.207-0700 I  NETWORK  [conn57] received client metadata from 192.168.122.1:48814 conn57: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.207-0700 I  NETWORK  [conn58] received client metadata from 192.168.122.1:48816 conn58: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:02.212-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.425-0700 I  NETWORK  [conn22] Marking host n4:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:02.426-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.429-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.493-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:02.693-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:02.993-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:03.193-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:03.493-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:03.693-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:03.694-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:03.695-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:03.696-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:03.696-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:03.757-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027520, 1), t: 5 }, now { ts: Timestamp(1589027522, 12), t: 6 }
2020-05-09T05:32:03.993-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:04.493-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:04.494-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:04.496-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2325769, timeInactiveMicros:0, 2325ms
2020-05-09T05:32:04.496-0700 I  TXN      [conn20] transaction parameters:{ lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 711, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027521, 6) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2495548, timeInactiveMicros:0, 2495ms
2020-05-09T05:32:04.496-0700 I  TXN      [conn22] transaction parameters:{ lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 653, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027521, 6) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:2494993, timeInactiveMicros:0, 2494ms
2020-05-09T05:32:04.496-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027521, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 1, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2326ms
2020-05-09T05:32:04.496-0700 I  COMMAND  [conn20] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027521, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("7eea782b-5bbc-49af-a641-58746afe6a48") }, txnNumber: 711, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027521, 6) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2495ms
2020-05-09T05:32:04.496-0700 I  COMMAND  [conn22] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027521, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("e334ba7d-8112-44e1-aeb4-69f7f56b8a15") }, txnNumber: 653, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027521, 6) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n4:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 2495ms
2020-05-09T05:32:04.497-0700 I  NETWORK  [conn20] end connection 192.168.122.1:47752 (9 connections now open)
2020-05-09T05:32:04.497-0700 I  NETWORK  [conn22] end connection 192.168.122.1:47816 (8 connections now open)
2020-05-09T05:32:04.594-0700 I  NETWORK  [conn52] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:04.596-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:05.096-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:05.595-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:05.595-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:05.596-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 3, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1078539, timeInactiveMicros:0, 1078ms
2020-05-09T05:32:05.596-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027524, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 3, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1078ms
2020-05-09T05:32:05.691-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 651 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027522, 11), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 1, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:319 protocol:op_msg 3478ms
2020-05-09T05:32:05.691-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 646 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027521, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 1, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 3499ms
2020-05-09T05:32:05.692-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:983, timeActiveMicros:3479849, timeInactiveMicros:451, 3480ms
2020-05-09T05:32:05.693-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 1, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1057, timeActiveMicros:3501062, timeInactiveMicros:716, 3501ms
2020-05-09T05:32:06.446-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 98, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027526, 552) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:105619, timeInactiveMicros:0, 105ms
2020-05-09T05:32:06.447-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027526, 552), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 98, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027526, 552) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 105ms
2020-05-09T05:32:06.912-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:06.912-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:06.912-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:07.136-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:07.136-0700 I  CONNPOOL [ShardRegistry] Connecting to n2:27019
2020-05-09T05:32:07.375-0700 I  SHARDING [conn57] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027522, 12), t: 6 }, now { ts: Timestamp(1589027527, 851), t: 7 }
2020-05-09T05:32:07.801-0700 I  CONNPOOL [ShardRegistry] Connecting to n7:27018
2020-05-09T05:32:08.074-0700 I  ACCESS   [UserCacheInvalidator] User cache generation changed from 5eb6a2a233caaefe806e3e97 to 5eb6a2a56cd5bebe167d1938; invalidating user cache
2020-05-09T05:32:08.156-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:08.700-0700 I  NETWORK  [conn52] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:08.700-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:08.703-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:08.724-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:09.088-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:09.088-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:09.201-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:09.201-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:10.082-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027527, 851), t: 7 }, now { ts: Timestamp(1589027529, 4), t: 8 }
2020-05-09T05:32:10.594-0700 I  NETWORK  [conn57] Marking host n9:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:10.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:10.596-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:11.096-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:11.595-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:12.095-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:12.095-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:12.096-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n1:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:12.096-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1114 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1575), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 578, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 3397ms
2020-05-09T05:32:12.096-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 474, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3394589, timeInactiveMicros:0, 3394ms
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1114 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1588), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 571, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:308 protocol:op_msg 3372ms
2020-05-09T05:32:12.097-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027528, 1578), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 474, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n9:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3394ms
2020-05-09T05:32:12.097-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:12.098-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 571, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:820, timeActiveMicros:3373807, timeInactiveMicros:634, 3374ms
2020-05-09T05:32:12.098-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 578, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1144, timeActiveMicros:3399149, timeInactiveMicros:714, 3399ms
2020-05-09T05:32:12.103-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:12.104-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:12.104-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:12.104-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_config
2020-05-09T05:32:12.597-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:12.597-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:13.936-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:14.026-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 581, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027532, 70) } }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1919644, timeInactiveMicros:0, 1919ms
2020-05-09T05:32:14.026-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 70), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 581, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027532, 70) }, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a5ac5676-f202-4661-980a-de6a757288e5:581 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 1919ms
2020-05-09T05:32:14.028-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 483, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1900679, timeInactiveMicros:0, 1900ms
2020-05-09T05:32:14.028-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 92), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 483, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 758d9ae3-26af-4183-b702-830d6102502d:483 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n5:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 1900ms
2020-05-09T05:32:14.028-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 573, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:1925449, timeInactiveMicros:0, 1925ms
2020-05-09T05:32:14.028-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1117 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027532, 68), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 573, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 39381f11-c86c-40f7-93f3-2ca3ff551686:573 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 1925ms
2020-05-09T05:32:14.029-0700 I  CONNPOOL [ShardRegistry] Connecting to n3:27019
2020-05-09T05:32:14.036-0700 I  CONNPOOL [ShardRegistry] Connecting to n5:27018
2020-05-09T05:32:14.042-0700 I  NETWORK  [conn52] Marking host n9:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:14.043-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:14.044-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:14.402-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1118 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 43), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 575, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 357ms
2020-05-09T05:32:14.402-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1122 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 39), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 485, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 358ms
2020-05-09T05:32:14.404-0700 I  SHARDING [conn57] Received reply from shard n7:27018 node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027530, 2), t: 8 }, now { ts: Timestamp(1589027534, 135), t: 10 }
2020-05-09T05:32:14.404-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 575, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2034, timeActiveMicros:359997, timeInactiveMicros:741, 360ms
2020-05-09T05:32:14.405-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 485, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:2156, timeActiveMicros:360595, timeInactiveMicros:829, 361ms
2020-05-09T05:32:14.406-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 584, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027534, 50) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:358889, timeInactiveMicros:0, 358ms
2020-05-09T05:32:14.406-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 50), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 584, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027534, 50) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 359ms
2020-05-09T05:32:14.784-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:14.784-0700 I  SHARDING [Sharding-Fixed-4] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:15.028-0700 I  NETWORK  [conn52] Marking host n5:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:32:15.029-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard1
2020-05-09T05:32:15.528-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:15.528-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:15.529-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 586, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027534, 1538) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:554476, timeInactiveMicros:0, 554ms
2020-05-09T05:32:15.529-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 694, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027534, 1570) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:539279, timeInactiveMicros:0, 539ms
2020-05-09T05:32:15.529-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 1538), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 586, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027534, 1538) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 554ms
2020-05-09T05:32:15.529-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 1571), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 694, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027534, 1570) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n5:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 539ms
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027535, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 695, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027535, 13) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 521ms
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027535, 13), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 587, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027535, 13) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 521ms
2020-05-09T05:32:16.055-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1214 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027534, 1571), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 685, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:297 protocol:op_msg 1065ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 695, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027535, 13) } }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1550, timeActiveMicros:523260, timeInactiveMicros:600, 523ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 587, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027535, 13) } }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1708, timeActiveMicros:523419, timeInactiveMicros:602, 524ms
2020-05-09T05:32:16.057-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 685, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:1349, timeActiveMicros:1066547, timeInactiveMicros:500, 1067ms
2020-05-09T05:32:16.059-0700 I  NETWORK  [conn52] Marking host n7:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:16.060-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.064-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.069-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:16.559-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.059-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:17.559-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:18.060-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.060-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:18.061-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n3:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:18.062-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:18.062-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:18.588-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027534, 135), t: 10 }, now { ts: Timestamp(1589027537, 5), t: 12 }
2020-05-09T05:32:18.607-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 697, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2543465, timeInactiveMicros:0, 2543ms
2020-05-09T05:32:18.607-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1213 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 37), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 697, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 39381f11-c86c-40f7-93f3-2ca3ff551686:697 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 2543ms
2020-05-09T05:32:18.608-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 591, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2539151, timeInactiveMicros:0, 2539ms
2020-05-09T05:32:18.608-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 58), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 591, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction 758d9ae3-26af-4183-b702-830d6102502d:591 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: Encountered error from n8:27018 during a transaction :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:697 protocol:op_msg 2539ms
2020-05-09T05:32:18.609-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 686, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:StaleConfig, timeActiveMicros:2550708, timeInactiveMicros:0, 2550ms
2020-05-09T05:32:18.609-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1176 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027536, 19), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 686, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Transaction a5ac5676-f202-4661-980a-de6a757288e5:686 was aborted on statement 0 due to: an error from cluster data placement change :: caused by :: epoch mismatch detected for jepsendb.jepsencoll, the collection may have been dropped and recreated" errName:StaleConfig errCode:13388 reslen:628 protocol:op_msg 2550ms
2020-05-09T05:32:18.636-0700 I  CONNPOOL [ShardRegistry] Connecting to n8:27018
2020-05-09T05:32:18.680-0700 I  NETWORK  [conn52] Marking host n4:27018 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:18.681-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard1 is rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:18.681-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard1/n4:27018,n5:27018,n6:27018
2020-05-09T05:32:20.087-0700 I  NETWORK  [UpdateReplicaSetOnConfigServer] Marking host n2:27019 as failed :: caused by :: NotMaster: not master
2020-05-09T05:32:20.088-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_config is rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:20.088-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_config/n1:27019,n2:27019,n3:27019
2020-05-09T05:32:20.630-0700 I  SHARDING [ShardRegistry] Received reply from config server node (unknown) indicating config server optime term has increased, previous optime { ts: Timestamp(1589027539, 417), t: 12 }, now { ts: Timestamp(1589027540, 105), t: 13 }
2020-05-09T05:32:20.754-0700 I  NETWORK  [conn57] Marking host n8:27018 as failed :: caused by :: NotMaster: Not primary so we cannot begin or continue a transaction
2020-05-09T05:32:20.755-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:21.256-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:21.755-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:22.256-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:22.256-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:22.257-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 876, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027540, 709) } }, numParticipants:1, terminationCause:aborted, abortCause:NotMaster, timeActiveMicros:1570870, timeInactiveMicros:0, 1570ms
2020-05-09T05:32:22.258-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027540, 710), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 876, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027540, 709) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: Not primary so we cannot begin or continue a transaction" errName:NotMaster errCode:10107 reslen:386 protocol:op_msg 1571ms
2020-05-09T05:32:22.949-0700 I  NETWORK  [conn52] Marking host n7:27018 as failed :: caused by :: InterruptedDueToReplStateChange: operation was interrupted
2020-05-09T05:32:22.951-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:22.952-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:23.450-0700 W  NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set rs_shard2
2020-05-09T05:32:23.950-0700 I  NETWORK  [ReplicaSetMonitor-TaskExecutor] Confirmed replica set for rs_shard2 is rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:23.951-0700 I  SHARDING [UpdateReplicaSetOnConfigServer] Updating sharding state with confirmed set rs_shard2/n7:27018,n8:27018,n9:27018
2020-05-09T05:32:23.952-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 976, autocommit: false }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:3197705, timeInactiveMicros:0, 3197ms
2020-05-09T05:32:23.952-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 877, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027542, 8) } }, numParticipants:1, terminationCause:aborted, abortCause:InterruptedDueToReplStateChange, timeActiveMicros:1692326, timeInactiveMicros:0, 1692ms
2020-05-09T05:32:23.953-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027540, 738), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 976, startTransaction: true, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 3197ms
2020-05-09T05:32:23.953-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027542, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 877, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027542, 8) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n7:27018 during a transaction :: caused by :: operation was interrupted" errName:InterruptedDueToReplStateChange errCode:11602 reslen:377 protocol:op_msg 1692ms
2020-05-09T05:32:24.099-0700 I  COMMAND  [conn52] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027543, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5") }, txnNumber: 977, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027543, 7) }, autocommit: false } nShards:1 nMatched:1 nModified:1 numYields:0 reslen:236 protocol:op_msg 143ms
2020-05-09T05:32:24.099-0700 I  COMMAND  [conn57] command jepsendb.jepsencoll command: find { find: "jepsencoll", filter: { _id: 1380 }, limit: 1, singleBatch: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027540, 731), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686") }, txnNumber: 969, startTransaction: true, autocommit: false } nShards:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:330 protocol:op_msg 3390ms
2020-05-09T05:32:24.100-0700 I  TXN      [conn55] transaction parameters:{ lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 878, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027543, 14) } }, numParticipants:1, terminationCause:aborted, abortCause:WriteConflict, timeActiveMicros:143052, timeInactiveMicros:0, 143ms
2020-05-09T05:32:24.100-0700 I  COMMAND  [conn55] command jepsendb.jepsencoll command: update { update: "jepsencoll", ordered: true, $db: "jepsendb", $clusterTime: { clusterTime: Timestamp(1589027543, 14), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, lsid: { id: UUID("758d9ae3-26af-4183-b702-830d6102502d") }, txnNumber: 878, startTransaction: true, readConcern: { afterClusterTime: Timestamp(1589027543, 14) }, autocommit: false } numYields:0 ok:0 errMsg:"Encountered error from n8:27018 during a transaction :: caused by :: WriteConflict" errName:WriteConflict errCode:112 reslen:347 protocol:op_msg 143ms
2020-05-09T05:32:24.100-0700 I  TXN      [conn57] transaction parameters:{ lsid: { id: UUID("39381f11-c86c-40f7-93f3-2ca3ff551686"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 969, autocommit: false }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:856, timeActiveMicros:3390966, timeInactiveMicros:527, 3391ms
2020-05-09T05:32:24.100-0700 I  TXN      [conn52] transaction parameters:{ lsid: { id: UUID("a5ac5676-f202-4661-980a-de6a757288e5"), uid: BinData(0, E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855) }, txnNumber: 977, autocommit: false, readConcern: { afterClusterTime: Timestamp(1589027543, 7) } }, numParticipants:1, terminationCause:committed, commitType:singleShard, commitDurationMicros:933, timeActiveMicros:144264, timeInactiveMicros:529, 144ms
2020-05-09T05:32:24.134-0700 I  NETWORK  [conn52] end connection 192.168.122.1:48776 (7 connections now open)
2020-05-09T05:32:24.134-0700 I  NETWORK  [conn57] end connection 192.168.122.1:48814 (6 connections now open)
2020-05-09T05:32:24.134-0700 I  NETWORK  [conn55] end connection 192.168.122.1:48802 (5 connections now open)
2020-05-09T05:32:24.135-0700 I  NETWORK  [conn58] end connection 192.168.122.1:48816 (4 connections now open)
2020-05-09T05:32:24.135-0700 I  NETWORK  [conn56] end connection 192.168.122.1:48804 (3 connections now open)
2020-05-09T05:32:24.136-0700 I  NETWORK  [conn53] end connection 192.168.122.1:48778 (2 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49744 #70 (3 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [listener] connection accepted from 192.168.122.1:49746 #71 (4 connections now open)
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn70] received client metadata from 192.168.122.1:49744 conn70: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn71] received client metadata from 192.168.122.1:49746 conn71: { driver: { name: "mongo-java-driver|sync", version: "4.0.2" }, os: { type: "Linux", name: "Linux", architecture: "amd64", version: "5.6.0-1-amd64" }, platform: "Java/Oracle Corporation/1.8.0_40-b25" }
2020-05-09T05:32:24.142-0700 I  NETWORK  [conn71] end connection 192.168.122.1:49746 (3 connections now open)
2020-05-09T05:32:24.143-0700 I  NETWORK  [conn70] end connection 192.168.122.1:49744 (2 connections now open)
